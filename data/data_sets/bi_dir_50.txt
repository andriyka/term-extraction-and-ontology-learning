Extending Temporal Reasoning with Hierarchical Constraints Fei Song Dept.
of Computing and Information Science University of Guelph Guelph, Ontario, Canada N1G 2W1 Abstract Existing reasoning algorithms for Allen's interval algebra may produce weak results when applied to temporal networks that involve decompositions of intervals.
We present a strengthened procedure for reasoning about such hierarchical constraints, which works interactively with an existing algorithm for temporal reasoning, to produce the desired stronger results.
We further apply our algorithm to the process of plan recognition and show that such an application can both reduce the number of candidate plans and make the constraints in the remaining plans more specific.
1.
Introduction Allen's (1983a) interval algebra has shown to be useful for such applications as knowledge-based systems, natural language processing, and planning (as described in Vilain, et al., 1989).
For example, a simplified plan for making a pasta dish can be represented as the temporal network in figure 1, where a node corresponds to the time interval over which a state holds or an event occurs, and a link label represents the temporal constraint between two intervals1.
InKitchen  Includes  Meets Make Pasta Dish  Includes Includes  Includes Includes  Make BeforeMeets Noodles Make Sauce  Ready ToEat  Boil BeforeMeets Put Noodles Together BeforeMeets  Figure 1: Temporal network of a cooking plan 1 Here, "Includes" and "BeforeMeets" are high-level  constraints, defined as the sets {si, di, fi, eq} and {b, m}, where b, m, eq are the basic relations "before", "meets", "equal", and si, di, fi are the inverses of "starts", "during", and "finishes" in Allen's interval algebra.
Given a temporal network, an important reasoning task is to compute the so-called minimal labeling, that is, to find the set of minimal constraints if the network is consistent (Vilain and Kautz, 1986).
A constraint (or a link label) is minimal if each of its basic relations is part of a consistent singleton labeling, for which each link is labeled by a basic relation and all the links in the network are satisfied.
Vilain and Kautz (1986) show that the time complexity of such a reasoning task is NP-complete for the interval algebra, where the problem size is the number of intervals.
However, this does not prevent people from proposing polynomial algorithms that are approximate for the interval algebra (Allen 1983; Van Beek 1989).
Allen's algorithm has O(n3 ) time complexity and is shown to be exact only for a subset of the interval algebra (Van Beek 1989).
Van Beek then proposes an O(n4 ) algorithm which is exact for a larger subset (the subset of the interval algebra that can be translated into the point algebra).
To get more exact results for the full interval algebra, one may have to use some exponential-time algorithms (e.g., Valdes-Perez 1987).
One problem with these existing algorithms is that they may produce weak results when applied to temporal networks that involve hierarchical constraints (i.e.
the decompositions of intervals into low-level subintervals).
In Song and Cohen (1991), we proposed a strengthened algorithm for temporal reasoning about hierarchical constraints.
The algorithm guarantees that the result is no weaker than that obtained from the existing temporal reasoning algorithms.
However, whether it can derive the minimal labeling for the hierarchical constraints depends on the order in which lower-level constraints are combined.
In this paper, we present a new order-independent reasoning procedure for hierarchical constraints, along with formal proofs for its associated properties.
We further apply our  algorithm to the problem of plan recognition, and show that the observed temporal constraints can both reduce the number of candidate plans and make the constraints in the remaining candidate plans more specific.
2.
Weak results from the existing algorithms A hierarchical constraint corresponds to the decomposition of an interval to a set of subintervals.
In terms of Allen's interval algebra, this means that the interval temporally includes all the subintervals.
Suppose that initially there is no specific constraint between a1 and a2 in figure 2(a).
Then, all we can decide is that A Includes a1 and A Includes a2, where Includes stands for the constraint {si, di, fi, eq}.
(a) Includes  {si,di}  a1  A  {b}  A1  Includes  a1  a2  a1  a3  Common  (b)  A2  A1 {si,di}  {di,fi}  {b}  a1  {b}  a2 {fi}  (c)  {si}  {fi}  {b}  a3  A2  A1 {si}  {di,fi}  {si,di}  {fi}  {b}  a2  a3 Figure 3: (a) Two decompositions, (b) Weak results from Allen's , and (c) Strong results desired  (c) {si}  includes  includes  a2  a1  a2  {di,fi}  A2  includes  includes  A  a1 (b)  (a)  A  {b}  {fi}  a2  Figure 2: (a) One decomposition, (b) Weak results from Allen's algorithm, and (c) Strong results desired  Now, if we add a new constraint {b} between a1 and a2, then we can use Allen's algorithm to propagate the constraint and produce the results shown in figure 2(b).
However, since a1 and a2 are the only subintervals of A and we know that a1 is located before a2, we should be able to decide that a1 is the starting part of A and a2 is the finishing part.
In other words, we should get the desired results shown in figure 2(c).
Such weak results can be carried further for networks that consist of more than one decomposition.
Suppose that initially we have the network shown in figure 3(a).
Later, if we add the constraints a1 {b} a2 and a2 {b} a3, we get the results shown in figure 3(b) using Allen's algorithm, where "Common" stands for the constraint: {o, oi, s, si, d, di, f, fi, eq}.
However, using a similar argument as made for the previous example, we should be able to get the stronger results shown in figure 3(c).
There are also networks that are considered to be consistent by Allen's algorithm but in fact are not when decompositions are involved.
For example, the network in figure 4(a) is regarded as consistent by Allen's algorithm, since we get the same network after applying the algorithm.
However, this is actually not true because if a1 and a2 are the only subintervals of A and a1 is located before a2, a2 should be the finishing part of A, not an interior part, as shown in figure 4(b).
(a) {si}  a1  A  {b}  (b) {di}  {si}  a2  a1  A  {fi}  {b}  a2  Figure 4: (a) Weak results from Allen's, and (b) Strong results desired  Such weak results are not simply caused by the inexactness of Allen's algorithm.
In fact, Allen's algorithm is exact for all these examples since the constraints used fall into a subset of the interval algebra for which Allen's algorithm is guaranteed to find the set of minimal labels (Van Beek 1989).
The reason for these weak results is that Allen's algorithm treats all the intervals as independent of each  other.
This is certainly not true for decompositions, since the abstract intervals are temporally dependent on their subintervals.
To make these dependencies explicit in the reasoning process, we need to assume that the decomposition of an abstract interval into its subintervals is complete, that is, no more subintervals can be added to the decomposition.
As a result, we can compute how an abstract interval is temporally bounded by its subintervals based on the constraints between all the subintervals.
For instance, if there is a linear ordering between all the subintervals, then we can clearly decide that the abstract interval is temporally bounded by the subintervals that occur the earliest and the latest.
We say that a decomposition is closed if the constraints between the abstract interval and its subintervals are minimal with respect to the constraints between all the subintervals.
More formally, we describe an abstract interval as the convex hull or the minimal cover of its subintervals, denoted by the equation: A = x1 + x2 + [?][?][?]
+ xn where A denotes the abstract interval and x1 , x2 ,..., xn denote the subintervals.
For the example in figure 3, the two decompositions can be represented as: A1 = a1 + a3 and A2 = a 2 + a3 .
Closing a decomposition means closing every decomposition edge between the abstract interval and its subintervals, which further implies computing the minimal labels on the decomposition edges.
We formally define a closure operation by the following first-order formula: A(Ci1 ,Ci2 ,...,Cim )c xi = xi C1 x1 [?]
xi C2 x2 [?]
[?][?][?]
[?]
xi Cm xm [?]
(A = x1 + x2 + [?][?][?
]xm ) where Ci1 ,Ci2 ,...,Cim are the constraints between the subinterval xi and all the subintervals from x1 to xm .
This formula suggests that a decomposition edge can be closed by using the existing constraints between a subinterval and all the subintervals and the fact that the abstract interval is the minimal cover of all its subintervals.
3.
Development of a strengthened temporal reasoning algorithm  To describe our strengthened algorithm for temporal reasoning with hierarchical constraints, we start with the simple case of closing one and two subintervals, and then, we generalize the result to close more than two subintervals.
After that, we provide a recursive procedure to close more than one decomposition, and finally, we present the strengthened algorithm that closes all the hierarchical structures in a temporal network.
3.1.
Closing one and two subintervals As described earlier, closing a decomposition means computing the minimal labels on all the decomposition edges.
If an abstract interval has only one subinterval, then the minimal label on the decomposition edge is obviously {eq}, that is: A(Cii )c xi = xi Cii xi [?]
(A = xi ) = xi {eq}xi [?]
(A = xi ) = A{eq}xi In the case of two subintervals, we can derive from the definition: A(Cii ,Cij )c xi = xi Cii xi [?]
xi Cij x j [?]
(A = xi + x j ) = xi {eq}xi [?]
xi Cij x j [?]
(A = xi + x j ) Since xi {eq}xi always holds for an interval (the so-called node consistency), we define the basic closure operation on a constraint as: A Cijc xi = xi Cij x j [?]
(A = xi + x j ) .
Lemma 1: Given Cij as a set of basic relations R1 , R2 ,..., Rm , the basic closure Cijc can be computed as {R1c , R2c ,..., Rmc}, where Rc is one of the four basic relations: si, di, fi, and eq, as defined in table 1.
R  Table 1: basic closure on basic relations b bi m mi o oi s si d di f fi eq  Rc si fi si fi si fi si eq di eq fi eq eq The validity of table 1 can be easily verified.
For example, if xi {b}x j , then the closed edge between A and xi is {si}, since if A consists of only xi and x j and xi is located before x j , then xi must be the starting part of A.
This basic closure operation also applies to  the case of one subinterval, i.e., (Cii )c = Ciic , since ACiic xi = A{eq}c xi = A{eq}xi .
3.2.
Closing more than two subintervals Having defined the basic closure operation, we can now extend it to close a decomposition of more than two subintervals.
More are the constraints specifically, if Ci1 ,Ci2 ,...,Cim between the subinterval xi and all the subintervals from x1 to xm , including the subinterval xi , then we can close xi and another subinterval x j using the basic closure operation: Cijc .
To get the final closed decomposition edge to xi , however, we need to somehow combine all of the Cijc 's.
It turns out that these Cijc 's can be combined with the normal composition operation in Allen's interval algebra.
Lemma 2 Given the basic relations Ri1 , Ri2 ,..., Rin ,we have A(Ri1 , Ri2 ,[?][?][?
], Rin )c xi = A(R x R x [?][?][?]
x R )xi .
c i1  c i2  c in  Proof.
We prove this lemma by induction on the number of subintervals.
For n = 1, we showed in the last subsection that A(Rii )c xi = ARiic xi .
For n = 2, we have: A(Rii , Rij )c xi = ARijc xi A(Riic x Rijc )xi = A({eq}c x Rijc )xi = ARijc xi So, the lemma holds for both n = 1 and n = 2.
Assume the lemma holds for n = k, that is, A' (Ri1 , Ri2 ,..., Rik )c xi = A' Ri1c x Ri2c x [?][?][?]
x Rikc xi , where A' = x1 + x2 + [?][?][?]
+ xk , we need to prove that the lemma also holds for n = k+1.
We know from table 1 that Rijc can only be one of the four basic relations: si, di, fi, and eq.
By checking table 2, a sub-multiplication table drawn from Allen's (1983a), we see that these four basic relations are closed under multiplication.
Table 2: A Sub-Multiplication Table  x si di fi eq  si si di di si  di di di di di  fi di di fi fi  eq si di fi eq  It follows that Ri1c x Ri2c x [?][?][?]
x Rikc can only be one of the four basic relations: si, di, fi, and eq.
Let us denote Ri1c x Ri2c x [?][?][?]
x Rikc as R , and Rikc +1 as S. Now, from the definition of the closure operation, we have: A(Ri1 ,..., Rik , Rik +1 )c xi = xi Ri1 x1 [?]
[?][?][?]
[?]
xi Rik xk [?]
xi Rik +1 xk +1 [?]
(A = x1 + [?][?][?]
+ xk + xk +1 ) = xi Ri1 x1 [?]
[?][?][?]
[?]
xi Rik xk [?]
(A' = x1 + [?][?][?]
+ xk ) [?]
xi Rik +1 xk +1 [?]
(A"= xi + xk +1 ) [?]
(A = A' + A") = A' (Ri1 ,..., Rik )c xi [?]
A" Rikc +1 xi [?]
(A = A' + A") = A' (Ri1c x [?][?][?]
x Rikc )xi [?]
A" Rikc +1 xi [?]
(A = A' + A") = A' Rxi [?]
A"Sxi [?]
(A = A' + A") To further evaluate the above expression, we need to consider the following special cases: (1) If A' {si}xi [?]
A"{si}xi , then we have A{si}xi , since if xi is the starting part of both A' and A" and A = A' + A", then xi should also be the starting part of A.
(2) If A' {fi}xi [?]
A"{fi}xi , then we have A{fi}xi .
The reason is similar to case (1) above.
(3) If A' {si}xi [?]
A"{fi}xi , then we have A{di}xi .
The reason for this is that if xi is the starting part of A', then there must be another interval that finishes after xi .
Similarly, if xi is the finishing part of A", then there must be another interval that starts before xi .
Thus, there are intervals that starts before xi and finishes after xi , and xi must be an interior part of the covering interval A.
(4) If A' {di}xi [?]
A"Sxi , then we have  A{di}xi , since if xi is an interior part of A', it is also an interior part of A.
(5) If A' {eq}xi [?]
A"Sxi , then we have ASxi .
This is obviously true since A' equals xi .
Since conjunctions are commutative, it is easy to see that these results are exactly the same as table 2 above.
In other words, we have proved that: A(Ri1 ,..., Rik , Rik +1 )c xi = A(R x S)xi = A(Ri1c x [?][?][?]
x Rikc x Rikc +1 )xi .
that is, lemma 2 also holds for n = k+1.
Lemma 2 implies that if the constraints between one subinterval and all the subintervals are one of the basic relations, the decomposition edge to the subinterval can be closed by multiplying the basic closures of these constraints.
Theorem 1: Given Ci1 ,Ci2 ,...,Cim as the constraints between xi and all the subintervals from x1 to xm , the closed edge between A and xi can be computed as follows: c c c c A(C  i1 ,Ci2 ,...,Cim ) xi = ACi1 o Ci2 o [?][?][?]
o Cim xi .
Proof.
The theorem can be proved by expanding constraints into sets of basic relations, converting the result into disjunctions of conjunctions, and applying lemma 2 to all the conjunctions: A(Ci1 ,Ci2 ,...,Cim )c xi = xi Ci1 x1 [?]
xi Ci2 x2 [?]
[?][?][?]
[?]
xi Cim xm [?]
(A = x1 + x2 + [?][?][?]
+ xm ) = xi {R11 , R12 ,..., R1n1 }x1 [?]
xi {R21 , R22 ,..., R2n2 }x2 [?]
...... xi {Rm1 , R2 m2 ,..., Rmnm }xm [?]
(A = x1 + x2 + [?][?][?]
+ xm ) = (xi R11 x1 [?]
xi R21 x2 [?]
[?][?][?]
[?]
xi Rm1 xm [?]
A = x1 + x2 + [?][?][?]
+ xm ) [?]
(xi R11 x1 [?]
xi R21 x2 [?]
[?][?][?]
[?]
xi Rm2 xm [?]
A = x1 + x2 + [?][?][?]
+ xm ) [?]
...... (xi R1n1 x1 [?]
xi R2n2 x2 [?]
[?][?][?]
[?]
xi Rmnm xm [?]
A = x1 + x2 + [?][?][?]
+ xm ) = A(R11 , R21 ,..., Rm1 )c xi [?]
A(R11 , R21 ,..., Rm2 )c xi [?]
...... A(R1n1 , R2n2 ,..., Rmnm )c xi c = AR11c x R21c x [?][?][?]
x Rm1 xi [?]
c c c AR11 x R21 x [?][?][?]
x Rm2 xi [?]
...... c c AR1nc 1 x R2n x [?][?][?]
x Rmn xi 2 m c c c = ACi1 o Ci2 o [?][?][?]
o Cim xi .
Lemma 3 Given constraints as subsets of {si, di, fi,eq}, the composition is commutative and associative, that is,  C1 o C2 = C2 o C1 , and (C1 o C2 ) o C3 = C1 o (C2 o C3 ).
Proof.
Given two subsets of {si, di, fi,eq}, the composition is both commutative and associative since for each pair of the basic relations, the results of multiplications are symmetric, as shown previously in table 2.
Theorem 2: In closing a decomposition constraint using theorem 1, we get the same result no matter what order we do the compositions.
Proof.
This follows directly from lemma 3, since the composition is both commutative and associative for subsets of {si, di, fi,eq}.
Based on theorems 1 and 2, we now present a new procedure for closing a decomposition of any number of subintervals.
procedure CLOSE(k, S) begin for each i [?]
S do begin t - {eq} for each j [?]
S do t - t o Cijc t - t [?]
Cki if t [?]
Cki then begin Cki - t Cik - INVERSE(t) Q - Q [?]
RELATED_PATHS(k, i) end end end Figure 5: Procedure for closing a decomposition  The above procedure closes all the decomposition edges in turn, and if a closed edge is more specific than the existing edge, the existing edge will be updated and all the related paths will be queued for further propagation.
Theorem 3.
The time complexity of the CLOSE procedure is O(m2 ) where m is the number of subintervals in a decomposition.
3.3.
Closing all the decompositions in a hierarchical structure A hierarchical structure often consists of more than one decomposition.
Our strategy is to close a hierarchy in a post-order fashion, since higher-level intervals can be defined in terms of lower-level subintervals.
In other words, we start the closing process from the bottom-level decompositions and work our way up until all the decompositions are closed in the hierarchy.
procedure CLOSE_ALL (k) begin get a list S of subintervals for k if S is not empty then begin for each i [?]
S do CLOSE_ALL (i) CLOSE (k, S) end end Figure 6: Closing all the decompositions in a plan  Theorem 4.
The time complexity of the CLOSE_ALL procedure is bounded below by O(n) and above by O(n2 ), where n is the number of intervals in a plan.
3.4.
The Strengthened Algorithm The CLOSE_ALL procedure closes all the decompositions in a hierarchical structure.
To get stronger results for a temporal network, we first use an existing reasoning algorithm to compute the set of constraints to be as specific as possible.
Then, for each hierarchical structure in the temporal network, we recursively close all the decompositions using the CLOSE_ALL procedure.
After that, some of the decomposition edges may be updated,  and we call the temporal reasoning algorithm again to propagate the effects of these new constraints.
Thus, we generally need to call interactively an existing reasoning algorithm and our CLOSE_ALL procedure.
Such a process will eventually terminate since every time we update a constraint, some of its basic relations will be eliminated and there are at most 13 basic relations in any constraint.
We now give the strengthened algorithm for temporal reasoning with hierarchical constraints: algorithm STRENGTHENED begin Q-{initial paths in a temporal network} H-{roots of all hierarchical structures} while Q is not empty do begin MODIFIED_TR foreach k [?]
H do CLOSE_ALL (k) end end Figure 7: The strengthened algorithm for temporal reasoning about plans  The set H contains the roots of all hierarchical structures, and CLOSE_ALL closes all the decompositions in a hierarchy.
The set Q contains those paths whose effects need to be propagated, and MODIFIED_TR is the same as an existing algorithm for temporal reasoning except that the initialization of Q is removed from the procedure.
Theorem 5.
The time complexity of our strengthened algorithm is at most O(T log2n), where n is the number of intervals in a temporal network and T is the time complexity of an existing reasoning algorithm (n3 for the path-consistency procedure, n4 for Van Beek's procedure, and exponential for some more exact procedures).
Proof: First, each iteration of our algorithm takes O(T+n 2 ) time or O(T), since all the existing algorithms take time at least O(n3 ).
Second, the worst case corresponds to a balanced binary tree, with maximum levels of decompositions and for which the effects of closed decompositions need to be propagated upwards.
Thus, we have the factor of log2n for the number of iterations.
4.
An application to plan recognition Plan recognition is the process of inferring an agent's plan based on the observation of the agent's actions.
A recognized plan is useful in that it helps to decide an agent's goal and predict the agent's next action.
For example, if we observe that John has made the sauce and he is now boiling the noodles, then based on the plan shown in figure 1, we can decide that John's goal is to make a pasta dish and his next action is to put noodles and sauce together.
Plan recognition has found applications in such areas as story understanding, psychological modeling, natural language pragmatics, and intelligent interfaces.
(a)  Make Noodles Includes  Includes  Includes  Measure BeforeMeets Mix BeforeMeets Flour Dough Make Sauce  (b) Includes  Thaw Beef (c)  Roll Dough  Includes  BeforeMeets  Mix {b,m} Dough  Includes  Heat BeforeMeets Beef  Add Paste  Thaw {b,m} Roll Beef Dough {b,m} Heat {b,m} Boil {b,m} Beef Noodles  Add Paste  Figure 8: An extended plan for making a pasta dish  Most existing models for plan recognition assume a library of all possible plans that might occur in a particular domain.
Then, through some kind of search and matching mechanism, one can find all the plans that contain the observed actions, called candidate plans.
Since the observation of an agent's actions is often incomplete and some actions may appear in many different plans of the plan library, it is often difficult to determine the unique plan that an agent is pursuing.
Kautz (1987) suggests  that one way of reducing the number of candidate plans is to use various kinds of constraints, including the temporal relations explicitly reported in the observations, to further eliminate those inconsistent plans2 .
However, Kautz only adopted a subset of Allen's interval algebra and did not use fully the temporal constraints that correspond to the decomposition edges in a candidate plan.
Our approach to plan recognition is to represent a plan as a temporal network and perform temporal reasoning to eliminate those candidate plans that are inconsistent with the temporal constraints explicitly given in the observations.
Such a reasoning process can have two useful effects: the given constraints can be used to reduce the number of candidate plans (an example of this effect can be found in Song and Cohen (1991)) and the given constraints can be made more specific by combining them with the prestored constraints in a candidate plan.
To illustrate the second effect, we extend the plan for making a pasta dish in section 1 by adding the decompositions for MakeNoodles and MakeSauce, shown in figure 8(a) and (b).
Suppose that the observation of an agent's actions is given in figure 8(c).
We can then use Allen's algorithm or our strengthened algorithm to make some of the constraints in the plan more specific.
Using Allen's algorithm, we can make some of the constraints more specific, as shown in figure 9(a).
Using our strengthened algorithm, we can make these constraints even more specific, as shown in figure 9(b).
MakePastaDish {si, di} MakeNoodles MakePastaDish {si, di} MakeSauce MakePastaDish {di, fi} PutTogether MakeNoodles {si, di} MeasureFlour MakeNoodles {di, fi} RollDough MakeSauce {si, di} ThawBeef MakeSauce {di, fi} AddTomatoPaste MakeNoodles {o, s, d} MakeSauce MakeNoodles {b, m} BoilNoodles Figure 9(a): Results from Allen's Algorithms 2 Other solutions include the use of preference heuristics  (Allen, 1983b; Litman, 1985; Carberry, 1986) and probabilities (Goldman and Charniak, 1988).
MakePastaDish {si} MakeNoodles MakePastaDish {di} MakeSauce MakePastaDish {fi} PutTogether MakeNoodles {si} MeasureFlour MakeNoodles {fi} RollDough MakeSauce {si} ThawBeef MakeSauce {fi} AddTomatoPaste MakeNoodles {o} MakeSauce MakeNoodles {b} BoilNoodles Figure 9(b): Results from our strengthened algorithm  5.
Conclusion We presented a strengthened algorithm for temporal reasoning about plans, which improves on straightforward applications of the existing reasoning algorithms for Allen's interval algebra.
We view plans as both temporal networks and hierarchical structures.
Such a dual view allows us to design a closing procedure which makes as specific as possible the temporal constraints between abstract actions and their subactions.
The procedure is then used interactively with an existing reasoning algorithm to help obtain the strengthened results.
We applied our algorithm to the problem of plan recognition and showed that such an application can both reduce the number of candidate plans make the constraints in the remaining plans more specific.
One possible area for future work is to improve the efficiency of our algorithm, which calls interactively an existing reasoning algorithm and our closing procedure.
Although the strengthened algorithm only adds a factor of log 2 n to the time complexity of an existing reasoning algorithm, it is worth investigating whether such interactions can be localized and reduced.
Some results on localizing the propagation of temporal constraints in Allen's interval algebra have been reported (Koomen 1989).
This would form a useful starting point for our future research.
Acknowledgments This work was supported in part by the Natural Sciences and Engineering Research Council of Canada.
ALLEN, J. F. 1983a.
Maintaining knowledge about temporal intervals.
Communications of the ACM, 26: 832-843.
_____1983b.
Recognizing intentions from natural language utterances.
In Computational models of discourse.
Edited by M. Brady and R. Berwick.
The MIT press, Cambridge, Mass.
pp.
107-166.
ALLEN, J. F., and KOOMEN, J.
A.
1983.
Planning using a temporal world model.
Proceedings of the Eighth International Joint Conference on Artificial Intelligence, pp.
741-747.
CARBERRY, S. 1986.
Pragmatic modeling in information system interfaces.
Ph.D. Dissertation, University of Deleware.
GOLDMAN, R., and CHARNIAK, E. 1988.
A probabilistic ATMS for plan recognition.
Proceedings of the AAAI Workshop on Plan Recognition.
KAUTZ, H. A.
1987.
A formal theory of plan recognition.
Ph.D. Dissertation, University of Rochester, Rochester, N.Y. KOOMEN, J.
A.
1989.
Localizing temporal constraint propagation.
Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, Toronto, Ontario, Canada, pp.
198-202.
LITMAN, D. 1985.
Plan recognition and discourse analysis: an integrated approach for understanding dialogues.
Ph.D. Dissertation, University of Rochester.
SONG, F. 1991.
A processing model for temporal analysis and its application to plan recognition.
Ph.D. Dissertation, University of Waterloo, Waterloo, Ontario, Canada.
SONG, F., and COHEN, R. 1991.
Temporal reasoning during plan recognition.
Proceedings of the Ninth National Conference on Artificial Intelligence, Anaheim, CA, pp.
247-252.
VALDES-PEREZ, R. E. 1987.
The satisfiability of temporal constraint networks.
Proceedings of the Sixth National Conference on Artificial Intelligence, pp.
256-260.
VAN BEEK, P. 1989.
Approximation algorithms for temporal reasoning.
Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, pp.
1291-1296.
VILAIN, M., and KAUTZ, H. 1986.
Constraint propagation algorithms for temporal reasoning.
Proceedings of the Fifth National Conference on Artificial Intelligence, pp.
377-382.
VILAIN, M., KAUTZ, H., and VAN BEEK, P. 1989.
Constraint propagation algorithms for temporal reasoning: a revised report.
In Readings in qualitative reasoning about physical systems.
Edited by D.S.
Weld and J. de Kleer.
Morgan Kaufman, San Mateo, CA, pp.
373-381.
2013 20th International Symposium on Temporal Representation and Reasoning  Making Time Just Another Axis in Geospatial Services Piero Campalani, Dimitar Misev, Alan Beccati and Peter Baumanna a School of Engineering & Science (JUB), Bremen, Germany Email: {p.campalani,d.misev,a.beccati,p.baumann}@jacobs-university.de Alongside, the consolidation and advancements of standards for the geospatial realm ([8], [9]) are creating premises for open interconnectedness and interoperability of location-based web services.
In particular, the Geography Markup Language (GML) a the XML grammar dedZned by the Open Geospatial Consortium (OGC) a is a description of application schemas, transport and storage of geographical features, as they are described in the ISO 19100 series of standards and the OpenGIS Abstract SpecidZcation.
Among the several conceptual models covered by GML (e.g.
spatial geometries, coverages, units of measure), of particular interest for this work are the schemas for Coordinate Reference Systems (CRSs), a key aspect of geoscience datasets, and their application to gridded coverages.
In [10] the authors described the advantages of a GML-oriented approach for referencing geospatial data when implementing services on the web, and this inevitably needs to include a proper management of the temporal information.
Time should not be meant as just an additional attribute, e.g.
support information, but should be integrated in the model of a coverage as a coordinate on its own, wrapping time series of data onto a single object, this way extending querying and processing capabilities of web services to the temporal dimension [11].
This is eagerly awaited by the scientidZc community, including geo image services ([12], [13]), the Model Web ([14], [15]), or geological sciences [16].
In this article we will propose a framework for serving regular/irregular time series of datasets by means of spatio-temporal CRSs in an OGC-oriented Web environment, and by seamless integration of the temporal dimension in the generic n-dimensional space of analysis, with focus on the implications for the OGC Web Coverage Service (WCS) [17] and Web Coverage Processing Service (WCPS) [18].
After an overview of related works in Sec.
II, Sec.
III will introduce the syntax behind the specidZcation and web-based retrieval of CRS dedZnitions; Sec.
IV will describe how GML addresses the recording of temporal coordinates as well as the concepts of the proposed framework; practical examples are presented in Sec.
V; conclusions are eventually drawn in Sec.
VI.
AbstractaThe use of large multidimensional, complex datasets to study the roots and the consequences of real-world phenomena is systematically gaining importance in the recent years.
These datasets and their requisite metadata can be managed by queryable databases, and the increasing processing capabilities of distributed computing and Array DBMS are opening new scenarios for Web-based access and analysis.
The spatio-temporal nature of these observations requires the establishment of an automated machine-readable system that seamlessly accounts for time as not just an attribute, but rather as one more axis in the n-dimensional structure.
This paper proposes a conceptual framework for the integration of temporal with spatial dimensions.
Based on the widely used Geography Markup Language (GML) it exploits temporal Coordinate Reference Systems (CRSs) in analogy to, and interoperable with, well-known spatial CRSs.
The proposed approach is then concretely applied to the OGC Web protocols Web Coverage Service (WCS) and Web Coverage Processing Service (WCPS), by means of which a user can visualize, aggregate, process remotely stored archives of scientidZc data.
It is based on an open-source CRS resolver, SECORE, which translates URL identidZers of CRSs into their GML dedZnitions.
SECORE has been adopted by OGC as its standard CRS resolver, and the whole concept is supported by an ad-hoc OGC working group.
Keywords-time series; coordinate systems; geoservices; big data;  I. I NTRODUCTION The increasing availability of multidimensional scientidZc datasets is giving room to a always wider range of applications that can take advantage of jointly spatial and temporal analytics capabilities [1].
In particular, Earth monitoring via satellites and remote sensing technologies offers a powerful mean for analyzing long-term datasets that are crucial for a clearer understanding of phenomena and thus for prevention; rising atmospheric CO2 or the Antarctic ozone hole were indeed discovered by a fruitful analysis of spatio-temporal datasets.
Developing applications can transversely span a variety of different domains, from land use [2] to cryosphere analysis [3], from environmental heritage [4] to planetary sciences [5], and more.
The mere visualization of the data is usually not enough if not accompanied by analysis and consequently adequate processing capabilities [1].
The rising of distributed computing resources as commodity services and the systematic development of Array DBMSs ([6], [7]) are making it possible to achieve important speed increases for analyses.
1530-1311/13 $26.00 AS 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.24  II.
R ELATED W ORKS The extension of spatial data models to the temporal dimension in a unidZed manner is a crucial aspect when 119 133  investigating dynamic phenomena [19].
Augmenting spatial modelling and analytics capabilities with temporal semantics has been addressed in in many areas of geosciences, dating back at least twenty years [20].
In recent years there has been a growing attention on the dZeld of spatio-temporal databases and how to query on them [21].
Such databases deal with geometries which can change over time in order to provide a DBMS data model and SQL-integrated query language capable of handling time-dependent geometries [22].
The proposed URI-based model of referring to a temporal dimension can be applied independently of the type of geometry of the desired feature, whether it is a point cloud over time, a time series of images, a trajectory, and so on.
This architecture might be seen as an additional extension, to be built on top of spatio-temporal databases to enable an online, and most of all interoperable, query interfaces.
Regarding OGC standardizations, this is not the dZrst effort to establish a dZrst-class citizen temporal dimension: for instance, Web Map Service (WMS) a most notably implemented by open-source geoservices like MapServer and GeoServer [23] a is working on the visualization of multidimensional gridded data with temporal capabilities via a aTIMEa parameter [24].
Time is treated as a special dimension, with mechanisms different from spatial selection.
The hereby discussed schema tends instead to a uniform inclusion of time, with no particular special treatment with respect to other spatial axes in the n-D aquarium.
Outside the context of OGC there are other ever-growing initiatives for temporal analysis of features and timegeography.
For instance, an international group of archaeologists, geoscientists, and experts in geomatics and data acquisition is emerging with the common goal of developing an international data standard for archaeological 4D data [25].
The R environment for statistical computing can already offer packages for the analysis of spatio-temporal datasets of different natures (e.g.
points, grids, trajectories) with dZrstclass citizen time analysis, as well as space-time statistical modelling tools [26].
Still at an early stage, the temporal extension for PostgreSQL, PostTIME [27], is currently being developed, and it is capable to manage different types of temporal reference, based on either temporal coordinates, calendars and as well ordinal systems.
In all these cases, still there is a lack of dZexibility when it comes to dedZne custom CRSs for time, and usually one cannot have more than one single temporal dimension.
Indeed, one of the key-point of our proposal is the freedom to generate custom ad-hoc temporal reference systems, and to attach one or more of them to the owned datasets.
Several services need to dedZne custom geospatial (or planetary) CRSs, and many of them can be fetched from Spatial Reference [28] in different formats, GML included.
Our  inherently distributed URI-oriented CRS resolver could coexist with it providing means for composing spatio-temporal CRSs that reliably host the data to be served, independently of the internal architectures.
III.
CRS  IDENTIFICATION  Coordinate Reference Systems contain all the information necessary to precisely relate abstract coordinates to concrete physical locations, in either space or time.
As such they are at the heart of all applications dealing with real-world data, when the knowledge of its unique physical coordinates is essential.
CRSs can be fully described in several machineunderstandable languages, including Geography Markup Language (GML) and Well-Known Text (WKT).
Communicating complete CRS dedZnitions is rather impractical, especially since a vast majority of the GIS applications rely on some commonly accepted standard Spatial Reference System IdentidZers (SRID).
Concerning geospatial CRSs, virtually all major spatial vendors have created their own SRID implementation or refer to those maintained by an authority, such as the Oil and Gas Producers (OGP) Surveying and Positioning Committee.
The EPSG SRID value for the WGS84 CRS is 4326 for example.
Based on SRID codes and the now deprecated CRS URN identidZers [29], we have devised a simple, expressive, and HTTP compatible mechanism for CRS identidZcation and dedZnition management.
A brief overview is given here; for full details we refer the reader to [30], [31].
CRS identidZers are modelled as Uniform Resource Locators (URL) [32], which uniquely resolve to the according CRS dedZnition.
This dZts well into the OGC Web Service (OWS) Common standard [33], according to which CRS references are XML attributes or elements of type anyURI.
Furthermore, it takes advantage of a well established architecture rather than introducing new protocols for resolving the identidZed CRS dedZnition.
A Web service which understands CRS URL identidZers and is able to dynamically construct and respond with an according CRS dedZnition is already available, and will be soon deployed at OGC.
Next we present the syntax and semantics of CRS identidZers.
We have categorized CRS identidZers into three types, according to the types of dedZnitions they refer to.
A.
Single CRS A single CRS dedZnition is uniquely identidZed by the authority that maintains this CRS, the dedZnition version, and the SRID code.
This translates to a URL identidZer in key-value pair (KVP) format as shown in Listing 1.
Alternatively, we can have a RESTful URL equivalent (see Listing 2), in which case the argument order is dZxed to authority, version, code: ahttp://www.opengis.net/def/crs/ EPSG/0/4326a is an example of such identidZer for the wellknown WGS84 CRS.
134 120  { r e s o l v e r ap r e f i x } / d e f / c r s ?
a u t h o r i t y ={ a u t h o r i t y }& v e r s i o n ={ v e r s i o n }& code={code}  Listing 1.
{ r e s o l v e r ap r e f i x } / d e f / crsacompound?
1={ l a t / l o n CRS i d e n t i f i e r }& 2={ h e i g h t 1D CRS i d e n t i f i e r }& 3={ t e m p o r a l CRS i d e n t i f i e r }  Single CRS identidZer (KVP format).
Listing 4.
{ r e s o l v e r ap r e f i x } / d e f / c r s / { a u t h o r i t y } / { v e r s i o n }/{ code}  Listing 2.  such a CRS is then simply a list of the URLs identifying the component CRSs.
CCRSs have been widely used to chain horizontal and vertical CRSs, which indeed in historic geodetic practice used to be determined independently [37].
This concept can be extended to involve theoretically any viable combination of CRSs, in both space and time.
For example, there is no pre-existing coordinate reference system for referencing 4D latitude/longitude/height/time data, so we can get a compound CRS on the dZy with an identidZer like the one shown in Listing 4.
A single CRS identidZer (RESTful).
h t t p : / / www.
opengis .
n e t / d e f / c r s / AUTO2/ 1 .
3 / 4 2 0 0 1 ?
l a t i t u d e =30 & l o n g i t u d e =a87  Listing 3.
Example of an AUTO2 parametrized CRS with two parameters.
B. Parametrized CRS  IV.
T EMPORAL CRS  A parametrized CRS is an incomplete, abstract CRS, where some parts of the dedZnition have to be provided by the identidZer in order to instantiate a concrete dedZnition.
A parametrized CRS dedZnition references the single CRS which will be instantiated, and a list of parameters.
Each parameter has: aV aV  aV  Compound CRS identidZer.
R (and ISO) GML encoding standard offers a OpenGIS wide variety of XML application schemas for expressing geographical features: it is clearly not limited to the purely spatial description of an object, offering models for the handling of temporal geometries and temporal reference systems as well.
A coverage is a subtype of feature that has a spatiotemporal domain and a set of homogeneous 1- to n-dimensional tuples, and may either represent one feature or a collection of features [38].
A CRS is usually meant as a spatial coordinate system that is related to Earth through one datum (geospatial CRS), but in its generic dedZnition a CRS might be bound to any object, whether it is an ellipsoid representing a different planet, or as well a temporal calendar for instance.
In the latter case, we would then have a temporal CRS.
Indeed GML provides the gml:TemporalCRS type, simply dedZned as 1D coordinate reference systems used for the recording of time [38].
Listing 5 shows the relative XML type dedZnition, which is basically composed of a temporal Coordinate System (CS) and a temporal datum.
As shown in Listing 6, a gml:TimeCS provides the dedZnition of one single axis which in turn dedZnes the proper temporal metadata, i.e.
the unit of measure (@uom) and a label, or abbreviation (axisAbbrev).
The abbreviation is unique and mandatory and could be easily used as identidZer for the time dimension when dealing with web requests that need to fetch e.g.
a sub-portion of the coverage in the temporal dimension (examples will follow in the next section).
Optionally, a coverage service might dedZne minimum and maximum values usually meant for that temporal axis, and as well a direction which could be of practical use e.g.
when dealing with temporal dimensions which are heading to the  a name, by which it can be referenced in the CRS identidZer; an optional value, which can be a single value a as a default if none is supplied in the identidZer a or a formula (Java Script expression [34]) which can compute the value based on the values of other parameters; an optional XPath target expression specifying where in the referenced CRS dedZnition should the value be set.
This new CRS type allows to create very dZexible CRS definitions and thus avoids creating new prededZned dedZnitions whenever some parameters need to be slightly different.
For example, Listing 3 identidZes the Auto universal transverse mercator Layer CRS (AUTO2:42001) as specidZed in WMS 1.3 [35], which is an automatic spatial coordinate reference system which gives the user the possibility to customize the centre of projection.
This way the proposed parametrized CRS lets the user specify this centre of projection as a tuple of latitude/longitude degrees (over Pensacola FL in the example), which are internally handled to set the correct central meridian and false northing parameters of the dedZnition.
Further details on CRS parametrization can be found in [30].
C. Compound CRS A Compound Coordinate Reference System (CCRS) is dedZned as an ordered composition of single non-compound, non-repeating component CRSs [36].
A URL identifying  135 121  In addition to any custom unit of measure that could be referenced by an external URI, there are well-known labels which could be directly applied, e.g.
a for year, wk for week, and so on (see [39] for a thorough list).
With regards to the complex GML modeling of stratigraphic geological time scales (see [40] and [41]), an absolute chronometric approach might be more practical, for instance by setting a time reference system with units millions of years (Ma), positive backwards.
In practice, the purpose of this framework is to let the system work with numerical coordinates by indexing the temporal domain, this way enabling OGC-compliant spatio-temporal queryable datasets on a web service.
Indeed, when describing the topology of a spatio-temporal feature in GML a that is where or when the feature components (points, lines, solids) are a then an element of type gml:DirectPositionType (a list of IEEE doubleprecision 64-bit dZoating-point numbers) is always required, whereas descriptive textual representations are not possible.
The service shall thus dedZne a gml:TemporalCRS with proper resolution and origin for the referred dataset, so that the domain of validity in time of the CRS can include its temporal extent.
The URL identidZer of the newly created temporal CRS (see Sec.
III) can then be concatenated to the spatial CRS of the feature in order to safely automatize its spatio-temporal reference system and to correctly translate the requests into the internal database system.
As a visual example, Fig.
1 depicts a time series of aerosols vertical prodZles from lidar observations onboard the CALIPSO satellite: a single 3D gridded coverage jointly binds three images in order to form a unique cube for spacetime queries.
As previously explained, the transition from the single image to the time series is achieved by extending its inherent geodetic CRS to a spatio-temporal composition with a temporal one.
Further practical use cases with data condZguration guidance along real request/response examples will be presented in the next section.
In order to avoid confusion, from now on we will refer to (geo)spatial CRSs as as-CRSsa, temporal CRSs as at-CRSsa and compound spatio-temporal CRSs as ast-CRSsa.
< element name = " TemporalCRS " type = " gml : TemporalCRSType " s u b s t i t u t i o n G r o u p = " gml : A b s t r a c t S i n g l e C R S "/ > < complexType name = " TemporalCRSType " > < complexContent > < extension base = " gml : AbstractCRSType " > < sequence > < choice > < element ref = " gml : timeCS " / > < element ref = " gml : usesTemporalCS "/ > </ choice > < element ref = " gml : temporalDatum " / > </ sequence > </ extension > </ complexContent > </ complexType >  Listing 5.  gml:TemporalCRSType.
< complexType name = " C o o r d i n a t e S y s t e m A x i s T y p e " > < complexContent > < extension base = " gml : I d e n t i f i e d O b j e c t T y p e " > < sequence > < element ref = " gml : axisAbbrev " / > < element ref = " gml : axisDirection " / > < element ref = " gml : minimumValue " minOccurs ="0"/> < element ref = " gml : maximumValue " minOccurs ="0"/> < element ref = " gml : rangeMeaning " minOccurs ="0"/> </ sequence > < attribute name = " uom " use = " required " type = " gml : UomIdentifier " / > </ extension > </ complexContent > </ complexType >  Listing 6.  gml:CoordinateSystemAxisType.
< complexType name = " T e m p o r a l D a t u m T y p e " > < complexContent > < extension base = " gml : T e m p o r a l D a t u m B a s e T y p e " > < sequence > < element ref = " gml : origin " / > </ sequence > </ extension > </ complexContent > </ complexType >  Listing 7.  gml:TemporalDatumType.
V. P RACTICAL EXAMPLES  past, so that positive coordinates can be used (for example in the case of geological time reference where is common practice to use an unsigned numbers of millions of years as meter).
In order to give full meaning to a temporal coordinate, it must be linked to an absolute point in time by means of a temporal datum (see Listing 7), just like a geodetic datum binds a set of axes to an Earth model.
In the simpler case, the datum just needs to specify the origin of the temporal CRS, which in the current version of GML is in the form of an xsd:dateTime element, i.e.
a concatenation of a date and a timestamp separated by a literal letter a T a.
A dZrst straightforward use of the proposed framework comes when serving a regularly spaced time series of 2D images.
Nevertheless, the concept generally applies for irregularly spaced series of n-dimensional features as well, not necessarily having a linkage to a geodetic system of coordinates (they could be medical CT scans as well, for instance).
We can imagine to have several years of daily aggregates of spectral projected images from a generic spaceborne sensor over, say, Armenia and that we group them into a single coverage named ARM-day-TS.
Each single map is a  136 122  fi  < TemporalCRS xmlns =[...] gml : id = " ANSI - Date " > < description > Continuous count of days starting from Jan 1 , 1601 (00 h00 ).
Equal to floor ( JulianDate -2305812.5).
</ description > < identifier c o d e S p a c e = " http :// www .
opengeospatial .
org " > { resolver - prefix }/ crs / OGC /0.1/ ANSI - D </ identifier > < name > ANSI date number </ name > < timeCS > < TimeCS id = " days - CS " > < identifier c o d e S p a c e = " http :// www .
opengeospatial .
org " > { resolver - prefix }/ cs / OGC /0.1/ days </ identifier > < axis > < C o o r d i n a t e S y s t e m A x i s id = " day - axis " uom = " d " > < identifier c o d e S p a c e = " http :// www .
opengeospatial .
org " > { resolver - prefix }/ axis / OGC /0.1/ days </ identifier > < axisAbbrev >t </ axisAbbrev > < axisDirection > future </ axisDirection > </ C o o r d i n a t e S y s t e m A x i s > </ axis > </ TimeCS > </ timeCS > < temporalDatum > < TemporalDatum id = " ANSI - TD " > < identifier c o d e S p a c e = " http :// www .
opengeospatial .
org " > { resolver - prefix }/ datum / OGC /0.1/ ANSI </ identifier > < origin > 1601 -01 -01 T00 :00 </ origin > </ TemporalDatum > </ temporalDatum > </ TemporalCRS >  	 fi  fi   Figure 1.
A visual example of the spatio-temporal gridded coverage model applied to a time series of lidar vertical prodZles from the CALIPSO satellite mission (Cloud-Aerosol Lidar and Infrared PathdZnder Satellite Observations, NASA/CNES).
collection on N spectral observation over different frequency channels and it has been mapped to UTM 38N cartesian coordinates with the WGS84 datum.
It should be noted how the multispectral nature of the feature does not increase its dimensionality, but rather its attribute space a known as range in the GML nomenclature.
The spatio-temporal dimensionality of our dataset is then three: two spatial axes a for which we can easily adopt the prededZned UTM EPSG:32628 s-CRS a and one temporal axis, which needs to be anchored to a proper t-CRS.
This will have an arbitrary origin and preferably daily resolution, since we do not need dZner-grained time analysis in this case.
An example of temporal CRS is proposed in Listing 8, which shows an hypothetical dedZnition for the ANSI date numbers, whose epoch dates back to January 1, 1601 (the beginning of the previous 400-year cycle of leap years in the Gregorian calendar, which ended with the year 2000).
As a side note, despite the dimensionality of our proposed grid coincides with the dimensionality of the encompassing spatio-temporal space, this must not be meant as a dZxed rule: more generally we can put any n-D feature inside an m-D CRS space, as soon as n a$?
m, e.g.
oblique 2D maps in the 3D space, trajectories in the 3D space, and so on.
Moreover, more one t-CRS could be anchored to th dataset, as could be the case of 5D meteorological forecasts data-cubes [42].
The overall system of coordinates for our data could thus be as showed in Listing 9, which in turn dedZnes three axis: the easting E and northing N, both dedZned by the cartesian CS of the UTM CRS, and the date t of the temporal CRS.
Having set up the metadata of our collection, we can then published it in a machine-understandable way, so that a client could read its description and then analyse it with cross-sections (WCS/WCPS), request intra-spectral process-  Listing 8.
Example of gml:TemporalCRS.
ing operations, aggregate through time or space (WCPS), etc.
As a practical example, a user might want to visualize the ratio of two different channels over the whole available spatial extent as a GeoTiff image, and this could be achieved by the WCPS request showed in Listing 10.
In order to allow a user specify more meaningful ISO 8601 time descriptions instead of time indexes, the use of quotes could be adopted as switch: in the WCPS example of Listing 10 then one could replace the ANSI date with its equivalent in the Gregorian calendar, which would be the glorious a2012-12-21a.
As a further example, one could exploit the GML encoding of a WCS response to retrieve the temporal series of data over a certain time interval and for a specidZed Region of Interest (RoI), like with the KVP-encoded request presented in Listing 11.
In this specidZc case, the request would then return the desired result over our ARM-day-TS along with a comprehensive description of the associated geometry, optional descriptive metadata and data range types [43].
The WCS 2.0 upcoming CRS extension [44] could also be exploited to retrieve data with more easily comprehensible longitude/latitude degrees coordinates, but this goes beyond the scope of this article.
137 123  { r e s o l v e r ap r e f i x } / d e f / crsacompound?
1={ r e s o l v e r ap r e f i x } / d e f / c r s /EPSG/0/32638& 2={ r e s o l v e r ap r e f i x } / d e f / c r s /OGC/ 0 .
1 / ANSIaD  Listing 9.
< gmlcov : R e c t i f i e d G r i d C o v e r a g e xmlns =[...] gml : id = " ID " > < boundedBy > < Envelope srsName = " { resolver - prefix }/ crs - compound ?
1={ resolver - prefix }/ crs / EPSG /0/32638& 2={ resolver - prefix }/ crs / OGC /0.1/ ANSI - D " axisLabels ="E N t" uomLabels ="m m d" srsDimension ="3"> < lowerCorner > 415000 4430000 149536 </ lowerCorner > < upperCorner > 500000 4530000 149565 </ upperCorner > </ Envelope > </ boundedBy >  A spatio-temporal compound CRS.
f o r map i n (ARMadayaTS ) return encode ( s l i c e ( map .
7 / map .
4 , { t (150470)} ) , a GTiff a )  Listing 10.
Example of WCPS query with time slicing.
h t t p : / / { s e r v i c eadomain } / path / t o / wcs / s e r v l e t ?
s e r v i c e =WCS& v e r s i o n =2.0.0& r e q u e s t =GetCoverage& c o v e r a g e i d =ARMadayaTS& subset =E(415000 ,500000)& subset =N(4430000 ,4530000)& subset = t ( a 2010a06a01 a , a 2010a06a30 a )& f o r m a t = a p p l i c a t i o n / gml+xml  Listing 11.
< domainSet > < RectifiedGrid id = " ID " d i m e n s i o n = " 3 " srsName = " { resolver - prefix }/ crs - compound ?
1={ resolver - prefix }/ crs / EPSG /0/32638& 2={ resolver - prefix }/ crs / OGC /0.1/ ANSI - D " axisLabels ="E N t" uomLabels ="m m d" srsDimension ="3"> < limits > < GridEnvelope > < low > 15 130 151 </ low > < high > 100 230 180 </ high > </ GridEnvelope > </ limits > < axis Labels >i j k </ axis Labels > < origin > < Point id = " ID " > < pos > 415000 4430000 149536 </ pos > </ Point > </ origin > < offsetVector > 1000 0 0 </ offsetVector > < offsetVector >0 1000 0 </ offsetVector > < offsetVector >0 0 1 </ offsetVector > </ RectifiedGrid > </ domainSet >  Example of WCS query with time subsetting.
Listing 12 shows how this GML response would look like.
In the dZrst place, due to the regular spatio-temporal spacing between the coverage points, the returned element would be a gmlcov:RectifiedGridCoverage (though GML can support more complex irregular and warped topologies as well, see [45]).
The dZrst boundedBy section dedZnes the Envelope, that is the bounding box of the RoI, i.e.
the one that was specidZed in the useras request (Listing 11), a posteriori of possible trimmings over areas outside the coverage extent.
This part is optional in the response and its purpose is to provide a direct transcription of the returned extent.
Afterwards, there is the gml:domainSet which describes the topology of the retrieved data cube in much more detail, allowing the client host to recover the position of each single point of the dataset in both space and time.
As visible in both of these two blocks of GML, the stCRS dedZned in Listing 9 is referenced here in the @srsName attribute, with associated informative metadata regarding its number of dimensions (@srsDimension), associated labels (@axisLabel) and Units of Measure (UoM, @uomLabels) for each axis in the st-CRS.
The indexes that appear inside the gml:GridEnvelope element dedZne the neutral index-based structure of the grid, to describe its topology independently of the external st-CRS onto which it is mapped.
The grid indexes shown in the example are meaningful with respect to the WCS request in Listing.
11, and assume that i) the entire source coverage spans the area (4 AV 105 ,43 AV 105 )A(5AV105 ,46AV105 ) [m2 ] in the projected geographic space with a nominal resolution of 1A1 km2 , ii) the origin of the time series is the 1st of January 2010 (ANSI date 149385),  < rangeSet > < DataBlock > < rangeParameters / > < tupleList > [...] </ tupleList > </ DataBlock > </ rangeSet > < rangeType > [...] </ rangeType > </ gmlcov : R e c t i f i e d G r i d C o v e r a g e >  Listing 12.
GML description a spatio-temporal coverage.
and that iii) grid indexes of the complete topology start from 0.
The subsequent XML elements map the grid onto the domain-aware space of the st-CRS.
Firstly, the names ai j ka exposed in the axisLabels element are the labels associated to the grid dimensions and should not be confused with the labels listed in the @uomLabels attribute.
Thinking of a rotated grid into a cartesian coordinate system might help distinguishing the two categories.
The offsetVector elements indeed denote the inherent directional resolution for each one of the grid axis, by means of a 3D tuple of coordinates a which dZt in the 3D st-CRS a representing the endpoint of a vector starting from the  138 124  origin.
The spatio-temporal location of each grid point can then be recovered by starting from the origin and spanning the coverage with the offset vectors.
In the proposed response, we can see that the resolution is of 1000 km for the grid axes in the horizontal spatial component of the st-CRS, while it is of 1 day along time.
In case of weekly aggregates instead, we would have had the triplet {0,0,7} as offset vector along time.
It is again underlined that the UoMs associated with the tuplesa components in the offset vectors a and generally for any coordinate listed in the response a can either be read in the @uomLabels attributes or as well, if missing, in the GML dedZnitions of each single CRS (see @uom attribute in Listing.
8).
To conclude, the actual payload of the response (rangeSet) and its description (rangeType) were partially hidden with ellipsis in the example since not relevant here.
A demo of the proposed framework has been implemented and tested by means of Petascope a a Java implementation of OGC standards and the reference implementation of WCPS [46] a on top of the rasdaman Array DBMS [47].
R EFERENCES [1] J. Dozier and J. Frew, aEnvironmental informatics,a Annual Review of Environment and Resources, vol.
37, no.
1, 2012.
[2] S. Natali, A. Beccati, S. DaElia, M. Veratelli, P. Campalani, M. Folegani, and S. Mantovani, aMultitemporal data management and exploitation infrastructure,a in Analysis of Multitemporal Remote Sensing Images (Multi-Temp), 2011 6th International Workshop on the.
IEEE, 2011, pp.
217a220.
[3] G. Triebnig, A. Diamandi, R. Hall, E. Malnes, L. Marklund, S. MetsaEmaEki, T. Nagler, J. Pulliainen, H. Rott, C. Schiller et al., aCryoLand-GMES service snow and land ice-interoperability, service integration and user access,a Environmental Software Systems.
Frameworks of eEnvironment, pp.
341a348, 2011.
[4] B. Cuca, R. Brumana, M. Scaioni, and D. Oreni, aSpatial data management of temporal map series for cultural and environmental heritage,a International Journal of Spatial Data Infrastructure Research (IJSDIR), vol.
6, 2011.
[5] J. H. P. Oosthoek, A. P. Rossi, B. P., D. Misev, and P. Campalani, aPlanetary data: A workshop for users and software developers,a in Planetary Data: A Workshop for Users and Software Developers, June 2012.
VI.
C ONCLUSIONS We have presented a framework for Web services that enables a valid OGC-compliant embedding of time as a dimension into the coverage models offered by the GML schema dedZnitions.
The proposed model uses existing gml:TemporalCRS elements to augment the coordinate reference system (CRS) of a coverage from purely spatial to spatio-temporal; it can be generally applied to arbitrary time scales and resolutions, and the overall system complexity is relatively low.
The use of URIs as policy for CRSs referencing completes the picture of a coherent automated system, with no need of out-of-band handling of the temporal dimension.
Particular attention was put on the practical application of the framework to the OGC WCS and WCPS services, and concrete request/response examples were described.
These examples were also successfully implemented and tested over a Java-servlet/Array-DBMS architecture.
The proposed framework a under discussion by the OGC consortium [48] a makes a step forward towards an open interconnectedness and interoperability of Web services for spatio-temporal coverages.
Forthcoming applications in the context of the European EarthServer project [49] will accelerate further evaluation and testing phases, and will represent lighthouse services for the access and elaboration of time series of scientidZc datasets.
[6] P. Baumann, A. Dehmel, P. Furtado, R. Ritsch, and N. Widmann, aThe multidimensional database system rasdaman,a in ACM SIGMOD Record, vol.
27, no.
2.
ACM, 1998, pp.
575a577.
[7] P. CudreE-Mauroux, H. Kimura, K. Lim, J. Rogers, R. Simakov, E. Soroush, P. Velikhov, D. Wang, M. Balazinska, J. Becla et al., aA demonstration of SciDB: a science-oriented DBMS,a Proceedings of the VLDB Endowment, vol.
2, no.
2, pp.
1534a1537, 2009.
R [8] Open Geospatial Consortium (OGC), aGeospatial and location standards,a http://www.opengeospatial.org/, accessed on June 25, 2013.
[9] INSPIRE, aINSPIRE geoportal,a http://inspire-geoportal.ec.
europa.eu/, accessed on June 25, 2013.
[10] P. Baumann, P. Campalani, D. Misev, and J. Yu, aFinding my CRS: A systematic way of identifying CRSs,a in ACM SIGSPATIAL GIS, November 2012, pp.
71a78.
[11] F. Prandi, R. De Amicis, G. Conti, and A. Debiasi, aUse of OGC web standard for a spatio-temporal enabled SDI for civil protection,a in Proceedings of the 17th International Conference on 3D Web Technology.
ACM, 2012, pp.
105a 111.
[12] L. Bernard and A. Wytzisk, aA web-based service architecture for distributed spatiotemporal modeling,a in Proceedings of the 5th AGILE Conference on Geographic Information Science, 2002, pp.
25a27.
ACKNOWLEDGMENT The research leading to the results presented here has received funding from the European Communityas Seventh Framework Programme (EU FP7) under grant agreement n. 283610 aEuropean Scalable Earth Science Service Environment (EarthServer)a.
[13] J. Yu and P. Baumann, aOn the systematic generation of reference output for geo image services,a in Geoinformatics, 2011 19th International Conference on.
IEEE, 2011, pp.
1a6.
139 125  [32] T. Berners-Lee, L. Masinter, and M. McCahill, aUniform Resource Locators (URL),a RFC 1738 (Proposed Standard), Internet Engineering Task Force, Dec. 1994, obsoleted by RFCs 4248, 4266, updated by RFCs 1808, 2368, 2396, 3986, 6196, 6270.
[Online].
Available: http://www.ietf.org/ rfc/rfc1738.txt  [14] E. Pebesma, D. Cornford, G. Dubois, G. Heuvelink, D. Hristopulos, J. Pilz, U. StoEhlker, G. Morin, and J. SkA,ien, aINTAMAP: the design and implementation of an interoperable automated interpolation web service,a Computers & Geosciences, vol.
37, no.
3, pp.
343a352, 2011.
[15] B. GraEler and C. Stasch, aFlexible representation of spatiotemporal random dZelds in the model web,a in EGU General Assembly Conference Abstracts, vol.
14, 2012, p. 4617.
[33] OGC, aOGC Web Service Common Implementation SpecidZcation 2.0.0,a 2010.
[34] M. Grogan, aJSR-223 a Scripting for the JavaTM Platform.
Final Draft SpecidZcation, version 1.0,a Oct. 2006.
[16] R. Lake, aThe application of geography markup language (GML) to the geological sciences,a Computers & Geosciences, vol.
31, no.
9, pp.
1081a1094, 2005.
[17] OGC, aOGC Web Coverage Service (WCS) - Core,a 2010.
[35] J. de la BeaujardieEre, aWeb map service,a OpenGIS Web Map Server Implementation SpecidZcation, pp.
06a042, 2006.
[18] OGC, aOGC Web Coverage Processing Service (WCPS) Language Interface Standard,a 2009.
[36] aISO 19111:2007: Geographic information a Spatial referencing by coordinates,a 2007.
[19] M. F. Worboys, aA unidZed model for spatial and temporal information,a The Computer Journal, vol.
37, no.
1, pp.
26a 34, 1994.
[37] OGP, aGuidance Note 7, part 1 a Using the EPSG Geodetic Parameter Dataset,a 2011.
[Online].
Available: {http://www.epsg.org/}  [20] M. Wachowicz and R. G. Healey, aTowards temporality in GIS,a Innovations in GIS, vol.
1, pp.
105a115, 1994.
R Geography Markup Language (GML) [38] OGC, aOpenGIS Encoding Standard,a August 2007.
[21] R. H. GuEting, M. H. BoEhlen, M. Erwig, C. S. Jensen, N. A. Lorentzos, M. Schneider, and M. Vazirgiannis, aA foundation for representing and querying moving objects,a ACM Transactions on Database Systems (TODS), vol.
25, no.
1, pp.
1a42, 2000.
[39] G. Schadow and C. J. McDonald, aThe UnidZed Code for Units of Measure (UCUM),a http://unitsofmeasure.org/ucum.
html, 2012, accessed on June 25, 2013.
[40] S. Cox and S. Richard, aA formal model for the geologic time scale and global stratotype section and point, compatible with geospatial information transfer standards,a Geosphere, vol.
1, no.
3, pp.
119a137, 2005.
[22] M. A. Sakr and R. H. GuEting, aSpatiotemporal pattern queries,a Geoinformatica, vol.
15, no.
3, pp.
497a540, 2011.
[23] S. Steiniger and A. J.
Hunter, aFree and open source GIS software for building a spatial data infrastructure,a in Geospatial Free and Open Source Software in the 21st Century.
Springer, 2012, pp.
247a261.
[41] M. Sen and T. Duffy, aGeoSciML: Development of a generic geoscience markup language,a Computers & Geosciences, vol.
31, no.
9, pp.
1095a1103, 2005.
[42] B. Domenico, S. Nativi, J. Caron, L. Bigagli, and E. Davis, aA standards-based, web services gateway to netCDF datasets,a in Proc.
of AMSa22nd IIPS Conference, Atlanta, Georgia, abstr, no.
8.1, 2006.
[24] J. Blower, A. Gemmell, G. GrifdZths, K. Haines, A. Santokhee, and X. Yang, aA Web Map Service implementation for the visualization of multidimensional gridded environmental data,a Environmental Modelling and Software, 2013.
[43] C. Reed, aThe Open Geospatial Consortium and Web Services Standards,a Geospatial Web Services: Advances in information interoperability, pp.
1a16, 2011.
[25] Geography Department of Ghent University and CReSTIC, a4DArcheo,a http://sites.google.com/site/4darcheo/, 2012, accessed on June 25, 2013.
R Web Coverage Service Interface Standard [44] OGC, aOGC CRS Extension,a December 2011, (Draft document).
[26] E. Pebesma, aspacetime: Spatio-temporal data in R,a Journal of Statistical Software, vol.
51, no.
7, pp.
1a30, 2012.
R Geography Markup Language (GML) a [45] C. Portele, aOGC Extended schemas and encoding rules,a February 2012.
[27] P. B. eit, aPostTIME,a https://github.com/52North/PostTIME, 2012, accessed on June 25, 2013.
[46] A. AiordaEchioaie and P. Baumann, aPetascope: An opensource implementation of the OGC WCS geo service standards suite,a in ScientidZc and Statistical Database Management.
Springer, 2010, pp.
160a168.
[28] H. Butler, C. Schmidt, and D. Springmeyer, aSpatial Reference,a http://spatialreference.org, 2007, accessed on June 25, 2013.
[29] OGC, aDedZnition identidZer URNs in OGC namespace,a 2007.
[47] RASter DAta MANager (rasdaman), www.rasdaman.org, 2009, accessed on June 25, 2013.
[30] D. Misev, M. Rusu, and P. Baumann, aA semantic resolver for coordinate reference systems,a Web and Wireless Geographical Information Systems, pp.
47a56, 2012.
[48] OGC, aTemporalDWG web,a http://external.opengeospatial.
org/twiki public/TemporalDWG, accessed on June 25, 2013.
R Name Type SpecidZcation for CRSs,a 2012.
[31] OGC, aOGC  [49] EarthServer, aThe EarthServer Initiative,a //www.earthserver.eu/, accessed on June 25, 2013.
140 126  http:
Believing Change and Changing Belief Peter Haddawy  haddawy@cs.uwm.edu Department of Electrical Engineering and Computer Science University of Wisconsin-Milwaukee Milwaukee, WI 53201  Abstract  We present a rst-order logic of time, chance, and probability that is capable of expressing the relation between subjective probability and objective chance at dierent times.
Using this capability, we show how the logic can distinguish between causal and evidential correlation by distinguishing between conditions, events, and actions that 1) in	uence the agent's belief in chance and 2) the agent believes to in	uence chance.
Furthermore, the semantics of the logic captures commonsense inferences concerning objective chance and causality.
We show that an agent's subjective probability is the expected value of its beliefs concerning objective chance.
We also prove that an agent using this representation believes with certainty that the past cannot be causally in	uenced.
1 Introduction  The ability to distinguish evidential from causal correlation is crucial for carrying out a number of dierent types of problem solving.
To perform diagnosis we must be able to identify the factors that caused an observed failure in order to determine how to repair the faulty device.
If we cannot distinguish causal from evidential correlation, we may end up treating the symptoms rather than the causes of the fault.
When reasoning about plans, an agent may have goals that involve achieving a specied state of the world, or achieving a specied state of knowledge, or a combination of both.
In order to eectively reason about such goals, we need to distinguish actions that in	uence the state of the world from those that only in	uence our state of knowledge of the world.
In this paper we extend Haddawy's 3] logic of time, chance, and action L by adding a subjective probability operator.
We show how the resulting rst-order logic of time, chance, and probability, L , can distinguish between causal and evidential correlation by distinguishing between conditions and events that 1) in	uence the agent's belief in chance and 2) the agent believes to in	uence chance.
Furthermore, the semantics of the logic captures some commonsense inferences tca  tcp  This work was partially supported by NSF grant #IRI9207262.
concerning causality and the relation between objective chance and subjective probability.
We prove that an agent's subjective probability is the expected value of its beliefs concerning objective chance.
We also prove that an agent whose beliefs are represented in this logic believes with certainty that the past cannot be causally in	uenced.
On the other hand, an agent can execute actions that in	uence its subjective beliefs about the past.
2 Ontology  We brie	y present the ontology of the logic, which includes the representation of time, facts, events, objective chance, and subjective probability.
For simplicity of exposition, we will omit the representation of actions and will treat them as events.
For a more detailed development of chance, facts, events, and actions see 3].
Time is modeled as a collection of world-histories, each of which is one possible chronology or history of events throughout time.
A totally ordered set of time points provides a common reference to times in the various world-histories.
We represent an agent's beliefs with subjective probabilities.
Since beliefs may change with time, subjective probability is taken relative to a point in time.
We represent it by dening a probability distribution over the set of world-histories at each point in time.
So an agent can have beliefs concerning temporally qualied facts and events.
We represent causal correlation with objective chance.
Objectively, actions and events can only aect the state of the world at times after their occurrence.
That is to say, at each point in time, the past is xed| no occurrences in the world will cause it to change but at each point in time the future might unfold in any number of ways.
So relative to any point in time, only one objectively possible past exists, but numerous possible futures exist.
Thus we represent objective chance by dening a future-branching tree structure on the world-histories and by dening probabilities over this tree.
Like subjective probability, chance is taken relative to a point in time.
By dening chance in this way, conditions in the present and past relative to a given time are either certainly true of certainly false.
So actions and other events can only aect the chances of future facts and events.
This property distinguishes objective chance from subjective probability.
Subjectively the past can be uncertain but objectively it is completely determined.
The present characterization of objective chance is not to be confused with the frequentist interpretation of probability 10, 11] which is often called objective probability.
Frequentist theories dene probability in terms of the limiting relative frequency in an innite number of trials or events.
The current work does not rely on relative frequencies for its semantics.
Rather it models objective chance by formalizing the properties that characterize objective chance.
Thus while frequentist theories have diculty assigning meaningful probabilities to unique events like a sh jumping out of the water at a given location and time, our model has no problem in assigning nontrivial probabilities to such events.
Our model of objective chance and subjective probability is motivated by the subjectivist theories of objective chance 6, 8, 9], which dene chance in terms of properties that one would expect a rational agent to believe objective chance to possess.
This distinction between the frequentist theory of probability and our conception of objective chance puts the present work in sharp contrast with Bacchus's 1] logic of statistical probabilities which models exactly relative frequency type probabilities.
One telling dierence between the two logics is that Bacchus's logic Lp assigns only probability 0 or 1 to unique events (more precisely, to all closed formulas).
The present logic can assign any chance value to unique events in the future, while events in the past are assigned only chance values 0 or 1, as required by our denition of objective chance.
It is reasonable to expect the subjective beliefs of a rational agent concerning objective chance to obey certain constraints.
Skyrms 7, Appendix 2] has argued for a constraint he calls Millers' principle.
This asserts that an agent's subjective belief in a proposition, given that he believes the objective chance to be a certain value, should be equal to that value.
Skyrms argues that this is a plausible rule for assimilating information about chance.
We will call this relation the subjective/objective Miller's principle.
The world is described in terms of facts and events.
Facts tend to hold and events tend to occur over intervals of time.
So facts and events are associated with the time intervals over which they hold or occur in the various world-histories.
Facts are distinguished from events on the basis of their temporal properties.
A fact may hold over several intervals in any given world-history and if a fact holds over an interval then it holds over all subintervals of that interval.
Events are somewhat more complex than facts.
First, one must distinguish between event types and event tokens.
An event type is a general class of events and an event token is a specic instance of an event type.
Event tokens are unique individuals { the interval over which an event token occurs is the unique interval associated with the event token and an event token can occur at most once in any world-history.
The present work deals with event types, which for brevity are simply referred to as events.
3 The Logic of Time, Chance, and Probability 3.1 Syntax  The language of L contains two predicates to refer to facts and event types occurring in time: HOLDS (FA t1 t2) is true if fact FA holds over the time interval t1 to t2, and OCCURS (EV t1  t2) is true if event EV occurs during the interval t1 to t2 .
Henceforth we will use the symbol t, possibly subscripted, to denote time points , fi, and  to denote formulas and  and  to denote probability values.
In addition to the usual rst-order logical operators, the language contains two modal operators to express subjective probability and objective chance.
The operators are subscripted with a time since according to the ontology subjective probability and objective chance are taken relative to a point in time.
We write P () to denote the subjective probability of  at time t and we write pr () to denote the objective chance of  at time t. Probability is treated as a sentential operator in the object language.
So the probability operators can be arbitrarily nested and combined with one another, allowing us to write complex sentences like: \I believe there was a one in a million chance of my winning the lottery, yet I won."
P 3 (pr 2 (OCCURS (win t1 t2)) = 10;6^ OCCURS (win t1 t2)) = 1 where t1 < t2 < t3.
We also allow conditional probability sentences such as P (jfi) = , which is interpreted as shorthand for P ( ^ fi) =   P (fi).
The language of L is fully rst-order, allowing quantication over time points, probability values, and domain individuals.
A formal specication of the syntax is provided in the full paper 2].
tcp  t  t  t  t  t  t  t  tcp  3.2 Semantics  We describe only the more interesting aspects of the models of L .
The models are completely specied in the full paper.
A model is a tuple hW D, FN, NFN, PFN, FRL, ERL, NRL, FA, EVENTS, EV, R, X , PR , PR , F i, where: fi W is the set of possible world-histories, called worlds.
fi D is the non-empty domain of individuals.
fi FA is the set of facts, a subset of 2(<<) .
A fact is 0 a set of htemporal interval, worldi pairs: fhht1 t1 i w1i ::: hht  t0 i w ig.
If fa is a fact and hht1  t2i wi 2 fa then fa holds throughout interval ht1  t2i in world-history w. fi EVENTS is the set of event tokens, a subset of (<<)  W .
An event token is a single htemporal interval, worldi pair.
fi EV is the set of event types, a subset of 2EVENTS .
An event type is a set of event tokens: fhht1 t01 i w1i ::: hht  t0 i w ig.
If ev is an event and hht1  t2i wi 2 ev then ev occurs during interval ht1 t2i in world-history w. tcp  o  s  W  n  n  n  n  n  n  1.
HOLDS (rf (trm 1  ::: trm ) ttrm1  ttrm 2)]] = true i hh ttrm 1 ]   ttrm 2] i wi 2 F (rf )(trm 1]  :::  trm ] ): 2.
OCCURS (re(trm 1  ::: trm ) ttrm 1  ttrm 2)]] = true i hh ttrm 1 ]   ttrm 2] i wi 2 e for some e 2 F (re)(trm 1 ]  ::: trm ] ): 0 3.  prttrm ()]] =  o ttrm] (fw 2 R ttrm] :  ] = trueg).
4.
Pttrm ()]] =  s ttrm] (fw0 :  ] = trueg).
Mwg  n Mwg  Mwg  Mwg  Mwg  n  Mwg  n Mwg  Mwg  Mwg  Mwg  n  Mwg  Mwg  w  w  Mwg  w  0  Mw g  Mwg  0  Mw g  Mwg  Figure 1: Semantic denitions fi R is an accessibility relation dened on <W W .
R(t w1 w2) means that world-histories w1 and w2 are indistinguishable up to and including time t. If R(t w1 w2) we say a world-history w2 is Raccessible from w1 at time t. The set of all worldhistories R-accessible from w at time t will be designated R .
For each time t, the R partition the world-histories into sets of equivalence classes indistinguishable up to t. fi X is a -algebra over W 1 , containing all the sets corresponding to w's in the language, as well as all R-equivalence classes of world-histories.
fi PR is the objective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution  o dened over X .
fi PR is the subjective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution  s dened over X .
Given the models described above, the semantic definitions for the well-formed formulas can now be dened.
Denotations are assigned to expressions relative to a model, a world-history within the model, and an assignment of individuals in the domain to variables.
The denotation of an expression  relative to a model M and a world-history w, and a variable assignment g is designated by  ] .
Figure 1 shows the less familiar semantic denitions.
The remainder are provided in the full paper.
w t  w t  o  w t  s  w t  Mwg  3.2.1 Semantic Constraints  In order to obtain the properties discussed in the ontology, we impose eight constraints on the models.
The future-branching temporal tree is dened in terms of the R relation over world-histories.
To capture the property that the tree does not branch into the past, we say that if two world-histories are indistinguishable up to time t2 then they are indistinguishable up to any earlier time: (C1) If t1t2 and R(t2 w1 w2) then R(t1 w1 w2).
A -algebra over W is a class of subsets that contains W and is closed under complement and countable union.
1  Since R just represents the indistinguishability of histories up to a time t, for a xed time R is an equivalence relation, i.e., re	exive, symmetric, and transitive: (C2) R(t w w) If R(t w1 w2) then R(t w2 w1) If R(t w1 w2) and R(t w2 w3) then R(t w1 w3) As mentioned earlier, facts and events dier in their temporal properties.
This distinction is captured by the following two semantic constraints.
If a fact holds over an interval, it holds over all subintervals, except possibly at the endpoints: (C3) If t1 t2 t3t4 t1 6= t3  t2 6= t4  fa 2 FA and hht1 t4i wi 2 fa then hht2  t3i wi 2 fa : An event token occurs only once in each world-history: (C4) If evt 2 EVENTS , hht1 t2i wi 2 evt, and hht3  t4i wi 2 evt then t1 = t3 and t2 = t4 .
If two worlds are indistinguishable up to a time then they must share a common past up to that time.
And if they share a common past up to a given time, they must agree on all facts and events up to that time.
To enforce this relationship, we impose the constraint that if two world-histories are R-accessible at time t, they must agree on all facts(events) that hold(occur) over intervals ending before or at the same time as t: (C5) If t0 t1 t2 and R(t2  w1 w2) then hht0  t1i w1i 2 A i hht0  t1i w2i 2 A, where A is a fact or event.
The ontology discussed two desired characteristics of objective chance.
The rst is that the chance at a time t be completely determined by the history up to that time.
The second desired characteristic is that the chance of the present and past should be either zero or one, depending on whether or not it actually happened.
These two properties follow as meta-theorems from the following two constraints: (C6) For all 0 X 2 X  tt0 and w w0 such that R(t w w )   (R ) > 0 !
(X ) =   (X jR ).
w t  w t  0  w t0  0  w t  w t0  0  (C7)   (R ) > 0.
Meta-theorem 1 The probability of the present and w t  w t  past is either zero or one.
(R ) = 1 w t  w t  Theorem 7 Objective Miller's Principle (OMP)  1.
(R ) > 0 (C7) 2.
(R ) =   (R jR ) Modus Ponens: (C6),1 3.
(R ) = 1 def of c-prob w t w t w t  w t w t w t  w t  w t  w t  tcp  t  Dening the probabilities in this way makes good intuitive sense if we look at the meaning of R. R designates the set of world-histories that are objectively possible with respect to w at time t. It is natural that the set of world-histories that are objectively likely with respect to w at time t should be a subset of the ones that are possible.
w t  Meta-theorem 2 If two worlds are indistinguishable  up to time t then they have identical probability distributions at that time.
If R(t w w0) then   (X ) =   (X ) w t  1.
2.
3.
4.
5.
0  w t  (R ) > 0 (C2), (C7) (R ) =   (X jR ) Modus Ponens: (C6),1 (X jR ) =   (X jR ) (C2) (R ) = 1 Meta-theorem 1 (X ) =   (X ) def of c-prob  w t w t w t w t 0 w t  0  w t 0 w t  w t  w t  w t  0  w t  w t  0  w t  w t  In the ontology, we argued that subjective probability and objective chance should be related to one another by Millers' principle.
This relation is enforced by the following constraint, which says that the probability of a set of worlds X , given some R equivalence class, should just be the objective chance in that equivalence class.
(C8)  s (X jR ) =  o (X ) w t  w t  w t  4 Theorems  We rst provide several simple theorems that will be used in later proofs.
Then we prove two forms of Miller's principle and provide two associated expected value properties.
Proofs not provided here appear in the full paper.
Theorem 3 From  $ fi infer pr () = pr (fi): t  t  Theorem 4 Stronger sentences have lower probability.
From  !
fi infer P ()  P (fi).
Theorem 5 Certainty cannot be conditioned away from.
P ( ^ fi) = P (fi) !
P ( ^ fi ^  ) = P (fi ^  ) Theorem 6 The present and past are objectively certain.
Let be a fact or event: HOLDS ( t  t0 ) or OCCURS ( t  t0 ) then 8t t  t0 (t0  t) !
pr ( ) = 0 _ pr ( ) = 1] t  t  t  t          t  t      t  All instances of the following sentence schema are valid in L .
8 t0 t1 (t0  t1 ) !
pr 0 ( j pr 1 () = ) =  Proof:    t  The semantic constraints on objective chance give us a version of Miller's principle that relates objective chance at dierent times.
It says that the chance of a sentence  at a time, given that the chance of  at the same or a later time is , should be .
t  We rst prove an expected value property and then use it to prove Miller's principle.
Let t t0 be two time points t  t0 and consider the R-equivalence classes of worlds at time t0 .
Let the variable r range over these equivalence classes.
The r form a partition of W , so the probability of a set X can be written as the integral over this partition: Z  o (X ) =  o (X jr) o (dr)  Since the history up to time t0 determines the probability at time tZ0, this can be written as  o (X ) =  o (X ) o (dr)  where  o denotes the probability at time t0 in equivalence class r. Since the probability at a given time is assumed to be constant over all worlds in an Requivalence class, the probability at a given time is the expected value Z of the probability at any future time:  o (X ) =  o (X ) o (dw0 ): Next we show that Miller's principle is valid in the probability models.
By the expected value property,  o (ZX \ fw0 :  o (X ) = g) =  o (X \ fw0 :  o (X ) = g) o (dw00): Now, by semantic constraints (C6) and (C7) it follows that 8 w 2fw0 :  o (X ) = g  o (fw0 :  o (X ) = g) = 1 8 w 62fw0 :  o (X ) = g  o (fw0 :  o (X ) = g) = 0: So we can restrict the integral to the set fw0 :Z o (X ) = g: =  o (X \ fw0 :  o (X ) = g) o (dw00): w t  w t  r  W  r  W  w t  w t  r t0  w t  r t0  w t0  w t  0  w t  W  w t  w t0  w t0  0  00  w t0  0  w t  W  w t0  w t0  w t0  0  w t0  0  w t0  w t0  w t0  0  0  0  w  00  w t0  t0 0 w 0 fiow0 X t  f  ( )=g  :  0  w t  And by the above property again  o (XZ\ fw0 :  o (X ) = g) = , so =   o (dw00): w t0  00  w t0  f  0  ( )=g  0 w 0 fiow0 X t  :  w t  =    o (fw0 :  o (X ) = g): By the semantic denitions it follows that P ( ^ P () = ) =   P (P () = ): And by a slight generalization of the proof it follows that 8(t  t0) P ( ^ P ()  )    P (P ()  ): 2 From the Objective Miller's Principle it follows directly that current chance is the expected value of current chance applied to current or future chance.
w t  t  w t0  t0  0  t  t  t0  t0  t  t0  Theorem 8 Objective Expected Value Property  All instances of the following sentence schema are valid in L .
8  t1 t2 (t1  t2 ) !
pr 1 (pr 2 ()  )   !
pr 1 ()     ] tcp  t  t  t  As discussed in the ontology, the current subjective probability of a sentence, given that the current or future chance is some value should be that value.
The following theorem shows that this property follows from the semantics of the logic.
Theorem 9 Subjective/Objective Miller's Principle (SOMP)  All instances of the following sentence schema are valid in L .
8 t0 t1(t0  t1 ) !
P 0 (jpr 1 () = ) =  Proof: We rst prove an expected value property and tcp  t  t  then use it to prove Miller's principle.
Let t t0 be two 0 time points t  t and consider the R-equivalence classes of worlds at time t0 .
Let the variable r range over these  equivalence classes.
The r form a partition of W , so the probability of a set X can be written as the integral over this partition:   s (X ) =  Z  w t  r   s (X jr) s (dr) w t    W  w t  Z  w t  r   o (X ) s (dr) r t    W  w t  where  o denotes the objective chance at time t in equivalence class r. Since the chance at a given time is assumed to be constant over all worlds in an Requivalence class, the subjective probability at any time is the expected value of the subjective probability applied to the objective chance at that time: r t   s (x) =  Z  w t   o (X ) s (dw0) w t  W  0  w t  Next we show that the Subjective/Objective Miller's principle is valid in the probability models.
By the above subjective/objective expected value property,  s (ZX \ fw0 :  o (X ) = g) =  o (X \ fw0 :  o (X ) = g) s (dw00) By Objective Miller's Principle,  s (XZ\ fw0 :  o (X ) = g) =   o (fw0 :  o (X ) = g) s (dw00) w t  w t0  w t  0  00  w t0  0  w t  W  w t  w t0  w t  0  00  w t0  W  0  w t  Finally, by the subjective/objective expected value property,  s (X \ fw0 :  o (X ) = g) =  s (fw0 :  o (X ) = g) So by the semantic denitions it follows that 8t t0 (t  t0 ) !
P (jpr () = ) =  w t  w t0  w t  0  w t0  t  0  t0  t  t0  Theorem 10 Subjective/Objective Value Property  Expected  All instances of the following sentence schema are valid in L .
8  t1 t2 (t1  t2) !
P 1 (pr 2 ()  )   !
P 1 ()     ] tcp  t  t  t  5 Distinguishing Evidential and Causal Correlation  We wish to distinguish between two situations in which an agent may believe that two conditions are correlated.
An agent may believe that two conditions are correlated because one is simply evidence for another and an agent may believe that they are correlated because one causes the other.
Let stand for the formula HOLDS ( t  t0 ) or OCCURS ( t  t0 ) and let !
stand for the formula HOLDS (fi t  t0 ) or OCCURS (fi t  t0 ).
We represent evidential correlation as correlation in the subjective probability distribution, which is the standard approach in Bayesian decision theory.
Denition 11 We say that !
is evidence for or   By semantic constraint (C8), this can be written as   s (X ) =  And by a slight generalization of the proof it follows that 8t t0 (t  t0 ) !
P (jpr ()  )   2 From the subjective/objective Miller's principle it follows directly that subjective probability is the expected value of current subjective probability applied to present or future chance.
          against i Pnow ( j !)
= 6 Pnow ( )      (1) It follows from this denition that !
is not evidence for or against i Pnow ( j !)
= Pnow ( ) We represent causal correlation by reference to the objective chance distribution.
We represent an agent's belief that !
causally in	uences by saying that there is some value for the objective chance of such that the agent's belief in given the objective chance of just before !
holds or occurs is not the same as the agent's belief given also knowledge of !.
In other words, knowledge of !
overrides knowledge of the objective chance of .
Denition 12 We say that !
is a cause of i 9 Pnow ( j pr ( ) =  ^ !)
6= : (2) Note that this does not necessarily imply that Pnow ( j!)
6= Pnow ( ).
Thus we may have causal correlation without evidential correlation and, conversely, we may have evidential correlation without causal correlation.
It follows from this denition that !
is not a cause of i 8 Pnow ( j pr ( ) =  ^ !)
= : t  t  5.1 Example  We now present an example demonstrating the use of the denitions and theorems.
We wish to describe the following situation.
You have a coin that may be biased 3:1 towards heads or 3:1 towards tails.
You believe there is an equal probability of each.
You can observe the coin.
If the coin looks shiny, this increases your belief that the coin is biased towards heads.
You also have a magnet that you can use to in	uence the outcome of the coin toss.
Turning on the magnet biases the coin more toward heads.
We can describe the situation with the following set of sentences in which \heads" is the event of the coin landing heads, \shiny" is the event of the coin being observed to be shiny, and \magnet" is the fact that the magnet is on.
(now < t0 < t1 < t2 < t3 < t4 ) Turning on the magnet in	uences the chance of heads.
Pnow (OCCURS (Heads t2 t3)j (3) pr 1 (OCCURS (Heads t2 t3)) = 3=4 ^ HOLDS (Magnet t1  t4)) = 7=8 Pnow (OCCURS (Heads t2 t3)j (4) pr 1 (OCCURS (Heads t2 t3)) = 1=4 ^ HOLDS (Magnet t1  t4)) = 1=2 The probability that the coin is biased toward heads and the probability that the coin is biased toward tails are equal.2 Pnow (pr 1 (OCCURS (Heads t2 t3)) = 3=4) = (5) Pnow (pr 1 (OCCURS (Heads t2 t3)) = 1=4) = 1=2 Observing the coin doesn't in	uence the chance of heads.
(6) 8 t (t > now) !
Pnow (OCCURS (Heads t2 t3) j pr (OCCURS (Heads t2 t3)) =  ^ OCCURS (Shiny t0  t2)) =  Observing the coin gives us knowledge of its bias.
Pnow (pr 0 (OCCURS (Heads t2 t3)) = 3=4 j (7) OCCURS (Shiny t0  t2)) = 5=8 Pnow (pr 0 (OCCURS (Heads t2 t3)) = 1=4 j (8) OCCURS (Shiny t0  t2)) = 3=8 Turning on the magnet does not give us knowledge of the coin's bias.
8 Pnow (pr 1 (OCCURS (Heads t2 t3)) =  j (9) HOLDS (Magnet t1  t4)) = Pnow (pr 1 (OCCURS (Heads t2 t3)) = ) The coin is either biased toward heads or toward tails.
8t pr (OCCURS (Heads t2 t3 )) = 3=4 _ (10) pr (OCCURS (Heads t2 t3)) = 1=4 (11) t  t  t  t  t  t  t  t  t  t  t  It would be more appropriate to say that our belief that the current chance is 3/4 or 1/4 is 1/2 and that in the absence of events that will inuence the chance, chance will remain unchanged till time t1 .
Such an inference would require some kind of theory of persistence, which is beyond the scope of this paper.
2  Using this information, we can make several useful inferences.
First we can derive the unconditional probability that the coin will land heads.
From (5) by SOMP we have Pnow (OCCURS (Heads t2 t3)) = (12) (1=2)(3=4) + (1=2)(1=4) = 1=2 Next, we can use the above information to derive the probability that the coin will come up heads given that it is observed to be shiny.
Instantiating (6) with  = 3=4 and t = t0 and multiplying the result by (7) we get Pnow (OCCURS (Heads t2 t3)^ (13) pr 0 (OCCURS (Heads t2 t3)) = 3=4 j OCCURS (Shiny t0  t2)) = (5=8)(3=4) = 15=32 And instantiating (6) with  = 1=4 and t = t0 and multiplying the result by (8) we get Pnow (OCCURS (Heads t2 t3)^ (14) pr 0 (OCCURS (Heads t2 t3)) = 1=4 j OCCURS (Shiny t0  t2)) = (3=8)(1=4) = 3=32 From (10), (13), and (14) by the law of total probability we get Pnow (OCCURS (Heads t2 t3) j (15) OCCURS (Shiny t0  t2)) = 9=16 We can also derive the probability of heads given that we activate the magnet.
From (3), (5), and (9) we get Pnow (OCCURS (Heads t2 t3)^ (16) pr 2 (OCCURS (Heads t2 t3)) = 3=4 j HOLDS (Magnet t1 t4)) = (1=2)(7=8) = 7=16 From (4), (5), and (9) we get Pnow (OCCURS (Heads t2 t3)^ (17) pr 2 (OCCURS (Heads t2 t3)) = 1=4 j HOLDS (Magnet t1 t4)) = (1=2)(1=2) = 1=4 From (10), (16), and (17) by the law of total probability we get Pnow (OCCURS (Heads t2 t3) j (18) HOLDS (Magnet t1 t4)) = 11=16 t  t  t  t  5.2 The temporal ow of causality  Using our denition of causal in	uence and SOMP we can now show that an agent whose beliefs are represented with L believes that the past cannot be in	uenced.
tcp  Theorem 13 Let be a fact or event: 0 0  HOLDS ( t  t ) or OCCURS ( t  t ) and let !
be a fact or event: HOLDS (fi t  t0 ) or OCCURS (fi t  t0 ).
Then all instances of the following sentence schema are valid in L .
8 t t  t0  t  t0 (t0  t ) ^ (t  t ) !
P ( jpr ( ) =  ^ !)
=              tcp    t      t              Proof: We prove a slightly more general result of which  the above sentence is an instance.
By the Subjective/Objective Miller's Principle, 8 t t0 t  t0 (t0  t0 ) ^ (t  t0) !
(19) P ( ^ pr ( ) = ) =   P (pr ( ) = ) Since valid formulas have probability one, it follows by Theorem 6 that, 8 t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(20) P ( ^ pr ( ) =  ^ pr ( ) = 0 _ pr ( ) = 1]) =   P (pr ( ) =  ^ pr ( ) = 0 _ pr ( ) = 1]) Since pr ( ) = 0 and pr ( ) = 1 are mutually exclusive, we have 8 t t0 t  t0 (t0  t0 ) ^ (t  t0) !
(21) P ( ^ pr ( ) =  ^ pr ( ) = 0) + P ( ^ pr ( ) =  ^ pr ( ) = 1) =   P (pr ( ) =  ^ pr ( ) = 0) +   P (pr ( ) =  ^ pr ( ) = 1) Now we have three cases to consider: i)  = 0, ii)  = 1, iii) 0 <  < 1.
      t0  t            t0  t  t0  t0  t  t0  t  t0  t0  t0  t0  t0      t  t0  t  t0    t0 t0  t  t0  t0  t  t0  t0  Case i)  Expression (21) reduces to (22) 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 0) = 0  P (pr ( ) = 0) So by Theorem 4 and universal generalization, 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(23) P ( ^ pr ( ) = 0 ^ !)
= 0  P (pr ( ) = 0 ^ !)
          t0  t      t0  t        t0  t  t0  t  Case ii)  Expression (21) reduces to (24) 8t t0 t  t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 1) = P (pr ( ) = 1) So by Theorem 5 and universal generalization, 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(25) P ( ^ pr ( ) = 1 ^ !)
= P (pr ( ) = 1 ^ !)
      t0  t    t          t0  t  t0  t  t0  Case iii)  For 0 <  < 1, P (pr ( ) = ) = 0.
So by Theorem 4 and universal generalization, 8 t t0 t  t0  t  t0 (26) 0 0 0 (t  t ) ^ (t  t ) ^ (0 <  < 1) !
P ( ^ pr ( ) =  ^ !)
= P (pr ( ) =  ^ !)
Therefore we have proven that the following sentence is valid (27) 8 t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
P ( jpr ( ) =  ^ !)
=  from which it follows that the past cannot be in	uenced.
2 t0  t            t0  t    t    t0    t      t0  6 Related Work  Three outstanding subjective theories of objective chance from the philosophical literature are those of van Fraassen 9], Lewis 6], and Skyrms 7].
van Fraassen's model of objective chance is more constrained than Lewis's model which is more constrained than Skyrms's model.
Thus, in van Fraassen's model, chance has more inherent properties than in either Lewis's or Skyrms's models.
van Fraassen's theory is the only one of the three that is cast in a temporal framework.
All three are semantic theories and do not provide logical languages.
The model of objective chance used in L is based on van Fraassen's 9] model of objective chance.
He presents a semantic theory that models subjective probability and objective chance, using a future-branching model of time points.
van Fraassen places two constraints on objective chance: 1.
The chance of a past is either 0 or 1, depending on whether or not it actually occurred.
2.
Chance at a time is completely determined by history of the world up to that time.
From these assumptions, he shows the following relation between subjective probability and objective chance P (X jY ) = E C (X )] where P is the subjective probability at time t, C is the objective chance at time t, E is the expected value given Y , and provided the truth of Y depends only on the history up to t. This relation entails both Miller's principle and Lewis's principal principle, discussed below.
Note that van Fraassen does not show that a similar relation holds between objective chances at dierent times.
In van Fraassen's models, objective chance can change with time but truth values cannot.
Lewis's 6] theory of objective chance is based on his assertion that ... we have some very rm and denite opinions concerning reasonable credence (subjective probability) about chance (objective chance).
These opinions seem to me to afford the best grip we have on the concept of chance.
He describes a number of intuitive relationships between subjective probability and objective chance and shows that these are captured by his principal principle: Pr(Ajpr (A) =  ^ E ) =  where Pr is subjective probability, pr is objective chance, and E is any proposition compatible with pr (A) =  and admissible at time t. The interesting thing here is the proposition E .
The constraint that E be compatible with pr (A) =  means that Pr(E ^ pr (A) = ) > 0.
Admissibility is less readily dened.
Lewis does not give a denition of admissibility but he does characterize admissible propositions as \the sort of information whose impact on credence about outcomes comes entirely by way of credence about the chances of those outcomes."
So objective chance is invariant with respect to conditioning on tcp  t  Y  t  t  t  Y  t  t  t  t  admissible propositions.
This concept of invariance under conditioning is the central notion of Brian Skyrms's theory of objective chance.
Skyrms 7] works with the notion of resiliency.
A probability value is resilient if it is relatively invariant under conditionalization over a set of sentences.
The resiliency of Pr(q) being  is dened as 1 minus the amplitude of the wiggle about : The resiliency of Pr(q) being  is 1;maxj; Pr (q)j over p1  ::: p , where the Pr 's are gotten by conditionalizing on some Boolean combinationof the p 's which is logically consistent with q. Skyrms then denes propensity (objective chance) as a highly resilient subjective probability.
Independent of his resiliency notion, Skyrms requires that propensities and subjective probabilities be related by Miller's principle: Pr(Ajpr(A) = ) =  where Pr is a subjective probability and pr is a propensity.
He shows that Millers' principle entails that subjective probabilities are equal to the expectation of the subjective probabilities applied to the objective probabilities.
But Skyrms 7, p158] points out that, counter to intuition, independence in every possible objective distribution does not imply independence in the subjective distribution.
This observation provided the motivation for our use of the two probabilities to distinguish causal from evidential correlation.
Halpern 4, 5] presents a probability logic that can represent both statistical and subjective probabilities.
Statistical probabilities represent proportions over the domain of individuals, while propositional probabilities represent degrees of belief.
The two probability operators in the language can be nested and combined freely with other logical operators.
So the language is capable of representing sentences like \The probability is .95 that more than 75% of all birds can 	y."
The models for the language contain a domain of individuals, a set of possible worlds, a single discrete probability function over the individuals, and a single discrete probability function over the possible worlds.
The rst probability function is used to assign meaning to the statistical probability operator, while the second is used to assign meaning to the propositional probability operator.
Although he does not place constraints within the logic on the relation between the two probabilities, he does discuss a form of Miller's principle that relates subjective and objective probabilities.
His version of the principle states that \for any real number r0 the conditional probability of (a), given that the probability of a randomly chosen x satises  is r0, is itself r0."
He points out that this could be used as a rule for inferring degrees of belief from statistical information.
Bacchus 1] presents a logic essentially identical to that of Halpern.
He goes further than Halpern in exploring the inference of degrees of belief from statistical probabilities.
According to his principle of direct inference, an agent's belief in a formula is the expected j  n  i  j  value with respect to the agent's beliefs of the statistical probability of that formula, given the agent's set of accepted objective assertions.
References  1] F. Bacchus.
Representing and Reasoning With Probabilistic Knowledge.
MIT Press, Cambridge, Mass, 1990.
2] P. Haddawy.
Believing change and changing belief.
Technical Report TR-94-02-01, Dept.
of Elect.
Eng.
& Computer Science, University of Wisconsin-Milwaukee, February 1994.
Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu.
3] P. Haddawy.
Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action, volume 770 of Lecture Notes in Arti	cial Intelligence.
Springer-Verlag, Berlin, 1994.
4] J.Y.
Halpern.
An analysis of rst-order logics of probability.
In Proceedings of the International Joint Conference on Arti	cial Intelligence, pages 1375{1381, 1989.
5] J.Y.
Halpern.
An analysis of rst-order logics of probability.
Arti	cial Intelligence, 46:311{350, 1991.
6] D. Lewis.
A subjectivist's guide to objective chance.
In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 267{298.
D. Reidel, Dordrecht, 1980.
7] B. Skyrms.
Causal Necessity.
Yale Univ.
Press, New Haven, 1980.
8] B. Skyrms.
Higher order degrees of belief.
In D.H. Mellor, editor, Prospects for Pragmatism, chapter 6, pages 109{137.
Cambridge Univ.
Press, Cambridge, 1980.
9] B.C.
van Fraassen.
A temporal framework for conditionals and chance.
In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 323{340.
D. Reidel, Dordrecht, 1980.
10] J. Venn.
The Logic of Chance.
MacMillan, London, 1866.
(new paperback edition, Chelsea, 1962).
11] R. von Mises.
Probability, Statistics and Truth.
Allen and Unwin, London, 1957.
2013 20th International Symposium on Temporal Representation and Reasoning  A New Approach To Abstract Reachability State Space of Time Petri Nets Kais Klai Institut TELECOM SudParis CNRS UMR Samovar, France kais.klai@lipn.univ-paris13.fr  Naim Aber UniversiteE Paris 13, Sorbonne Paris CiteE LIPN, CNRS UMR, France naim.aber@lipn.univ-paris13.fr  raising the problem of handling an infinite number of states.
In fact, the set of reachable states of the TPN is generally infinite due to the infinite number of time successors a given state could have.
Two main approaches are used to treat this state space: region graphs [1] and the state class approach [3].
The other methods [2], [21], [4], [9], [5], [14], [6], [10] are either refinements or improvements of these basic approaches.
The objective of these representations is to yield a state-space partition that groups concrete states into sets of states with similar behaviour with respect to the properties to be verified.
These sets of states must cover the entire state space and must be finite in order to ensure the termination of the verification process.
In this work, we propose a new contribution for the abstraction and the verification of finite TPN-based timed systems.
This paper is organised as follows: In Section II, some preliminaries about TPNs and the corresponding semantics are recalled.
In Section III, we define the Timed Aggregate Graph (TAG) associated with a TPN and we discuss the main preservation results of the TAG-based approach.
Section IV relates our work to existing approaches.
In Section V, we discuss the experimental results obtained with our implementation compared to two well-known tools, namely Romeo [8] and TINA [5].
Finally, a conclusion and some perspectives are given in Section VI.
AbstractaTime Petri nets (TPN model) allow the specification of real-time systems involving explicit timing constraints.
The main challenge of the analysis of such systems is to construct, with few resources (time and space), a coarse abstraction preserving timed properties.
In this paper, we propose a new finite graph, called Timed Aggregate Graph (TAG), abstracting the behaviour of bounded TPNs with strong time semantics.
The main feature of this abstract representation compared to existing approaches is the encoding of the time information.
This is done in a pure way within each node of the TAG allowing to compute the minimum and maximum elapsed time in every path of the graph.
The TAG preserves runs and reachable states of the corresponding TPN and allows for verification of both event- and state-based properties.
Keywords-Real Time Systems; Time Petri Nets; State Space Abstraction; Model Checking of Timed Properties;  I. I NTRODUCTION Time Petri nets are one of the most used formal models for the specification and the verification of systems where the explicit consideration of time is essential, such as communication protocols, circuits, or real-time systems.
The main extensions of Petri nets with time are time Petri nets [15] and timed Petri nets [19].
In the first, a transition can fire within a time interval whereas, in the second, time durations can be assigned to the transitions; tokens are meant to spend that time as reserved in the input places of the corresponding transitions.
Several variants of timed Petri nets exist: time is either associated with places (p-timed Petri nets), with transitions (t-timed Petri nets) or with arcs (a-timed Petri nets) [20].
The same holds for time Petri nets [7].
In [18], the authors prove that p-timed Petri nets and t-timed Petri nets have the same expressive power and are less expressive than time Petri nets.
Several semantics have been proposed for each variant of these models.
Here we focus on t-time Petri nets, which we simply call TPNs.
There are two ways of letting the time elapse in a TPN [18].
The first way, known as the Strong Time Semantics (STS), is defined in such a manner that time elapsing cannot disable a transition.
Hence, when the upper bound of a firing interval is reached, the transition must be fired.
In contrast, the Weak Time Semantics (WTS) does not make any restriction on the elapsing of time.
For real-time systems, the dense time model (where time is considered in the domain RaL0 ) is the only possible option, 1530-1311/13 $26.00 AS 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.22  Laure Petrucci UniversiteE Paris 13, Sorbonne Paris CiteE LIPN, CNRS UMR, France laure.petrucci@lipn.univ-paris13.fr  II.
P RELIMINARIES  AND  BASIC N OTATIONS  A t-time Petri net (TPN) is a P/T Petri net [17] where a time interval [tmin ;tmax ] is associated with each transition t. Definition 1: A TPN is a tuple N = P, T, Pre, Post, Ifi where: aV P, T, Pre, Postfi is a P/T Petri net where: a P is a finite set of places; a T is a finite set of transitions with P aS T = 0/ ; a Pre : T aa NP is the backward incidence mapping; a Post : T aa NP is the forward incidence mapping; aV I : T aa N A (N aS {+a}) is a time interval function s.t.
I(t) = (tmin ,tmax ) (tmin a$?
tmax ), where tmin (resp.
tmax ) is the earliest (resp.
latest) firing time of transition t. A marking of a TPN is a function m : P aa N where m(p), for a place p, denotes the number of tokens in p. A marked TPN is a pair N = N 1 , m0 fi where N 1 is a TPN and m0 is 103 117  a corresponding initial marking.
A transition t is enabled by a marking m iff m aL Pre(t) and Enable(m) = {t a T : m aL Pre(t)} denotes the set of enabled transitions in m. If a transition ti is enabled by a marking m, then a(m,ti ) denotes the set of newly enabled transitions [2].
Formally, a(m,ti ) = {t a T | (maPre(ti )+Post(ti )) aL Pre(t)aSS(maPre(ti )) < Pre(t)}.
If a transition t is in a(m,ti ), we say that t is newly enabled by the successor of m by firing ti .
Dually, a(m,ti ) = {t a T | (m a Pre(ti ) + Post(ti )) aL Pre(t) aSS (m a Pre(ti )) aL Pre(t)} is the set of oldly enabled transitions.
The possibly infinite set of reachable markings of N is denoted Reach(N ).
If Reach(N ) is finite we say that N is bounded.
The semantics of TPNs can be given in terms of Timed Transition Systems (TTS) [12] which are usual transition systems with two types of labels: discrete labels for events (transitions) and positive real labels for time elapsing (delay).
States of the TTS are pairs s = (m,V ) where m is a marking and V : T aa RaL0 aS {aL} a time valuation.
In the following, s.m and s.V denote the marking and the time valuation respectively of a state s. If a transition t is enabled in m then V (t) is the elapsed time since t became enabled, otherwise V (t) = aL.
Given a state s = (m,V ) and a transition t, t is said to be firable in s iff t a Enable(m) aSS V (t) = aL aSS tmin a$?
V (t) a$?
tmax .
Definition 2 (Semantics of a TPN): Let N = P, T, Pre, Post, I, m0 fi be a marked TPN.
The semantics of N is a TTS S N = Q, s0 , afi where: 1) Q is a (possibly infinite) set of states 2) s0 = (m0 ,V0 ) is the initial state such that:  0 if t a Enable(m0 ) at a T, V0 (t) = aL otherwise  transition must fire within its firing interval unless disabled by the firing of others.
Second, a state change occurs either by the firing of transitions or by time elapsing: The firing of a transition may change the current marking while the time elapsing may make some new transitions firable.
When a deadlock marking is reached, then only elapsing time is possible and the system remains in the same state.
Given a TPN N and the corresponding TTS S N , a path Ia1 Ia2 s1 aa .
.
.
, where Iai a (T aS RaL0 ), is a run of D = s0 aa S N iff (si , Iai , si+1 ) aa for each i = 0, 1, .
.
.
.
The length of a run D can be infinite and is denoted by | D |.
The possibly infinite set of runs of S N is denoted [S N ].
Without loss of generality, we assume that for each non empty run Ia1 Ia2 D = s0 aa s1 aa .
.
.
of a STS corresponding to a TPN, there do not exist two successive labels Iai and Iai+1 belonging both to RaL0 .
Then, D can be written, involving the reachable (d1 ,t1 ) (d2 ,t2 ) m1 aa .
.
.
where di is the markings of N , as D = m0 aa time elapsed at marking mia1 before firing ti .
In order to associate a run D of S N with a run of N , denoted P (D), we define the following projection function, where  denotes the concatenation operator between paths and Di , for i = 0, 1 .
.
.
, denotes the suffix of D starting at state si .
aSS s0 .m if | D |= 0 aS aS aS a" s .m(0,Ia1 )  P (D1 ) if Ia1 a T aa 0 P (D) = (Ia1 ,Ia2 ) 2 aS s0 .m aa  P (D ) if Ia1 a RaL0 aSS | D |aL 2 aS aS aS Ia1  P (D1 ) if Ia1 a RaL0 aSS | D |= 1 s0 .maa  3) a a Q A (T aS RaL0 ) A Q is the discrete and continuous transition relations: a) the discrete transition relation: t at a T : (m,V ) a a (m ,V  ) iff:  In this subsection, we propose to abstract the reachability state space of a TPN using a new graph called Timed Aggregate Graph (TAG) where nodes are called aggregates and are grouping sets of states of a TTS.
The key idea behind TAGs is that time information is encoded inside aggregates.
The time information includes the time the system is able to stay in the aggregate as well as a dynamic interval associated with each enabled transition.
The first feature allows to encapsulate the delay transitions of the corresponding TTS (the arcs of a TAG are labeled with transitions of the corresponding TPN only), while the second allows to dynamically update the earliest and latest firing times of enabled transitions.
It also allows to maintain the relative differences between the firing times of transitions (diagonal constraints).
Before we formally define the TAG and illustrate how the attributes of an aggregate are computed, let us first formally define aggregates.
Definition 3 (Timed Aggregate): A timed aggregate associated with a TPN N = P, T, Pre, Post, Ifi is a 4-tuple a = (m, E, h, H), where: aV m is a marking;  III.
A BSTRACTION  OF A  TPN S TATE S PACE  A.
Timed Aggregate Graph  aSS t a Enable(m) aSS m = m a Pre(t) + Post(t) aS aS aS aS a" tmin a$?
V (t) a$?
tmax aSS if t  a a(m,t) a" 0 aS )  a T : V  (t  ) = aS V (t if t  a a(m,t) at aS aS aS aS aL otherwise b) the continuous transition relation: ad a RaL0 , d (m,V ) a a (m ,V  ) iff: aSS at a Enable(m), V (t) + d a$?
tmax aS aS aS aS a" m = m at a T :  aS aS V (t) + d if t a Enable(m); aS aS aS V  (t) = V (t) otherwise.
The above definition requires some comments.
First, the delay transitions respect the STS semantics: an enabled  118 104  p1  p2  t1 [1; 2]  t2 [1; 1]  p1  aV aV  p3  t1 [1; 1] t2 [2; 2] t3 [0; 1]  Figure 1.  aV  p2  p1  p2  t1 [1; 2]  t2 [2;a]  3) I' a A A T A A is the transition relation such that: for an aggregate a = m, h, H, Efi, a transition t s.t.
t, Iat , I,t fi a E and an aggregate a = m , h , H  , E  fi, (a,t, a ) a I' iff the following holds: a) m = m a Pre(t) + Post(t) b) Iat a$?
H c) at  , Iat  , I,t  fi a E,   a Ia  ) aL (t tmin > tmax a (tmin a Iat ) a (tmin min a t  ) tmax d) E  = E1 S aS E2 , where:   ,t  fi} aV E1 = t  aa(a,t) {t  ,tmin max S   aV E2 = t  aa(a,t) {t , Iat  a H, I,t  a max(0, Iat )fi} e) h = mint  ,Iat  ,I,t  fiaE  (max(0, Iat  )) f) H  = mint  ,Iat  ,I,t  fiaE  (I,t  ) Given an aggregate a = m, h, H, Efi and a transition t a t T , t is said to be enabled by a, denoted by aaa , iff: (1) a(Iat , I,t ) a (Z aS {aa}) A (N aS {+a}) s.t.
(t, Iat , I,t ) a E and Iat a$?
H, and, (2) there is no other transition t  , enabled by a.m, that should be fired before t. In fact, the first condition is sufficient if the static interval of t overlaps with any other transitionas interval but is not sufficient when tmin is greater  than tmax for some other transition t  .
The firing of t from a leads to a new aggregate a = m , h , H  , E  fi whose attributes are computed by analysing the sets a (a,t) and a (a,t).
This is the key idea behind the TAG.
 aV The elements of E are processed by taking the transitions that are enabled by m and computing their earliest and latest firing times depending on their membership in a (a,t) and a (a,t).
For each transition t  a Enable(a.m), if t  is newly enabled, then its dynamic earliest and latest firing times are statically defined by   tmin and tmax respectively.
Otherwise, let t  , Iat  , I,t  fi a  a.E and t , Iat , I,t fi a a .E, then the maximum time elapsed by the system at a.m (i.e., a.H) is subtracted from Iat  and the minium time is substracted from I,t  .
Indeed, the more the system can stay in a.m the less it can stay in a .m (and vice versa).
Thus, the earliest firing time of t starting from a is max(0, Iat  a a.H) while its latest firing time is I,t  a max(0, Iat ).
aV The computation of a .h (resp.
a .H) is ensured by taking the minimum of the dynamic earliest (resp.
latest) firing time of enabled transitions.
Three TPN Examples  E = {t, Iat , I,t fi | t a Enable(m), Iat a (Z aS {aa}) aSS I,t a N aS {+a}} is a set of enabled transitions each asssociated with two time values; h = mint,Iat ,I,t fiaE (max(0, Iat )): the minimum time the system can stay in the aggregate a; H = mint,Iat ,I,t fiaE (I,t ): the maximum time the system can stay in the aggregate a.
Each aggregate is characterised by three attributes that are computed dynamically: a marking m, a set E of enabled transitions and two times h and H. Each enabled transition t is associated with two time values: Iat represents the minimum time the system should wait before firing t and I,t represents the maximum time the system can delay the firing of t. Note that Iat can be negative which means that t can be fired immediately.
Otherwise, Iat represents the the earliest firing time of t. Starting from this aggregate, the firing of t can occur between max(0, Iat ) and H. In the rest of this paper, Iat will be abusively called the dynamic earliest firing time of t and I,t its dynamic latest firing time.
Finally, the h and H attributes represent the minimum and the maximum time, respectively, the system can spend at the current aggregate.
As for states of a TTS, the attributes of an aggregate a are denoted by a.m, a.E, a.h and a.H. Now, we are ready to formally define the TAG associated with a marked TPN N .
A TAG is a labeled transition system where nodes are timed aggregates.
A TAG has an initial aggregate, a set of actions (the set of transitions of N ) and a transition relation.
The initial aggregate is easily computed by considering static information of the TPN.
In fact: (1) the marking attribute is the initial marking of N , (2) the minimum (resp.
maximum) time the system can stay in the initial aggregate is equal to the minimum of the earliest (resp.
latest) firing time of the enabled transitions and, (3) each enabled transition t is firable between tmin and tmax .
Definition 4 (Timed Aggregate Graph): A TAG associated with a TPN N = P, T, Pre, Post, I, m0 fi is a tuple G = A , T, a0 , I'fi where: 1) A is a set of timed aggregates; 2) a0 = m0 , h0 , H0 , E0 fi is the initial timed aggregate s.t.
: a) m0 is the initial marking of N b) h0 = mintaEnable(m0 ) (tmin ) c) H0 = mintaEnable(m0 ) (tmax ) d) E0 = {t,tmin ,tmax fi | t a Enable(m0)}  B. Equivalence relation between aggregates According to Definition 4, the dynamic earliest firing time of a transition can decrease infinitely which could lead to an infinite state space TAG.
In the following, we define a relation allowing to identify equivalent aggregates.
This equivalence relation will be used in the construction of a TAG so that each newly built aggregate is not explored as long as an already built equivalent aggregate has been.
Definition 5: Let a and a be two time aggregates.
a is said to be equivalent to a , denoted by a aA a , iff:  119 105  1) a.h = a .h, a.H = a .H and a.m = a .m 2) a(t, Iat , I,t fi, t, Iat , I,t fi) a (a.E A a .E), I,t = I,t :  a0 aggregate a0 a1 a2 a3 a4 a5  a) Iat = Iat or, b) max(0, Iat ) = max(0, Iat ) and i) ii) iii) iv)  t    (tmax   ) or, aT : < tmin ) a" (tmax < tmin   ) or, at a (T \ Enable(a.m)) : (tmax < tmin   at a (T \ Enable(a.m)) : tmax < tmin aSS  ) aSS (Ia a$?
t  ) or, (Iat a$?
tmax t max  at  a Enable(a.m) : tmax < tmin aSS   ) aSS (Ia a Ia ) ((Iat a Iat  ) a$?
(tmax a tmin t t   (tmax a tmin )) a" ((Iat  a Iat ) = (Iat a Iat )).
(h,H) (1,1) (0,0) (0,1) (0,0) (0,1) (0,0)  E {t1 , 1, 2fi, t2 , 1, 1fi} {t1 , 1, 2fi, t2 , a1, 0fi} {t1 , 0, 1fi, t2 , 1, 1fi} {t1 , 1, 2fi, t2 , 0, 1fi} {t1 , 0, 2fi, t2 , 1, 1fi} {t1 , a1, 0fi, t2 , 1, 1fi}  t1 t2  a1  t1  a5  t2  t1  t2  a2 t1  t2 t1  a3  aggregate a0 a1 a2 a3 a4  a$?
Informally, the previous definition guarantees that two equivalent aggregates have the same behavior.
First, point 1 guarantees that a and a have the same marking and the same minimum and maximum stay time.
Second, each enabled transition t should have the same latest firing time (point 2).
Then, if the earliest firing time of a given enabled transition t in a is different from its earliest firing time in a , then this should not influence the future behavior starting from a and a .
First, the earliest firing times of t in a and a must be negative so that the firing of t from a and a do not lead to different aggregates.
This condition is sufficient  if there is no transition t  such that tmax < tmin (point 2(b)i),   or if any transition t s.t.
tmax < tmin is not enabled by a (point 2(b)ii).
In the opposite case, other conditions must be fulfilled: First, if there exists a transition t  such that  tmax < tmin but t  is not enabled by a (point 2(b)iii), then  Iat and Iat should be both less or equal to tmax (i.e.
t is firable anyway in both aggregates).
Second, if t  is enabled by a (point 2(b)iv), either t is firable by both aggregates a  a Ia  ) is equal to and a or the difference (tmin a Iat ) a (tmin t    (tmin a Iat ) a (tmin a Iat  ).
Figure 2 illustrates the TAGs corresponding to the first and the third TPNs of Figure 1.
The TAG associated with the second TPN contains 18 aggregates and 38 edges, and is not presented here because of lack of space.
In the first TAG, the marking associated with aggregates is omitted since it is always the same as the initial one.
Although, the three models of Figure 1 are quite simple, they are representative enough to explain the TAG construction.
Indeed, in the first one the transitions intervals overlap, while the case of disjoint intervals is considered through the second model.
Finally, the third model illustrates the case of an infinite latest firing time.
More significant examples are considered in Section V. In the following, we establish that the TAG, built under the previous equivalence relation between aggregates, associated with a bounded TPN is finite.
For this, we show that the number of its aggregates is bounded and compute this bound.
The following two lemmas establish two preliminary results before proving the finiteness of a TAG in Theorem 1.
Lemma 1: Let N be a TPN and let G = A , T, a0 , I'fi be the corresponding TAG.
Let a be an aggregate of G  marking (1,1) (1,0) (1,0) (1,1) (1,0)  (h,H) (1,2) (0,0) (1,2) (0,2) (0,2)  E {t1 , 1, 2fi, t2 , 2, afi} {t1 , a1, 0fi} {t1 , 1, 2fi} {t1 , 1, 2fi, t2 , 0, afi} {t1 , a1, 2fi}  Figure 2.  t2  t2 t1 t1  a2  a4  a1  a0 t1 t1  t1  a3 t2  a4  TAGs of Figure 1  and let t a Enable(a.m).
Then, the number of possible dynamic intervals [Iat ; I,t ] associated with t in non equivalent aggregates is at most equal to Bt where   if t  a T : tmax < tmin bt Bt = bt a ct otherwise where bt = (tmin + 1)a (tmax + 1)a (tmin + (tmin a (tmin + 1)/2))  )+1  <t and ct = Maxt  aT : tmax (t a tmax min min Proof: The possible intervals are obtained by all the possible combinations of the earliest and latest firing times Iat and I,t , minus the invalid ones (i.e.
those where Iat > I,t and those where Iat = tmin aSS Iat = I,t ).
In the first case, we  consider that there is no transition t  such that tmax < tmin .
Since negative values of Iat are equivalent to 0 the possible values of Iat are {tmin ,tmin a 1, .
.
.
, 0} (i.e tmin + 1 possible values).
Moreover, I,t a {tmax ,tmax a 1, .
.
.
, 0} (i.e tmax + 1 possible values) and there are tmin + (tmin a (tmin + 1)/2) invalid intervals.
The first tmin intervals are invalid by construction of the TAG since I,t can never reach Iat by decrement (Ia < H).
Moreover, there are (tmin a (tmin + 1)/2) intervals where Iat > I,t , and these are invalid as well.
In the second case, the previous reasoning is also valid, but one has to consider the difference between t and t  .
Following the definition of the equivalence relation between aggregates, this difference is ignored when it allows the firing of t.  Thus, only tmin a tmax + 1 values are to be distinguished (for   t having the minimal tmax < tmin ) and should be combined with the number of possibilities obtained in the first case.
Lemma 2: Let N be a TPN, let G = A , T, a0 , I'fi be the corresponding TAG and let m a Reach(N ).
The number of aggregates in G having m as marking is at most equal to asa2Enable(m) (atas Bt ).
Proof: Let m be a marking, the number of aggregates having m as a marking are different with respect to the E attribute.
There are as many possibilities of partitionning enabled transitions into oldly and newly enabled as subset of Enable(m).
For a given subset s of Enable(m) there are at most atas Bt (using Lemma 1) possible time intervals for  120 106  I,l+1tn+1 aL 0, thus Ial+1tn+1 a$?
I,l+1tn+1 .
By iterating this result we establish that Iantn+1 a$?
I,ntn+1 and that I,ntn+1 aL 0.
Moreover, it is clear that I,ia1tn+1 aL I,itn+1 (for all i = l + 1 .
.
.
n).
In particular, we have 0 a$?
Iantn+1 a$?
I,ntn+1 a$?
I,na1tn+1 a$?
AV AV AV a$?
I,ltn+1 = tn+1max .
Thus, the system can stay at mn for Iantn+1 .
Furthermore, the fact that tn+1 is firable at an implies that it is also firable in mn leading to mn+1 , whose marking is the same as an+1.
Let us show now that it is possible to stay at mn+1 for an+1 .H (or any d a$?
an+1 .H) time units.
We can use the same reasoning as above to show that for any transiton t enabled by mn+1 , Ian+1t a$?
tmax .
Since an+1.H = mintaEnable(mn+1 ) I,t we can deduce that the system can stay at mn+1 an+1.H (or any lower value) time units.
its transitions.
The two previous lemmas lead to the following theorem.
Theorem 1: Given a TPN N , if N is bounded then the corresponding TAG is finite and its number of aggregates is at most equal to amaReach(N ) asa2Enable(m) ataEnable(m) Bt .
C. Preservation Results In this section, we establish the main results of this paper: The TAG is an exact representation of the reachability state space of a TPN.
For each path in the TAG (resp.
in the TPN) it is possible to find a path in the TPN (resp.
TAG) involving the same sequence of transitions and where the time elapsed within a given state is between the minimum and the maximum stay time of the corresponding aggregate.
Theorem 2: Let N be a TPN and let G = A , T, a0 , I'fi be the TAG associated with N .
Then, for any path D = t1 tn a1 aa .
.
.
aa an in the TAG, ad a RaL0 s.t.
d a$?
an .H, a0 aa (d1 ,t1 ) (dn ,tn ) d m1 aa .
.
.
aa mn aa in N , there exists a run D = m0 aa s.t.
mi = ai .m and aia1 .h a$?
di a$?
aia1 .H, for i = 1 .
.
.
n. t1 tn Proof: Let D = a0 aa a1 aa .
.
.
aa an and let d a RaL0 satisfying d a$?
an .H.
We denote by Iait (resp.
I,it ) the maximum between 0 and the dynamic earliest firing time (resp.
the dynamic latest firing time) of a transition t at aggregate ai .
Let us prove that the path (Ia0t ,t1 )  Theorem 3: Let N be a TPN and let G = A , T, a0 , I'fi be the TAG associated with N .
Then dn+1 (dn ,tn ) (d1 ,t1 ) (d2 ,t2 ) m1 aa .
.
.
aa mn aa , with di a RaL0 , for aD = m0 aa t1 tn an s.t.
aia1 .h a$?
di a$?
i = 1 .
.
.
n + 1, aD = a0 aaa1 aa .
.
.
aa aia1 .H, mi = ai .m, for i = 0 .
.
.
n and dn+1 a$?
an .H.
dn+1 (d1 ,t1 ) (d2 ,t2 ) (dn ,tn ) m1 aa .
.
.
aa mn aa be a path Proof: Let D = m0 aa of N , with di a RaL0 , for i = 1 .
.
.
n + 1.
Let us prove by induction on the length of D the existence of a path D in the TAG satisfying Theorem 3. aV | D |= 0: Obvious since m0 = a0 .m (by construction) and since d1 is less or equal to mintaEnable(m0 ) tmax which is exactly the value of a0 .H.
aV Assume Theorem 3 true for any path D s.t.
| D |a$?
n. (d1 ,t1 ) (d2 ,t2 ) (d dn+2 (dn ,tn ) ,tn+1 ) m1 aa .
.
.
aa mn n+1 Let D = m0 aa aa mn+1 aa t1 t2 tn be a path of length n + 1.
Let D = a0 aaa1 aa .
.
.
aaan be the path in the TAG associated with the n-length prefix of D (by the induction hypothesis).
We denote by Iait (resp.
I,it ) the maximum between 0 and the dynamic earliest firing time (resp.
the dynamic latest firing time) of a transition t at aggregate ai .
Since an .m = mn and dn+1 a$?
an .H, tn+1 is also enabled by an (by construction) and can be fired leading to an+1 whose marking is the same as mn+1 .
Let us now show that dn+2 a$?
an+1.H.
If Enable(mn+1) = 0/ then mn+1 is a deadlock state and so is an+1 and dn+1 < an+1 .H = +a.
Otherwise, let t a Enable(mn+1) let 1 a$?
k a$?
n + 1 be the largest integer, satisfying t aa (mk ,tk+1 ).
The fact dn+2 implies that an+1 that mn+1 aa i=k di a$?
tmax , then that dn+1 a$?
tmax a ani=k di .
By proving that di aL Iaiti+1 for all i = k .
.
.
n, we can deduce that dn+1 a$?
tmax a ani=k Iaiti+1 = I,n+1t .
This result holds for any enabled transition t then dn+1 a$?
mintaEnable(mn+1 ) (I,n+1t ) = an+1 .H.
Finally, let us prove that di aL Iaiti+1 for all i = k .
.
.
n. Let k a$?
i a$?
n, if Iaiti+1 = 0 then di aL Iaiti+1 .
Otherwise, let 1 a$?
l a$?
i be the highest integer value, if any, satisfying ti+1 aa (ml ,tl ) (if such a value does not exist then l = 0).
Then aij=l d j aL ti+1min (since ti+1 is fired from  (Iana1 ,tn )  tn d 1 m1 aa .
.
.
aa mn aa satisfies the required rem0 aa sult.
The particularity of this path is that the firing of each transition ti is performed at its dynamic earliest firing time.
We proceed by induction on the length of D. Note first that, aia1 .h a$?
Iaia1ti and Iaia1ti a$?
aia1 .H (by construction), for i = 1 .
.
.
n. aV | D |= 0: Since, m0 = a0 .m, a0 .H is the minimum value of the latest firing time of all transitions enabled by m0 d .
and a0 .h a$?
d a$?
a0 .H.
Thus m0 aa t1 tn an and aV Assume that for any path a0 aaa1 aa .
.
.
aa for any d a RaL0 satisfying d a$?
an .H, the path  (Ia0t ,t1 )  (Iana1 ,tn )  (Ia0t ,t1 )  (Iana1 ,tn )  tn d 1 m1 aa .
.
.
aa mn aa is a run of N .
m0 aa tn+1 t1 t2 tn Let D = a0 aaa1 aa .
.
.
aaan aa an+1 be a path of length n + 1.
Since an .h a$?
Iantn+1 a$?
an .H, we can use the induction hypothesis to exhibit a path  Iant  tn n+1 1 m0 aa m1 aa .
.
.
aa mn aa .
We show now that it is possible to complete this path by firing tn+1 from mn (after a delay Iantn+1 at this state).
Note first that tn+1 is enabled by mn (since mn = an .m).
Let l (with l < n) be the greatest integer, such that tn+1 aa (ala1 ,tl ), then tn+1 ,tn+1min ,tn+1max fi a al .E.
Moreover, ai = l + 1 .
.
.
n, tn+1 , Iaitn+1 , I,itn+1 fi a ai .E with Iaitn+1 = max(0, Iaia1tn+1 a aia1 .H) and I,itn+1 = I,ia1tn+1 a Iaia1ti .
We know by construction that Iaia1ti a$?
aia1 .H (condition for firing ti at aia1 ) (for all i = l + 1 .
.
.
n).
Using the fact that Ialtn+1 a$?
I,ltn+1 and the fact that Ialtl+1 a$?
al .H a$?
I,ltn+1 , we can deduce that Ialtn+1 a al .H a$?
I,l+1tn+1 = (I,ltn+1 a Ialtl+1 ) and that  121 107  mi ) which means that di aL ti+1min a aia1 j=l d j .
Using the induction hypothesis d j > a ja1 .H for all j = l .
.
.
i a 1, then di aL max(0, (ti+1min a aia1 j=l a ja1 .H)) = Iaiti+1 .
the bounds of time intervals.
Lime and Roux also used TPNs to model system behavior [14].
They used the state class approach to build a timed automaton that preserves the behaviour of the TPN using as few clock variables as possible.
The resulting model is then verified using the UPPAAL tool [13].
However, even though UPPAAL can answer about quantitative temporal properties, it can only verify a subset of TCTL.
Adding a new transition to measure elapsed time was proposed in [6] to perform TCTL modelchecking in TPNs.
Using this transition, TCTL formulae are translated into CTL formulae.
Then a ZBG for TPN is refined leading to a graph called Atomic Zone Based Graph (AZBG) that preserves CTL properties.
Unlike the TAG, in all existing approaches, the time information does not appear explicitly in nodes.
This limitation, in turn leads to additional and complex calculations such as: the manipulation of DBM to encode the zones (for zones-based approaches) and the classes (for stateclass based approaches), the approximations to counter the problem of unbounded transitions, conversion of graphs to timed automata (using UPPAAL) to model check properties, etc.
In our work the time information is encoded within the aggregates allowing to check time properties just by browsing the graph, which has a significant impact on the construction complexity.
The encoding of the timing information in the aggregates is such that the minimum and maximum elapsed time in every path of the TAG can be computed.
Another difference with these approaches is that every TAG preserves the runs of the corresponding TPNs as well as the reachable states, which allows the preservation of both event- and state-based (linear and branching) logics.
Using the above result one can use the TAG associated with a TPN in order to analyse both event and state based properties.
In particular, we can check whether a given marking (resp.
transition) is reachable (resp.
is firable) before (or after) a some time.
IV.
R ELATED WORK This section reviews the most well-known techniques, proposed in the literature, that abstract and analyse the state space of real-time systems described by means of TPN.
Abstraction techniques aim at constructing, by removing some irrelevant details, a contraction of the state space of the model, which preserves properties of interest.
The existing abstraction approaches mainly differ in the state agglomeration criteria, the characterisation of states and state classes (interval states or clock states) and the kind of preserved properties.
The States Class Graph (SCG) [3] was the first method of state space representation adapted to TPNs.
A class (m, D) is associated with a marking m and a time domain D represented by a set of inequalities over variables.
The variables represented in the SCG are the firing time intervals of enabled transitions.
The SCG allows for the verification of some TPN properties like reachability and boundness.
However, it preserves the linear time properties only.
To address this limitation, a refinement of the method was proposed in [21], in the form of a graph called Atomic States Class Graph (ASCG).
The authors use a cutting of state class by adding linear constraints so that each state of an atomic class has a successor in all the following classes.
With this improvement, they are able to verify CTLa properties on TPN, but with the limitation that the time intervals of transitions are bounded.
A new approach for the construction of atomic classes was proposed in [4] and allows the verification of CTLa without restriction on time intervals.
The state class approach is implemented in a software tool called TINA [5].
The Zones Based Graph (ZBG) [9] is another approach allowing to abstract the TPN state space.
This approach is inspired by the Region Graph (RG) [1] technique, initially introduced for timed automata.
In practice, the number of regions is too large for an effective analysis, thus, the regions are grouped into a set of zones.
A zone is a convex union of regions and can be represented by a DBM (Difference Bound Matrix).
In [9], the clocks of transitions are directly encoded within the zones.
This allows to verify temporal and quantitative properties but not CTLa properties.
As for timed automata, a disadvantage of the method is the necessary recourse to approximation methods (k-approximation or kxapproximation) in the case where the infinity is used in  V. E XPERIMENTAL RESULTS Our approach for building TAG-TPN was implemented in a prototype tool (written in C++), and used for experiments in order to validate the sizes of the graphs generated by the approach.
Note that the prototype was not optimised for time efficiency yet, therefore no timing figures are given in this section.
All results reported in this section have been obtained on 2.8 gigahertz Intel with four gigabytes of RAM.
The implemented prototype allowed us to have first comparison with existing approaches with respect to the size of obtained graphs.
We used the TINA tool to build the SCGs, ROMEO tool for the ZBGs and our tool for the TAGs.
We tested our approach on several TPN models and we report here the obtained results.
The considered models are representative of the characteristics that may occur in a TPN, such as: concurrency, synchronisation, disjoint firing intervals and infinite firing bounds.
The first two models (Figure 3(a) and Figure 3(b)) are two parametric models where the number of processes can be increased.
In Figure 3(a), the number of self loops (pn a tn a pn ) is increased while in Figure 3(b) the number of processes,  122 108  Parameters Nb.
prod/cons 1 2 3 4 5 6 7 8 9 10 Nb.
self-loops 1 2 3 4 5 Nb.
processes 1 2 3 4 5 6 7 Nb.
processes 1 2 3 4 5 6 7 8  SCG (with Tina) (nodes / arcs)  ZBG (with Romeo) TAG-TPN (nodes / arcs) (nodes / arcs) TPN model of producer/consumer 34 / 56 34 / 56 34 / 56 748 / 2460 593 / 1 922 407 / 1 255 4 604 / 21891 3 240 / 15 200 1 618 / 6 892 14 086 / 83 375 9 504 / 56 038 3 972 / 20 500 31 657 / 217 423 20 877 / 145 037 8 175 / 48 351 61 162 / 471 254 39 306 / 311 304 15 157 / 99 539 107 236 / 907 708 67 224 / 594 795 26 113 / 186 363 175 075 / 1 604 319 107 156 / 1 044 066 42 503 / 324 600 270 632 / 2 655 794 161 874 / 1 718 104 66 103 / 534 055 400 648 / 4 175 413 234 398 / 2 687 147 99 036 / 839 011 TPN example with concurrency (Figure 3(a)) 39 / 72 40 / 74 39 / 72 471 / 1 296 472 / 1 299 354 / 963 6 735 / 25 056 6 736 / 25 060 2 745 / 9 888 119 343 / 563 040 119 344 / 563 045 19 488 / 87 375 2 546 679 / 14 564 016 ?/?
130 911 / 701 748 TPN example with synchronization (Figure 3(b)) 1/2 2/4 1/2 13 / 35 14 / 38 13 / 35 157 / 553 158 / 557 118 / 409 2 245 / 10 043 2 246 / 10 048 915 / 3 909 3 9781 / 21 7681 39 782 / 217 687 6 496 / 33 071 848 893 / 5 495 603 848 894 / 5 495 610 43 637 / 258 051 ?/?
?/?
282 514 / 1.90282e+06 Fischer protocol 4/4 4/4 4/4 18 / 29 19 / 32 20 / 32 65 / 146 66 / 153 80 / 171 220 / 623 221 / 652 308 / 808 727 / 2 536 728 / 2 615 1 162 / 3 645 2 378 / 9 154 2 379 / 10 098 4 274 / 15 828 7 737 / 24 744 7 738 / 37 961 15 304 / 66 031 25 080 / 102 242 25 081 / 139 768 53 480 / 265 040 Table I E XPERIMENTATION RESULTS  whose behavior is either local, by transition ti , or global, by transition t0 , is increased.
In addition to these two illustrative examples, we used two other well known parametric TPN models.
The first one [11] represents a composition of producer/consumer models by fusion of a single buffer (of size 5).
The second (adapted from [16]) is Fischeras protocol for mutual exclusion.
for the producers/consumers models show that the TAG yields better abstraction (linear order) than the SCG and the ZBG approaches.
Each time a new module of producer/consumer is introduced, the size of graphs increases for all three approaches.
However, the TAG achieves a better performance than the two other approaches.
For the TPN of Figure 3(a), the obtained results show that the size of the TAG exponentially increases when the parallelism occurs in the structure of TPN.
This is also the case also for the ZBG and the SCG methods, and we can see that our method behaves better when we increment the self-loop structures in the model.
The ZBGas and the SCGas executions have aborted due to a lack of memory when the number of selfloops was equal to 5.
The number of edges of the obtained graphs follows the same proportion.
In the synchronisation pattern exmaple, our approach also behaves.
Indeed, with, 1, 2 and 3 processes, the sizes of the obtained graphs are almost similar with the three approaches.
But, from 4 synchronised processes, the size of the SCGs and the ZBGs increase exponentially, leading to a state explosion with 7 processes, whereas the TAGs have been computed  p1 p4 t1 [1; 5]  p5 p1  t3 [1; 5] p2  p3  p2 t0 [1; 5]  t4 [1; 5] t5 [1; 5]  t2 [1; 5]  t1 [1; 5]  (a) concurrency  (b) synchronisation  Figure 3.  t2 [1; 5]  TPN models used in the experiments  Table I reports the results obtained with the SCG, the ZBG and the TAG-TPN approaches, in terms of graph size (number of nodes/number of edges).
The obtained results  123 109  successfully with 7 processes (and even more).
The Fischer protocol model is the only model where our approach leads to relatively bad results (although the difference with the two other approaches is linear).
Our first explanation is that, in case of disjoint firing intervals, the abstraction can be weak in some cases.
In fact, when a transition t is enabled by an aggregate t and there exists a transition t  , not enabled  , a is considered non-equivalent (while by a, s.t.
tmin > tmax it could be) to all aggregates where the earliest firing time of t is not the same.
However, it could be that t and t  are never enabled simultanously, in which case the difference does not play any role.
This issue should be investigated in order to refine our abstraction (e.g.
by taking into account the structure of the TPN model).
To conclude, the experimental results show (in most cases) an important gain in performance in terms of graph size (nodes/arcs) compared to the SCG and the ZBG approaches for the tested examples.
Although we are aware that our approach needs to be confronted to more significant applications, the obtained preliminary results are promising.
[5] B. Berthomieu and F. Vernadat.
Time Petri Nets Analysis with TINA.
In QEST, pages 123a124, 2006.
[6] H. Boucheneb, G. Gardey, and O. H. Roux.
TCTL Model Checking of Time Petri Nets.
J. Log.
Comput., 19(6):1509a 1540, 2009.
[7] M. Boyer and O. H. Roux.
Comparison of the Expressiveness of Arc, Place and Transition Time Petri Nets.
In ICATPN 2007, volume 4546 of LNCS, pages 63a82.
Springer, 2007.
[8] G. Gardey, D. Lime, M. Magnin, and O.
(h. Roux.
Romeo: A Tool for Analyzing time Petri nets.
In In Proc.
CAV05, vol.
3576 of LNCS, pages 418a423.
Springer, 2005.
[9] G. Gardey, O. H. Roux, and O. F. Roux.
Using Zone Graph Method for Computing the State Space of a Time Petri Net.
In FORMATS 2003, volume 2791 of LNCS, pages 246a259.
Springer, 2003.
[10] R. Hadjidj and H. Boucheneb.
Improving state class constructions for CTL* model checking of time Petri nets.
STTT, 10(2):167a184, 2008.
[11] R. Hadjidj and H. Boucheneb.
On-the-fly TCTL model checking for time Petri nets.
Theor.
Comput.
Sci., 410(42):4241a 4261, 2009.
VI.
C ONCLUSION We proposed a new symbolic graph for the abstraction of the TPN state space.
The proposed graph, called TAG, produces a finite representation of the bounded TPN behaviour and allows for analysing timed reachability properties.
Unlike the existing approaches, our abstraction can be directly used to check both state and event-based logic properties.
Our ultimate goal is to use the TAG traversal algorithm for the verification of timed reachability properties expressed in the TCTL logic.
Several issues have to be explored in the future: We first have to carry out additional experimentation (using more significant use cases) to better understand the limits of our approach and to better compare the TAG technique to the existing approaches.
Second, we believe that the size of the TAG can be further reduced while preserving time properties without necessarily preserving all the paths of the underlying TPN.
We also plan to design and implement model checking algorithms for full TCTL logic.
[12] K. G. Larsen, P. Pettersson, and W. Yi.
Model-checking for real-time systems.
In FCT a95, volume 965 of LNCS, pages 62a88.
Springer, 1995.
[13] K. G. Larsen, P. Pettersson, and W. Yi.
UPPAAL: Status and Developments.
In CAV, pages 456a459, 1997.
[14] D. Lime and O. H. Roux.
Model Checking of Time Petri Nets Using the State Class Timed Automaton.
Discrete Event Dynamic Systems, 16(2):179a205, 2006.
[15] P. M. Merlin and D. J. Farber.
Recoverability of modular systems.
Operating Systems Review, 9(3):51a56, 1975.
[16] W. Penczek, A. PoElrola, and A. Zbrzezny.
SAT-Based (Parametric) Reachability for a Class of Distributed Time Petri Nets.
T. Petri Nets and Other Models of Concurrency, 4:72a 97, 2010.
[17] C. A. Petri.
Concepts of net theory.
In MFCSa73, pages 137a146.
Mathematical Institute of the Slovak Academy of Sciences, 1973.
R EFERENCES [1] R. Alur and D. L. Dill.
A theory of timed automata.
Theor.
Comput.
Sci., 126(2):183a235, 1994.
[18] M. PezzeE and M. Young.
Time Petri Nets: A Primer Introduction.
In Tutorial at the Multi-Workshop on Formal Methods in Performance Evaluation and Applications, 1999.
[2] B. Berthomieu and M. Diaz.
Modeling and Verification of Time Dependent Systems Using Time Petri Nets.
IEEE Trans.
Software Eng., 17(3):259a273, 1991.
[19] C. Ramchandani.
Analysis of asynchronous concurrent systems by timed Petri nets.
Technical report, Cambridge, MA, USA, 1974.
[3] B. Berthomieu and M. Menasche.
An Enumerative Approach for Analyzing Time Petri Nets.
In IFIP Congress, pages 41a 46, 1983.
[20] J. Sifakis.
Use of Petri nets for performance evaluation.
Acta Cybern., 4:185a202, 1980.
[4] B. Berthomieu and F. Vernadat.
State Class Constructions for Branching Analysis of Time Petri Nets.
In TACAS 2003, volume 2619 of LNCS, pages 442a457.
Springer, 2003.
[21] T. Yoneda and H. Ryuba.
CTL model checking of time Petri nets using geometric regions.
1998.
124 110

2013 20th International Symposium on Temporal Representation and Reasoning  A Tool for Deciding the Satisfiability of Continuous-time Metric Temporal Logic Marcello M. Bersani , Matteo Rossi , Pierluigi San Pietro:  Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Italy : CNR IEIIT-MI, Milano, Italy Email: {marcellomaria.bersani, matteo.rossi, pierluigi.sanpietro}@polimi.it Abstract--Constraint LTL-over-clocks is a variant of CLTL, an extension of linear-time temporal logic allowing atomic assertions in a concrete constraint system.
Satisfiability of CLTL-overclocks is here shown to be decidable by means of a reduction to a decidable SMT (Satisfiability Modulo Theories) problem.
The result is a complete Bounded Satisfiability Checking procedure, which has been implemented by using standard SMT solvers.
The importance of this technique derives from the possibility of translating various continuous-time metric temporal logics, such as MITL and QTL, into CLTL-over-clocks itself.
Although standard decision procedures of these logics do exist, they have never been realized in practice.
Suitable translations into CLTLover-clocks have instead allowed us the development of the first prototype tool for deciding MITL and QTL.
The paper also reports preliminary, but encouraging, experiments on some significant examples of MITL and QTL formulae.
I.  typically based on Timed Automata [6], but, to the best of our knowledge, they have never been realized in practice.
This may suggest that these approaches are not easily implementable although they were the first used to prove the decidability properties of such logics.
In general, the level of support for verification of continuous-time temporal logics is not as well developed as for discrete-time models.
Uppaal [7] is the de-facto standard tool for verification of Timed Automata, but it does not support continuous-time temporal logics: not only satisfiability checking is not available in Uppaal, but even the formalization of system properties in temporal logic is not allowed, aside from rather simple invariants and reachability properties.
Satisfiability Modulo Theories is a promising but well-consolidated theory, supported by efficient solvers that are able to decide problems of many disciplines.
In particular, decidable SMT problems have been already considered in the recent past, for instance to solve reachability [8] and the bounded version of language inclusion [9] for Timed Automata.
The idea is to give a direct representation of bounded runs of Timed Automata through an SMT formula, capturing a bounded unrolling of the transition relation.
Similarly, also Bounded Model-Checking of Linear Temporal Logic on Timed Automata [10] can be tackled by reducing the problem to an instance of a SMT problem, by using a technique extending the traditional BMC procedure for LTL finite automata [11], but by restricting the set of valid runs to those that are periodic in the values of the clocks.
Finite or periodic runs of Timed Automata can then be encoded in SMT formulae with explicit arithmetic.
Nonetheless, also this approach has so far failed to produce a concrete decision procedure for logics such as MITL and QTL.
This difficulty is caused by the gap of translating formulae into Timed Automata, a step which is avoided by our approach.
I NTRODUCTION  Constraint-LTL [1], called CLTL, is an extension of lineartime temporal logic allowing atomic assertions in a concrete constraint system.
By carefully choosing the constraint system, CLTL may be decidable, as well as expressive and well-suited to define infinite-state systems and their properties.
In this paper, we define a variant of CLTL, called CLTLover-clocks (CLTL-oc), where arithmetic variables occurring in atomic assertions are evaluated as clocks.
A clock "measures" the time elapsed since the last time the clock itself was "reset" (i.e., the variable was equal to 0); clocks can also be tested against a constant.
By definition, in CLTL-oc each (discrete) instant i is associated with a "time delay" corresponding to the "time elapsed" between i and the next instant i 1.
This allows mixing of discrete events with continuous-time, a typical situation arising in many computer-controlled applications.
Satisfiability of CLTL-oc is here shown to be decidable by means of a reduction to a decidable SMT (Satisfiability Modulo Theories) problem, resulting in a complete Bounded Satisfiability Checking procedure.
Although other automatabased decision procedures would be suitable to show decidability of CLTL-oc (e.g., [1]), the novelty of our reduction is that it can easily be implemented (by using standard SMT solvers).
In fact, the paper also reports on a new tool, publicly available, to verify CLTL-oc formulae.
Suitable translations into CLTL-oc have instead allowed us the development of the first available tool for deciding both MITL and QTL, hence showing the generality and effectiveness of our approach.
Further evidence of this is provided by the fact that we have also been able to provide a translation of the extension of QTL with so-called Pnueli and counting modalities [12], thus providing its first concrete decision procedure.
Although CLTL-oc may be used to specify and verify timed systems, a further advantage of our approach is that it is possible to translate various continuous-time metric temporal logics, such as MITL (Metric Interval Temporal Logic) [2] and QTL [3], into CLTL-oc itself.
Standard decision procedures of MITL and QTL logics do already exist (e.g., [2], [4], [5]), 1530-1311/13 $26.00 (c) 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.20  We also report preliminary, but encouraging, experiments on some significant examples, such as the timed lamp and its properties, in CLTL-oc, MITL and QTL.
The paper is organized as follows: Sect.
II defines CLTLoc, and illustrates it by means of a running example (a 87 99  pp, s q, i |u p o p P p piq for p P AP  timed lamp).
Sect.
III proves that CLTL-oc is decidable, while Sect.
IV outlines the corresponding SMT-based decision procedure.
Sect.
V briefly describes MITL and QTL, showing also the general idea behind their translation into CLTL-oc.
Sect.
VI illustrates the tool, showing verification results of CLTL-oc, MITL and QTL formulae.
Sect.
VII concludes.
II.
pp, s q, i |u Rpa1 , .
.
.
, an q o ps pi pp, s q, i |u  |an |, xan qq P R  pp, s q, i |u ph ^ ps o pp, s q, i |u ph and pp, s q, i |u ps pp, s q, i |u X pphq o pp, s q, i  1 |u ph  pp, s q, i |u Y pphq o pp, s q, i  1 |u ph ^ i !
0 pp, s q, i |u phUps o D j Y= i : pp, s q, j |u ps ^ pp, s q, n |u ph @ i $?
n   j  C ONSTRAINT LTL ( OVER CLOCKS )  pp, s q, i |u phSps o D 0 $?
j $?
i : pp, s q, j |u ps ^  Constraint LTL (CLTL [1], [13]) is the decidable logic that is used in Sect.
V to solve the satisfiability problem of various metric temporal logics over continuous time.
CLTL formulae are defined with respect to a finite set V of variables and a constraint system D, which is a pair pD, Rq with D being a specific domain of interpretation for variables and constants and R being a family of relations on D, such that the set AP of atomic propositions coincides with set R0 of 0-ary relations.
An atomic constraint is a term of the form Rpx1 , .
.
.
, xn q, where R is an n-ary relation of R on domain D and x1 , .
.
.
, xn are variables.
A valuation is a mapping v : V N D, i.e., an assignment of a value in D to each variable.
A constraint is satisfied by v, written v |uD Rpx1 , .
.
.
, xn q, if pv px1 q, .
.
.
, v pxn qq P R. Given a variable x P V over domain D, temporal terms are defined by the syntax: a : c | x | Xa, where c is a constant in D and x denotes a variable over D. Operator X is very similar to X, but it only applies to temporal terms, with the meaning that Xa is the value of temporal term a in the next time instant.
Well-formed CLTL formulae are defined as follows:  pp, s q, n |u ph @ j   n $?
i  TABLE I.
S EMANTICS OF CLTL.
unless it is "reset" (i.e., s pi 1, xq  0).
We show in Sect.
III that CLTL-oc is decidable.
Before going further, to motivate our approach, we provide an example of a CLTL-oc formula representing a simple yet realistic timed system.
Example 1: we consider the LTL specification of a timed lamp and its properties (studied in Sect.
VI) from [14].
The lamp is controlled by two buttons, labeled ON and OFF respectively, which cannot be pressed simultaneously.
The lamp itself can be either on or off.
When ON is pressed the lamp is immediately turned on, regardless of its current state, while if OFF is pushed then the lamp is immediately turned off, also regardless of its current state.
After ON is pressed, the lamp will not stay on forever, but, if no more buttons are pressed, it will automatically turn off with a delay D, a positive real constant.
By pressing the ON button before the timeout expiration then the timeout is extended by a new delay D.  ph : Rpa1 , .
.
.
, an q | ph ^ ph | ph | X pphq | Y pphq | phUph | phSph where ai 's are temporal terms, R P R, X, Y, U and S are the usual "next", "previous", "until" and "since" operators of LTL, with the same meaning.
The dual operators "release" R, and "trigger" T may be defined as usual, i.e., phRps is p phU ps q and phTps is p phS ps q.
Our CLTL-oc formula makes use of atomic propositions on, off and l representing, respectively, events "push button ON" and "push button OFF" and the state "light is on".
Clocks may be used to measure the exact time elapsed since the last on; clearly some clock must be "reset" (i.e., set to 0, in analogy to Timed Automata) whenever ON is pressed, while when a clock is equal to D then the timeout expires.Since the introduction of clocks is not straightforward, we first define a few shorthands called rst-c, testcD and test0 c$?D .
They have the intuitive meaning (which will be formalized after the main specification) that they are true if, and only if, a clock c is reset or, respectively, c  D, or 0   c $?
D. The specification of the lamp, still lacking the precise 	 clock specification, is defined by 5 the formula G i0 piq , where G pphq is the usual globally operator defined by KRph, of the following formulae:  The semantics of CLTL formulae is defined with respect to a strict linear order representing time pN,  q.
Truth values of propositions in AP , and values of variables belonging to V are defined by a pair pp, s q where s : N  V N D is a function which defines the value of variables at each position in N and p : N N pAP q is a function associating a subset of the set of propositions with each element of N. The value of terms is defined with respect to s as follows: s pi, aq  s pi  |a1 |, xa1 q, .
.
.
, s pi  ph o pp, s q, i |u ph  |a|, xa q  where xa is the variable in V occurring in term a and |a| is the depth of a temporal term, namely the total amount of temporal shift needed in evaluating a: |x|  0 when x is a variable, and |Xa|  |a| 1.
The semantics of a CLTL formula ph at instant i Y= 0 over a linear structure pp, s q is recursively defined as in Table I, A formula ph P CLTL is satisfiable if there exists a pair pp, s q such that pp, s q, 0 |u ph.
pon ^ offq on o rst-c Yplq n test0 c$?D turnoff o Yplq ^ poff _ testcD q l o turnoff S on.
In this paper, we consider a variant of CLTL, where arithmetic variables are evaluated as clocks and set RzR0 is t , u.
A clock "measures" the time elapsed since the last time the clock was "reset" (i.e., the variable was equal to 0).
By definition, in CLTL-oc each i P N is associated with a "time delay" d piq, where d piq !
0 for all i, which corresponds to the "time elapsed" between i and the next state i 1.
More precisely, for all clocks x P V , s pi 1, xq  s pi, xq d piq,  (1) (2) (3) (4) (5)  Formula (1) ensures mutual exclusion; (2) states that the timeout must be (re)started whenever button ON is pressed; (3) constrains the time elapsed since the previous instant if the light was on at that moment (i.e., not more than D); (4) defines (for readability) an event turnoff, capturing the two cases when the lamp (supposed to be ON in the previous instant) must be turned off at the current instant (i.e., OFF being pressed or  100 88  a sequence of clock regions R0 R1 , .
.
.
such that, for all time position i, Ri 1 is a time-successor of region Ri [6], except for the clocks that in Ri 1 are reset (i.e., whose value is 0).
Let ph be a CLTL-oc formula and Aph be its Buchi automaton recognizing symbolic models of ph [15].
Then, we define an automaton AR ph accepting all the symbolic models belonging to L Aph , such that the sequence of regions entailed by clock constraints within symbolic valuations obeys the timeR, d be the automaton where successor relation.
Let AcR R is the set of all regions induced by the clocks, c is the maximum constant that all clocks are compared with and d is the transition relation containing all R R1 such that R1 R is a time-successor of R R, except for the clocks whose value is 0 in R1 .
Automaton AR ph is defined as the product of Aph and automaton AcR recognizing the language of successive regions, which are induced by formula ph.
It is worthy to be noticed that the following construction only guarantees that time elapses and all clocks progress by the same amount of time.
Since we are dealing with a CLTL formulae where atoms may be relations over clocks, the construction of AR ph does not force the value of clocks which is instead constrained by the formula.
This impacts the definition of the initial region, which does not follow the standard construction where all clocks are zero.
In our case, we relax the assumption that all clocks start from 0, by simply considering each region as potentially initial.
the timeout expiring); finally, (5) gives the specification of the light, as being on if, and only if, there was in the past an on event not followed by a turnoff.
Initialization is implicit in the specification (at instant 0, the light is off).
To complete the specification, we must formalize also the clock behavior.
In CLTL-oc, "resetting a clock" c, e.g., following an on event is as simple as stating that on c 0; testing a clock c against a constant D and causing say, a turnoff is a simple as stating that c D turnoff.
Unfortunately, the same clock cannot be tested and reset at the same time.
A possible solution is to introduce two clocks c0 and c1 , rather than just one clock, so that they are reset alternatively: only one of the two clocks is reset and a new reset of the same clock will eventually occur only after the occurrence of a reset of the other clock.
The behavior of this clock pair is described by the axiom G 6 7 , where formulae (6) and (7) are:  p q  n    n  i  i  i 1  i  2  0,1  0  1  2  2  2  c D  0 c D  0  1  0 c D  c D  i  iPt0,1u  III.
We briefly recall some key elements of Aph (see [13] for further details).
Let SV ph denote the set of symbolic valuations associated with ph.
The closure of ph, denoted cl ph , is the smallest set containing all subformulae of ph and closed under negation.
An atom G cl ph is a maximally consistent subset of formulae of cl ph , i.e., such that, for each subformula x in ph, either x G or x G. Automaton Aph is the tuple SV ph , Q, Q0 , e, F where Q is the set of all the atoms and e is defined as in the standard Vardi-Wolper construction.
pq  i  i  0,1  i 1  2  i 1  P  N  P  pp q ^ p qq  (6) c  0 n X pcp q !
0 U c  0q Pt u (7) c  0 n pc  0q and pq stands for the modulo 2 operator (i.e., p1q  0, p2q  0).
Finally, the above clock shorthands rst-c, test  and test   $?
are defined as follows: rst-c o c  0 _ c  0 a 0 c $?D test   $?
o Pt u a  c  D ^ pcp q !
D _ cp q  0q test  o  (c)  p q  2  P  p pq  D ECIDABILITY OF CLTL OVER CLOCKS  Our argument is divided in two parts.
First, in this section, we show that a CLTL-oc formula ph can be translated into a suitable Buchi automaton AR ph , which recognizes the language of the regions of the clocks appearing in ph.
If the automaton accepts some ultimately periodic words of the form uv o over the alphabet of clock regions induced by ph, then ph is satisfiable.
In fact, through arguments akin to those in [6], we can show that an infinite sequence of successive regions is representative of a trace of a CLTL-oc formula.
Automaton AR ph is built using a slight variation of the construction used in [1] and [13]; it differs from those built in the earlier works in that its symbolic runs include the sequences of symbolic valuations that satisfy ph [1] and also constraints representing the clock regions induced by ph.
Second, in Sect.
IV we provide a way to solve in practice the satisfiability of CLTL-oc, through the method used in [13] to solve satisfiability of CLTL.
The technique relies on encoding CLTL formulae into formulae of a decidable fragment of first-order logic, which can then be solved by off-the-shelf SMT solvers.
The decision procedure hinges on finding a finite sequence of assignments to the clocks appearing in the CLTL formula ph, which satisfies ph and such that it is a witness of an ultimately periodic sequence of successive clock regions.
Since the clock regions define a partition of the space of clock assignments, each assignment of values to clocks uniquely identifies a region, hence an exhaustive definition of all the regions is not needed.
q  pq  pq   pq P  p pq   Rq.
Y 1 pG, Rq YYYN pG , R1q if, and only if, sv P SV pphq satisfies G, the pair pG, G1 q is onestep consistent, R N R1 P d and sv Y R is satisfiable.
Set I  Q  R of initial states consists of states (atoms) of Q that are consistent with respect to regions in R; i.e., the set of arithmetical constraints in G P Q union R is a satisfiable 1 Now, we define AR ph as tuple SV ph , Q R, I, e , F sv R  Relation e 1 is defined as follows:  0  0  0  conjunction of formulae.
A run r of AR ph is a sequence:  Y Y N .
.
.
pG , R q YYYYY N pG , R q .
.
.
pG , R q YYYYY where pG , R q P I.
Let pp, s q be a sequence where p : N N pAP q and s : N  V N R. pp, s q witnesses r, i.e., pp, s q |u r, when for all i Y= 0: p piq  G X AP and s, i |u sv Y R .
Lemma 1.
Let ph be a CLTL-oc formula.
pp, s q |u ph if, and only if, there is an accepting run r of A such that pp, s q |u r. Proof: We first show that, if pp, s q |u ph, then there is 0  0  0  sv0 R0  i  i  svi Ri  i 1  i 1  0  i  i  i  R ph  an accepting run of automaton AR ph .
In [1] it is shown that a CLTL formula ph is satisfiable if, and only if, there is a run r sv0 sv1 .
.
.
of automaton Aph recognizing symbolic models of the formula.
We have to show that when the variables of ph behave like clocks, then the sequence of valuations defines a    To represent correctly the elapsing time as measured by clocks, symbolic models of CLTL-oc formulae has to define  101 89  sequence of successive clock regions, hence r is also a run of AR ph .
In fact, we have that s, i |u svi .
Since the set of clock regions is a partition of the clocks space, there is only one region R P R such that s, i |u Ri , with Ri  R. Therefore, s, i |u svi Y Ri and model pp, s q induces a sequence of regions R0 R1 .
.
.
.
By construction, each atom Gi is such that p piq  Gi X AP .
Finally, we prove that each Ri Ri 1 in the sequence R0 R1 .
.
.
is a pair of successive regions.
In fact, if s pi, xq and s pi 1, xq are two adjacent valuations for a clock x of ph, then either there is a t !
0 such that xpi 1q  xpiq t or xpi 1q  0 (reset).
Therefore, Ri 1 is a time successor of Ri (except for the clocks whose value is 0 in Ri 1 ) and the sequence R0 R1 .
.
.
is a sequence of successive regions which belongs to the language L pAcR q.
At each position i, we have that p piq  Gi X AP and s piq |u svi Y Ri .
Hence, pp, s q |u r.  show the PSPACE-completeness for CLTL-oc using arguments similar to those used in [6] to show how the transition relation of the automaton checked for language emptiness can be computed in PSPACE.
In fact, consider a CLTL-oc formula ph.
If we indicate with |ph| the number of subformulae of ph, with N the number of clock variables in ph, and with K the biggest constant against which the clock variables of ph are compared, since the number of clock regions is OpN !
fi K N q [6], the |ph| fi N !
fi K N q. number of states of automaton AR ph is O p2 However, to check for the emptiness of L pAR ph q we do not need to build the whole state space, but only a constant number of vertices at a time.
Since the space needed to store a vertex of automaton AR ph , when using a binary encoding for K, is polynomial in |ph| logpK q, the algorithm for checking the emptiness of AR ph is in PSPACE.
We now show that, if automaton AR ph has an accepting run r, then CLTL formula ph is satisfiable.
The Vardi-Wolper construction of the Buchi automaton Aph guarantees that at each position of the run r a subset of the subformulae of ph are satisfied and ph is witnessed at position 0.
By construction, the sequence of symbolic valuation sv0 sv1 .
.
.
is a symbolic model of ph and such that it admits arithmetical model; i.e., there is an infinite sequence of valuations of the variables occurring in ph and satisfying the constraints in svi , for all i [1].
By construction, the sequence R0 R1 .
.
.
is a sequence of successive clock regions in the language L pAcR q.
Therefore, by standard arguments from Timed Automata, we can build a sequence of delays d piq such that, for each clock x P V , it is xpi 1q  xpiq d piq, unless x is reset (i.e.
xpiq  0).
IV.
We outline how to decide the satisfiability problem for CLTL-oc formulae by a SMT-based technique instead of automata.
The technique is based on previous work [16] [15], in which we used a k-bounded satisfiability problem to solve the satisfiability of CLTL formulae by using a polynomial reduction to a SMT problem.
k-bounded satisfiability is complete, and deciding the satisfiability of a CLTL formula can be done by means of a finite amount of k-bounded satisfiability tests, for increasing values of k. To deal with variables that behave like clocks, the method developed in [15] is extended to represent time progress.
Given a CLTL formula ph, we say that ph is k-bounded satisfiable if there exists an ultimately periodic sequence of symbolic valuations sv0 , .
.
.
, svl1 psvl .
.
.
svk1 qo , which is a symbolic model of ph and such that there is a partial assignment of values to all the variables occurring in ph only for a finite number of positions in time, from 0 to k 1.
In other words, in k-bounded satisfiability we look for a finite sequence of symbolic valuations sv0 , .
.
.
, svl1 psvl .
.
.
svk1 svk q, where svk  svl , which admits a k-bounded arithmetical model and that is representative of an infinite symbolic model for ph of the form sv0 , .
.
.
, svl1 psvl .
.
.
svk1 qo .
While in PSPACE, in practice k-bounded satisfiability can be quite efficient, at least when the value of k is small enough to perform the check: checking k-bounded satisfiability is then equivalent to solve a few SMT problems in P. Obviously, the upper bound for k is in general exponential in the size of the formula.
Observe that time progression in automaton AR ph is not guaranteed by the construction.
However, this requirement is easily achieved by the CLTL formula: G pXx  0 _ Xx !
xq ^ pGF px  0q _ FG px !
cpxqqq (where cpxq is the biggest constant clock x is compared to), for all clocks x P V .
Finally, the following result is a direct consequence of Lemma 1 and of properties of CLTL and Timed Automata.
Theorem 1.
Satisfiability for CLTL-oc is decidable.
Proof: Let ph be a CLTL-oc formula.
By Lemma 1 we can build automaton AR ph , recognizing symbolic models of ph, that has an accepting run (i.e., whose accepted language is non-empty) iff ph is satisfiable.
Checking the emptiness of the language L pAph q is done by standard techniques which look for cycles in the graph of AR ph embedding (at least) one accepting control state.
The language of AR ph is not empty if there exists a path of AR ph of the form p  In [15] we show how to solve k-bounded satisfiability for CLTL formulae over a class of arithmetical constraints that include the family of clock constraints used in Sect.
II.
The kbounded satisfiability problem is solved through a polynomialtime reduction to the satisfibility problem of a formula in the theory of Equality and Uninterpreted Functions combined with Linear Integers/Reals Arithmetic.
The combination of the two theories is decidable and its decision procedure is implemented by many SMT-solvers.
The reduction of [15] has been implemented in the ae2 zot plugin of the Zot tool [17].
Therefore, an instance of the k-bounded satisfiability problem for CLTL formulae has the complexity of the underlying SMT problem, which depends on the arithmetic theory required.
In our case, since clocks are in R, we solve SMT problems in QF-EUF Y LRA, whose complexity is P. A peculiarity of the SMT-based approach is that, if the set of symbolic  G0 , R0 q .
.
.
pGl1 , Rl1 qpGl , Rl q .
.
.
pGk , Rk q  where Gk  Gl , Rk  Rl and all atoms belonging to F occur at least once in pGl1 , Rl1 qpGl , Rl q .
.
.
pGk1 , Rk1 q.
The word which is recognized by the run is an ultimately periodic one over the language SV pphq Y R of the form: p  S OLVING CLTL- OVER - CLOCKS SATISFIBILITY  o  sv0 , R0 q .
.
.
psvl1 , Rl1 q ppsvl , Rl q .
.
.
psvk1 , Rk1 qq .
1) Complexity.
: The satisfiability problem for CLTL-oc is PSPACE-hard, as any LTL formula (whose satisfiability problem is PSPACE-complete) is also a CLTL formula.
We can  102 90  valuations partitions of the space D|V | (with D the domain of the variables in V ), then a sequence of valuations uniquely induces a sequence of symbolic valuations.
By solving the k-bounded satisfiability problem for a formula ph we obtain, from the model of the QF-EUF formula, the sequence of valuations satisfying the constraints occurring in the formula, which induces a symbolic model.
Hence, unlike automatabased techniques, our approach does not require the explicit construction of the set SV pphq.
We exploit this to avoid building the set of clock regions induced by CLTL formulae.
d x y  1  k  0.2  0.9  2.4  0.5  0.6  ...  0.1  0.3  1.2  0  0.5  ...  2.1  2.3  3.2  5.5  6  Rl1  Rl  R  svl  Rk  1.1 svk  6.6  Fig.
1.
A (portion of) bounded model satisfying infinitely often formula py !
0qUpx  0q.
P er pacpRph qq enforces regions Rl and Rk (dashed rectangles) to be equal, where Rl  txl   yl , 1   xl   2, 2   yl u and Rk  txk   yk , 1   xk   2, 2   yk u.
Solid rectangles represent symbolic valuations svl  svk where constraints x  c are not written because included in the regions.
The set of all constraints a N b (representing a   b) between all the pairs of elements in tx, y, 0, 2u defines a symbolic valuation.
Value xk1  0 satisfies constraint G pF px  0qq and values yi , with i P rl  1, k  1s, witnesses F pG py !
cpy qqq.
The complete definition of |ph|k can be found in [15].
We provide some of its formulae for the sake of space.
Formula 1 $?
l $?
k  1 sets position l of the loop in r1, k  1s.
The semantics of the formula ph  py !
0qUpx  0q is achieved by means of the fixpoint definition of U over all positions in 0, k that is ki0 phi o pxi  0q _ pyi !
0 ^ phi 1 q.
The semantic equivalence of position k and l, i.e., all the subformulae of ph have the same truth value at k and l, is enforced by phl o phk , pxl  0q o pxk  0q, pyl !
0q o pyk !
0q.
The eventuality of px  0q in the periodic part, when ph holds at position k, is guaranteed by phk n l $?
iph $?
k ^ pxiph  0q.
To solve the satisfiability of CLTL-oc we still use kbounded satisfiability to look for ultimately periodic models, but we extend the method in order to represent clock regions and time progression.
Representing clock regions is quite straightforward and exploits the fact that regions partition the space of all possible clock valuations.
In other words, a clock valuation identifies a clock region, so it is not necessary to precompute the set of all clock regions from the formula.
The only requirement to be enforced is the periodicity of the sequence of clock regions corresponding to clock valuations.
If one is looking for a model of length k, the sequence of clock regions is of the form: R0 .
.
.
Rl1 pRl .
.
.
Rk1 qo , which is obtained from a finite sequence R0 .
.
.
Rl1 pRl .
.
.
Rk1 Rk q with the periodicity constraint Rl  Rk .
The QF-EUF encoding of CLTL formulae is defined to enforce periodicity of all atomic formulae (atomic propositions and clock constraints) between positions k and l. For instance, given two clocks x, y, if x  y holds at position k (i.e., xpk q  y pk q) then, by the periodicity constraints, it must also hold at position l: xpk q  y pk q o xplq  y plq.
To obtain a periodic sequence of regions we provide the solver with all the clock constraints which may occur in the definition of regions in Rph (but not all the regions).
Given a CLTL-oc formula ph, we define the set acpRph q as the set of all clock constraints induced by ph.
Let ph1 be a CLTL formula, Cph be the set of clocks appearing in ph1 , and x, y P Cph .
If cpxq is the maximum constant with which clock x is compared in ph1 and P t , , !u, the set acpxq  tx  c | @c P r0, 1, .
.
.
, cpxqsuztx   0u is the set of all clock constraints between x and constant cpxq, while set acpx, y q  tx  y u is the set of all clock constraints between x and y.
Then, set acpRph q is defined as: x,y P Cph ,xy acpxqY acpx, y q.
We indicate with P erpacpRph qq the set of QF-EUF periodicity constraints on arithmetic constraints acpRq, that is, @th P acpRq thpk q o thplq.
Time elapsing is obtained by forcing all clocks in ph1 to progress by the same amount of time between two positions of the model.
Let i P r0, k  1s; then, constraint xpi 1q  xpiq d piq _ xpi 1q  0, where d piq !
0, is imposed to represent a positive elapsing time, for all clocks x P Cph .
We indicate with Adv pCph q the set of constraints that impose the uniform time advancement of clocks in Cph .
Since all variables in the theory of Reals are defined over R and all x P Cph behave like clocks, we force xpiq Y= 0 for all x P Cph and for all i P r0, k s. We indicate the conjunction of these constraints as nN eg pCph q.    V.  E NCODING M ETRIC T EMPORAL L OGICS  We exploit the decision procedure for CLTL-oc outlined in Sect.
IV to define mechanisms for deciding various metric temporal logics over continuous time.
In fact, we have defined several satisfiability-preserving reductions from metric temporal logics to CLTL-oc; hence, satisfiability of formulae of these former logics can be determined by solving the corresponding problem for CLTL-oc.
In particular, the logics we have targeted so far are: MITL [2], QTL [18], and QTL with counting and Pnueli modalities [12].
In this section, after briefly recalling the definition of MITL and QTL, we present some highlights from the aforementioned reductions.
1  1  Let AP be a finite set of atomic propositions.
The syntax of (well formed) formulae of MITL is defined as follows:    ph : p | ph ^ ph |  1  1  k  l  ph | phUI ph  with p P AP and I is an interval of the form xa, by or of the form xa, 8y, where a, b P N are constants, with a   b. Interval xa, by can be, in general, left open or closed (respectively, p or r) but only right closed (written as s).
We omit the interval I when it is r0, 8q.
1  M, t M, t  1  1  1  p  o  p  ph  o  M, t |u ph M, t  P  M, t  |u  ph^ps  o  M, t  |u  phUI ps  o Dt  1  M ptq  P  We solve the satisfiability problem of CLTL-oc formula ph by feeding the SMT solver the set of constraints |ph1 |k Y P erpacpRph qq Y Adv pCph q Y nN eg pCph q, where |ph1 |k is the bounded representation of ph1 described in [15].
p  AP  P  |u  ph and M, t  t  I : M, t  TABLE II.
1  1  |u  |u  1  |u |u  ps ps and M, t  2  |u  ph @t  2  P rt,  t  1  q  S EMANTICS OF MITL.
The semantics of MITL is defined in Table II with respect to signals.
A signal is a function M : R N 2AP (with R the set of nonnegative reals).
A MITL formula ph is satisfiable if there exists a signal M such that M, 0 |u ph (in this case, M is called a model of ph).
The globally GI and eventually FI  1  The complete definition of |ph|k can be found in [15].
103 91  operators can be defined by the usual abbreviations: FI ph JUI ph and GI ph  FI p phq.
  false to true), this occurred more than b instants ago (i.e., the clock associated with ps that is not reset now is Y= b).
QTL is similar to MITL, but it is based on a single metric operator, Fp0,1q (and its past counterpart Pp0,1q ), so its syntax is the following:1 ph:   p|ph^ph|  |  |  |  th  |  ph phUp0,8q ph Fp0,1q ph phSp0,8q ph Pp0,1q ph.
We now briefly show how to encode MITL and QTL formulae into CLTL-oc ones .
For space reasons we only provide some highlights of the reduction in a special case.
Let us restrict signals to those where intervals are leftclosed and right-open (l.c.r.o.
signals, ).
In addition, given a MITL formula ph we are interested in signals that are non-Zeno [20] models of ph, i.e., such that in every finite interval of the temporal domain there is a finite number of change points of the value of the atomic propositions of ph.
For these (l.c.r.o.)
signals, the temporal domain can be partitioned in a countable set of adjacent l.c.r.o.
intervals such that in each such interval the value of every subformula of ph is constant.
Then, for each subformula th of ph (th P subf pphq) we introduce  a CLTL-oc predicate th that represents the value of th in the intervals in which the temporal domain is partitioned.
We also introduce the following abbreviations:     x  x        !x   Yp x q^ x    GpGx0,1s pp ^ q q n Fx1,2s pp p ^ q qUpGx0,0.5s q qq Gp p ^ q n Gx1,2s pq  psR  iPt0,1u  (8)  The case for th becoming true is not shown for brevity.
Consider the case th  Pr0,bq pps q.
Formula (9) captures the condition in which th becomes true.
This occurs when ps becomes true and either the current instant is the origin (O is an abbreviation for Y pJq), or ps has never become true since the origin, or the last time ps changed value (necessarily from 1 Note  (10) (11)  (12) (13)  Predicates p and q become false before each position 2k 1.5 by requiring that p ^ q occurs until an interval of length 0.5 where both p and q are false.
Let tpk P p2k 1, 2k 1.5q be the instant where p becomes false, and tqk  tpk dk P p2k 1, 2k 1.5q the one where q becomes false; let dk  tpk  tqk be the length of the interval where p does not occur while q does.
Formula (13) lengthens signal p of dk time units over the next interval starting from 2k: p holds in rtpk 1, tpk 2 dk q.
The series of values dk is strictly monotonic decreasing because each value is arbitrarily strictly less than the previous one, i.e., dk !
dk 1 , for all k. Therefore, the sequence of d piq is not periodic, although the sequence of clock regions of induced by the clocks in the CLTL-oc formula corresponding to the formulae above is indeed periodic.
Formula (8), then, captures the condition in which formula th  Fp0,bs pps q becomes false: in this case, ps must become false, and it cannot become true again for b instants (i.e., ps cannot become true again before its associated clock that is reset when ps becomes false hits b).
!
th o !ps ^  iPt0,1u   Y= b (9)  Both signals p and q hold over intervals longer than one time unit, because of the l.c.r.o.
assumption.
In addition, we require that q is at least as long as p by means of formula G pp n q q. Formulae (10)-(11) admit, in general, models that can be periodic; therefore, we have to restrict the set only to aperiodic models.
This may be achieved by enforcing that, over intervals of the form r2k 1, 2k 2s, with k Y= 0, signal q is strictly longer than p, while over intervals r2k 1.5, 2k 2q both p and q are false, as required by the followig two formulae:  For simplicity, we focus our attention on temporal operators Fp0,bs pps q and Pr0,bq pps q.
We remark that it can be shown that, if ps holds only in l.c.r.o.
intervals, so do Fp0,bs pps q and Pr0,bq pps q (the same does not hold, for example, for Fp0,bq pps q).
For each subformula th P subf pphq we introduce two clocks, zth0 and zth1 , which measure the time from the last change point (either th or !th , so we have th _ !th o zth0  0 _ zth1  0), and whose resets alternate.
zpsi $?
b  pO^ ps q _  i zps  Gx0,1s p ^ GpGx0,1s p n Gx2,3s pq Gx0,1s q ^ GpGx0,1s q n Gx2,3s q q.  where x , for example, captures the situation in which x changes value from false to true, with the formula being true in the current interval.
fi  ps^ (c)  psS  a  Example 2: consider the conjunction of the following MITL formulae defining the behaviour of two signals p, q as depicted in Figure 2.
Signal p holds in r2k, 2k 1 eq, for all k, and is false elsewhere, as formalized by the MITL formulae  Yp x q^ x   ps     To conclude this section, we provide an example of MITL formula (to be evaluated over l.c.r.o.
signals) over two atomic propositions p, q whose model is intrinsically aperiodic in the values of the delays between changepoints in the values of p and q.
The existence of formulae admitting only aperiodic models shows that, in the decision procedure of Sect.
IV, the periodicity must be enforced on the set of constraints defining regions, but not on the actual values of the clocks, nor on the time differences d; i.e., the encoding of CLTL formula ph1 does not include constraints d pk q  d plq and xpk q  xplq.
In other words, for the example below there does not exist a periodic sequence of time increments d p0qd p1q .
.
.
pdl .
.
.
dk1 qo representing the time elapsing for aperiodic models even if the sequence of clock regions is periodic.
For brevity, we omit the semantics of QTL, which is however similar to the one in Tab.
II.
Note that, despite its apparent simplicity, QTL has the same expressive power as MITL [19].
x  o  fi  ^ O _ Y  VI.
I MPLEMENTATION & E XPERIMENTAL R ESULTS  The decision procedure of Sect.
IV for CLTL-oc is implemented in a plugin, called ae2 zot, of our Zot toolkit [17], whereas the reductions outlined in Sect.
V are implemented in the qtlsolver tool, available from [21].
The tool translates  that MITL can be enriched with the "metric since" SI past operator.
104 92  fi      QTL        We used the above two encodings and the CLTL-oc decision procedure to carry out some verification experiments on the example of the Timed Lamp described in Sect.
II.
More precisely, we have built several descriptions of the behavior of the lamp: (i) the CLTL-oc model presented in Sect.
II; (ii) a MITL specification assuming l.c.r.o.
signals; (iii) a QTL specification in which predicates on and off are constrained to be true only in isolated instants.
On each of these specifications we have carried out three experiments, assuming D  5: a check of the satisfiability of the specification, to show that it is consistent (sat); the (dis)proof of property "the light never stays on for more than D time units" (p1 ); the proof of property "if at some point the light stays on for more than D time units, then there is an instant when on is pressed, and then it is pressed again before D time units" (p2 ).
Depending on the temporal logic and of the restrictions on the signals (l.c.r.o.
or not) the formalization of the timed lamp and of the properties can change.
    Fig.
2.
Aperiodic model for MITL formula of Example 2  MITL or QTL into CLTL-oc, which can be checked for satisfiability by ae2 zot.
The resulting toolkit has a 3-layered structure, where CLTL-oc is the intermediate layer between SMT-solvers and various temporal formalisms that can be reduced to CLTLoc.
This not only supports (bounded) satisfiability verification of different languages, but it also allows the expression of different degrees of abstraction.
For instance, QTL and MITL abstract away the notion of clocks, inherently encompassed within temporal modalities, which are instead explicit in CLTL-oc (as witnessed by the example of the timed lamp in Sect.
II) and available to a user, e.g., to express or verify properties where clocks are very convenient.
In fact, preliminary experimental results point out that the time required to solve CLTL-oc may be significantly smaller than the one needed for more abstract classes of languages, such as MITL.
This gap is caused by the "effort" required to capture the semantics of temporal modalities, which, on the other hand, allow for more concise and manageable high-level specifications.
One can then take advantage of the layered structure, which allows the resolution of a formula to be compliant also with constraints imposed at lower layers, for instance by adding at the CLTLoc layer some extra formula limiting the set of valid models (e.g., by discarding certain edges of some events or by adding particular timing requirements).
Also the third layer (the SMT solver) may be used to add further constraints, e.g., to force the occurrence of a proposition or of a certain clock value at a specific discrete position of the finite model.
In the case of the CLTL-oc specification of the timed lamp, in order to formalize properties p1 and p2 we introduce an auxiliary clock caux , which is reset every time the light is turned on, i.e., caux o l ^ Y p lq.
Then, in CLTL-oc property p1 is captured by formula G pY plq n caux $?
Dq.
In addition, property p2 is formalized by the following formula: F pl ^ caux Y= Dq n F pon ^ Xp rst-cUpon ^ test0 c$?D qqq (14)  The behavior of the timed lamp can be captured by the following MITL formula over l.c.r.o.
signals (we write G for Gr0,8q , and S for Sr0,8q ): G  l o p off S onq ^ Pr0,Dq ponq    ^ pon n  offq    (15)  In MITL over l.c.r.o.
signals, where predicates hold over nonnull intervals, we limit the length of intervals in which on (and off) holds to be at most 1 by adding the following constraint: G  Gp0,1s ponq ^    Gp0,1s poffq .
(16)  Over unrestricted signals, instead, we force on to hold only in isolated instants by adding QTL constraint (similarly for off) G  The current implementation of qtlsolver supports various reductions.
More precisely, it realizes the MITL-to-CLTLover-clock translation tailored to l.c.r.o.
signals, as highlighted in Sect.
V. It also implements a translation from a generalized version of QTL to CLTL-oc.
This translation does not assume any special shape for signals, except that they be finitely variable; it natively supports operators Fx0,by and Gx0,by (and their past counterparts), where the bounds can be either included or excluded.
These operators allow us to define concisely Fxa,by and Gxa,by as abbreviations.
Forinstance, Gp3,6q pphq is equivalent to Gp0,3q Fp0,3q Gp0,3q pphq ; defining a similar equivalence using only the Fp0,1q and Gp0,1q modalities (see, e.g., [3]) involves the recursive expansions of each conjunct Gpn,n 1q pphq is of Gp3,4q pphq ^ Gr4,5q pphq ^ Gr5,6q pphq, where  equivalent to Gpn1,nq Fp0,1q Gp0,1q pphq .
The following two encodings are currently available: MITL  providing the definition of generalized QTL operators with unrestricted signals (other than they be finitely variable), and MITL operators through abbreviations.
pon  Up0,  8q Jq ^  pon  Sp0,  8q Jq    .
(17)  Properties p1 and p2 over unrestricted signals are captured by the following QTL formulae (where F stands for Fr0, 8q ):   G Fr0,Ds p lq   F Gr0,Ds plq n F on ^ Fp0,Ds ponq  (18) (19)  Over l.c.r.o.
signals property p1 is still captured by Formula (18); property p2 , instead, is more involved, and corresponds to the following formula: F Gr0,Ds plq    n  F  p    on ^ Pr0,Dq ponqqU on  (20)  Table VI reports the time and space required for the checks outlined above (all tests have been done using the Common Lisp compiler SBCL 1.1.2 on a 2.13GHz Core2 Duo MacBook Air with MacOS X 10.7 and 4GB of RAM; the solver was z3 4.0).
All bounded satisfiability checks have been performed using a bound k  20.
The first line of each row shows  providing a direct definition of MITL operators, assuming l.c.r.o.
intervals;  105 93  limited to logics, but in principle also Timed Automata or Timed Petri Nets).
TABLE III.
E XPERIMENTAL RESULTS WITH THE TIMED LAMP, REPORTING T IME ( SEC ) AND HEAP SIZE (MB).
Problem  Satisfiable?
CLTL-o-c  MITL (l.c.r.o)  QTL (unrest.)
sat  Yes  0.48/0.33 5.63  15.5/13.84 66.45  4.24/3.04 27.12  p1  Yes  0.52/0.35 6.22  36.74/33.16 102.47  17.2/14.86 63.5  p2  No  0.67/0.49 6.55  6.61/5.09 110.27  257.1/240.88 58.66  To the best of our knowledge, our approach is the first allowing an effective implementation of a fully automated verification tool for continuous-time metric temporal logics such as MITL and QTL.
The tool is still a non-optimized prototype, whose performance might also be substantially improved in future versions.
Still, verification of formulae requiring many clocks may always be infeasible, since satisfiability of MITL is EXPSPACE-complete (but we also support verification also of an interesting, PSPACE-complete fragment of MITL).
However, in practice a large number of clocks is not very frequent, and the examples of MITL (and QTL) formulae that we studied were verified in a fairly short time.
the total processing time (i.e., parsing and solving) and the time taken by the SMT-solver (both times in seconds).
The second line reports the heap size (in Mbytes) required by Z3.
In every case the specification is satisfiable, property p1 does not hold (the tool returns a counterexample), while property p2 holds ("unsat" is returned).
In addition to the results shown in the table, a variant of Formula (14) where test0 c D is used instead of test0 c$?D (i.e., $?
is replaced by  ) is shown to not hold, and a counterexample is obtained in less than 1 second.
R EFERENCES [1] [2]  Finally, we present an interesting behavior over unrestricted signals.
The behavior is captured by the following formulae, which state that p and q only occur in isolated instants, with p occurring exactly every 80 time units, and q occurring within 80 time units in the past from each p (origin excluded).
  [3] [4]     Gp0,80q p pq n Gp80,160q p pq ^ G pp n Fp0,160q pq ^ pq n p qq U Jq ^ p ^ Gp0,80q p pq ^ Gp0,8q pp n Pp0,80q q q  [5] [6]  (21)  [7]  In this case, the bound k  10 is enough to prove that the formula is satisfiable and a model is produced in about 40 secs.
In around the same time the solver shows that property Gpp n Fp0,80q pq qq holds for model (21) (up to the considered bound), whereas property Gpq n Fp0,80q pq qq does not.
Note that, in Formula (21), the constants involved in the temporal modalities are significantly greater than the bound k required to obtain a model.
In fact, any value is possible in principle for the clock increments between two consecutive discrete instants, controlled by the (nondeterministic) variable d. This highlights that the length of the intervals described by a CLTL-oc model is independent of the bound k, as long as this is big enough to capture all changepoints that are necessary to build a periodic sequence of regions.
VII.
[8]  [9]  [10]  [11]  [12]  [13]  C ONCLUSIONS  This paper investigates a bounded approach to satisfiability checking of an extension of CLTL where variables behave like clocks (CLTL-oc).
The decidability of the logic (by means of an automata-based technique) is shown first, followed by an encoding into a decidable SMT problem.
This encoding, implemented in our ae2 zot tool, allows, both in principle and in practice, the use of SMT solvers to check the satisfiability of CLTL-oc.
We provide a short but non-trivial example of a CLTL-oc specification describing a timed behavior over continuous time, which should demonstrate the effectiveness of this approach, as we are able to (dis)prove various properties of the specification.
The paper also outlines the encoding of two continuous time, metric temporal logics, namely MITL and QTL, that are implemented in our qtlsolver tool.
This shows that CLTL-oc can be considered as a target language to reduce decision problems of various continuous-time formalisms (not  [14]  [15]  [16] [17] [18] [19] [20] [21]  106 94  S. Demri and D. D'Souza, "An automata-theoretic approach to constraint LTL," Inf.
Comput., vol.
205, no.
3, pp.
380-415, 2007.
R. Alur, T. Feder, and T. A. Henzinger, "The benefits of relaxing punctuality," Journal of the ACM, vol.
43, no.
1, pp.
116-146, 1996.
Y. Hirshfeld and A. Rabinovich, "Timer formulas and decidable metric temporal logic," Inf.
and Comp., vol.
198, no.
2, pp.
148 - 178, 2005.
O. Maler, D. Nickovic, and A. Pnueli, "From MITL to timed automata," in Proc.
of FORMATS, ser.
LNCS, 2006, vol.
4202, pp.
274-289.
P.-Y.
Schobbens, J.-F. Raskin, and T. A. Henzinger, "Axioms for realtime logics," Theor.
Comput.
Sci., vol.
274, no.
1-2, pp.
151-182, 2002.
R. Alur and D. L. Dill, "A theory of timed automata," Theoretical Computer Science, vol.
126, no.
2, pp.
183-235, 1994.
J. Bengtsson and W. Yi, "Timed automata: Semantics, algorithms and tools," in Lect.
on Concurrency and Petri Nets, ser.
LNCS.
Springer, 2004, vol.
3098, pp.
87-124.
P. Niebert, M. Mahfoudh, E. Asarin, M. Bozga, O. Maler, and N. Jain, "Verification of timed automata via satisfiability checking," in FTRTFT, ser.
LNCS, 2002, vol.
2469, pp.
225-243.
B. Badban and M. Lange, "Exact incremental analysis of timed automata with an SMT-solver," in FORMATS, ser.
LNCS, 2011, vol.
6919, pp.
177-192.
G. Audemard, A. Cimatti, A. Kornilowicz, and R. Sebastiani, "Bounded model checking for timed systems," in Proc.
of FORTE, 2002, pp.
243- 259.
E. M. Clarke, D. Kroening, J. Ouaknine, and O. Strichman, "Completeness and complexity of bounded model checking," in VMCAI, ser.
LNCS, vol.
2937.
Springer, 2004, pp.
85-96.
A. Rabinovich, "Complexity of metric temporal logics with counting and the Pnueli modalities," Th.
Comp.
Sci., vol.
411, pp.
2331-2342, 2010.
M. M. Bersani, A. Frigeri, M. Rossi, and P. San Pietro, "Completeness of the bounded satisfiability problem for constraint LTL," in Reachability Problems, ser.
LNCS, 2011, vol.
6945, pp.
58-71.
M. Pradella, A. Morzenti, and P. San Pietro, "Bounded satisfiability checking of metric temporal logic specifications," ACM Transactions on Software Engineering and Methodology (TOSEM), 2013, to appear.
M. M. Bersani, A. Frigeri, A. Morzenti, M. Pradella, M. Rossi, and P. San Pietro, "CLTL Satisfiability Checking without Automata," arXiv:1205.0946v1, 2012.
----, "Bounded reachability for temporal logic over constraint systems," in TIME.
IEEE Computer Society, 2010, pp.
43-50.
"Zot: a bounded satisfiability checker," available from zot.googlecode.com.
Y. Hirshfeld and A. Rabinovich, "Quantitative temporal logic," in Computer Science Logic, ser.
LNCS, 1999, vol.
1683, pp.
172-187.
Y. Hirshfeld and A. M. Rabinovich, "Logics for real time: Decidability and complexity," Fund.
Inf., vol.
62, no.
1, pp.
1-28, 2004.
C. A. Furia, D. Mandrioli, A. Morzenti, and M. Rossi, Modeling Time in Computing, ser.
EATCS Monographs in Th.
C. Sci.
Springer, 2012.
"qtlsolver," available from qtlsolver.googlecode.com.
Belief Revision in a Discrete Temporal Probability-Logic  Scott D. Goodwin  Department of Computer Science University of Regina, Canada  Howard J. Hamilton  Department of Computer Science University of Regina, Canada  Abdul Sattar  School of Computer & Information Technology Grifith University, Australia  Abstract  We describe a discrete time probabilitylogic for use as the representation language of a temporal knowledge base.
In addition to the usual expressive power of a discrete temporal logic, our language allows for the specication of non-universal generalizations in the form of statistical assertions.
This is similar to the probability-logic of Bacchus, but diers in the inference mechanisms.
In particular, we discuss two interesting and related forms of inductive inference: interpolation and extrapolation.
Interpolation involves inferences about a time interval or point contained within an interval for which we have relevant statistical information.
Extrapolation extends statistical knowledge beyond the interval to which it pertains.
These inferences can be studied within a static temporal knowledge base, but the further complexity of dynamically accounting for new observations makes matters even more interesting.
This problem can be viewed as one of belief revision in that new observations may conict with current beliefs which require updating.
As a rst step toward a fulledged temporal belief revision system, we consider the tools of inductive logic.
We suggest that Carnap's method of conrmation may serve as a simple mechanism for belief revision.
1 Introduction  Standard discrete temporal logics allow the representation of what is true at a point, in a situation, or over an interval.
To introduce uncertainty, many researchers in AI have turned to nonmonotonic \logics," but semantic and computational diculties have led some to consider probability as a representational device.
Here we describe a discrete time probabilitylogic for use as the representation language of a tem-  Eric Neufeld  Department of Computational Science University of Saskatchewan, Canada  Andre Trudel  Jodrey School of Computer Science Acadia University, Canada  poral knowledge base.
In addition to the usual expressive power of a discrete temporal logic, our language allows for the specication of non-universal generalizations in the form of statistical assertions.
This is similar to the probability-logic of Bacchus 1], but diers in the inference mechanisms.
In particular, we discuss two interesting and related forms of inductive inference: interpolation and extrapolation.
Interpolation involves inferences about a time interval or point contained within an interval for which we have relevant statistical information.
Extrapolation extends statistical knowledge beyond the interval to which it pertains.
These inferences can be studied within a static temporal knowledge base, but the further complexity of dynamically accounting for new observations makes matters even more interesting.
This problem can be viewed as one of belief revision in that new observations may conict with current beliefs which require updating.
As a rst step toward a full-edged temporal belief revision system, we consider the tools of inductive logic.
We suggest that Carnap's method of conrmation 3] may serve as a simple mechanism for belief revision.
We begin by introducing our temporal logic and then turn to the problem of inferencing.
The rst form of inference we consider is what Carnap calls direct inference: the inference from a population to a sample.
In the case of temporal information, this amounts to inference from an interval statistic to a subinterval or point.
Before moving on to more complex kinds of inference, we introduce the learning (or belief revision) component, Carnap's method of conrmation, which incorporates new observations into the direct inference process.
Next we consider the general case of direct inference: interpolation.
Then we turn our attention to the problem of extrapolation of statistical information (what Carnap calls predictive inference).
Finally, we consider the problem of belief revision in connection with these temporal inferences.
2 Discrete temporal probability-logic  In this section, we introduce a discrete probabilitylogic which serves as a representation language for temporal applications.
The probability-logic, which we call PL(T ), is similar to that of Bacchus 1].
The most important dierence is in the inference machinery and the addition of time into the ontology.
PL(T ) allows the expression of standard rst order logic expressions plus two kinds of probability statements.
Before examining the probability-logic, we rst explore the two kinds of probability.
2.1 Statistical and inductive probabilities  Carnap 3] has suggested the need for two distinct concepts of probability (the relevance of this view to AI was recently suggested 1, 8]).
The statistical concept of probability, having the sense of relative frequency, is needed for empirical knowledge (e.g., most birds y).
As well, the inductive concept of probability, measuring the degree of conrmation of a hypothesis on the basis of the evidence, is needed for beliefs (e.g., to what degree is the belief that Tweety ies supported by the evidence that Tweety is a bird and most birds y).
While statistical probability is empirically based, inductive probability is epistemologically based that is, inductive probabilities constitute a logical relationship between belief (or hypothesis) and evidence.
To give such beliefs empirical foundations, a connection must be made between the statistical and inductive probabilities.
This connection is made on the basis of an appeal to some form of the principle of indierence which says that if our knowledge does not favour the occurrence of one event over another, then the evidence provides equal conrmation for the events.
The inference of inductive probabilities from statistical probabilities via a principle of indierence is called direct inference.
As Carnap 4] has noted, the form of indierence used must be carefully restricted to avoid the introduction of contradictions at the same time, it must remain strong enough to sanction the appropriate conclusions.
The principle of indierence comes into play when choosing the prior probabilities of hypotheses.
Each consistent assignment of priors constitutes a dierent inductive method.
Carnap 4] described two inductive methods which we outline next.
2.2 Two inductive methods  Carnap's two methods are most easily explained with reference to the example shown in Figure 1.
In this example, we have four individuals (balls in an urn) and one property (colour).
Since each ball is either blue (B) or white (W), we regard colour as a binary property (blue or not-blue).
An individual distribution is specied by ascribing one colour to each individual e.g., in individual distribution #2, the rst three balls are blue and the last ball is not.
A statistical distribution is specied by stating the number of individuals for which the property is true, without identifying the individuals e.g., in statistical distribution #2, three of the balls are blue and one is not.
There are 16 possible individual distributions and 5 statistical distributions.
As can be seen in Figure 1, several individual distributions may correspond to a single statistical distribution.
If equal prior probabilities are assigned to each of the individual distributions, the result is Carnap's Method I, and if equal prior probabilities are assigned to each of the statistical distributions, the result is Method II.
Method I consists of applying the principle of indierence to individual distributions and, in the examples, gives each individual distribution a prior probability of 1/16.
Method II consists of rst applying the principle of indierence to the statistical distributions, and then, for each statistical distribution, applying the principle to its individual distributions.
In the example, each of the ve statistical distribution is assigned 1/5, and each 1/5 is divided equally among the individual distributions of the appropriate statistical distribution.
Method II assigns 1/20 to each of individual distributions #2 to #5 because they are the four possibilities (arrangements) for statistical distribution #2 (3 blue balls and 1 white ball).
Method II is consistent with the principle of learning from experience, but Method I is not.
The principle of learning from experience is: \other things being equal, a future event is to be regarded as the more probable, the greater the relative frequence of similar events observed so far under similar circumstance" 4, p. 286].
Suppose we draw three blue balls in sequence, and then consider the probability of the fourth ball being blue.
There are two individual distributions consistent with the evidence: #1 (in which the fourth ball is blue) and #2 (in which the fourth ball is not blue).
Using Method I, the probability is 1/2 because each of individual distributions #1 and #2 is assigned a probability of 1/16, and 1/2 is the relative weight of 1/16 to (1/16 + 1/16).
Using Method II, the probability of the fourth ball being blue is 4/5 because individual distribution #1 is assigned a probability of 1/5 and individual distribution #2 is assigned a probability of 1/20, and 4/5 is the relative weight of 1/5 to (1/5 + 1/20).
Because Method II incorporates the principle of learning from experience, it is better suited to our intended application of temporal reasoning in dynamic situations where new observations are being made.
In Section 3.1, we apply Method II to direct inference from temporal statistical knowledge, but rst we turn to the description of our temporal probability logic.
2.3 PL(T ): A 	rst order temporal probability-logic PL(T ) is a four sorted, rst order, modal logic.1 The 1  Some material in this section is derived from 2].
STATISTICAL INDIVIDUAL METHOD I METHOD II DISTRIBUTIONS DISTRIBUTIONS Initial Initial Probability of Number Number Probability Statistical Individual of of of Individual Distributions Distributions Blue White Distributions 1.
4 0 1.
    1/16 1/5 1/5 = 12/60 2.
3  1  2.
3.
4.
5.
                    1/16 1/16 1/16 1/16  1/5  1/20 = 3/60 1/20 = 3/60 1/20 = 3/60 1/20 = 3/60                              1/16 1/16 1/16 1/16 1/16 1/16  1/5  1/30 = 2/60 1/30 = 2/60 1/30 = 2/60 1/30 = 2/60 1/30 = 2/60 1/30 = 2/60            3.
2  2  6.
7.
8.
9.
10.
11.
4.
1  3  12.
13.
14.
15.
          1/16 1/16 1/16 1/16  1/5  1/20 = 3/60 1/20 = 3/60 1/20 = 3/60 1/20 = 3/60  5.
0  4  16.
    1/16  1/5  1/5 = 12/60  Figure 1: Carnap's Two Methods (from 3, p. 285]) sorts are: object types, object instances, numbers, and times.
Suitable function and predicate symbols are associated with each sort.
Time invariant assertions can be made about domain objects via their object types, while object instances are used to describe domain objects at particular times.
The numeric sort is used to make numeric assertions, specically, assertions about the numeric values of certain probabilities.
The temporal sort allows assertions to include references to the time.
Both the numeric and temporal sort include the constants 1, -1, and 0.
The functions + and fi and the predicates = and < are \overloaded" to provide for all necessary combinations of argument and result sorts.
Additional inequality predicates, numeric and temporal constants can easily be added by denition, and we use them freely.
The formulas of the language are generated by applying standard rst order formula formation rules.
Additional rules are used to generate object instance terms from object type terms and temporal terms: 1.
If o is an object type term, t is a temporal term, ~o is a vector <o1 ,: : : ,on> of n object type terms, and ~t is a vector <t1 ,: : : ,tn> of n temporal terms, then (a) o@t is an object instance term (b) ~o@~t is a vector of n object instance terms,  specically, <o1 @t1,: : : ,on @tn> (c) ~o@t is a vector of n object instance terms, specically, <o1 @t,: : : ,on@t> (d) o@~t is a vector of n object instances terms, specically, <o@t1 ,: : : ,o@tn>.
Two additional rules are used to generate new numeric terms (specically probability terms) from existing formulas: 2.
If  is a formula and ~x is a vector of n distinct object type, object instance and/or temporal variables, then ]~x is a statistical probability term.
3.
If  is a formula, then prob() is an inductive probability term.
These new (numeric) terms denote numbers (that correspond semantically to the values of the probability measure) which can in turn be used as arguments of numeric predicates in the generation of additional new formulas.
We dene conditional probability terms (of both types): j ]~x =df  ^  ]~x = ]~x, and prob(j ) =df prob( ^  )=prob ( ).2 Semantically the language is interpreted using For ease of exposition, we ignore the technicalities of dealing with division by zero.
See 1] for details.
2  models of the form3 M = hO S #  O   S i where: 1.
O is a domain of objects types (i.e., the domain of discourse).
S is a set of states or possible worlds.
# is a state dependent interpretation of the symbols.
Numbers are interpreted as reals IR and the set of times T is taken as integers ZZ .
The associated predicate and function symbols are interpreted as relations and functions over the appropriate domain while +, fi, 1, -1, 0, < and = are given their normal interpretation in every state.4 2.
O is a discrete probability measure P over O. ThatPis, for every A  O,  O (A) = o2A  O (o) and o2O  O (o) = 1.
3.
S is a discrete probability measure P over S .
ThatPis, for every S 0  S ,  S (S 0 ) = s2S  S (s) and s2S  S (s) = 1.
4.
T is a discrete probability measure P over T .
ThatPis, for every T  T ,  T (T ) = t2T  T (t) and t2T  T (t) = 1.
5.
O@T is a discrete probability measure over the set of object instances O@T .
That is, for every O @T P  O@TP ,  O@T (O@T ) = o@t2O@T  O@T (o@t) and o@t2O@T  O@T (o@t) = 1.
O@T is a product measure formed from  O and  T .
The formulas of the language are interpreted with respect to this semantic structure in a manner standard for modal languages.
In particular, the interpretation of a formula depends on a structure M , a current state s 2 S , and a variable assignment function .
The probability terms are given the following interpretation:   1.
(]~x)(Msfi) =  nfi f~as:t:(M s ~x=~a]) j= g , where ~x=~a] is the variable assignment function identical to  except that (xi ) = ai , and  nfi is the n-fold product measure formed from  fii where i = O or O@T or T depending on whether xi is an object type variable, an object instance variable, or a temporal variable.
 ; 2.
(prob())(Msfi) =  S fs0 s:t:(M s0  ) j= g .
So we see that ]~x denotes the measure of the set of satisfying instantiations of ~x in  and prob() denotes the measure of the set of states that satisfy .
Unicorns have a single horn: 8o: unicorn(o) !
singleHorn(o).
Unicorns have never, do not, and will never exist: 8o t: t < now & unicorn(o) !
:exists(o@t), 8o: unicorn(o) !
:exists(o@now), 8o t: t > now & unicorn(o) !
:exists(o@t).
or, more simply: 8o t: unicorn(o) !
:exists(o@t): Most birds y: fly(o)jbird(o)]o > 0:5.
Most birds y now: fly(o@now)jbird(o@now)]o > 0:5.
At any time, most birds y: 8t: fly(o@t)jbird(o@t)]o > 0:5.
For most object instances, if the object type is a bird at the time then it ies at the time: fly(o@t)jbird(o@t)]o@t > 0:5.
Most of the time, most birds y: fly(o@t)jbird(o@t)]o > 0:5]t > 0:5.
Informally, the above expression says that if we pick a time at random, chances are that more than 50% of the birds y at that time.
In addition to statistical assertions, we can also represent inductive probability assertions (which correspond to an agent's beliefs).
For example,  Halpern has called such structures type III probability structures.
4 We ignore the technicalities of dealing with overloading and argument/result type conversions.
The degree of belief in the proposition \Tweety is ying now" is 0.9: prob(fly(tweety @now)) = 0:9:  0  3  In addition to the statistical and inductive probabilities, we need an extension that allows us to represent epistemic expectation.
Specically, if p is a statistical probability term, then E(p) is a new numeric term whose denotation is dened as follows: X (E(p))(Msfi) =  S (s0 ) fi p(Ms fi) : 0  s 2S 0  That is, the expected value of a term is the weighted (by  S ) average of its denotation over the set of states.
2.4 Representation in PL(T ) PL(T ) allows for the representation of a rich variety of statistical and probabilistic temporal information.
Because time is associated with object instances rather than with properties of objects, we can describe objects that come into existence or cease to exist.
We can also talk about properties of object types that have no instances, such as unicorns.
The following examples gives some idea of the expressive power of the language.
The degree of belief in the proposition \Most birds y" is 0.75:   prob fly(o)jbird(o)]o > 0:5 = 0:75: Two remarks are in order here.
First, although PL(T ) supports the representation of beliefs about temporal assertions, there is no support for temporal beliefs, i.e., only the current set of beliefs is representable.
This shortcoming while be addressed in future work.
Second, some form of direct inference is needed to connect the inductive probabilities to the statistical ones as was discussed in section 2.1.
We are now in a position to provide this connection.
3 Inferences in PL(T )  The choice of the distributions  O ,  S , and  T affect inferences in PL(T ).
Choosing a \uniform" distribution for  O ,  S , and  T corresponds to Carnap's Method I.
In the case of  T , we can not have a true uniform distribution since T is innite, so we take  T (T ) = jT j/jTnj, where Tn = f0 ;1 1 ;2 2 :: : ;1n;1 fibn=2cg, and then we consider the situation in the limit as n !
1.
For any nite set of times T , the measure is 0 so we must amend the interpretation of conditional statistical probabilites.
With j ]~x =df limTn !T  ^  ]~x= ]~x, what matters is the relative sizes of the sets of times involved in the numerator and denominator.
We can also choose distributions which result in inferences corresponding to Carnap's Method II.
To do this, the distributions  O and  T are taken as above, but to dene the distribution  S , we need to introduce the concept of structures which are equivalence classes of states.
Two states, s1 and s2 are considered isomorphic if replacing the individuals of s1 with one of their permutations results in s2 .
Let S be the set of structures corresponding to the set of states S .
We can now dene the distribution  S in such a way that every subset S 0 of S which is a member of S has the same measure and every member of S 0 has the same measure.
This results in inferences corresponding to Carnap's Method II.
We examine both Method I and II inferences in section 3.1.
Then in sections 3.2 and 3.3, we discuss interpolation and extrapolation.
Finally, we consider temporal belief revision issues in section 3.4.
1  3.1 Direct inference  We can connect inductive and statistical probabilities in a similar manner as Bacchus did in 1].
We start by assuming that an agent expresses assertions about his environment in a xed statistical language Lstat.
Assertions in Lstat, which are all the assertions of PL(T ) excluding those involving inductive probability, are called objective assertions.
The agent's degree of belief in the objective assertions are represented in another language Lcomb which extends Lstat with the inductive probability operator prob and an  royal elephant(clyde) & elephant(clyde) 8x:royal elephant(x) !
elephant(x) gray(x)jelephant(x)]x > 0:5 :gray(x)jroyal elephant(x)]x > 0:5:  Figure 2: Redundant Information epistemic expectation operator E. Formulas of Lcomb that are also in Lstat are called objective formulas.
The knowledge base KB is the complete nite collection of objective formulas   which are fully believed by the agent i.e., prob KB = 1.
De	nition 1 (Randomization 1]) stat  Let  be a formula of L .
If hc1 : : : cni are the n distinct object constants5 that appear in  ^ KB and hv1  : : : vni are n distinct object variables that do not occur in  ^ KB, then let KBv (v ) denote the new formula which results from textually substituting ci by vi in KB (), for all i.
(KBv is referred to as the randomization of KB or KB randomized.)
De	nition 2 (Direct Inference Principle 1] ) If the agent fully believes that KBv ]~v > 0 and if  is a formula of Lstat then the agent's degree of belief in  should be determined by the equality prob() = E(v jKBv ]~v ): Method I inferences: If the distributions are chosen for Method I as described in section 3, inferences in PL(T ) have similar properties to those described in 6], e.g., desirable inheritance properties.
For example, in Figure 2, PL(T ) infers that prob(:gray(clyde)) > 0:5.
That is, we have inheritance with specicity in spite of the redundant information elephant(clyde).
This method supports a number of desirable inferences such as those involving simple inheritance, multiple inheritance with specicity, ambiguity, cascaded ambiguity, cycles, redundant information, and negative paths (see 6]).
Such a system might be sucient for most needs.
It even includes the ability to revise beliefs about individuals, i.e., inheritance of properties is aected by receiving more specic information about an individual.
Furthermore, the inclusion of additional statistical assertions may aect properties inherited to individuals.
What is lacking, however, is an ability to revise beliefs in statistical formulas given individual observations.
This can be addressed by Method II.
Method II inferences: If the distributions are chosen for Method II as described in section 3, inferences in PL(T ) have in addition to the desirFor our purposes, these refer to object types, object instances, and/or times.
5  able inheritance properties described in 6], the ability to dynamically account for observations in beliefs about statistical assertions.
For example, in Figure 3, if O contains only ve object types, s1, s2, s3, s4, and s5, then, as reported in 7], initially prob(fly(s5)jsparrow(s5)) = 0:6 (see Figure 3).
The table in Figure 3 was computed by the method of exhaustive enumeration as described in 7].
In the table, probI means prob with the distributions set for Method I probII means prob with the distributions set for Method II.
Upon learning that s1 is a ying sparrow, prob(fly(s5)jsparrow(s5)) = 0:5714 under Method II as compared to 0.5 under Method I.
Comparing this to prob(fly(s5)jbird(s5)) which is 0.5, we see that in spite the the observed ying sparrow, Method I sticks to straight inheritance of the ying birds statistic to sparrows, whereas Method II adjusts to the observation and infers sparrows are even more likely to y than birds.
So far, the examples in this section have not involved time.
In sections 3.2 and 3.3, we examine the temporal inferences we call interpolation and extrapolation.
3.2 Interpolation  Suppose we have the following situation: Over the year, it rains 40% of the time.
During winter (December 21{March 20), it rains 75% of the time.
Over the summer (June 21{September 20), it rains 20% of the time.
What percentage of rainfall occurs during December?
What is the chance of rain on December 24th?
We can represent this in PL(T ) by letting the integers 1 through 365 represent the days (i.e., each day is a time point) and provide axioms such as shown in Figure 5.
Inferences about the rainfall in December or on December 24th based on the given statistical information are in a class of inferences we call interpolation.
These inferences involve using interval statistics to induce subinterval statistics or point probabilities.
For instance, the actual percentage of rainfall in December is: P3 = P rain(t)jr3(t)]t rain(t) = R3jR3 j (t)jr3b(t)]tjR3b j = 	rain(t)jr3a(t)]tjjRR33aajj++	jRrain 3b j where the value of the numerator is unknown.
(Note in the summation, we are treating rain as if it were a 0-1 function with value 1 at t if there is rain at time t and value 0 at t otherwise.)
To compute the amount of rainfall in December we divide the month (region R3 from Figure 5) into subregions R3a = dec1 dec20] and R3b = dec21 dec31]: The specic information about R3a is obtained from R5 where R5 = mar21 jun20] + sep21 dec20] = R1 ; R2 ; R4.
rain(t)jr1(t)]t = 0:4, rain(t)jr2(t)]t = 0:75, rain(t)jr4(t)]t = 0:2, % plus axioms dening the % regions r1, r2, r3, r4 R3 : ??
R2 : 75%  Dec1 Dec21 Dec31 Jan1  Mar20  R1 : 40% R4 : 20% Jun21  Sep20  Figure 5: Rainfall Interpolation The statistic for R5 can be computed from the statistics for R1, R2, and R4, and from the relative sizes of these intervals.
We compute the actual percentage of rain P5 over R5 to be approximately 33% (see Figure 4).
By assuming every subset of R5 has the same expected percentage of rain (i.e., using Method I), we conclude the expected percentage of rain over R3a is P5 : The most specic reference class (for which we have or can compute the actual percentage of rainfall) that contains R3b is R2.
By assuming every subset of R2 has the same expected percentage of rain (Method I), we conclude the expected percentage of rain over R3b is 75%.
The expected percentage of rain over R3 equals a weighted average based on R3a and R3b:   E(P3) = E rain(t)jr3(t)]t :75jR3bj = P5 jR3a jj+0 R3 j :7511  0:3320+0 31  48%.
The answer to the original question is that it rains roughly half the time during December.
3.3 Extrapolation  Persistence (the frame problem) has been viewed in two ways: 1) action-invariance of a property: whether a property that is true before an action or event will remain true afterwards, cf.
temporal projection 9] or, 2) time-invariance of a property: if a property is true at some point in time, how long is it likely to remain true 5].
Under these views, a property such as raining at a given point in time is highly action-invariant (few actions aect rain) and slightly time-invariant (it rains for a while and then stops).
Here we consider a previously unexplored aspect of the frame problem: action and time invariance of statistical knowledge.
Given statistical information about various time  A Statistical KB fly(x)jbird(x)]x = 0:6, 8x:sparrow(x) !
bird(x).
Method I and II Inferences Known ying sparrows => none probI (fly(s5)jbird(s5)): 0.6 probII (fly(s5)jbird(s5)): 0.6 probI (fly(s5)jsparrow(s5)): 0.6 probII (fly(s5)jsparrow(s5)): 0.6  s1 0.5 0.5 0.5 0.5714  s1, s2 0.3333 0.3333 0.3333 0.4286  Figure 3: Belief Revision  P5 = rain(t)jr5(t)]t = 	rain(t)jr1(t)]tjR1 j;	rain(t)jjrR2(5tj)]tjR2 j;	rain(t)jr4(t)]tjR4 j ;0:75	79+11];0:292  33%.
= 0:4jR1j;0:75jRj5 jR2j;0:2jR4j = 0:4365365 ;	79+11];92 Figure 4: Calculation of P5.
intervals, we wish to make reasonable inferences about past or future intervals.
For example, Figure 6 depicts a situation where we know that it rained 75% of the time in the winter, and 20% of the time during the summer.
We have no statistical information about the coming year (R6: December 1 to November 30) so the interpolation technique in the previous section is not applicable.
The temporal projection technique of Hanks and McDermott 9] is also inappropriate.
We cannot determine from the statistical information whether it was raining on September 20.
Even if we knew it was raining at that time, it does not make sense to allow raining to persist indenitely.
We have no information about actions or events that may aect raining.
Finally, Dean and Kanazawa's 5] probabilistic temporal projection cannot be used as it requires the construction of a survivor function for raining based on many observations of raining changing from true to false.
In our example, we have no observations of raining at particular points.
We only have interval statistics.
Instead of considering persistence at the level of individual time points, we can view it at the interval level and describe the persistence of statistical information.
If we take the observed statistics to be samples of raining over time (i.e., over the whole time line), we can base our inferences for other intervals on these samples.
For instance, we can infer a statistic for R6 in Figure 6 using R2 and R4 as follows:   E rain(t)jr6(t)]t rain(t)jr4(t)]tjR4 j = 	rain(t)jr2(t)]tjjRR22 jj+	 +jR4 j :292 = 0:7590+0 182  47%.
This result corresponds to that obtained by both Method I and II.
Space considerations force us to omit a detailed discussion of the precise mechanics of interpolation and extrapolation inferencing in PL(T ), but we have provided enough detail to highlight relevant issues.
As well, our discussion of interpolation and extrapo-  lation, so far, has not touched on belief revision issues.
We turn to consideration of this next.
3.4 Temporal belief revision  In the preceeding two subsections, we have described two forms of inferencing in PL(T ).
For a xed temporal knowledge base which includes only interval level statistics (such as in the examples of Figures 5 and 6), the results for Method I and Method II are the same.
The situation becomes more interesting when the knowledge base is updated with new statistics and point information.
There are three important cases to consider: 1) new interval statistics 2) new point information aecting the relevancy of interval statistics and 3) new point information aecting the predicted value of interval statistics.
New interval statistics: Suppose in the example of Figure 6, as time passed, we came to observe the rainfall in December of the coming year (R7, a subinterval of R6) and found it to be 60%.
Prior to learning this, we had predicted the rainfall for the coming year to be about 47%.
The newly acquired interval statistic for December should cause us to revise our prediction for the coming year.
Under both Method I and II, this is indeed the case.
Referring to December of the coming year as region R7, the result under either method would be approximately 50% (see Figure 7).
New point information (relevance): Suppose in the example of Figure 5, we wanted to predict the chances of rain on the day of a party to be held in December (R3).
Since we do not know the exact day, the prediction about rain on the day of the party given the day will be in December is based on the inferred statistic for R3, i.e., prob(rain(party day)) is about 48% (cf.
the example of Figure 4).
As time passes, we come to learn the party will be held on December 24.
This (point level) information should cause us to base our prediction of rain on the statistic for R3b (which is derived from R2) which is more relevant than the inferred statistic for R3 given that the  R2 : 75%  R7 : 60% R4 : 20%  Dec21  Mar20 Jun21  Sep20  Dec1  R6 : ?
?%  Jan1  Figure 6: Rainfall Extrapolation  Nov30      E rain(t)jr6(t)]t = E 	rain(t)jr7(t)]tjR7 j+	rainjR(t6)jjr6(t) & :r7(t)]t jR6 ;R7 j     = E 	rain(t)jjrR7(6tj)]tjR7 j  + E 	rain(t)jr6(t) &jR:6rj7(t)]t jR6 ;R7 j  	 rain ( t ) j r 2( t )] j R t 2 j+	rain(t)jr 4(t)]t jR4 j+	rain(t)jr 7(t)]t jR7 j jR6 ;R7 j   = 	rain(t)jjrR7(6tj)]tjR7 j + jR2 j+jR4 j+jR7 j jR6 j = 0:631 + (0:7590+0:292+0:631)334  50%.
365  213365  Figure 7: Calculation of next year's expected rainfall.
day of the party is in R3b.
Again, this is indeed the case in both Method I and II, and the revised belief becomes: prob(rain(party day)) is 75%.
New point information (value): So far, there is has been no reason to choose between Method I and II.
A dierence arises, however, as we incorporate point level observations that aect the predicted value of interval statistics.
To see this, again consider the example from the previous paragraph about rain on the day of the party.
Suppose we observe the rain on certain days in December (but not the day of the party).
Let us suppose that, although we have made these observations, we have not come to learn the party is not on one of those days.
(This could happen, say, if a friend was telling us about the party and we had independently observed the weather.)
Now suppose each of the days we observed was a rainy day.
This should cause us to revise our belief in rain on the party day, i.e., we should increase our belief in rain on the party day.
Method I does not do this.
It stubbornly holds to the belief prob(rain(party day)) is about 48% based on an unchanged R3 (inferred) statistic.
Method II, however, increases the predicted value of the R3 statistic and hence increases the value of prob(rain(party day)).
4 Conclusion  We have described the discrete temporal probabilitylogic we call PL(T ) which is expressive enough to represent and reason with a rich variety of problems.
Underlying the probability-logic is a choice of distributions over objects, states, and times.
Dierent choices correspond two dierent inductive methods.
We have focused on two methods described by Carnap.
For most purposes, either method seems adequate, but we found there are cases in the context of belief revision where Method II is superior.
This is  particularly true when new point level observations are made which aect the value of predicted interval statistics.
References  1] F. Bacchus.
Representing and Reasoning with Probabilistic Knowledge.
MIT Press, Cambridge, Massachusetts, 1990.
2] F. Bacchus and S.D.
Goodwin.
Using statistical information in planning.
unpublished extended abstract], May 1991.
3] R. Carnap.
Logical Foundations of Probability Theory.
University of Chicago Press, Chicago, Illinois, 1950.
4] R. Carnap.
Statistical and inductive probability.
In Readings in the Philosophy of Science.
Prentice-Hall, 1989.
5] T. Dean and K. Kanazawa.
Probabilistic temporal reasoning.
In Proceedings of the Seventh National Conference on Articial Intelligence, pages 524{528, St. Paul, Minnesota, August 1988.
6] S.D.
Goodwin.
Second order direct inference: A reference class selection policy.
International Journal of Expert Systems: Research and Applications, 5(3):1{26, 1992.
7] S.D.
Goodwin and H.J.
Hamilton.
An inheritance mechanism for default reasoning that learns.
In International Symposium on Articial Intelligence, pages 234{239.
Monterrey, Mexico, 1993.
8] J. Halpern.
An analysis of rst-order logics of probability.
In Proceedings of the Eleventh International Joint Conference on Articial Intelligence, pages 1375{1381, August 1989.
9] S. Hanks and D.V.
McDermott.
Nonmonotonic logic and temporal projection.
Articial Intelligence, 33(3):379{412, November 1987.
2013 20th International Symposium on Temporal Representation and Reasoning  A New Metric Temporal Logic for Hybrid Systems Mark Reynolds School of Computer Science and Software Engineering The University of Western Australia, Perth Email: mark.reynolds@uwa.edu.au  AbstractaWe introduce a new way of dedZning metric temporal logic over the continuous real model of time.
The semantics refer to a single universal clock in order to impose metric constraints to any desired precision.
Furthermore, the expression of any nonmetric aspects can correctly utilise the full power of continuous time temporal logic.
Syntactic constructs afford the convenient succinct expression of many useful and typical constraints while other, more intricate properties are able to be captured but may require more lengthy formulation.
A decision procedure is provided via a simple translation into an existing non-metric temporal logic and this gives a workable complexity and the possibility of automated reasoning.
There are advantages in expressiveness, naturalness, generality and amenability to reasoning techniques over the existing metric temporal logics.
Combining purely continuous with adequate metric aspects in one language makes the logic very suitable for dealing with hybrid systems.
The most highly developed version of MTL is based on what is often called point-wise or discrete semantics [28].
This means that we evaluate formulas over countably indZnite discrete sequences of events at which a system may change state.
This logic may be amenable to automated techniques essentially by conversion to discrete reasoning on the sequences.
Unfortunately, the formulas in this logic have what can only be seen to be un-intuitive meanings with sub-formulas needing to be evaluated at state change points only.
For example, F(0,5) F(0,5) p may not be true even if p holds within ten seconds (because there is no intervening change of state).
See [29], [19].
The other, less common, semantics for MTL is called the continuous semantics.
It allows more natural understanding of temporal operators [28] and allows more properties to be expressed [14].
Unfortunately, MTL is highly undecidable over continuous time semantics [1].
See section II.
In this paper we introduce another seemingly similar but actually quite different metric temporal logic 1CMTL, one clock metric temporal logic, with a continuous time semantics.
The main difference between 1CMTL and MTL is that 1CMTL is based on the idea of there being one universal clock available against which all quantitative measurements are evaluated.
The 1CMTL clock is universal in the sense that the clock readings mentioned in one subformula of a 1CMTL specidZcation are from the same clock as readings mentioned in any other subformula.
This allows fairly straightforward expression of many typical metric temporal constraints.
We will see how to translate 1CMTL formulas into roughly equivalent MTL ones.
0.25 For example, G0.25 (0,8) (p a qU(0,4.25) r) means that, as measured on a digital clock which changes its display only every 0.25 seconds, for the next 8 seconds, every p event is followed by q remaining continuously true until r holds, and that will happen between 0 and 4.25 seconds after the p event.
There are, of course, precursor suggestions allowing imprecision in metric constraints when formalising requirements.
Notable are the imprecise recording of times of state changes in [4], the approximate properties in [17], the robust timed automata of [16], the weakening functions of [22] and the metric interval temporal logic MITL introduced under the idea of relaxing punctuality [1].
However, our one clock approach to imprecision seems to be novel and we will see that it has some advantages.
This paper also tackles the need to reason with 1CMTL.
To that end we show that 1CMTL formulas can actually be expressed in a simple, somewhat low-level, metric temporal  I. I NTRODUCTION Metric temporal logic is used for applications involving specidZcation and veridZcation of real-time and hybrid systems [10].
A dense, or specidZcally real-numbers, model of time is used and a formal logical language is employed with the ability to express metric, or quantitative timing requirements as well as the relative order and overlap of propositional states and events.
Early approaches include [24] and [26].
Several closely related popular current metric temporal logics are called MTL for metric temporal logic [24], [2].
They allow convenient expression of metric or quantitative temporal constraints.
For example, we might want to say that every time a button is pressed, p, then it will be disabled, q, until the dialogue disappears, r, and that will happen within 3 seconds.
In MTL, our requirement is rendered as G(0,a) (p a (qU(0,3) r)) where G(0,a) is a temporal operator quantifying a formula as always holding from now on, and qU(0,3) r indicates that formula q will hold until formula r does sometime within the next 3 seconds.
Other metric temporal logics such as TPTL [4], MITL [1] or the Duration Calculus [9] have since developed and comparisons are not always straightforward but most subsequent work on metric temporal logics has been with MTL or fragments of MTL.
The current situation with metric temporal logics is unsatisfactory for several reasons.
There are two main versions of MTL with different semantics.
Unfortunately, the version that is less natural, and less expressive is the version most amenable to automated reasoning tasks.
1530-1311/13 $26.00 AS 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.17  63 73  language called MRTL which was recently introduced in [32].
MRTL itself is built on RTL [31] which is a traditional nonmetric temporal logic.
RTL is just the propositional temporal logic of the Until and Since connectives over real-numbers time.
This was developed in [23], shown to be sufdZciently expressive [23], shown to be decidable in [8], axiomatized in [15], [30] and recently shown to be in PSPACE [31].
RTL has a pure continuous semantics with no ad hoc constraints such as dZnite variability or non-zenoness imposed on the behaviours of the propositions.
We give a few more details about RTL in section IV.
It is important to note that the purely continuous RTL is a sublanguage of both MRTL and 1CMTL.
Thus its pure continuous version of Until and Since are available for specidZcations.
1CMTL is thus not like older translations of continuous properties into discrete ones [17].
So, for example, density of a proposition is required by just a simple G(AZ((AZp)U )) conjunct and this means we do not have intervals of any length without p holding ( is just truth).
Such truly continuous properties are needed for hybrid systems and faithful capture of natural language specidZcations.
MRTL builds on top of RTL simply by using some propositions to mark the ticking of a single universal clock matching the standard metric on the reals.
These metric, or ticking, propositions are dZxed, or pre-dedZned in any MRTL structure.
Having a hierarchy of nested ticking propositions allows simple reference to arbitrarily accurate and arbitrarily extensive constraints.
Again, the other non-metric propositions are completely unconstrained.
Interestingly, some simple useful properties can be easily expressed in MRTL even though they are known to be beyond any MTL style metric temporal logic [32].
In [32] we were also able to to show the decidability of the validity problem for MRTL in a surprising way, namely by transforming each MRTL formula into a non-metric RTL formula.
Neither ICMTL nor MRTL can be translated into (traditional discrete time) PLTL.
It is true that in any given 1CMTL formula, there is a most dZne precision mentioned and all metric durations can be assumed to be provided in multiples of that.
Many traditional simple approaches to continuous time properties rely on such an assumption of dZnite variability for all properties and this allows a trivial translation into discrete time temporal logics.
However, 1CMTL is designed to allow reasoning about truly continuous aspects of systems as well as metric constraints and the interrelationships between aspects of both sorts.
Properties related to density, zenoness, accumulations of oscillations, separability, dedekind completeness etc are able to be truly stated in MRTL, because pure continuous RTL is a sub-language.
There is no apparent way to preserve them while making a translation to a discrete model of time.
We do not translate 1CMTL reasoning to PLTL reasoning.
The expressivity of the pure continuous semantics of 1CMTL, MRTL and RTL, and the consequent inability to translate trivially to PLTL, is shared by some other recent approaches to metric temporal reasoning.
However, they seem  to have their own complications.
We could mention [20] with its indZnite number of counting modalities and [7] with its complicated syntactical restrictions and undecidability of satisdZability.
As a fairly simple example of the usefulness of having a pure continuous semantics, consider one of the plausible (but not actually physically realisable) models of a repeatedly bouncing ball described in [12].
The ball bounces an indZnite number of times after being dropped but comes to rest within a dZnite period because of the convergence of the sum of shorter and shorter bounce times (as it loses energy).
In reasoning about a detector capable of sensing when the ball is touching the dZoor, say f , we may want an alarm a to sound within 5 seconds of the ball coming to rest after an episode of such indZnite bouncing.
In MTL, MITL, RTL, MRTL and 1CMTL we can use the Since S operator, the past-time mirror to U , to describe a bouncing accumulation point via I, = I,1 aSS I,2 aSS I,3 as follows: I,1 = AZ((AZf )S) I,2 = ((AZf )Sf )S I,3 = f U  In MITL (and so in MTL), the overall specidZcation for the alarm system can be given as G(I, a Fa$?5 a) while in 1CMTL, we just have to also specify a clock precision and 0.125 a).
In both languages, the say, for example, G(I, a F[0,5] semantics allows truly continuous behaviour, and the specidZcations do mean what we say they mean: an alarm sounds shortly after the end of an accumulation of bounces.
The advantage of the 1CMTL language here, over MITL, is that 1CMTL is decidable: as the bouncing property contravenes dZnite variability, there is no known decision procedure for handling such specidZcations in MITL (or MTL).
There are many more sophisticated and practical examples from the world of mechanical, electrical and quantum devices which we hope to illustrate in a future paper.
We note that in other related work [33], [31], [34], [35] tableau techniques are being developed for reasoning with RTL.
These will carry over directly to MRTL via the abovementioned translation and then thus be available for 1CMTL.
We also show that the two translations give an EXPSPACE complexity result for 1CMTL in section VII.
Thus 1CMTL is a new metric temporal logic which is very expressive, can truly capture continuous-time properties, is natural to use, can be applied in very general situations, affords a wide range of useful operators, has a decision procedure and has tableau-based implementable decision procedures under development.
Recall that, in contrast, continuous-time MTL is undecidable, MITL without dZnite variability has no existing decision procedure and MITL with dZnite variability can not express many truly continuous-time properties.
We will see below that there are also philosophical advantages to using 1CMTL, in addition to that of having a fairly simple metric language based faithfully, aconservativelya, on a purely continuous model of time.
In section II we explain how the one clock approach has advantages in physical plausibility  74 64  Suppose that we have dedZned the truth of formulas Ia and I, at all points of R. Then for all points x: R, x |= p iff x a h(p), for p atomic; R, x |= AZIa iff R, x |= Ia; R, x |= Ia aSS I, iff both R, x |= Ia and R, x |= I,; R, x |= I,UI Ia iff there is y > x in R such that y a x a I and R, y |= Ia and for all z a R such that x < z < y, we have R, z |= I,; and R, x |= I,SI Ia iff there is y < x in R such that x a y a I and R, y |= Ia and for all z a R such that y < z < x, we have R, z |= I,.
over specidZcation languages such as MTL and MITL which ainvolvea an indZnite number of indZnitely precise stop-clocks.
More generally, in section II we give a short account of existing metric temporal logics.
In section III we describe our new metric temporal logic 1CMTL.
In section IV we remind the reader of the non-metric RTL and the low-level metric MRTL.
In section VI we show that 1CMTL formulas can be expressed in MRTL.
This allows us to establish the decidability and complexity of 1CMTL in the next section.
We conclude with a summary and discussion of future work.
II.
E XISTING MTL We have mentioned that there are a wide variety of metric temporal logics.
There are choices in the fundamentals of the semantics, discrete or continuous, and also in the expressiveness of the language.
As we have seen, and as already noted in [19], the situation is messy with general results about expressiveness, decidability and complexity being confused by ad hoc circumstances and these properties being sensitive to slight differences in the semantics or choice of operators [13].
Thus we only give a brief overview.
Most of the timing work over the last two decades have been using the discrete (also called pointwise) semantics and the reasoning algorithms have been built on discrete temporal techniques such as automata or translations to PLTL.
However, such approaches give rise to an un-natural, un-intuitive, expression of specidZcations exemplidZed by the F(0,5) F(0,5) Ia situation which we mentioned above.
The discrete logics are also less generally applicable especially as they make strict assumptions on the behaviour of propositions.
Expressiveness of the approaches is compared in [11].
We will concentrate on the more natural continuous semantics (also called interval-based).
The models are based on boolean signals, i.e.
maps which determine the truth or falsity of propositions at any realnumbers time.
We consider signals over the whole real numbers dZow, allowing behaviours to have been going on indZnitely into the past.
However, it is also common to see the positive or non-negative reals being used as a frame.
DedZnition.
[R-structure] Fix a countable set A of atoms.
An R-structure R = (R, <, h) has a frame (R, <), the reals under the usual irredZexive ordering, and a valuation, or boolean signal, h for the atoms, i.e.
for each atom p a A, h(p) a R. In what follows, (metric) intervals I will be interval subsets of (0, a) a R with end points in Q aS {a}.
Again, there are variants in which the intervals only have natural number end-points.
The language for MTL is generated by the 2-place connectives UI and SI for each interval I along with classical AZ and aSS.
So we dedZne the set of formulas recursively to contain the atoms and for formulas Ia and I, we include AZIa, Ia aSS I,, I,UI Ia and I,SI Ia.
MTL formulas are evaluated at points in structures R = (R, <, h).
We write R, x |= Ia when Ia is true at the point x a R. This is dedZned recursively as in Figure 1.
Abbreviations include FI Ia aA IUIa and GI Ia aA AZFI AZIa.
The unrestricted Until of RTL is also an abbreviation IaU I, aA  Fig.
1.
Semantics for MTL  IaU(0,a) I,.
Similarly, Since.
Finite variability of the boolean signals is often assumed (explicitly) in order to obtain technical results about expressibility, decidability or complexity of MTL-like languages.
There are some different ways of dedZning these restrictions but essentially we require that every proposition changes truth value only a dZnite number of times in any bounded interval of time [19].
One aspect of MTL (and MTL-like languages) which is not often discussed but is relevant for us is the way that actual observed behaviours may be evaluated against specidZcations.
This is important for practical applications, but it also determines whether specidZcations in the language can correspond to some desired property in theory.
MTL has formulas such as G(r a pU[2.5,3.5] q)) saying that every r event is followed after a period of between 2.5 and 3.5 units (inclusive), by a q event and p holds continuously in between.
Checking whether an actual behaviour of a system satisdZes an MTL specidZcation may thus be physically impossible.
It would seem to need an indedZnite number of stop-watches, one being set off whenever an r event occurs.
Why do we need a lot of stop-watches?
Because, the time limits are strictly dedZned.
There is a non-zero range or interval in which an event can occur (this means the formula is in the sub-language MITL that we meet below), but the range has very precise end points that have to be measured exactly from when the r event occurs.
It is no good trying to use a global clock unless you are capable of recording the time of every r event with indZnite accuracy.
This is because having a q event 2.49999 units after r and none until the next 1.00002 units after that is not enough to satisfy the specidZcation.
MTL (and MITL) languages rely on measuring durations to indZnite accuracy in order to determine whether formulas are satisdZed, i.e.
whether a particular observed duration lies within an interval or not.
Furthermore, even a short formula (such as G(r a pU[2.5,3.5] q)) may require an indZnite number of such measurements to be made (as an Until formula may need to be evaluated at an indZnite number of starting points).
Thus we claim in this paper that MTL (and MITL) requires indZnitely many, indZnitely accurate clocks.
75 65  MTL-like languages can express a reasonable range of metric temporal constraints.
However, Amir Pnueli suggested that the modalities of MTL, and similar languages, are not completely adequate.
He presented the following example specidZcation: p and then q will hold within the coming unit of time.
He conjectured that such specidZcations can not be expressed in metric languages like MTL with dZnite numbers of connectives [2], [36].
This is sometimes known as Pnuelias conjecture.
In [6] it was shown that this example can be expressed in MTL, but other useful properties can not be and in [18], [21], HirschdZeld and Rabinovich proved a stronger lack of expressiveness result for MITL.
It seems that MTL style languages are not able to express these simple and useful properties.
See also [27].
It has long been known that deciding valid formulas in MTL over dense time is highly undecidable [3]: there can be no procedure for determining validity.
With some restrictions on behaviour, the (restricted) logics can be decided [14] and [1] but the procedures are so complicated that no implementations exists.
Over the much simpler discrete model of time MTL is decidable with an EXPSPACE complexity [3] and tools do exist [5].
Over continuous time semantics the best results are probably for the following two MTL-like languages.
Metric Interval Temporal Logic (MITL) was introduced in [1] to be the fragment of MTL in which the intervals I on the operators UI can not be singleton intervals.
They showed that deciding validity MITL (in pointwise time semantics with dZnite variability) is EXPSPACE-complete.
MITL was introduced in a paper on arelaxing punctualitya but as we saw in the example above, the allowed intervals still have indZnitely precise limits as measured from each and every one trigger event.
Thus checking that a behaviour satisdZes a MITL formula in general can involve an indZnite number of indZnitely precise stop clocks.
QTL, the quantidZed temporal logic, was introduced in [19].
It has ordinary non-metric until and since along with just two new operators aS1 Ia meaning that Ia is true within the next one unit of time (plus mirror image operator).
They showed that QTL is exactly as expressive as MITL over unrestricted continuous time semantics provided that the intervals in the MITL syntax only have integer end points.
They show that deciding QTL is PSPACE-complete but note that the language is not succinct as the expression of any long term constraint requires repeated nesting of aS1 .
R, x |= p R, x |= AZIa R, x |= Ia aSS I, R, x |= I,UIe Ia  iff iff iff iff  R, x |= I,SIe Ia  iff  Fig.
2.  x a h(p), for p a A; R, x |= Ia; both R, x |= Ia and R, x |= I,; there is y > x in R such that [y]e a [x]e a I and R, y |= Ia and for all z a R s.t.
x < z < y, we have R, z |= I,; and there is y < x in R such that [x]e a [y]e a I and R, y |= Ia and for all z a R s.t.
y < z < x, we have R, z |= I,.
Semantic clauses for 1CMTL  The language for 1CMTL is generated by the 2-place connectives UIe and SIe for each interval I and each clock granularity e, along with classical AZ and aSS.
So we dedZne the set of formulas recursively to contain the atoms and for formulas Ia and I, we include AZIa, Ia aSS I,, I,UIe Ia and I,SIe Ia.
Suppose e = 2am for some m a ZaL0 .
This value will determine the granularity of clock that is used to assess the metric information.
With respect to a clock of granularity e, we say that the e-clock time of an event which occurs at realtime t a R is the rational value [t]e = et/e.
For example, [0.367]0.25 = 0.25.
Thus we imagine a digital 0.25-clock showing 0.25 on the display at every time t a [0.25, 0.5).
The termination interval is determined by two non-negative rational numbers, a, b a Q such that 0 a$?
a a$?
b.
In fact, we will see that we can also suppose that a = [a]e and b = [b]e as specifying an interval to a greater accuracy is ignored in our semantics.
Thus, expressing a and b in binary needs at most m places after the binary point.
We now give the semantics for the new two-place connective e e .
The formula pU[a,b] q means that p holds from now, at U[a,b] real-time t say, until some future real-time s, such that q holds at real-time s, and the difference [s]e a [t]e in e-clock time between now and real-time s lies in the range [a]e to [b]e , i.e.
[a]e a$?
[s]e a [t]e a$?
[b]e .
Figure 2 gives the semantic clauses.
Abbreviations include FIe Ia aA UIe Ia and GeI Ia aA AZFIe AZIa.
The unrestricted Until of RTL is also an abbreviation IaU I, aA 1 I, and the reader can check that this is indeed standard IaU[0,a) Until despite the imprecision of our timing.
Unrestricted future occurrence F , and constant truth into the future G are then dedZned in the usual way from U .
Similarly, Since is used to dedZne PIe Ia aA SIe Ia, HIe Ia aA AZPIe AZIa and unrestricted S, P and H. The combination GHIa thus means that Ia holds at all times in the past, present and future.
As an example, suppose that e = 0.25, q holds at time 1.2 and p holds constantly over the open interval (0.1, 1.2).
0.25 q is true at time 0.1.
This is despite the fact Then pU[0.5,1.0] that q was not true up to 1 unit after the evaluation time and stayed false a little longer.
That is because the clock concerned showed time 0 when we started the evaluation and still showed time 1 when q became true.
0.125 q is not true at In the same situation the formula pU[0.5,1.0] time 0.1.
This is because the (new more accurate clock) shows  III.
1CMTL In this section we introduce the new metric temporal logic 1CMTL which is the main contribution of the paper.
Semantics is over R-structures just as for the version of MTL which we introduced above.
Temporal formulas involve a clock granularity, or precision, which is assumed to be e = 2am for some m aL 0.
Following MTL, (metric) intervals I will be interval subsets of [0, a) a R with end points in Q aS {a}.
Note that 0 is allowed to be in the interval (unlike in MTL).
76 66  time 0 when we start and it shows time 1.125 (and not still 1.0) before q is true.
e Note that, as mentioned above, the formula IaU[a,b] I, has the e same truth conditions as IaU[a ,b ] I, whenever [a]e = [a ]e and [b]e = [b ]e .
Thus, we assume for now that we always choose a and b so that a = [a]e and b = [b]e .
On a similar note, it is recommended, but not required, that properties are usually formalised using one minimum precision value in all superscripts.
This is intuitively sensible if we are thinking about timing behaviours against one global clock.
Asking whether p is true within 5 seconds, as measured on the clock using 1 second precision, but not true within 5 seconds if using a 0.5 second precision is possible but not a very natural query.
It is better to ask the equivalent query: is p true next within 4.5 to 5 seconds, as measured on the clock using 0.5 second precision.
For a more complicated example consider the MTL formula G(pU[2.5,3.5] q).
Again, we can not say this exactly in 1CMTL.
However, we can something arbitrarily close to this.
Consider the 1CMTL version of this property as rendered with a clock 0.25 q).
The display updating every 0.25 seconds: it is G(pU[2.5,3.5] task of assessing whether a particular behaviour satisdZes this formula just involves running one global clock with the far from indZnite precision of 0.25 seconds.
We do have to note down the time of each r event, but we only have to note what the clock saysa accurate to 0.25 seconds.
For example if there was an r event at time 1.75921 and at time 1.9203 then we just look at the clock each time and note that it says 1.75 both times.
We then watch p staying true until perhaps we see q true when the clock says 5.25 and we are done.
We do not have to start off a new indZnitely precise stop-watch every time that an r event occurs as one does in MTL or MITL.
In the same situation for MITL, in contrast, you have to start one indZnitely precise stop-watch when you see r true at time 1.75921 and another one at time 1.9203.
You need to watch very carefully to see that the q event occurs before 5.25921 seconds after the 3.5 duration elapses from the dZrst r. Because indZnite precision matters in MITL ayes, even though the timing intervals have non-zero durationa every trigger event needs its own stop watch in principle.
Thus, we have sketched an expressiveness result along the lines of the following.
For each formula of the form IaUI I, of existing MTL, there is a sense in which we can approximate the semantics, the meaning, to any desired level of accuracy with a 1CMTL formula.
We leave the rigorous formulation and proof of a result along these lines for the future.
the dZrst-order monadic logic of the real numbers.
Later in the section we will see that there are reasoning techniques for RTL.
The language L(U, S) is generated by the 2-place connectives U and S along with classical AZ and aSS.
Formulas are again evaluated at points in R-structures.
The semantic clauses are as for 1CMTL except that R, x |= I,U Ia iff there is y > x in R such that R, y |= Ia and for all z a R such that x < z < y, we have R, z |= I, (and I,SIa is the mirror image).
In [31], we show that, as far as determining validity is concerned, RTL is just as easy to reason with as PLTL.
In particular, the complexity of the decision problem is PSPACEcomplete.
The proof in that paper uses intricate reasoning with the mosaic techniques in temporal logic.
We decide whether a dZnite set of small pieces of models is sufdZcient to be used to build a real-numbers model of a given formula.
Mosaic reasoning techniques can often be the foundation of tableau implementations [25].
The mosaic proof in [31] suggests a tableau based method for determining RTL validity but details and subsequent development were left for future work.
In [35] we make further progress in this direction but there is still much to do.
V. MRTL In this section we remind the reader of our recently introduced low-level metric temporal logic, MRTL [32].
To dedZne MRTL we work in RTL but split the set of propositional atoms L into two disjoint indZnite sets and reserve one of the countable sets of atoms for special metric purposes leaving the other countable set of atoms for normal propositions.
Suppose L = A aS T where A and T are disjoint countably indZnite sets of atoms.
Suppose further that T = {..., !a2 , !a1 , !0 , !1 , !2 , ....}.
These metric propositions are going to represent the ticking of a clock over time.
One element, !
a T , also called !0 , will hold for an instant on the event of the regular ticking of the clock every one unit of time.
The other propositions in T represent dZner and coarser rates of ticking allowing us to easily refer to arbitrarily small and arbitrarily large durations of time.
We will informally call !
=!0 a tick, !a1 a sub-tick, !1 a super-tick, !a2 a sub-sub-tick, !2 a super-super-tick, etc.
These are a range of levels of granularity of ticking.
See Figure 3.
The various levels of ticks are propositions indicating the ticking of one single universal clock.
Ticks will occur regularly across time.
Sub-ticks will happen mid-way between ticks as well as coinciding with each tick: so they are twice as frequent.
Super-ticks happen only at alternative ticks so they are half as frequent.
Sub-sub-ticks will occur on every sub-tick and midway between each adjacent pair of sub-ticks.
Super-super-ticks will only occur once every four ticks.
And so on.
There is thus a two-way indZnite linear hierarchy of ticking propositions related to each other by factors of powers of two.
Base 10, or other bases, could equally be used instead.
As we mentioned earlier, we call the clock universal because there is just one clock, albeit with a hierarchy of layers  IV.
RTL As background we outline recent work on a traditional non-metric temporal logic over real-numbers time.
RTL, the propositional temporal logic over real-numbers time uses the Until and Since connectives introduced in [23].
We know from [23] that this logic is sufdZciently expressive for many applications: technically it is expressively complete and so at least as expressive as any other usual temporal logic which could be dedZned over real-numbers time and as expressive as  77 67  e So we sketch the proof that the formula pU[a,b] q can be expressed in MRTL.
Recall that we can assume that e = 2am for some m aL 0 and that a = [a]e and b = [b]e .
Say that n = log2 b + 1.
Our rendering of the formula will be a rather long MRTL formula using only the atoms p n = {!am , !am+1 , ..., !n }.
and q and those in Tam The dedZnitions below assume that n and m are now dZxed in context.
e Consider pU[a,b] q being true at some time t0 a R in n switch on and off some MRTL model.
The atoms in Tam in a certain pattern spread over a length of 2n which repeats indZnitely in both directions.
For each j a Z, call the interval [j.2n , (j + 1).2n ) the jth repeat of the pattern.
There are 2n+m + 1 distinct time points during that interval of repeated pattern of length 2n at which !am (and possibly some of the other ticking propositions) are true, including the start and end point.
The jth repeat (which does not include the dZnal end point) is thus divided into 2n+m sub-intervals of the form Dkj = [j AV 2n + k AV 2am , j AV 2n + (k + 1) AV 2am ) for each k = 0, 1, ..., 2n+m a 1.
Thus every time point in R belongs to one such sub-interval.
For given n and m, we say that a time point t is in the kth sector and the jth repeat iff k = ([t]e a [t]2n )/e and j = [t]2n or equivalently, t a Dkj for some j.
There are 2n+m sectors of each repeat indexed by k = 0, 1, ..., 2n+m a 1. e q into 2n+m differWe will break up the meaning of pU[a,b] ent disjuncts depending on the sector of the starting position.
For each k = 0, 1, ..., 2n+m a1 we will below make a formula Dk .
This says that now we are in the kth sector (of some repeat) 2n+m a1 e e and IaU[a,b] I, holds.
Thus IaU[a,b] I, aA k=0 Dk .
Now consider some dZxed k. We will put Dk = I,(IV) where IV is a MRTL formula and I,(r) is a MRTL formula using a fresh atom r which we later substitute by IV.
Let l = ((k + a/e)mod2n+m ) which is the sector number at a duration of a after the start of the kth sector and let l = ((k + b/e)mod2n+m ) which is the sector number at a duration of b after the start of the kth sector.
We will arrange that I,(r) says that p holds from now (during the kth sector) until the very start of the next lth sector when r holds.
And IV says that p holds from now at the very start of a lth sector until some time at which q holds and lying at the latest in the next l th sector.
Let us represent a sector number k = 0, 1, ..., 2n+m a 1 bj (k).2j where each bj (k) a in binary as k = ILj<n+m j=0 {0, 1}.
We can  say that now we are in a kth sector via n Dk = (AZ!am )U ( j=am I,j (k + 1)) where I,j (k + 1) =!j if bj (k + 1) = 1 and I,j (k + 1) = AZ!j if bj (k + 1) = 0.
We thus look ahead to the start of the k + 1th sector to see what metric atoms hold then.
Note that we could as well have made an alternative formulation instead looking back to the start of the kth sector using Since.
Lemma.
t a R is in a kth sector iff R, t |= Dk .
Now, between the kth sector and the next lth sector there should be no !n true if k < l < 2n+m or exactly one place where !n is true if l a$?
k. We need to say that in order to limit  of ticking, in the semantics.
All references to ticks within subformulas of an MRTL formula are references to the ticks in that one hierarchy.
We see that this is in contrast to the semantics of MTL-like languages, where every truth evaluation of a subformula at every time point sets off its own stopwatch.
So !
will be true in our MRTL structures at the integer points Z = {..., a2, a1, 0, 1, 2, ...} a R. In general !n will be true at exactly the points 2n Z = {m AV 2n |m a Z}.
So at time point t = a2 we have all the following propositions true {..., !a2 , !a1 , !, !1 } in all MRTL structures.
See the Figure 1.
To be more rigorous, MRTL-structures R = (R, <, h) will have the reals as frame and a valuation h for the atoms which is restricted, i.e.
pre-dedZned, for the atoms in T as follows: for each n a Z, h(!n ) = 2n Z.
The language is just L(U, S) as for RTL and formulas are evaluated at points in structures R = (R, <, h) just as for RTL.
Thus we do not set out the semantic clauses yet again here.
The surprising result from [32] is that reasoning about validity (or equally satisdZability) in the metric logic MRTL can be be accomplished by reasoning (about a slightly different formula) in the non-metric RTL.
This gives a PSPACE decision procedure for MRTL via what is quite a simple translation to then use the PSPACE decision procedure for RTL [31].
See [32] for full details.
VI.
1CMTL INTO MRTL In this section we show how to translate 1CMTL formulas into equ-satisdZable ones in MRTL.
Similar ideas allow translation of 1CMTL directly into equivalent MRTL ones but, for the purposes of deciding satisdZability, it is better to translate to shorter equi-satisdZable formulas of MRTL (which are not necessarily equivalent).
First, look briedZy at an example.
How do we translate 0.25 pU[2.5,3.5] q?
Given that we are considering a duration of nearly 4 seconds here and that we want to work at a granularity of 0.25 seconds one way of dedZning this property in MRTL is to use 4/0.25 = 16 different conjuncts for the 16 different intervals between sub-sub-ticks lying between adjacent supersuper-ticks.
Each of these conjuncts is to capture the situation if the starting time point lies in that interval.
For example, one conjunct might say (roughly) that the starting point (modulo 4) is in [1.25, 1.5) and q holds from then until an end point where p holds at a time (modulo 4) in either the next interval [3.75, 4) or the next interval [0, 1.0).
Saying that a time modulo 4 lies in a particular interval such as [1.25, 1.5) can be accomplished by checking the truth of the various ticks at the end point.
For example, (AZ!a2 )U (!a2 aSS!a1 aSSAZ!0 aSS(AZ!0 )U (!1 aSSAZ!2 )) says that a time (modulo 4) lies within the interval [1.25, 1.5).
To return to the proof now, our dZrst, and most complicated, task is to show how simple 1CMTL formulas can be translated into MRTL.
Later we will show how to work on more complicated formulas by breaking them down.
We will just consider e q for 0 < a < b.
Other the case of a formula of the form pU[a,b] e e e e q and pS[a,b] q are formulas such as pU(a,b] q, pU(0,b] q, pU[a,a) similar and we do not present the details.
78 68  !1 !0 !0 !a1 !a1 !a1 !a1  .
.
.4 !
!3 !2 !1 !1 !0 !0 !0 !0 !a1 !a1 !a1 !a1 !a1 !a1 !a1 !a1  !2 !1 !1 !0 !0 !0 !0 !a1 !a1 !a1 !a1 !a1 !a1 !a1 !a1  !3 !2 !1 !0 !a1  a2  0  4  8  a1  1  2  Fig.
3.
3  5  6  7  MRTL pre-dedZned atoms  the range of the until operator to just the next lth sector (not any later ones).
I,(r) = Dk aSS (AZ!n aSS p)U (Dl aSS r) if k < l and I,(r) = Dk aSS (AZ!n aSS p)U (!n aSS p aSS (AZ!n aSS p)U Dl aSS r) if l a$?
k. Lemma.
p holds from now (during the kth sector) until the start of the next lth sector when r holds iff R, t |= I,(r).
Similar considerations allow us to dedZne IV to mean that p holds from now (at the start of an lth sector) until some time at which q holds before the start of the next (l + 1)th sector.
Thus, pU q holds and we do not have AZq holding constantly until the start of the next (l + 1)th sector.
So we put IV = (pU q) aSS AZ(AZq aSS AZ!n )U (Dl +1 ) if l < l and IV = (pU q) aSS AZ(AZq aSS AZ!n )U (AZqaSS!n aSS (AZq aSS AZ!n )U Dl +1 ) if l a$?
l. Lemma.
p holds from now at the start of a lth sector until some time at which q holds and lying at the latest in the next l th sector iff R, t |= IV.
So dZnally we can dedZne Dk = I,(IV) and we get our result.
Lemma.
p holds from now (during the kth sector) until the start of the next lth sector and further until some time at which q holds and lying at the latest in the next l th sector iff R, t |= Dk .
2n+m a1 e Lemma.
R, t |= k=0 Dk iff R, t |= IaU[a,b] I,.
As we have said, we are not going to go through the details for other variations on simple 1CMTL formulas as they are similar and similarly intricate.
It remains to show how to translate a more complicated formula, D say, from 1CMTL into MRTL.
This is accomplished by a very straightforward induction based on using fresh atoms for each of the direct subformulas.
For example, to translate e IaU[a,b] I, we choose fresh atoms pIa and pI, and assuming the e translation function is T , we put T (IaU[a,b] I,)  answering correctly whether the formula is valid in RTL or not, and (3) the space taken for machine to do its job is bound by a polynomial in terms of the size of the input formula.
It is important to be careful about what we mean by the size of the input formula when we consider complexity results for decision procedures for formal languages.
In [31] we showed that for RTL we could consider the length of the input to be the same as the number of symbols in the formula.
This is despite the fact that we could not use an input alphabet which has a separate symbol for each atom as there are indZnitely many atoms.
We will see that things are different for MRTL and 1CMTL.
In [32] we dedZne the length of a formula of MRTL to be the number of symbols in the formula (counting repeated appearances) with the integer numbers in the superscripts of !Aan being in unary notation.
That is the length of !n is 2 + |n|.
For example, D3 =!3 aSS (((AZ!3 )U !3 ) aSS ((AZ!3 )S!3 )) has length 31.
The use of unary for the superscripts was justidZed on the basis that those superscripts will be used to support durations specidZed in binary as we will see below.
In essence, the use of !5 , for example, is to encode a duration given as 32 = 25 : thus the length of the duration, input as a binary number is 5.
Using that dedZnition of length we get a PSPACE decision procedure for MRTL via the translation into RTL [32].
Now consider 1CMTL.
We would want to assume that the binary rational numbers attached to connectives and specifying durations can be 0.5 entered in binary.
For example, in pU(0,32) q, meaning that p will hold until q is true and that happens before a clock with precision 0.5 units reaches 32 units more than what it displays now.
Consider the 32 unit duration.
It will be convenient for such a measure to be entered in binary.
Thus this formula would be input into an algorithm in binary as something like p UE0.1_(0,100000)q of length 18 symbols.
When we translate such a formula into low-level MRTL there is an exponential expansion into a formula involving levels of ticks from !a1 up to !5 .
So, by writing the 32 in binary using six symbols we have effectively made use of a reference to !5 .
We have seen in the last section that a 1CMTL formula of length n translates into an equally-satisdZable formula of MRTL of length 2n (and using only metric atoms !k for an a$?
k a$?
n).
Inputting such a formula into the PSPACE  = T (pIa U pI, ) aSS GH(pIa a T (Ia)) aSS GH(pI, a T (I,)).
Lemma.
The length of the equi-satisdZable MRTL formula to 1CMTL formula Ia of length n is less than 24n .
VII.
C OMPLEXITY In this section we consider the complexity of the decision procedure which we have just outlined.
The main work of the procedure is done by the RTL decision procedure which we know from [31] is in PSPACE.
This means that (1) there is a Turing machine which can accept formulas of RTL as input, (2) for any formula it halts  79 69  [9] Zhou Chaochen.
Duration calculus, a logical approach to real-time systems.
In Armando Martin Haeberer, editor, AMAST, volume 1548 of Lecture Notes in Computer Science, pages 1a7.
Springer, 1998.
[10] J. Davoren and A. Nerode.
Logics for hybrid systems.
Proceedings of the IEEE, 88(7):985a1010, 2000.
[11] Deepak DaSouza and Pavithra Prabhakar.
On the expressiveness of mtl in the pointwise and continuous semantics.
STTT, 9(1):1a4, 2007.
[12] E. Falcon, C. Laroche, S. Fauve, and C. Coste.
Behaviour of one inelastic ball bouncing repeatedly off the ground.
The European Physical Journal B, B(3):45a57, 1998.
[13] Carlo A. Furia and Matteo Rossi.
On the expressiveness of mtl variants over dense time.
In Jean-FrancESSois Raskin and P. S. Thiagarajan, editors, FORMATS, volume 4763 of LNCS, pages 163a178.
Springer, 2007.
[14] Carlo A. Furia and Matteo Rossi.
Mtl with bounded variability: Decidability and complexity.
In Franck Cassez and Claude Jard, editors, FORMATS, volume 5215 of Lecture Notes in Computer Science, pages 109a123.
Springer, 2008.
[15] D. M. Gabbay and I. M. Hodkinson.
An axiomatisation of the temporal logic with until and since over the real numbers.
Journal of Logic and Computation, 1(2):229 a 260, 1990.
[16] V. Gupta, T. Henzinger, and R. Jagadeesan.
Robust timed automata.
In Proceedings of the International Workshop on Hybrid and Real-Time Systems (HART), volume 1201 of LNCS, pages 331a345.
Springer, 1997.
[17] T. A. Henzinger, Z.
Manna, and A. Pnueli.
What good are digital clocks?
In the 19th International Colloquium on Automata, Languages, and Prog.
(ICALP), vol.
623 of LNCS, pages 545a558.
Springer, 1992.
[18] Yoram Hirshfeld and Alexander Moshe Rabinovich.
A framework for decidable metrical logics.
In JirAaE Wiedermann, Peter van Emde Boas, and Mogens Nielsen, editors, ICALP, volume 1644 of Lecture Notes in Computer Science, pages 422a432.
Springer, 1999.
[19] Yoram Hirshfeld and Alexander Moshe Rabinovich.
Logics for real time: Decidability and complexity.
Fundam.
Inform., 62(1):1a28, 2004.
[20] Y. Hirshfeld and A. Rabinovich.
An expressive temporal logic for real time.
MFCS, 2006.
[21] Y. Hirshfeld and A. Rabinovich.
Expressiveness of metric modalities for continuous time.
Logical Methods in Computer Science, 3(1), 2007.
[22] J. Huang, J. Voeten and M. Geilen.
Real-time property preservation in approximation of timed systems.
1st ACM and IEEE International Conference on Formal Methods and Models for Co-Design, 2003.
[23] H. Kamp.
Tense logic and the theory of linear order.
PhD thesis, University of California, Los Angeles, 1968.
[24] Ron Koymans.
Specifying real-time properties with metric temporal logic.
Real-Time Syst., 2(4):255a299, 1990.
[25] M. Marx, S. Mikulas, and M. Reynolds.
The mosaic method for temporal logics.
In R. Dyckhoff, editor, Automated Reasoning with Analytic Tableaux and Related Methods, Proceedings of International Conference, TABLEAUX 2000, Saint Andrews, Scotland, July 2000, LNAI 1847, pages 324a340.
Springer, 2000.
[26] J. S. Ostroff.
Temporal Logic for Real-Time Systems.
Advanced Software Development Series.
John Wiley and Sons, 1989.
[27] J. Ouaknine and J. Worrell.
On the decidability of metric temporal logic.
In Proceedings of the 20th Annual Symposium on Logic in Computer Science (LICSa05), pages 188a197.
IEEE Comp.
Soc.
Press, July 2005.
[28] JoeEl Ouaknine and James Worrell.
Some recent results in metric temporal logic.
In FORMATS a08: Proceedings of the 6th international conference on Formal Modeling and Analysis of Timed Systems, pages 1a13, Berlin, Heidelberg, 2008.
Springer-Verlag.
[29] J. Raskin.
Logics, Automata and Classical Theories for Deciding Real Time.
PhD thesis, UniversiteE de Namur, Belgium, 1999.
[30] M. Reynolds.
An axiomatization for Until and Since over the reals without the IRR rule.
Studia Logica, 51:165a193, May 1992.
[31] M. Reynolds.
The complexity of the temporal logic over the reals.
Annals of Pure and Applied Logic, 161(8):1063a1096, 2010.
[32] M. Reynolds.
Metric temporal reasoning with less than 2 clocks.
Journal of Applied Non-classical Logics, 20:437a455, 2010.
[33] M. Reynolds.
Dense time reasoning via mosaics.
In TIME a09, pages 3a10, Washington, DC, USA, 2009.
IEEE Comp.
Soc.
[34] Mark Reynolds.
A tableau for until and since over linear time.
In TIME 2011, pages 41a48, 2011.
[35] Mark Reynolds.
A tableau for general linear temporal logic.
J of Logic and Computation, 2013.
[36] Thomas Wilke.
Specifying timed state sequences in powerful decidable logics and timed automata (extended abstract).
In LNCS 863, pages 694a715.
Springer-Verlag, 1994.  decision procedure for MRTL will answer our 1CMTL satisdZability query and the computation space will be bound by some exponential in n: Lemma.
1CMTL is in EXPSPACE.
VIII.
C ONCLUSION In this paper we have presented a new paradigm for metric temporal logics.
We have introduced the simple metric temporal logic 1CMTL which is based on the idea of referring temporal constraints to the reading on an arbitrarily, but not indZnitely precise single universal clock.
This contrasts with existing metric temporal logics which require specidZcations of indZnite accuracy, or at least specidZcations which put indZnitely accurate end points on ranges.
Existing metric temporal logics also allow specidZcations which are unrealistic to check because they seem to require the setting off of an indZnite number of indZnitely accurate stop-watches.
1CMTL is a general metric temporal logic being able to handle arbitrary boolean signals over real-numbers time.
There are no dZnite variability assumptions on the behaviour of the signals.
1CMTL is superdZcially similar to existing MTL but the semantics are quite different in several ways.
Nevertheless, 1CMTL is an expressive language able to specify a wide range of metric temporal constraints.
It captures adequately approximately all MTL formulas.
We have proved the decidability of 1CMTL by showing how it it can be translated via the low-level metric MRTL into the non-metric dense-time temporal logic RTL.
This gives an EXPSPACE decision procedure.
This contrasts with the undecidability of MTL and (more than) matches the complexity of common sub-languages of MTL used for metric specidZcations.
Future work will concentrate on reasoning tasks.
Work is underway [35] on developing tableau techniques for languages like RTL.
Hopefully, that can be extended to MRTL and 1CMTL.
There are currently no implementations for decision procedures for MTL-like languages.
R EFERENCES [1] R. Alur, T. Feder, and T. A. Henzinger.
The benedZts of relaxing punctuality.
J. ACM, 43(1):116a146, 1996.
[2] Rajeev Alur and Thomas A. Henzinger.
Logics and models of real time: A survey.
In J. W. de Bakker, Cornelis Huizing, Willem P. de Roever, and Grzegorz Rozenberg, editors, REX Workshop, volume 600 of Lecture Notes in Computer Science, pages 74a106.
Springer, 1991.
[3] Rajeev Alur and Thomas A. Henzinger.
Real-time logics: Complexity and expressiveness.
Inf.
Comput., 104(1):35a77, 1993.
[4] R. Alur and T. Henzinger.
A really temporal logic.
J. ACM, 41(1):181a 203, 1994.
[5] Domenico Bianculli, Paola Spoletini, Angelo Morzenti, Matteo Pradella, and Pierluigi San Pietro.
Model checking temporal metric specidZcations with trio2promela.
In In FSENa07, 2007.
[6] P. Bouyer, F. Chevalier, and N. Markey.
On the expressiveness of TPTL and MTL.
In FSTTCS 2005, pages 432a443.
Springer, 2005.
[7] P. Bouyer, N. Markey, J. Ouaknine, J. Worrell.
On Expressiveness and Complexity in Real-Time Model Checking.
ICALP (2), pages 124a135, 2008.
[8] J. P. Burgess and Y. Gurevich.
The decision problem for linear temporal logic.
Notre Dame J.
Formal Logic, 26(2):115a128, 1985.
80 70

2013 20th International Symposium on Temporal Representation and Reasoning  Optimal Design of Consistent Simple Temporal Networks Romeo Rizzi and Roberto Posenato Computer Science Department University of Verona Verona, Italy {romeo.rizzi,roberto.posenato}@univr.it restricted requiring to check the consistency frequently.
In the case that an STN becomes (is) inconsistent, it is desirable to easily adjust constraints to make the network consistent again.
One method to solve the inconsistency is finding a minimum set of constraints that has to be removed in order to make the graph free of negative cycles.
It is known that this problem is NP-hard [2], and in fact it is APX-hard because the Feedback Arc Set (FAS) problem can be reduced to it.
Indeed, the feedback arc sets of a graph G = (V, E) are precisely the sets of constraints whose removal makes consistent the STN made of G with weight -1 associated to each one of its arcs.
FAS is APX-hard [3], and can be approximated to within O(log(n) log(log(n))) [4], [5].
In this paper, we denote by n and m the number of nodes and arcs of the graph of reference, respectively.
Therefore, in the literature, many alternatives to tackle the problem have been proposed.
To the best of our knowledge, the most interesting ones are the following.
Planken et al.
[6] presented a polynomial-time algorithm that maintains partial path consistency when new constraints are added or existing constraints are tightened.
In such a way it is possible to verify if the set of new/modified constraints can be accepted or not.
Even if the proposed system exhibits a practically good performance, it does not determine the minimal network and, therefore, the set of all possible values for each timepoint.
Indeed, the algorithm has to be applied iteratively in order to successfully add/restrict constraints to a consistent STN.
Dasdan [2] presented the problem to solve constraint violations in an STN as a more general problem, called Temporal and Spatial Difference Constraint Violations Problem.
After showing that the problem is NP-hard, Dasdan considered specific domain driven conditions on how to modify constraints and, then, gave a polynomial-time algorithm to assist a designer to plan a consistent network by an iterative debugging procedure.
The proposed algorithm determines which constraints are violated supporting the ordering of violations using their inherent criticality or user-defined priority.
This paper introduces a different approach that allows one to solve the constraint violations problem in only one step producing, in polynomial time, a globally optimal network.
Our viewpoint is that each violated constraint should be repaired  Abstract--Simple Temporal Networks (STNs) are used in many applications, as they provide a powerful and general tool for representing conjunctions of minimum and maximum distance constraints between pairs of temporal variables.
During construction of an STN, it is possible that the network presents some constraint violations that need to be resolved.
One way to solve such violations is to remove a minimal number of constraints, already shown to be an APX-hard problem.
Another way is relaxing some constraints in different ways till violations are solved and choosing the best configuration according to one or more criteria.
In this paper, assuming that it is possible to increase any constraint bound of an STN paying a constraint-specific cost, we exhibit a polynomial-time algorithm that repairs an STN eliminating all constraint violations at minimum global cost.
Index Terms--Simple Temporal Networks; STNs design; optimization problem; consistency; minimum cost flow; linear programming.
I. I NTRODUCTION In many areas of Artificial Intelligence (AI), including knowledge representation and planning & scheduling, the representation and management of quantitative temporal aspects is of crucial importance.
Examples of possible quantitative temporal aspects are: constraints on the earliest start time and latest end one of activities, constraints over the minimum and maximum temporal distance between activities, etc.
In many cases, these constraints can be represented as an instance of a Simple Temporal Network (STN) [1], a directed weighted graph where a node represents a time-point variable (timepoint), usually corresponding to the beginning/end of activities, and an arc represents a temporal distance constraint between a v pair of timepoints, e.g., x - y stands for y - x <= v, where v [?]
R. In an STN it is possible to represent constraints like u <= y - x <= v (minimal and maximal temporal distance v -u between x and y) as a pair of arcs, x - y and y - x.
An STN is said to be consistent if it is possible to assign a real value to each timepoint so that all temporal constraints are satisfied.
The consistency property can be verified by searching for negative cycles in the graph and it has been shown that the consistency check and the determination of the earliest/ latest value for each timepoint can be calculated in polynomial time [1].
During the development of an STN, new timepoints or constraints may be added or existing constraints may be 1530-1311/13 $26.00 (c) 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.12  19  (i.e., its bound can be augmented, not reduced) paying a linear cost that can be specified for each constraint.
Within such setting, we exhibit a O(nm) time algorithm that, given a not consistent network, returns a consistent one at minimum global reparation cost.
Since each constraint may have a specific cost function, it is possible to customize in a detailed way the fixing phase and obtain the consistent network avoiding the iterative fixing procedures proposed by other approaches.
Our framework also allows for more general convex cost functions to be dealt with, and we offer algorithms that are efficient both in theory and in practice.
II.
BACKGROUND AND N OTATION In this section, we introduce our basic terminology, some definitions and well-know results about circulations and conservative graphs; we also restate a characterization of the consistency property of STNs.
Our graphs are directed.
For every node v, dv+ denotes the set of arcs exiting v and dv- denotes those entering.
A graph is eulerian if |dv+ | = |dv- | at every node v. It is well known that eulerian graphs can be decomposed into directed circuits [10].
Given a function c : E 7- R, we write ce or c(e) P interchangeably, and when F is a set, c(F ) stands for e[?
]F ce .
Given a directed graph G = (V, E), together with an upper bound capacity ce [?]
R+ , and a value `e [?]
R specified for every arc e, a circulation in (G, c) is the specification of an amount of flow fe to be sent along every arc e, subject to the conservation of flow constraints:  A related line of research was fostered by Khatib et al.
[7].
In [7], the authors introduced a generalization of STNs: Simple Temporal Problems with Preferences (STPPs).
In an STPP each constraint is represented by an arc, an interval, and a preference function.
An assignment of reals to the timepoints is a feasible solution for an STPP if, for every arc, the difference between its two timepoint values falls within the arc interval.
The preference function specifies a quality measure for each point in the interval and, therefore, the goal is to find a solution optimizing the global preference value.
They provide polynomial-time algorithms for the case where the preference function of each constraint is convex.
Though the formalism they proposed is rich, their global preference value essentially amounts however to the maximum of the preference values on the single constraints.
This can be regarded as a bottleneck problem and can hence be solved by means of a binary search on the optimum solution value.
Indeed, it is a property of this framework that, once the optimal solution value has been guessed, then checking whether a solution of that value exists reduces to a classical STN consistency problem.
These results were improved in [7], where the solution to the bottleneck STPP was extended to semi-convex preference functions and with the observation that the sum of costs STTP (i.e., utilitarian global temporal value) can be formulated as a linear program when each preference function is a linear one.
f (dv+ ) = f (dv- ) for every node v. A circulation f is called admissible ifP 0 <= fe <= ce for every arc e. The value of a circulation f is e[?
]E `e fe .
The problem of finding a maximum value circulation can be solved by linear programming, since we optimize a linear function, and all constraints are linear.
As for more efficient solutions, combinatorial algorithms are known for this problem (for a comprehensive survey see [11]).
The main algorithmic approaches pursued in the literature and in applications are: Minimum Mean Cycle Canceling: it is the first special case of cycle canceling (a general primal method) proven to involve a polynomial number of iterations.
In [12], the authors proposed a simple polynomial-time algorithm which runs in O(nm(log n) min{log(nC), m log n}) time on a network of n vertices, m arcs, and arc costs of maximum absolute value C. Successive Shortest Path and Capacity Scaling: in [13] a dual method is presented which can be viewed as the generalizations of the Ford-Fulkerson algorithm.
Cost Scaling: in [14] a primal-dual approach is presented which can be viewed as the generalization of the push-relabel algorithm [15].
Network Simplex: a specialized version of the linear programming simplex method.
Morris et al.
[8] generalized the positive result on the utilitarian version of STPP to convex piece-wise linear functions.
Moreover, proposed a characterization of different notions of global temporal value and the identification of tractable subclasses of STPPs.
Finally, Peintner et al.
[9] proposed a greedy algorithm, and offered an experimental evaluation, for solving STPPs where the preference functions have not to be convex.
In practice, the circulation problem is the classical problem that we have to solve when, once a maximum flow has been found, we seek to find a minimum cost one by iteratively redirecting the flow along cycles of negative costs in an auxiliary network.
Indeed, even if the traditional approaches improve the flow considering one negative circuit at each iteration, it can be argued that these approaches are ultimately interested in finding a circulation of maximum value, that, in turn, can be regarded as a maximum-value eulerian subgraph in the auxiliary network, which decomposes into a packing of cycles.
A weighted graph (G, `) is called conservative when P `(C) := e[?
]C `e >= 0 for every directed circuit C of G.  The remainder of the paper is organized as follows.
in Sect.
II we introduce some definitions and well-know results in order to state a new property of STNs.
In Section III we introduce the problem to repair an inconsistent STN as a linear programming one, while in Section IV we present and discuss the combinatorial algorithm that solves the repair problem most effectively.
In Section V we suggest a suitable approach to get practical solutions when each one of the arc cost functions is convex.
Finally, Section VI concludes the paper.
20  The Bellman-Ford algorithm [16] can be used to produce in O(nm) time: * *  either a proof that (G, `) is not conservative in the form of a negative circuit C in G; or a proof that (G, `) is conservative in the form of a potential function p : V 7- R such that for every arc e = (u, v) of G, its reduced length `pe := `e - pv + pu is non-negative.
[?]
arc (u, v) of G.  h-2, 3 i  h-6, 1 i  B  h-4, 2 i  A h6, 1 i  D h5, 1 i  Fig.
1.
A graph with two negative cycles.
Each label has the form hl, ci, where l is the length and c is the cost of the associated edge.
programming problem: + + + + min `+ (A,B) + `(B,A) + 3 `(A,C) + 3, `(C,A) + 2 `(A,D)  (1)  + + + + + `+ (D,A) + `(B,C) + 2 `(C,B) + 2 `(C,D) + 2 `(D,C)  +  tB <= tA + 6 + `(A,B)    +  t   A <= tB - 6 + `(B,A)   +  tC <= tA + 2 + `(A,C)      tA <= tC - 2 + `+  (C,A)   +   tD <= tA - 4 + `(A,D) tA <= tD + 5 + `+ (D,A)    tC <= tB - 2 + `+  (B,C)     tB <= tC + 3 + `+  (C,B)     tD <= tC - 3 + `+  (C,D)    tC <= tD + 4 + `+ (D,C)   `+ >= 0.
Proof.
If t : V 7- R is a scheduling for (G, `), then each reduced length `t(u,v) := `(u,v) -tv +tu is non-negative by (1); thus (G, `t ) is conservative and, since `(C) = `t (C) for every circuit C of G, then (G, `) is conservative as well.
On the other side, if (G, `) is conservative, then, using the Bellman-Ford algorithm, it is possible to determine a potential function p : V 7- R such that for every arc e = (u, v) of G, pv <= pu + `e .
Such p satisfies (1) and, therefore, (G, `) is consistent.
(Ex1)  By well-known results about linear programming, and convex programming, this model will be amenable of polynomialtime solution algorithms even when the linear addenda ce `+ e in the objective function get replaced by general convex functions and even when the whole objective function is a generic (smooth) convex function in the variables `+ e , e [?]
E. However, in the next section, we will provide extremely efficient combinatorial algorithms in order to more conveniently solve the problem.
III.
P ROBLEM F ORMULATION In this section, we formalize the problem to solve the inconsistency of an STN as a linear programming problem.
Let us consider a graph G = (V, E) augmented by the following two functions: *  h-3, 2 i h2, 3 i  Theorem 1 ( [1], [16], [17]).
An STN (G, `) is consistent if and only if it is conservative.
*  h4, 2 i  h3, 2 i  An STN can be viewed as a weighted graph (G, `) whose nodes are timepoints that must be placed on the real line and whose arcs express mutual constraints on the allocations of their endpoints.
An STN is called consistent if there exists a scheduling t : V 7- R such that tv <= tu + `(u,v)  C  h-2, 1 i  length ` : E 7- R, and, cost c : E 7- R+ , where R+ .
ce represents the unitary cost for increasing `e .
Here, the weighted graph (G, `) may contain negative cycles.
We are interested at a minimum cost plan to transform an inconsistent STN (G, `) into a consistent one by suitably relaxing some of its constraints (increasing the lengths of some of the arcs) and paying a cost specified by the cost function c. Our minimum cost network design problem can be expressed by means of the following linear programming problem: P min (u,v)[?
]E c(u,v) `+ (u,v) ( (P1) tv <= tu + `(u,v) + `+ [?]
arc (u, v) of G, (u,v)  IV.
T HE C OMBINATORIAL A LGORITHM In this section, we propose an efficient combinatorial algorithm that repairs, at a minimum global cost, an inconsistent STN where constraint bounds are allowed to be augmented paying a cost.
By Theorem 1, the problem to repair an inconsistent STN can be regarded as the request for a minimum cost plan to transform (G, `) into a weighted graph with no negative cycles (conservative weighted graph) by suitably increasing the lengths of some arcs.
This view leads to an alternative mathematical formulation of the Problem P1: P min e[?
]E ce `+ e ( (P2) `+ (C) >= -`(C) [?]
directed cycle C of G  `+ >= 0, where `+ : E 7- R+ is the decision variables vector specifying the length increment adopted for each arc.
`+ >= 0.
Example 1.
Fig.
1 depicts a STN where cycles ACB, ACD, and ADCB are negative.
The associated minimum cost network design problem is given by the following linear  Example 2.
Considering the Problem (Ex1) presented in Example 1, the only meaningful constraints are those associated  21  (only a polynomial number of variables) linear programming formulation by making the link with the classical concept of circulation.
Indeed, as recalled in Section II, a circulation can be regarded as an eulerian subgraph, which then can be decomposed into a packing of cycles.
Therefore, Problem (P3) can be regarded as an instance of the more classical and compact max circulation problem.
The following two lemmas are meant to prove this formally.
to the negative cycles in the graph.
Therefore, Problem (Ex1) can be rewritten as the following linear programming problem: + + + + min `+ (A,B) + `(B,A) + 3 `(A,C) + 3, `(C,A) + 2 `(A,D) + + + + + `(D,A) + `(B,C) + 2 `(C,B) + 2 `(C,D) + 2 `+ (D,C)  + + + (cycle ACB)  `(A,C) + `(C,B) + `(B,A) >= 1  `+ + + (cycle CAD) (C,A) + `(A,D) + `(D,C) >= 2 + + + `(A,D) + `(D,C) + `+ + ` >= 3 (cycle ADCB)  (C,B) (B,A)   + ` >= 0.
(Ex2)  Lemma 2.
From any feasible solution l to Problem (P3), we P can determine P a circulation f of (G, c) with value e[?
]E -`e fe = C -`(C)lC .
P Proof.
For every arc e of G, let fe := C3e lC .
Note that fe >= 0 since l >= 0 and does not exceed the capacity ce by the feasibility of l. Also, this f obeys the conservation of flow constraints since it is a linear combination of characteristic vectors of directed circuits.
Finally, X X X -`e fe = -`e lC  Even though the above linear programming problem has an exponential number of constraints, the separation problem associated to the polytope of its feasible solutions essentially amounts to the detection of a negative cycle C in the weighted graph (G, ` + `+ ), whence can be solved in polynomial time by means of the Bellman-Ford algorithm.
It follows then by the milestone equivalence result [15] between separation and optimization that an optimal solution to Problem (P2) can be found in polynomial time by means of the ellipsoid algorithm.
Indeed, it was this observation that suggested us to propose and pursue our STN design framework, safe in the knowledge that we were proposing a model amenable of efficient algorithmic solutions.
Now, we want to show how it is possible to solve the problem in a more effective way by means of a combinatorial algorithm.
As a starting point, we consider the dual of Problem (P2): P max C -`(C)lC (P (P3) for every edge e [?]
E, C3e lC <= ce l >= 0,  e[?
]E  =  C3e  lC  X e[?
]C  -`e =  X  -`(C)lC .
C  Lemma 3.
From any circulation f of (G, c) we P can determine a feasible solution l to Problem (P3) with C -`(C)lC = P -` f .
e e e[?
]E Proof.
Let d be a natural number such that d * fe is integer for every e. Let G(d * f ) be the multigraph obtained form G by taking d * fe parallel copies of arc e, for every e. Since f obeys the conservation of flow constraints, then G(d * f ) is an eulerian digraph and can be decomposed into directed circuits.
Clearly, each one of these circuits maps down naturally to a unique circuit of G (when all copies of an edge are read just as that original edge of G).
For every directed circuit C of G, let nC the number of circuits in the decomposition of G(d * f ) that map down to C. Then we define lC := ndc .
Example 3.
Considering the Problem (Ex2) presented in Example 2, its dual is the following linear programming problem: (B, A) (A, C) (C, A) (A, D) (C, B) (D, C)  X C  where there is a variable lC for every directed circuit C of G. Problem (P3) essentially asks for packing negative cycles into (G, c) (clearly, if `(C) > 0, then lC = 0 in every optimal solution to Problem (P3)).
max lACB + 2 lCAD + 3 lADCB  lACB + lADCB <= 1 for the arc      lACB <= 3 for the arc      l <= 3 for the arc CAD  lCAD + lADCB <= 2 for the arc    lACB + lADCB <= 2 for the arc      lCAD + lADCB <= 2 for the arc    l >= 0.
e[?
]E  This simple reduction already delivers an efficient purely combinatorial algorithm to solve Problem (P3), whence its consequences deserve to be explicitly pinned down in the following fact.
Fact 4.
An optimal solution to Problem (P3) can be obtained in O(nm(log n) min{log(nC), m log n}) time.
Furthermore, when c is an integer valued function, then the optimal solution l obtained is also integer.
(Ex3)  On this small example, it can be easily seen that the optimal solution is given by lACB = 0, lCAD = 1, and lADCB = 1.
The value of the optimal solution is 5.
Proof.
The proof follows from Lemma 2 and 3.
The time bound refers to the algorithm in [12].
The integrality considerations follow from the well known total unimodularity properties of network flows.
Unfortunately, due to the exponential number of constraints of the primal Problem (P2), the dual Problem (P3) is bound to have an exponential number of variables.
However, we can faithfully express this problem by means of a more compact  Now we concentrate on how to solve Problem (P2), the problem of true pertinence to us and core of the framework we intend to propose in this paper, assuming the optimal solution l to Problem (P3) is given.
22  The following algorithm will do the job in O(nm) time even in case l is not integral.
P c | C3e lC = ce }, E 0 := {e [?]
E | PLet E := {e [?]
E 6= c 0 C3e lC = 0}, and E := E \ (E [?]
E ).
Starting from (G, `), we determine a new weighted graph (G0 , `), with G0 = (V, E 0 ), as follows.
First, we copy all e [?]
E in E 0 ; then, for every arc e = (u, v) [?]
E c [?
]E 6= , we introduce in E 0 a new arc eR = (v, u) and extend ` by setting `(eR ) = -`(e); next, we remove from E 0 all arcs in E c .
In practice, for every arc e [?]
E c we replace e with one reversed both in direction and in length while for every arc e [?]
E 6= we add a parallel arc eR with opposite direction and length, this time without removing e. The mate operator [*]R is defined as [e]R := eR for every e [?]
E \ E 0 and [eR ]R := e for every eR [?]
E 0 \ E 0 , and can be extended to every edge set F [?]
(E [?]
E 0 ) \ E 0 by setting [F ]R = {[f ]R : f [?]
F }.
Note that `(F [?]
[F ]R ) = 0 for every F .
With this notation, E 0 = E 0 [?]
E 6= [?]
[E 6= ]R [?]
[E c ]R .
2 C  -3 -2  -4 -3  3  2  2  -2  6 6  5 4  B 5  A 0  D -2  Fig.
2.
The auxiliary graph (G0 , `) based on the optimal solution lCAD = lADCB = 1 and the instance graph depicted in Fig.
1.
Bold labels associated to nodes represent values of the potential function p returned by Bellman-Ford algorithm with A as starting node.
2) then, decrease it back by e on each arc e [?]
C \ C [?]
(E 0 [?]
E 6= ) = C [?]
([E 6= ]R [?]
[E c ]R ); this step nullify the f on arcs nor present in G; 3) finally, decrease it by e on each arc e such that eR [?]
C [?]
[E 6= [?]
E c ]R , i.e., e [?]
[C]R [?]
(E 6= [?]
E c ) as required by the definition of f~.
The first step does clearly not spoil the property of f being a circulation since C is eularian.
But the very same argument works for the next two steps combined since (C [?]
([E 6= ]R [?]
[E c ]R )) [?]
([C]R [?]
(E 6= [?]
E c )) is also eulerian as [C [?]
([E 6= ]R [?]
[E c ]R )]R = [C]R [?]
(E 6= [?]
E c ) for the operator [*]R is idempotent and [A [?]
B]R = AR [?]
B R and [A [?]
B]R = AR [?]
B R .
Finally, by taking e := e := min{mine[?]C[?
](E 0 [?
]E 6= ) (ce - fe ), mineR [?
][C]R [?
](E 6= [?
]E c ) fe }, then the circulation f~ is admissible.
Note that e > 0.
Lemma 5.
If l is an optimal solution to Problem (P3), then (G0 , `) is conservative.
Proof.
Assume that (G0 , `) is not conservative and let C be a negative circuit in (G0 , `).
P Also, represent Pl as a circulation f of (G, c) with value P -` f = e e e[?
]E C -`(C)lC .
This is done by setting fe := C3e lC for every arc e of G, as more exaustively explained in the proof of Lemma 2.
Since l is an optimal solution to Problem (P3), it follows that f is a maximum value circulation for (G, c) by Lemma 3.
We will contradict this fact by showing how the negative circuit C can be used to produce a better circulation.
Since C is a directed circuit of G0 then C [?]
E 0 = E 0 [?]
6= E [?]
[E 6= ]R [?]
[E c ]R .
We suggest to modify f as follows:  0 6=  fe + e if e [?]
C [?]
(E [?]
E ), f~e = fe - e if eR [?]
C [?]
[E 6= [?]
E c ]R ,   fe otherwise.
Example 4.
Considering the dual problem presented in Example 3, we now build up the auxiliary weighted graph (G0 , `) based on the optimal solution lCAD = lADCB = 1 with value l = 5.
Here, E c = {(B, A), (A, D), (D, C)}, E 6= = {(C, B), (C, A)}, and E 0 := E \ (E c [?]
E 6= ).
The auxiliary weighted graph (G0 , `) is represented in Fig.
2.
Now, since (G0 , `) is conservative, then we can can compute in O(nm) time a potential function p : V 7- R such that Clearly, for every edge of G0 , that is, for every edge e = (u, v) [?]
E 0 = E 0 [?]
E 6= [?]
[E 6= ]R [?]
[E c ]R , the reduced length `p (e) := X X X X `e f~e = `e fe + e `e-e `eR `(e) - pv + pu is non-negative.
In this way, for every edge e[?
]E e[?
]E e [?]
E 0 [?]
E 6= we have that e[?]C[?
](E 0 [?
]E 6= ) e[?]C[?
]([E 6= ]R [?
][E c ]R  =  X e[?
]E  =  X e[?
]E  ` e f e + e   X  `e+e  e[?]C[?
](E 0 [?
]E 6= )  `e fe + e `(C) <  X     X  `p ((u, v)) >= 0 ,  `e   whereas, for every edge e = (u, v) [?]
E c we have that  e[?]C[?
]([E 6= ]R [?
][E c ]R  `p ((u, v)) = `((u, v)) - pv + pu  `e fe ,  e[?
]E  = -`((v, u)) - (-pu ) + (-pv )  as long as e > 0, since `(C) < 0.
Also, for every e > 0, f~ is a circulation for G since we can think of it as obtained from the circulation f through the following three steps:  = -`p ((v, u)) <= 0.
Based on this, we propose considering the following solution to Problem (P2): ( 0 for every e [?]
E 0 [?]
E 6= , + ` (e) = -`p (e) for every e [?]
E c .
1) first, increase fe by a same quantity e on all the arcs e of the directed circuit C; this step could extend f to arcs not present in G;  23  2 C  1  C  -2  4  0 -3  3 0  1 0  0  -6 + 1 = -5  -1  B 5  -2  A 0  1  B  D -2  3  Simple reductions from FAS, like those mentioned in the introduction, already show that the problem becomes APXhard as soon as the costs are non convex.
We have already observed in Section III that our model must be in class P when the cost function is convex.
Here we want to indicate more effective approaches P for the case when the global cost function is of the form e[?
]E ce (`+ e ), with each ce (*) convex.
Assume first cP e (*) is a convex piecewise linear function: in k this case ce = i=1 fxi ,mi , where  0 [?]
0 <= x <= xi , fxi ,mi (x) = mi (x - xi ) [?]
x >= xi .
!
=- =-  e[?
]E c  C3e  X  lC  =-  X  X  `p (e) `p (e)  e[?]C[?
]E c  C  <=-  lC  lC  X  `p (e)  C  e[?
]C  X  lC `p (C)  Note that the arc e = (u, v) can then be represented by k arcs (where k was P the number of pieces) ej = (u, v) with `(ej ) = `(e) + i<=j xi and c(ej ) = mj , for j = 1, .
.
.
, k. Notice that the cost function associated to each one of these k arcs is now linear so that we are back to the model investigated into the previous section.
The same trick essentially works in order to obtain an effective FPTAS for the more general case when all the costs ce (*) are semiderivable convex functions, since, for any e > 0, and for each B > 0, each such function can be approximated by a convex piecewise fuction pe (*) with ce (x) <= pe (x) <= (1 + e)c  e (x) for each x >= 0 with x <= X, and made of O 1e log B pieces, where B <= ce (X).
e[?
]E  =-  X  D 5  V. C ONVEX C OSTS  e[?
]E c  X  A  Fig.
4.
A minimal-cost consistent STN determined from the original STN of Fig.
1.
The bold labels represent the new length values of the associated edges.
This is a feasible solution to our original problem simply because (` + `+ )p = `p + `+ >= 0, and the feasibility of the resulting STN network is certified by the same potential computed above.
In order to prove its optimality, we analyze its cost as follows: X X ce `+ (e) = -ce `p (e) X  -4 + 2 = -2  6  Fig.
3.
The values of `p for the STN of Fig.
1 determined using the potential function depicted in Fig.
2.
e[?
]E  -2  2  `(C)lC .
e[?
]E  Since we could rewrite the cost of the proposed solution to Problem (P2) as the optimal solution value of its dual Problem (P3), then the optimality follows by the weak duality theorem.
Example 5.
Fig.
3 depicts `p obtained applying the potential function p defined in the auxiliary graph (G, `) of Fig.
2 to the original length ` function of the STN in Fig.
1, as previously described.
The optimal solution to the primal problem (i.e., the minimal-cost consistent STN) is determined considering only the negative edges values in Fig.
3 and adding their absolute values to the corresponding original edge lengths in Fig.
1, as depicted in Fig.
4.
Thus constraint (B, A) is relaxed by 1 and constraint (A, D) is relaxed by 2.
The cost of these relaxations is 1 * 1 + 2 * 2 = 5 and is indeed the same as the cost of the solution to the dual problem, whence optimality is confirmed and we have produced the optimal solution to our original problem.
VI.
C ONCLUSIONS In the literature, there are different frameworks and approaches aimed to solve the constraint violations in an inconsistent STN.
Some authors proposed semi-automated protocols in which a designer interacts with a solving algorithm proposing a set of constraints to be removed/relaxed.
In this paper, we propose a novel framework where the problem of eliminating constraint violations is reformulated as an optimization problem where violated constraints can be relaxed paying a cost.
In this way, we show that the problem is tractable and can be solved by linear programming.
Therefore, the framework allows a designer to solve the inconsistency of an STN in only one step.
Moreover, we offer an analysis of the mathematical structure of the model that leads to effective (time complexity O(nm))  The most expensive step in computing this optimal solution to Problem (P2) along the above lines, once the l are given, is the computation of the potential function p, which can be done in O(nm) by a standard Bellman-Ford algorithm.
24  combinatorial algorithms that allow the resolution of bigger instances.
As for future work, we aim to evaluate the practical performances of the proposed algorithms and the effectiveness and applicability of the framework in some application domains.
[8] P. Morris, R. Morris, L. Khatib, S. Ramakrishnan, and A. Bachmann, "Strategies for global optimization of temporal preferences," in Principles and Practice of Constraint Programming - CP 2004, ser.
LNCS, M. Wallace, Ed.
Springer, 2004, vol.
3258, pp.
408-422.
[Online].
Available: http://dx.doi.org/10.1007/978-3-540-30201-8 31 [9] B. Peintner and M. E. Pollack, "Any time, complete algorithm for finding utilitarian optimal solutions to STPPs," in Proc.
of the 20th nat.
conf.
on Artificial Intelligence, ser.
AAAI'05, vol.
1.
AAAI Press, 2005, pp.
443-448.
[Online].
Available: http://dl.acm.org/citation.cfm?
id=1619332.1619404 [10] D. B.
West, Introduction to graph theory, 2nd ed.
Prentice, 2001.
[11] R. K. Ahuja, T. L. Magnanti, and J.
B. Orlin, Network flows: theory, algorithms, and applications.
Prentice H., 1993.
[12] A. V. Goldberg and R. E. Tarjan, "Finding minimum-cost circulations by canceling negative cycles," J. of the ACM (JACM), vol.
36, no.
4, pp.
873-886, 1989.
[13] J. Edmonds and R. M. Karp, "Theoretical improvements in algorithmic efficiency for network flow problems," J. of the ACM (JACM), vol.
19, no.
2, pp.
248-264, 1972.
[14] A. V. Goldberg and R. E. Tarjan, "Finding minimum-cost circulations by successive approximation," Math.
of Oper.
Res., vol.
15, no.
3, pp.
430-466, 1990.
[15] M. Grotschel, L. Lovasz, and A. Schrijver, Geometric Algorithms and Combinatorial Optimization, 2nd ed., ser.
Algorithms and Combinatorics.
Springer, 1993, vol.
2.
[16] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to Algorithms.
The MIT Press, 2001.
[17] R. Bellman, "On a routing problem," Quarterly of Applied Mathematics, vol.
16, no.
1, pp.
87-90, 1958.
R EFERENCES [1] R. Dechter, I. Meiri, and J. Pearl, "Temporal constraint networks," Artificial Intelligence, vol.
49, no.
1-3, pp.
61-95, 1991.
[2] A. Dasdan, "Provably efficient algorithms for resolving temporal and spatial difference constraint violations," ACM Tran.
on Design Aut.of Elect.
Sys.
(TODAES), vol.
14, no.
1, p. 8, 2009.
[3] V. Kann, "On the approximability of NP-complete optimization problems," Ph.D. dissertation, Royal Inst.
of Tech.
Stockholm, 1992.
[4] G. Even, J. S. Naor, B. Schieber, and M. Sudan, "Approximating minimum feedback sets and multicuts in directed graphs," Algorithmica, vol.
20, no.
2, pp.
151-174, 1998.
[5] E. Speckenmeyer, "On feedback problems in digraphs," in GraphTheoretic Concepts in Computer Science: WG'89, vol.
15.
Springer Verlag, 1990, p. 218.
[6] L. Planken, M. de Weerdt, and N. Yorke-Smith, "Incrementally solving STNs by enforcing partial path consistency," in Proc.
of ICAPS, 2010, pp.
129-136.
[7] L. Khatib, P. Morris, R. Morris, and F. Rossi, "Temporal constraint reasoning with preferences," in Proc.
of the 17th int.
joint conf.
on Artif.
Intelligence, vol.
1.
Morgan Kaufmann, 2001, pp.
322-327.
25
A temporal structure that distinguishes between the past, present, and future Andre Trudel  Jodrey School of Computer Science Acadia University Wolfville, Nova Scotia, Canada, B0P 1X0  Abstract  We present a two dimensional temporal structure that has an ever changing present.
Relative to each present, there is a past and future.
The main representational advantage our two dimensional structure has over traditional linear temporal structures is the ability to record when knowledge is added or updated.
We dene a rst order logic that has this structure as its temporal ontology.
1 Introduction  Most temporal rst order logics in Articial Intelligence have a linear (i.e., non-branching) temporal ontology.
Examples of logics with a linear structure are those of Allen 1], Kowalski 4], and Shoham 6].
Even the logic of McDermott 5] uses linear time: Note that, contrary to what is often stated, McDermott's system does not use branching time: time itself is represented by the linear ordering of the real numbers branching only occurs with respect to the totality of possible states ordered by date.
(2], p. 1178) Linear time has its drawbacks.
There is no distinguised element in the ontology to represent the present.
Consequently, there is no concept of a past or future.
Another drawback is that a linear time based logic represents the current state of aairs.
There is no record of when knowledge is obtained or updated.
Humans do not view time as being linear.
Instead, we neatly compartmentalize time into the past, present, and future.
As the present changes, so does the past and future.
For example, we are continually learning things about our past and revising our future plans.
We present a two dimensional temporal structure that captures some of our intuitions about the past, present and future.
It has an ever changing present, and a past and future relative to each present.
We then formally dene a rst order logic that has this structure as its temporal ontology.
2 Proposed logic  Each predicate has two temporal arguments.
For example, red(1,1,house) and alive(5,10).
The two temporal arguments do not specify an interval.
For example, alive(5,10) is not used to represent the fact that alive is true over the interval (5,10).
Instead, the two temporal arguments are cartesian coordinates.
The relation alive(5,10) species that alive is true at the point (5,10) on the cartesian plane.
The temporal ontology consists of a cartesian plane.
The line y = x is used to represent the actual state of the world.
Relative to any point (p p) on the line y = x the line segment fy = x x > pg represents the actual future, fy = x x < pg represents the actual past, fy = p x > pg represents the expected future, and fy = p x < pg represents the perceived past (see gure 1).
What an agent observes or experiences at time p is recorded at the point (p p): Any plans or expectations the agent may have about the future at time p is recorded on the line fy = p x > pg: Similarly, any knowledge the agent learns or is given about the past at time p is recorded on the line fy = p x < pg: On the diagonal line y = x we record what actually happens in the world.
For example, in gure 2 the house is red at time 10 (i.e., red(10,10)).
At time 10, we plan to paint the house white at time 20 (i.e., white(20,10)).
But for some unforeseen reason, the house gets painted earlier at time 15 (i.e., white(15,15)).
We also know that at time 2, the house is white (i.e., white(2,2)).
At time 10, we learn that the house was blue at time 5 (i.e., blue(5,10)).
Note that blue(5,10) records two items of information.
The rst is that the house is blue at time 5, and the second is that this fact was recorded (learned) at time 10.
Formulas along a vertical line need not be consistent.
Figure 3 shows a situation where at time 10 we plan to go to the movies at time 15 (i.e., movies(15,10)).
But at time 15, something comes up that prevents us from going to the movies (i.e., not movies(15,15)).
Also, at time 5 we thought the house had been painted red at time 2 (i.e., red(2,5)).
We later learn at time 10 that the house was not red at time 2 (i.e., not red(2,10)).
The x and y axes of the cartesian plane must be linear and of the same type.
No further restrictions  6 y perceived past        past     x      future y=x   expected   (p,p)  future  x  -  Figure 1: The dierent pasts and futures relative to (p,p)  6  white(15,15)x   y blue(5,10)  x    x     x       x   red(10,10)   white(20,10)   white(2,2) x  -  Figure 2: Colors of a house over time  6  not movies(15,15)  y not red(2,10)  x  red(2,5)  x                    x      x  movies(15,10)  x Figure 3: Inconsistent information  -  19  6  15                       .h    .
.
nancing(19,(15,19)) .
.
.h .
.
.
.h  university((19,23),15) 19  23  -  Figure 4: Intervals are placed on the axes.
They can be discrete, dense, points, intervals, points-intervals, etc.
If intervals are allowed, they appear as one of the temporal parameters.
For example, in gure 4 a 15 year old student plans to attend university between the ages of 19 and 23 (i.e., university( (19,23), 15)).
Also, between the ages of 15 and 19 the student believes that nancing will be in place when entering university at age 19 (i.e., nancing(19, (15,19) )).
Although the examples in this paper only use the north-east corner of the cartesian plane, the whole plane can be used to represent information.
We conclude with an outline of the syntax and semantics for the proposed logic.
2.1 Syntax The logic has two disjoint sorts called temporal and non-temporal.
All terms are sorted.
Predicates have 2 temporal arguments followed by m  0 non-temporal arguments.
Terms and well formed formulas are dened in the standard fashion.
2.2 Semantics An interpretation is a tuple hT U i where T is a non-empty temporal universe, U is a non-empty nontemporal universe, and  is an interpretation function which maps each temporal constant to an element of T, each non-temporal constant to an element of U, each n-ary temporal function to an n-ary function from T n to T , each n-ary nontemporal function to an n-ary function from U n to U, and each (2 m)ary predicate to an (2 m)-ary predicate on T 2  U m .
Quantied variables range over the appropriate universe.
Well formed formulas are interpreted in the usual fashion.
3 Examples  3.1 Leave lights on  Information recorded on the line y = x may later be discovered to be false.
For example in gure 5, the driver of the car believes that he shut o the headlights when he left the car at time 5.
Upon returning to the car at time 20, he discovers the battery is dead.
He then checks the light switch and it is in the \on" position.
Therefore, the lights were not shut o at time 5.
3.2 Course  The proposed logic can be used to model an agent's changing expectations or beliefs over time.
For example, assume a course starts at time 5 and ends at the end of the term at time 25.
At the start of the course, the student believes he will pass (see gure 6).
At time 10, the student does very poorly on the rst assignment and thinks he will not pass the course.
The student does very well on the midterm at time 15 and now believes that he has a chance of passing.
But, the student does poorly on the second assignment at time 20 and once again believes he will fail.
The story has a happy ending.
The student aces the nal exam and passes the course.
3.3 Planning  Assume that at time 5, an agent constructs a plan to enter a room.
The plan consists of going to the door over the interval (5,10) (i.e., gtd( (5,10), 5)), opening the door over the interval (10,15) (i.e., od( (10,15), 5)), and then entering the room over the interval (15,20) (i.e., er( (15,20), 5)).
Note that we represent the plan along with the time that it was constructed.
The plan is shown in gure 7.
Over the interval (5,10), the agent excutes the rst action of the plan which is to go to the door.
Once at the  6 y    not lights-o(5,20)  x          x lights-o(5,5)          x  battery(20,20,dead)  x  -  Figure 5: Lights  6 y   nal(25,25) assgn2(20,20) x  midterm(15,15) x assgn1(10,10)  x begin(5,5) x             x pass(25,25) x x x x  not pass(25,20) pass(25,15) not pass(25,10) pass(25,5) x  -  Figure 6: Expectations of passing the course changes over time      6 10 5  .
gtd((5,10),(5,10)) .
.
.
   x door-locked(10,10) .  .x .
.
.
.
x .
.
.
.
x. .
.
.
.x  gtd((5,10),5) od((10,15),5) er((15,20),5)   -  5  10  15  Figure 7: Remembering a plan and re-planning  20  door, the agent observes that the door is locked which is unexpected.
The agent cannot execute the next action which is to open the door.
At this point, the agent must construct another plan which would be stored on the line fy = 10 x > 10g: The old plan constructed at time 5 remains untouched.
It can be used as a guide while re-planning at time 10.
It can also be used to answer queries.
For example, if we ask the agent why he is at the door at time 10 without a key, the agent can examine the old plan and reply that he expected the door to be unlocked at time 10.
3.4 Multi-agents  The proposed temporal structure is two dimensional.
Additional dimensions can be added to the structure to represent and reason about multi-agent problems.
The addition of a third temporal parameter (i.e., (x y z)) allows us to represent individual knowledge of an agent and common knowledge.
Each agent is assigned a plane.
Information about the n'th agent is stored on the plane (x y n): Information that is common to all agents is stored on the plane (x y 0): For example, assume there are three agents, and all three know that block A is on block B at time 5: on(5,5,0, A,B).
Agent 1 also knows that A is on B at time 6: on(6,6,1, A,B).
At time 10, agent 2 plans to move block C on top of A over the interval (15,20): move((15,20),10,2, C,A).
Agent 3 knows that block A is red at time 7: red(7,7,3, A).
We could also have the situation where all three agents know a fact, but don't realize it is common knowledge (i.e., not contained on the 0'th plane).
For example, each agent has local knowledge that block B is blue at time 10: blue(10,10,1, B), blue(10,10,2, B), blue(10,10,3, B).
Each agent does not know that the other 2 agents also have the information that B is blue at time 10.
Instead of assigning a plane to each agent, we can add a fourth temporal parameter to the structure and assign a cube to each agent.
In agent i's cube (i.e., (x y z i)), information agent i has about agent n is stored on the n'th plane (i.e., (x y n i)), and i's personal information is stored on plane i (i.e., (x y i i)).
For example, agent 1 knows that block B is blue at time 10, and also believes that agent 2 has this information: blue(10,10,1,1, B), blue(10,10,2,1, B).
Information common to all agents is stored on the plane (x y 0 0): A fth dimension can be used to represent groups of agents.
Each group consists of one or more agents.
Information about group n is stored using (x y z a n): The rst four parameters are used to store information about a particular agent in group n: For example, information about the third agent in group 2 is stored in (x y z 3 2):  Other dimensions can be added as needed.
4 Persistence  If the house is blue at time 10, is it also blue at time 15?
Given no knowledge of the house changing color, it seems reasonable to assume that the color of the house persists from time 10 to 15, and we conclude the house is blue at time 15.
This is called the persistence problem.
Traditional linear temporal structures only need to deal with persistence along a single axis.
Here, we must consider two dimensional persistence.
In gure 8, the house is blue at time 10 (i.e., blue(10,10)).
As discussed above, persistence should be allowed into the future (i.e., along the line fy = 10 x > 10g).
Using a similar argument, persistence into the past should also be allowed (i.e., along the line fy = 10 x < 10g).
For example, if the house is blue at time 10, it was probably also blue at time 9.
We also need persistence in the upward direction (i.e., along the line fy > 10 x = 10g).
For example, at the point (11,11), we should remember that the house was blue at time 10 (i.e., blue(10,11)).
Upward persistence models the agent's memory.
We do not allow persistence in the downward direction.
The relation blue(10,10) also records the fact that the color of the house was learnt at time 10.
Therefore at time 9, we have no informationabout the color of the house (i.e., the truth value of blue(10,9) is unknown).
To summarize, we have horizontal bi-directional persistence and vertical upward persistence.
Persistence is not allowed in the vertical downward direction.
In either of the three directions where persistence is allowed, standard algorithms can be used.
Problems arise when vertical and horizontal persistence are inconsistent.
For example in gure 9, at time 20 we know the house was not blue at time 5, and at time 15 we know the house was blue at time 10.
At time 20, was the house blue at time 10 (i.e., is blue(10,20) true)?
Using horizontal persistence and not blue(5,20) we can conclude not blue(10,20).
We can also conclude the opposite using vertical persistence and blue(10,15).
Which answer do we prefer?
The preference between vertical and horizontal persistence depends on the particular situation.
In this case, either answer is reasonable.
In the future, we will investigate algorithms for resolving persistence conicts.
5 Conclusions  We presented a general rst order logic that has a unique two dimensional temporal structure.
The structure consists of a cartesian plane.
The present moves along the line y = x: At any point on the line y = x we can record plans or expectations about the future, and information about the past or present.
The proposed temporal structure has the appearance of being a branching one.
But, it is not.
Time  yes  6  6  y yes fi  x  - yes  no x  -  Figure 8: The persistence of blue(10,10)  6 y  not blue(5,20)  x  - x(10,20) 6 x  blue(10,15) x Figure 9: Vertical and horizontal persistence are inconsistent  -  moves along the single line y = x: The branches emanating from each point on the line y = x are used to store information about the past or future obtained at that point in time.
The main representational advantage our two dimensional structure has over traditional linear temporal structures is the ability to record when knowledge is added or updated.
For example, simple English sentences like \Last night I planned to go to the movies tonight, but now I don't feel like going" cannot be represented using a linear structure.
A linear structure can either represent the fact that the person is going to the movies or not.
It cannot represent the fact that going to the movies tonight was true yesterday and false today.
The sentence is easily represented in the proposed logic: movies(tonight yesterday) ^ not movies(tonight tonight): Instead of using the proposed logic, it is possible to extend the syntax and semantics of traditional linear time logics so that they use a two dimensional structure.
For example, RGCH 3] uses the real numbers.
We can easily add another temporal argument to the logic.
Acknowledgements  Thanks to Denis Gagne for discussing the material contained in this paper.
Research supported by Natural Sciences and Engineering Research Council of Canada grant OGP0046773.
References  1] J.F.
Allen.
Towards a general theory of action and time.
Articial Intelligence, 23(2):123{154, 1984.
2] A. Galton.
Reied temporal theories and how to unreify them.
In 12th International Joint Conference on Articial Intelligence, pages 1177{1182, Sydney, Australia, 1991.
3] S.D.
Goodwin, E. Neufeld, and A. Trudel.
Temporal reasoning with real valued functions.
In  Pacic Rim International Conference on Articial Intelligence (PRICAI'92), pages 1266{1271,  Seoul, Korea, Sept 1992.
4] R.A. Kowalski and M. Sergot.
A logic-based calculus of events.
New Generation Computing, 4:67{95, 1986.
5] D.V.
McDermott.
A temporal logic for reasoning about processes and plans.
Cognitive Science, 6:101{155, 1982.
6] Y. Shoham.
Temporal logics in AI: Semantical and ontological considerations.
Articial Intelligence, 33:89{104, 1987.
2013 20th International Symposium on Temporal Representation and Reasoning  Spatio-Temporal Competition for Transportation Resources Ouri Wolfson Dept.
of Computer Science University of Illinois at Chicago wolfson@cs.uic.edu  we will show that in the worst case the ratio between the two (often called the Price of Anarchy) is unbounded, but in practice it is usually not higher than 30%.
We also discuss the commonality and differences between the problem of Spatio-temporal competition and the Stable Marriage (see [1]) problem.
Then we will discuss an incomplete-information variant of the problem, where each agent knows the locations of the resources, but not the locations of the other competing agents.
This situation arises in an experimental project in San Francisco called SFPark (see http://sfpark.org/).
The project uses sensors buried in the pavement to detect when street-parking slots are occupied and released.
The results are posted on a web site in the form of a street-block parking availability map.
Drivers then consult this map to determine where to park.
Of course, this raises safety concerns due to the fact that drivers looking to park frequently glance at their smart-phone.
Thus, it is desirable that an app guides the driver to the most appropriate parking slot, similarly to the way a car-navigation-system guides her to her destination.
This app would be aware of the available parking-slot locations, but not the locations of the other vehicles searching for parking, thus the practical motivation for the incomplete information variant of Spatio-temporal competition.
We propose a gravitational approach to the incompleteinformation problem, in which resources exert a gravitational force on the mobile agents.
In turn, each agent moves according to the vector-sum of the forces exerted on it by the resources.
We show that the Gravitational approach is more efficient by up to 40% than the Greedy, or nave, approach in which each agent simply pursues the closest resource.
The implications of this comparison are compelling.
Studies conducted in 11 major cities reveal that the average time to search for curbside parking is 8.1 minutes and cruising for these parking spaces accounts for 30% of the traffic congestion in those cities on average (see [2]).
Even if the average time to find parking were smaller, it would still account for a large amount of traffic.
Suppose that the average time to find parking were 3 minutes, each parking space would still generate 1,825 vehicle miles traveled (VMT) per year ([3]).
That number would of course be multiplied by the number of parking spaces in the city.
For example, in a city like Chicago with over 35,000 curbside parking spots ([4]), the total number of VMT becomes 63  Abstract--A lot of work has been devoted to collaboration among distributed computing devices.
Sensor networks and crowdsourcing are prominent examples of distributed collaborative computing.
Much less attention has been paid to competition among computing agents, particularly the type that we call spatio-temporal competition.
In it mobile agents compete for point resources located in space.
An example of such competition is drivers, guided by their smartphones, attempting to park; they are competing for a limited number of parking spaces.
This is an example, but spatio-temporal competition arises in many other transportation applications.
Furthermore, it gives rise to new research problems which will be described in this presentation.
Keywords-mobile computing, game theory, equilibrium, optimum, pricing, stable-marriage  I will briefly describe the IGERT interdisciplinary PhD program in Computational Transportation Science at the University of Illinois at Chicago.
The program lies at the intersection of Computer Science and Transportation.
The description will include several Intelligent Transportation applications and research projects in the program.
They involve spatio-temporal data management on vehicles and smart-phones, as well as communication among them.
The applications' objectives are to improve safety, mobility, convenience, efficiency, and environmental impact of urban transportation.
Then I will focus on the problem of spatio-temporal competition for resources.
It consists of n mobile agents (e.g.
vehicles) competing for m static resources (e.g.
parking slots, or taxi cab customers) in the plane or the road network.
A resource can be used by a single agent at a time, and thus the competition among the agents for the resources.
A solution to the problem is a 1-to-1 matching between agents and resources.
We consider mainly travel time as the optimization criterion, i.e.
we assume we are interested in a matching that minimizes the total travel-time.
However, we will also discuss the extension to other criteria such as $-cost.
We also assume that each agent wants to minimize her travel time to capture a resource.
This dichotomy between the social welfare (minimizing total travel-time) and selfishness (minimizing individual travel time) gives rise to a gap.
This is a gap between the optimal and the Nash equilibrium matching of resources and agents.
We will show that the algorithms for the two types of matching, although both efficient, are totally different.
Then 1530-1311/13 $26.00 (c) 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.10  75  million VMT per year due to cruising while searching for parking.
Furthermore, this would account for a waste of over 3.1 million gallons of gasoline and over 48,000 tons of CO2 emissions.
Therefore, even a 10% reduction in the time to find parking would have important ramifications for urban transportation and the environment.
Next we discuss congestion pricing strategies to mitigate the gap between the optimum and equilibrium solutions to the Spatio-temporal Competition problem.
The motivation is that social welfare favors the optimum, but agents selfishness forces the system into an equilibrium state.
By pricing the resources we can convert the equilibrium to the optimum.
In other words, the equilibrium when considering both traveltime and price (assuming some standard conversion between travel-time and $-cost) is the optimum when considering travel-time alone.
In routing this conversion from equilibrium to optimum is achieved by tolling.
In other words, tolls on certain road-segments can convert the equilibrium to a minimum total travel time, i.e.
social welfare.
We adapt an existing (Auction) algorithm for this type of pricing.
However, the Auction pricing algorithm does not provide guarantees for individual agents in terms of the total price.
Therefore, we discuss an additional pricing scheme in which each agent is guaranteed to pay a price (including travel-time and $-cost) that is not higher than her price in equilibrium.
The agent may travel longer than in equilibrium, but in this case she will be compensated by a $reward.
If she travels shorter than in equilibrium, then she will pay a $-price.
We provide the guarantee by $-pricediscrimination, i.e., different agents may pay different $prices for the same resource.
An important result from the practical point of view is that the Agent-guarantee pricing scheme is self-sustaining, i.e.
does not need to be subsidized.
In other words, the total $-price that agents pay is not higher than the total $-price that agents are being paid.
Time permitting, I will discuss additional aspects of the Spatio-temporal competition, namely: truthfulness, i.e.
incentivizing agents to disclose their true travel-times to the resources; management of uncertainty; and detection of spatial resources by time-series analysis of smart-phone sensor data.
This talk is based in part on references [5], [6], [7].
R EFERENCES [1] Gale, D., Shapley, L.: College admissions and the stability of marriage.
The American Mathematical Monthly 69(1) (1962) 9-15.
[2] D. Shoup, The High Cost of Free Parking.
Chicago, IL: American Planning Association, 2005.
[3] D. Shoup, Cruising for parking, Transport Policy, vol.
13, pp.
479486, 2006.
[4] Pricing the Curb: How San Francisco, Chicago and Washington D.C. are reducing traffic with innovative curbside parking policy, Transportation Alternatives (www.transalt.org), New York, NY, July 2008.
[5] D. Ayala, O. Wolfson, B. Xu, B. Dasgupta, J. Lin, "Parking Slot Assignment Games", Proc.
of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM GIS), Chicago, IL, Nov. 2011, pp.299-308.
[6] D. Ayala, O. Wolfson, B. Xu, B. Dasgupta, and J. Lin, "Pricing of Parking for Congestion Reduction", Proc.
of the 20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM GIS) Redondo Beach, CA, Nov. 2012.
[7] B. Xu, O. Wolfson, J. Yang, L. Stenneth, P. Yu, P. Nelson, "Real time street parking availability estimation" Proc.
of the 14th International Conference on Mobile Data Management (MDM), Milan, Italy, June 2013.
68
Propagating Possibilistic Temporal Constraints Rasiah Loganantharaj  1 Introduction  Automated Reasoning laboratory The Center for Advanced Computer Studies University of SouthWestern Louisiana Lafayette, LA - 70504  The notion of time plays an important role in any intelligent activities.
Time is represented either implicitly or explicitly.
We are interested in explicit representation of time.
The popular approaches for such representation are based on points or intervals or a hybrid of both.
Propositional temporal assertions are represented as relations among the points, or among the intervals.
The indenite information among either the points or the intervals are represented as disjunctions.
In real world, information is often incomplete, imprecise, uncertain and approximate.
Temporal knowledge is not an exception to this reality.
For example, consider the following information: John often drinks coee during his breakfast.
Sometimes, he drinks his coee before the breakfast and drinks orange juice during his breakfast.
There were few occasions he drank water during his breakfast and drank coee after the breakfast.
Mike talked to John over the phone while John was having coee.
Suppose, we are interested in nding out how Mik's telephone conversation was related to John's breakfast.
From the given information, we have denite relation between the telephone call and John's coee, but there is no information about the relationship between the coee and the breakfast on that particular day.
In the absence of such information, we can use John's habitual pattern to infer plausible relations.
Suppose, Ic and Ib respectively represent the interval over which John was having coee, and John was having breakfast.
Let It represents the interval over which Mike was having telephone conversation with John.
In interval logic, the information is represented as It is during Ic , and Ic is before or during or after Ib .
In such representation, the disjunctive relations do not provide any clue about which relation is highly probable than the others.
Instead, the representation may let us believe that all the relations of a disjunction have equal probability, for example, having coee before, during or after breakfast has equal probability.
This is not what the original information tells us.
Based on John's habit, having coee during breakfast is much more probable than having coee either before or after the breakfast.
This issues have not been studied in temporal reasoning.
In  this paper we will provide a representation to specify uncertain information and to propagate them over temporal constraint network.
This paper is organized as the following.
We introduce interval-based logic in Section 2.
In Section 3, we describe the representation of uncertain temporal knowledge and its propagation.
This paper is concluded by a summary and discussion in section 4.
2 Background on Interval Based System Allen 1] has proposed an interval logic that uses time intervals as primitives.
In this logic, the following seven relations and their inverses are dened to express the temporal relations between two intervals: before(after), meets(metby), overlaps(overlapped-by), starts(started-by), during(contains), ends(ended-by), and equals.
Here, the inverse relations are indicated within parentheses.
Since the inverse of equal is same as itself, there are, in fact, only thirteen relations.
Temporal inferencing is performed by manipulating the network corresponding to the intervals.
Each interval maps onto a node of a network called temporal constraint network (TCN).
A temporal relation, say R, from an interval, say Ii , to another interval, say Ij , is indicated by the label Rij on the directed arc from Ii to Ij .
Obviously, the label Rji of the directed arc from Ij to Ii is the inverse relation of Rij .
If we have denite information about the relation Ii to Ij then Rij will be a primitive interval relation, otherwise it will be disjunctions of two or more primitive interval relations.
Suppose the relation Ii to Ij (Rij ) and the relation Ij to Ik (Rjk ) are given.
The relation between Ii and Ik , constrained by Rij and Rjk , is given by composing Rij and Rjk .
In general, Rij and Rjk can be disjunctions of primitive relations, they are represented as: 1  r2  : : : rn g Rij = frij1  rij2  : : : rijm g and Rjk = frjk jk jk where rij is one of the primitive relations dened in the system.
The interval Ii is related to the interval Ik by the temporal relation given by the following expression:  Rij  Rjk =  (  p) (rijl  rjk  )  l=1:::m p=1:::n p l where (rij  rjk) is a composition (transitive relap , and is obtained from the entry tion) of rijl and rjk j of the transitivity table 1] at the riji row and the rjk  column.
Alternatively this could be written as Rij  Rjk = fT(rij  rjk)jrij 2 Rij ^ rjk 2 Rjkg where T(rij  rjk) is the value of Allen's look up composition table of row rij and column rjk .
Temporal constraints are propagated to the rest of the network to obtain the minimal temporal network in which each label between a pair of intervals is minimal with respect to the given constraints.
Vilain et al.
7] have shown that the problem of obtaining minimal labels for an interval-based temporal constraint network is NP-complete.
Approximation algorithms, however, are available for temporal constraint propagation.
Allen proposed an approximate algorithm that has an asymptotic time complexity of O(N 3 ) where N is the number of intervals.
His algorithm is an approximate one in the sense that it is not guaranteed to obtain the minimum relations, but it always nd the superset of the minimal label.
Since any set is a super set of a null set it is not very comforting because it is possible that global inconsistency may be hiding under 3-consistency.
3 Representation of Uncertainty  The problem of uncertainty is not new to AI problem solving.
In many expert system applications, uncertainty have been studied under approximate reasoning.
Mycin system 6, 2] has used certainty factor whose value varies from -1 to 1 through 0 to represent the condence on an evidence or on a rule.
The value 1 indicates the assertion is true while the value -1 indicates the evidence is false.
0 indicates no opinion on the evidence.
The other values correspond to some mapping of the belief on the evidence onto the scale of -1 to 1.
Prospector model 4, 5] uses probabilistic theory with Bayes' theorem and other approximation techniques to propagate evidences over causal network.
Fuzzy logic 8] has also been used in expert systems to capture knowledge with fuzzy quantiers such as `very much', `somewhat' etc.
Other techniques have also been used to handle uncertainty in expert systems.
Let us look back at the same example presented in the introduction of this paper.
John often drinks coee during his breakfast.
Sometimes he drinks his coee before the breakfast and drinks orange juice during his breakfast.
There were few occasions he drank water during his breakfast and drank coee after the breakfast.
The statement has fuzzy quanties indicating that the frequency of John having coee during his breakfast is much higher than he is having coee either before or after his breakfast.
We should capture the fuzzy quantiers into probabilistic measures in our temporal constraint representation such that the summation of the probabilities of the relations between a pair of intervals is equal to 1.
Let us represent this idea more formally.
The relation Rij , the relation Ii to Ij , is represented as frij1 (w1) rij2 (w2) ::: rijm(wm )g where rijl (wl ) is a primitive relation with its probability or the relative weight of wl .
Since each primitive relation between a pair of intervals is associated with a weight to represent the probability or the relative strength, the summation of the weights must be equal to 1 which we P call probabilistic condition for the weights.
That is, mi=1 wi = 1.
The boundary value of the weight 1 indicates that the relation is true while the value 0 indicates that the relation is false.
Further, the inverse relation of Rij will be the inverse of all the primitive relations of Rij with the same weights.
In the presence of new evidences, the probability values of the relations are modied to take account of the new evidences.
That is, when the relations between a pair of intervals are modied or rened because of other constraining relations, the probability or the weights of the relations are adjusted to satisfy the probabilistic condition.
This process is called normalization.
Let us explain this with an example: Suppose (1) R12 = fb(0:6) O(0:3) d(0:1)g, (2) R13  R32 = fb(0:4) o(0:5) m(0:1)g. The relation R12 is rened to fb(w1) o(w2)g. The weights w1 and w2 are computed using the intersection operation and then the weights are normalized such that w1 + w2 = 1.
When propagating constraints with probabilistic weights, we may need to dene such as union, intersection, composition and normalization operations which are used in propagation.
0  0  Union operation:  Rij p Rij = fr(w)jr(wij ) 2 Ri ^ r(wij ) 2 Rj ^ w = max(wij  wij )g 0  0  0  Intersection Operation:  Rij \p Rij = fr(w)jr(wij ) 2 Ri ^ r(wij ) 2 Rj ^ w = min(wij  wij )g 0  0  0  Composition Operation: Rij  Rjk =  l (wl ) 2 Rij ^ rm (wm ) 2 Rjk fp r(w)jrij jk l  rm ) ^ w = min(wl  wm )g ^ r = T(rij jk  Normalization operation: Suppose the label Rij takes the following form after renement 1 (w ) r2 (w ) ::: rm(w )g. Let w = Pm w .
frij 1 ij 2 ij m i=1 i After normalization operation the label becomes frij1 (w1) rij2 (w2) :::Prijm(wm )g where wi = wi=w which ensures that mi=1 wi = 1 In this approach we use possibilistic ways of combin0  0  0  0  0  ing the constraints as has been used in many expert systems under uncertainty.
3.1 Temporal Propagation  A temporal constraint network (TCN) is constructed from the given temporal assertion such that each node of the constraint network represents each interval of the temporal assertions.
The labels on each arc of a TCN corresponds to the relations between the corresponding intervals.
Further the summation of the weights of each component in each arc should be equal to 1.
If no constraint is specied between a pair of intervals it will take a universal constraint1 as label in the TCN and it will not be used for the purpose of propagation.
When propagating a constraint, other label of the network may get updated to a subset of its label.
The process of updating of a label as a result of propagating a constraint is called label renement.
The label renement takes the following forms: (1) The weights of the labels of an arc get changed, or (2) the primitive relations of a label get reduced.
In either case normalization operation is performed to ensure the summation of the weights adds to 1.
Suppose we are propagating the label Rij of the arc < I J > to the arc < I K > of the triangle IJK.
Let the labels of the arcs < J K > and < I K > are respectively Rjk and Rik.
The new label of the arc < I K > is computed as Rik \ fRij  Rjkg.
When the new relation is not null the weights on the label are normalized.
3.2 Temporal Constraints Propagation Algorithm for uncertain constraints  This is an extension of Allen's propagation algorithm.
The algorithm uses a rst in rst out (FIFO) queue to maintain the constraints that need to be propagated.
Initially all the pairs of constrained intervals are placed into the queue.
The propagation of constraints is initiated by removing an arc, say < Ii  Ij >, from the queue and checking whether the relation between Ii to Ij can constrain the relations on all the arcs incident to either Ii or Ij except the arc < Ii Ij >.
When a new relation is constrained, that is, the old label is modied, the arc (the pair of intervals related by this relation) is placed in the queue.
The main propagation algorithm is described in Figure 1.
In this algorithm, we use the notation Rij to denote the label of the arc i to j.
When we omit the weights on the labels and use the union, the intersection operations of set, and the composition operation of temporal logic, the algorithm becomes identical to the one of Allen's 1].
One may expect the asymptotic complexity to be O(N 3 ) where N is the number of nodes of the TCN.
Intuitively one may make a conclusion that this algorithm 1 a universal constraint is the weakest constraint and thus it is a disjunctions of all the primitive relations of the time model  will also converge in O(N 3) time.
This may be misleading because we have not yet considered the instability eect of the algorithm due to it normalization operation.
An arc is placed back in the queue when either the number of primitive relations of the label is reduced or the weight of the primitive relation of the label is modied even when the label remains unchanged.
An arc may be placed in the queue at most 12 times as a result of the disjunctive relations being rened one at a time till it becomes a singleton relation.
On the other hand, the number of times an arc is placed in the queue due to the change of weight depends on the following parameters: (1) the resolution of the weights (the number of decimal places that counts) and (2) the error bound we are prepared to tolerate.
A complete study on these issues can be found in one of our report 3].
Let us consider an example.
The probability of `having coee' before breakfast is 0.15, during breakfast is 0.8 and after breakfast is 0.05.
The probability of `having a coee' overlapping `reading morning newspaper' is 0.8 and `having coee' meets `reading the newspaper' is 0.2.
Suppose we want to nd the relation between having breakfast and reading newspaper.
Let us propagate the constraints and nd out how the labels gets rened.
Suppose Ib  Ic  Ir respectively represent the intervals of having breakfast, coffee and reading newspaper.
Using the notations dened in this paper we can dene the labels of the initial TCN as following.
Initial TCN Rcb = fb(0:15) d(0:8) a(0:05)g Rcr = fo(0:8) m(0:2)g Rbr = to be computed TCN after propagating Rbc to < Ib  Ir > Rcb = fb(0:15) d(0:8) a(0:05)g Rcr = fo(0:8) m(0:2)g Rbr = fo(:8) oi(:15) d(:15)di(:8)f(:15) fi(:8) b(:05) a(:15)g After normalizing Rbr Rbr = fo(:26) oi(:049) d(:049) di(:26)f(:049) fi(:26) b(:024) a(:049)g This is also the 3-consistent TCN labels.
4 Summary and Discussion  In many real world applications we are faced with the information that is incomplete, indenite, imprecise and uncertain.
When explicit time was used for temporal reasoning, indenite information is accommodated as disjunctions.
For example, drinking coffee is either before, during or after the breakfast.
The disjunctive information implicitly assume equal probability of occurrence even though exactly one can be true between a pair of intervals (points).
In such representation we fail to distinguish or dierentiate the highly probable one from the remotely possible one.
According to our example, having coee during breakfast is highly probable than having coee before  procedure propagate1() 1 While queue is not empty Do 2  f  3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  g  get next < i j > from the queue /* propagation begins here */ For ( ( k 2 set of intervals ) ^k 6= i ^ k 6= j )Do f temp 	 Rik \p (Rij  Rjk) If temp is null Then signal contradiction and Exit Normalize temp If Rik 6= temp Then f place < i k > on queue Rik 	 temp g temp 	 Rkj \p (Rki  Rij ) If temp is null Then signal contradiction and Exit Normalize temp If Rkj 6= temp Then f place < k j > on queue Rkj 	 temp g  g  Figure 1: propagation algorithm or after a breakfast.
In this paper we have proposed a formalism to represent temporal constraints with the associated probabilistic weights and use them to propagate to the rest of the network to obtain 3-consistency.
We have extended Allen's algorithm to handle probabilistic relations among intervals.
The operations we have dened for the labels with weights are applicable to both the points and the intervals.
Therefore, our formalism will be applicable to both the points and the intervals.
Acknowledgement  This research was partially supported by a grant from Louisiana Education Quality Support Fund (LEQSF).
References  1] J. F. Allen.
Maintaining knowledge about temporal intervals.
Communications of ACM, 26(11):832{843, 1983.
2] B. G. Buchanan and E. H. Shortlie Eds.
RuleBased Expert Systems.
Addision-Wesley, 1984.
3] R. Loganantharaj.
Complexity issues of possibilistic temporal reasoning.
preperation, 1994.
4] J. Gaschnig R. O. Duda and P. E. Hart.
Model design in the prospector consultant system for mineral exploration.
In D. Michie, editor, Expert Systems in the Microelectronics Age.
Edinburgh University Press, 1979.
5] P. E. Hart R. O. Duda and N. J. Nilsson.
Subjective bayesian methods for rule-based inference  systems.
In Proceedings of the AFIPS National Computer Conference, volume 45, 1976.
6] E. H. Shortlie.
Computer Based Medical Consultations:MYCIN.
Elsvier, 1976.
7] M. Vilain and H. Kautz.
Constraint propagation algorithm for temporal reasoning.
In Proceedings of AAAI-86, pages 377{382, 1986.
8] L. A. Zadeh.
Making computers think like people.
IEEE Spectrum, pages 26{32, August 1984.
2013 20th International Symposium on Temporal Representation and Reasoning  Rethinking Logics of Action and Time James F. Allen Dept.
of Computer Science University of Rochester, Rochester, NY and Florida Institute for Human and Machine Cognition Pensacola, FL jallen@ihmc.us  Abstract--It is over thirty years since I developed interval temporal logic and the accompanying logic of action and time.
Overall, these theories have held up well and, with some extensions over the years, have remained useful in our work on AI planning/reasoning systems and natural language understanding.
Recently I have become interested in systems that can learn by reading, and specifically, that can learn necessary conditions for event occurrence from reading dictionary definitions.
This task adds new constraints on the form of the temporal logic we need.
In this talk, I will review our earlier work on temporal logic and then look at the problems that have forced a recent generalization of the formalism in order to allow compositional construction of event definitions from natural language definitions.
Allen & Hayes also derive a notion of points, defined as the "places" where two intervals meet.
Points have no duration, and so are distinct from intervals (and moments), but we can define a notion of some property holding at a point indirectly by saying that there is an interval over which the property is true that contains the point.
Given this logic of time, we construct a logic of events by associating eventualities with times.
For states (or properties), we have a predicate H OLDS(p, t) that asserts the property p holds over an interval t. A key property of H OLDS is homogeneity, namely if a property holds over T then it also holds over all subintervals of T , i.e.,  Keywords-Temporal Logic; Models of Events and Action  [?
]o, P, t .
H OLDS(P (o), t) [?]
[[?
]t [?]
t.H OLDS(P (o), t )]  I.
BACKGROUND My original formulations of actions and time still seem valid today, and form the underpinnings of our new work.
The major claim in this work was that eventualities (reified states, events and activities) define stretches of time (time intervals) over which they are realized (i.e., where states hold and events occur).
Studying these temporal projections of eventualities lead to the interval theory of time.
Critical to this theory was stepping away from the standard physics interpretation of time as a continuous dense ordering modeled on the real numbers.
The most prominent departure of the interval model was the preeminence of the meets relation, where one interval is entirely before another and yet there is no time between them and they share no time in common.
Allen & Hayes (1990) show how the complete interval logic can be derived from the meets relation, yielding the thirteen possible interval relations introduced in Allen (1984).
The Allen & Hayes model also introduced the notion of moments, which are minimal intervals of time.
Moments have no subintervals and represent a conceptual snapshot of time.
Nothing can change within a moment, otherwise it could be subdivided and thus would be a true interval rather than a moment!
In essence, moments capture the limits of our perception (or the measuring capabilities of devices we invent).
They bear many similarities to the notion of states (in STRIPS-like planning models) or situations (in the situation calculus).
For those that worry about points, 1530-1311/13 $26.00 (c) 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.8  For events, the predicate OCCURS was used, where OCCUR(e, t) asserts that event e occurred over time t. This relation only holds for the minimum time over which the event can be said to occur, and thus an event occurrence uniquely defines its time of occurrence and the homogeneity property definitely does not hold!
II.
R ECENT D EVELOPMENTS Recently, we have been working on systems that can automatically derive common sense knowledge from definitions.
For instance, in Allen & Teng (2013) we focused on what is needed to be able to capture an adequate definition of the notion of change from the compositional interpretation of its definition becoming different.
In tackling this problem, several significant issues arose that forced further development of the temporal logic.
First, we needed a notion of scales (e.g., hotter/colder, happier/sadder, color, etc), as being different must mean that the objects differ on some relevant dimension, captured by the scale.
Without scales the notion of different reduces to simple inequality, which is not an intuitively satisfactory formulation.
If one defined different in this way, then no two distinct things could ever be similar as they are not equal.
With such a notion of scales in hand, we can formalize the property that one object A is different than another object B in a fairly satisfactory way.
But in defining the notion of change it is the same object that is being compared, just at 31  different times.
In other words, an object X changes at time t if it is different after t than it was before t!
Our previous temporal logics had no way of directly comparing an object at different times since times were associated with properties and events, not objects.
To handle this, we introduce a new function that takes an object and a time and denotes that object over that time, e.g., x@t represents "object x over time t".
We refer to these as temporally situated objects.
Thus, John is Happy today might be written as  [5] J. F. Allen and C. Teng, "Becoming different: A languagedriven formalism for commonsense knowledge," in Eleventh International Symposium on Logical Formalization on Commonsense Reasoning.
Cypress, 2013.
[6] A. Whitehead, Process and Reality.
1929.
T RUE O F(john@today, Happy) Where T RUE O F plays the same role as H OLDS in our old logic, where this would have been expressed as H OLDS(Happy(john), today).
For unary properties, these two formulations are equivalent and thus notational variants of each other.
For binary relations, however, the situation is very different.
For example, we might express I am different today from yesterday as: T RUE O F 2(me@yesterday, me@today, Different) This fact cannot be expressed using the H OLDS predicate with its single temporal argument.
The notion that objects are temporally situated and properties are not is in stark contrast to standard temporal logics in which objects are atemporal and properties change over time.
As is usual the case whenever I work on temporal logic, this insight is not new, and such formulations have long been discussed in philosophy, going back to before Whitehead (1929).
We also introduce a predicate E XISTS that defines the temporal range of an object, i.e., when the temporally situated object o@t exists.
For instance, if I was born in 1983, then E XISTS(me@1984 ) and E XISTS(me@1982 ) both hold.
With this extension, we can also now define concepts such as creation and destruction, with were always problematic in the old formalism.
In this talk I will discuss these and other issues that have arisen as we try to take the notion of compositional interpretation of definitions seriously.
R EFERENCES [1] J. F. Allen and P. Hayes, "Moments and points in an intervalbased temporal logic," Computational Intelligence, vol.
5, no.
3, pp.
225-238, 1990.
[2] J. F. Allen, "Maintaining knowledge about temporal intervals," Communications of the ACM, vol.
26, no.
11, pp.
832-843, 1983.
[3] ----, "Towards a general theory of action and time," Artifical Intelligence, vol.
23, pp.
123-154, 1984.
[4] J. F. Allen and G. Ferguson, "Actions and events in interval temporal logic," Journal of Logic Computation, vol.
4, no.
5, pp.
531-579, 1994.
24  Macmillan, New York,

A complete classification of the expressiveness of interval logics of Allen's relations over dense linear orders Luca Aceto* , Dario Della Monica* , Anna Ingolfsdottir* , Angelo Montanari+ and Guido Sciavicco++ ICE-TCS, School of Computer Science, Reykjavik University, Iceland - Email: {luca,dariodm,annai}@ru.is + Department of Mathematics and Computer Science, University of Udine, Italy - Email: angelo.montanari@uniud.it ++ Department of Information Engineering and Communications, University of Murcia, Spain - Email: guido@um.es *  Abstract--Interval temporal logics are temporal logics that take time intervals, instead of time instants, as their primitive temporal entities.
One of the most studied interval temporal logics is Halpern and Shoham's modal logic of time intervals (HS), which has a distinct modality for each binary relation between intervals over a linear order.
As HS turns out to be undecidable over most classes of linear orders, the study of HS fragments, featuring a proper subset of HS modalities, is a major item in the research agenda for interval temporal logics.
A characterization of HS fragments in terms of their relative expressive power has been given for the class of all linear orders.
Unfortunately, there is no easy way to directly transfer such a result to other meaningful classes of linear orders.
In this paper, we provide a complete classification of the expressiveness of HS fragments over the class of (all) dense linear orders.
Keywords-Interval Temporal Logics; Expressive Power; Bisimulations.
I. I NTRODUCTION Interval reasoning naturally arises in various fields of computer science and AI, ranging from hardware and realtime system verification to natural language processing, from constraint satisfaction to planning [1], [2], [3], [4], [5], [6].
Interval temporal logics make it possible to automate reasoning on interval structures over (linearly) ordered domains, where time intervals, rather than time instants, are the primitive ontological entities.
The variety of binary relations between intervals in a linear order was first studied by Allen [5], who investigated their use in systems for time management and planning.
In [7], Halpern and Shoham introduced and systematically analyzed the (full) logic of Allen's relations, called HS, that features one modality for each Allen's relation.
In particular, they showed that HS is highly undecidable over most classes of linear orders.
This result motivated the search for (syntactic) HS fragments The authors acknowledge the support from the Spanish fellowship program 'Ramon y Cajal' RYC-2011-07821 and the Spanish MEC project TIN2009-14372-C03-01 (G. Sciavicco), the project Processes and Modal Logics (project nr.
100048021) of the Icelandic Research Fund (L. Aceto, D. Della Monica, and A. Ingolfsdottir), the project Decidability and Expressiveness for Interval Temporal Logics (project nr.
130802-051) of the Icelandic Research Fund in partnership with the European Commission Framework 7 Programme (People) under "Marie Curie Actions" (D. Della Monica), and the Italian GNCS project Extended Game Logics (A. Montanari).
offering a good balance between expressiveness and decidability/complexity.
A comparative analysis of the expressive power of the variety of HS fragments naturally sets the scene for such a search.
This analysis is far from being trivial, because some HS modalities are definable in terms of others, and thus syntactically different fragments may turn out to be equally expressive.
To complicate matters, the ability of a given subset of HS modalities to define a specific modality may depend on the class of linear orders in which the logic is interpreted.
Many classes of linear orders are of practical interest, including the class of all linear orders and the class of all dense (resp., discrete, finite) linear orders, as well as the linear order of R (resp., Q, Z, and N).
In [8], Della Monica et al.
gave a complete characterization of all expressively different subsets of HS modalities over all linear orders.
Unfortunately, such a classification cannot be easily transferred to any other class of linear orders (proving a specific undefinability result amounts to providing a counterexample based on concrete linear orders belonging to the considered class).
As a matter of fact, specific assumptions on the underlying linear orders give rise, in general, to different sets of inter-definability equations.
In this paper, we give a complete classification of the expressiveness of HS fragments over all dense linear orders.
We assume strict semantics (excluding point intervals) and we identify a correct and complete set of inter-definability equations among HS modalities.
Undefinability results are essentially based on counterexamples referring to the linear order of R. However, the proposed constructions can be modified to deal with specific sub-classes of the class of all dense linear orders, e.g., the linear order of Q.
As a final result, we show that there are exactly 966 expressively different HS fragments over (all) dense linear orders (over all linear orders, they are 1347), out of 4096 distinct subsets of HS modalities.
II.
P RELIMINARIES Let D = hD, <i be a linear order.
An interval over D is an ordered pair [a, b], where a, b [?]
D and a <= b.
An interval is called a point (resp., strict) interval if a = b (resp., a < b).
In this paper, we restrict ourselves to strict intervals.
If we  HS modalities  Allen's relations  Graphical representation a b c d  hAi  [a, b]RA [c, d] = b = c  hLi  [a, b]RL [c, d] = b < c  hBi  [a, b]RB [c, d] = a = c, d < b  hEi  [a, b]RE [c, d] = b = d, a < c  hDi  [a, b]RD [c, d] = a < c, d < b  hOi  [a, b]RO [c, d] = a < c < b < d  Figure 1.  c  d  c d c d c  d c  d  Allen's interval relations and the corresponding HS modalities.
exclude equality, there are 12 different relations between two strict intervals in a linear order, often called Allen's relations [5]: the six relations RA , RL , RB , RE , RD , and RO depicted in Figure 1 and the inverse ones, that is, RX = (RX )-1 , for each X [?]
{A, L, B, E, D, O}.
We treat interval structures as Kripke structures and Allen's relations as accessibility relations over them, thus associating a modality hXi with each Allen's relation RX .
For each X [?]
{A, L, B, E, D, O}, the transpose of modality hXi is modality hXi, corresponding to the inverse relation RX of RX .
A. Syntax HS is a multi-modal logic with formulae built from a finite, non-empty set AP of atomic propositions, the propositional connectives [?]
and !, and a modality for each Allen's relation [7] .
With every subset {RX1 , .
.
.
, RXk } of these relations, we associate the fragment X1 X2 .
.
.
Xk of HS, whose formulae are defined by the grammar: ph ::= p | !ph | ph [?]
ph | hX1 iph | .
.
.
| hXk iph, where p [?]
AP.
The other propositional connectives and constants (e.g., [?
], -, and >) can be derived in the standard way, as well as the dual modalities (e.g., [A]ph [?]
!hAi!ph).
For a fragment F = X1 X2 .
.
.
Xk and a modality hXi, we write hXi [?]
F if X [?]
{X1 , .
.
.
, Xk }.
Given two fragments F1 and F2 , we write F1 [?]
F2 if hXi [?]
F1 implies hXi [?]
F2 , for every modality hXi.
Finally, for a fragment F = X1 X2 .
.
.
Xk and a formula ph, we write ph [?]
F, or, equivalently, we say that ph is an F-formula, meaning that ph belongs to the language of F. B.
Models and semantics The (strict) semantics of HS is given in terms of interval models M = hI(D), V i, where D is a linear order, I(D) is the set of all (strict) intervals over D, and V is a valuation function V : AP 7- 2I(D) , which assigns to every atomic proposition p [?]
AP the set of intervals V (p) on which p holds.
The truth of a formula on a given interval [a, b] in an interval model M is defined by structural induction on formulae as follows: * M, [a, b]  p iff [a, b] [?]
V (p), for each p [?]
AP;  M, [a, b]  !ps iff it is not the case that M, [a, b]  ps; M, [a, b]  ph [?]
ps iff M, [a, b]  ph or M, [a, b]  ps; * M, [a, b]  hXips iff there exists an interval [c, d] such that [a, b]RX [c, d] and M, [c, d]  ps, for each modality hXi.
For every p [?]
AP and [a, b] [?]
I(D), we say that [a, b] is a p-interval if M, [a, b]  p. By M, [a, b] 6 ps, we mean that it is not the case that M, [a, b]  ps.
Formulae of HS can be interpreted in several interesting classes of interval models over linear orders (in short, classes of linear orders).
Among them, we mention the following ones: * the class of all linear orders; * the class of (all) dense linear orders (i.e, those in which for every pair of distinct points there exists at least one point in between them -- e.g., Q, R); 1 * the class of (all) discrete linear orders (i.e, those in which every element, apart from the greatest element, if it exists, has an immediate successor, and every element, other than the least element, if it exists, has an immediate predecessor -- e.g., N, Z, Z + Z); * the class of (all) finite linear orders (i.e., those having only finitely many points).
A formula ph of HS is valid over a class C of linear orders, denoted C ph, if it is true on every interval in every interval model belonging to C. Two formulae ph and ps are equivalent relative to the class C of linear orders, denoted ph [?
]C ps, if C ph - ps.
* *  C. Definability and expressiveness The following definition formalizes the notion of definability of modalities in terms of others.
Definition 1 (Inter-definability).
A modality hXi of HS is definable in an HS fragment F relative to a class C of linear orders, denoted hXi C F, if hXip [?
]C ps for some Fformula ps over the atomic proposition p, for some p [?]
AP.
In such a case, the equivalence hXip [?
]C ps is called an inter-definability equation (or simply inter-definability) for hXi in F relative to C. We write hXi  6 C F if hXi is not definable in F over C. Notice that smaller classes of linear orders inherit the inter-definabilities holding for larger classes of linear orders.
Formally, if C1 and C2 are classes of linear orders such that C1 [?]
C2 , then all inter-definabilities holding for C2 are also valid for C1 .
However, more inter-definabilities can possibly hold for C1 .
On the other hand, undefinability results for C1 hold also for C2 .
In the rest of the paper, we will omit the class of linear orders when it is clear from the context 1 In the literature, these are sometimes called weakly discrete linear orders, in opposition to the so-called strongly discrete ones, where, for every pair of distinct points, there are only finitely many points in between them -- e.g., N, Z.
(e.g., we will simply say hXip [?]
ps and hXi  F instead of hXip [?
]C ps and hXi C F, respectively).
It is known from [7] that, in the strict semantics, all HS modalities are definable in the fragment containing modalities hAi, hBi, and hEi, and their transposes hAi, hBi, and hEi.
(In the non-strict semantics, including non-strict intervals and defined accordingly, the four modalities hBi, hEi, hBi, and hEi suffice, as shown in [9].)
In this paper, we compare and classify the expressiveness of all HS fragments relative to the class of all dense linear orders.
Formally, let F1 and F2 be any pair of such fragments.
We say that: * F2 is at least as expressive as F1 , denoted F1  F2 , if each modality hXi [?]
F1 is definable in F2 ; * F1 is strictly less expressive than F2 (or, equivalently, F2 is strictly more expressive than F1 ), denoted F1 [?]
F2 , if F1  F2 holds but F2  F1 does not; * F1 and F2 are equally expressive (or, expressively equivalent), denoted F1 [?]
F2 , if both F1  F2 and F2  F1 hold; * F1 and F2 are expressively incomparable, denoted F1 6[?]
F2 , if neither F1  F2 nor F2  F1 hold.
Now, it is possible to define the notion of optimal interdefinability, as follows.
Definition 2 (Optimal inter-definability).
A definability hXi  F is optimal if hXi 6 F 0 for any fragment F 0 such that F 0 [?]
F. In order to show non-definability of a given modality in an HS fragment, we use a standard technique in modal logic, based on the notion of bisimulation and the invariance of modal formulae with respect to bisimulations (see, e.g., [10], [11]).
Let F be an HS fragment.
An F-bisimulation between two interval models M = hI(D), V i and M 0 = hI(D0 ), V 0 i over AP is a relation Z [?]
I(D) x I(D0 ) satisfying the following properties: * local condition: Z-related intervals satisfy the same atomic propositions in AP; 0 0 * forward condition: if [a, b]Z[a , b ] and [a, b]RX [c, d] for some hXi [?]
F, then there exists some [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ] and [c, d]Z[c0 , d0 ]; 0 0 0 0 * backward condition: if [a, b]Z[a , b ] and [a , b ]RX 0 0 [c , d ] for some hXi [?]
F, then there exists some [c, d] such that [a, b]RX [c, d] and [c, d]Z[c0 , d0 ].
The important property of bisimulations used here is that any F-bisimulation preserves the truth of all formulae in F, that is, if ([a, b], [a0 , b0 ]) [?]
Z and Z is an F-bisimulation, then [a, b] and [a0 , b0 ] satisfy exactly the same formulae in F. Thus, in order to prove that a modality hXi is not definable in F, it suffices to construct a pair of interval models M = hI(D), V i and M 0 = hI(D0 ), V 0 i, and an Fbisimulation Z between them, relating a pair of intervals [a, b] [?]
I(D) and [a0 , b0 ] [?]
I(D0 ), such that M, [a, b]  hXip, while M 0 , [a0 , b0 ] 6 hXip.
In this case, we say that Z breaks hXi.
hLip hLip hOip hOip hDip hDip hLip hLip  [?]
hAihAip [?]
hAihAip [?]
hEihBip [?]
hBihEip [?]
hEihBip [?]
hEihBip [?]
hBi[E]hBihEip [?]
hEi[B]hEihBip  hLi A hLi A hOiBE hOiBE hDiBE hDiBE hLi BE hLi BE  Table I T HE COMPLETE SET OF OPTIMAL INTER - DEFINABILITIES FOR THE CLASS OF ALL LINEAR ORDERS .
D. The problem As we already pointed out, every subset of the set of the 12 modalities corresponding to Allen's relations gives rise to a logic, namely, a fragment of HS.
There are 212 (the cardinality of the powerset of the set of modalities) such fragments.
Due to possible inter-definabilities of modalities in terms of other ones, not all these fragments are expressively different.
The problem we consider here is the problem of obtaining a complete classification of all HS fragments with respect to their expressive power over the class of (all) dense linear orders.
In other words, given two HS fragments F1 , F2 , we want to be able to decide how they relate to each other with respect to expressiveness (that is, whether F1 is strictly less expressive than F2 , F1 is strictly more expressive than F2 , F1 and F2 are expressively equivalent, or F1 and F2 are incomparable).
In order to do so, all we need to do is to provide the complete set of optimal inter-definabilities between HS modalities.
Indeed, provided with such a set, it is immediate to decide which relation exists between any two given fragments with respect to their expressive power.
The class of all linear orders.
The problem we address in this paper has been solved for the class of all linear orders in [8], where the complete set of optimal inter-definabilities in Table I has been identified.
All the bisimulations used in [8] to solve the problem for the class of all linear orders are based on dense structures, apart from those for hLi and hLi, which are based on discrete structures.
As a consequence, the above results for all modalities but hLi and hLi immediately extend to all classes of dense linear orders.
In what follows, we identify a new set of optimal inter-definabilities holding for hLi and hLi over classes of dense linear orders, and we prove it to be complete (for the modalities hLi and hLi).
III.
T HE CLASS OF ALL DENSE LINEAR ORDERS From now on, we focus our attention on the class of all dense linear orders, and we provide bisimulations based on R. However, it is possible to extend our results to sub-classes of the class of all dense linear orders (that might not include R), by providing bisimulations based on different (suitable)  hLip hLip hLip hLip hLip hLip hLip hLip hLip hLip  [?]
hOi(hOi> [?]
[O]hDihOip) [?]
hOi(hOi> [?]
[O]hDihOip) [?]
hBi[D]hBihDihBip [?]
hEi[D]hEihDihEip [?]
hOi[E]hOihOip [?]
hOi[B]hOihOip [?]
hOi(hOi> [?]
[O]hBihOihOip) [?]
hOi(hOi> [?]
[O]hEihOihOip) [?]
hOi[O][L]hOihOip [?]
hOi[O][L]hOihOip  hLiDO hLiDO hLiBD hLiED hLiEO hLiBO hLiBO hLiEO hLiLO hLiLO  Table II A SET OF INTER - DEFINABILITY EQUATIONS FOR hLi AND hLi OVER THE CLASS OF ALL DENSE LINEAR ORDERS .
dense linear orders.
In what follows, we first prove that Table II depicts a set of inter-definabilities for the operators hLi and hLi (Lemma 1).
Then, we show that the union of all equations for hLi and hLi shown in Table I and Table II constitutes the complete set of optimal inter-definabilities for those operators (Theorem 1).
Lemma 1.
Table II depicts a set of inter-definabilities for the operators hLi and hLi.
Proof: Notice that it is enough to verify the interdefinability equations relative to hLi, as those for hLi follow by symmetry.
Here we only give the proof for the first equation.
The other proofs proceed analogously and are omitted.
(See the Appendix for full details.)
Firstly, suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
We want to prove that M, [a, b]  hOi(hOi> [?]
[O]hDihOip) holds as well.
By M, [a, b]  hLip, it follows that there exists an interval [c, d] in M such that b < c and M, [c, d]  p. Consider an interval [a0 , c], with a < a0 < b (the existence of such a point a0 is guaranteed by the density of the linear order).
It is such that [a, b]RO [a0 , c] and it satisfies: 0 * hOi>, as [a , c]RO [b, d], and 0 * [O]hDihOip, as every interval [e, f ], with [a , c]RO [e, f ], is such that e < c < f .
Thus, by density, there exists an interval [e0 , f 0 ] such that [e, f ]RD [e0 , f 0 ] and [e0 , f 0 ]RO [c, d], which implies M, [e, f ]  hDihOip, which, in turn, implies M, [a0 , c]  [O]hDihOip.
Hence, M, [a0 , c]  hOi> [?]
[O]hDihOip and M, [a, b]  hOi(hOi> [?]
[O]hDihOip).
Secondly, let us assume that M, [a, b]  hOi(hOi> [?]
[O]hDihOip) for an interval [a, b] in a model M .
That means that there exists an interval [c, d] such that [a, b]RO [c, d] and that (i) M, [c, d]  hOi>, and thus there exists a point e > d, and (ii) M, [c, d]  [O]hDihOip.
The interval [b, e] is such that [c, d]RO [b, e], and thus, by (ii), it satisfies hDihOip.
Therefore, there exists an interval [f, g] such that [b, e]RD [f, g], and a p-interval [h, i] with [f, g]RO [h, i].
Since h > b, we conclude that M, [a, b]  hLip.
The rest of the paper is devoted to establishing our main  Algorithm 1 Max = maxF ragN onDef Op(Def, hXi) input parameters: - Def : list of inter-definabilities - hXi: modality output parameters: - Max: list of maximal fragments not defining hXi according to Def 1: Max - [?]
2: for all HS fragment F do 3: F - addDef inableOperators(F , Def ) 4: if hXi [?]
/ F then 5: add - true 6: for all F1 [?]
Max do 7: if F  F1 then 8: add - false 9: else if F1 [?]
F then 10: remove(Max, F1 ) 11: if add then 12: add(Max, F ) 13: return Max  result, that is, to prove that Table I and Table II depict a complete set of optimal inter-definabilities for the operator hLi.
This means that we cannot define hLi by means of any other optimal equation.
It is immediate to verify, by symmetry, that the same result holds for the operator hLi.
As a first step, we need to identify all maximal HS fragments not containing, as definable (according to the inter-definabilities of Table I and Table II), the operator hLi.
Given the large number of inter-definabilities, it is not immediate to detect all such fragments.
For this purpose, we used a tool based on the pseudo-code presented in Algorithm 1.
The algorithm takes as input a list Def of known interdefinabilities and a modality hXi, and it returns the list M ax of maximal fragments that are not capable to define hXi according to the definabilities in Def .
For each HS fragment F (line 2), the algorithm proceeds as follows.
First (line 3), it computes the fragment F which is expressively equivalent to F but whose language also explicitly includes all the modalities that are included only as definable in F (e.g., it computes ALBED from ABE).
Next (line 4), if modality hXi does not belong to the language of F, then F is a potential candidate to be part of the output list M ax.
So, its expressive power is compared (lines 6-10) to the one of the elements currently belonging to M ax and it is added to it if and only if there is no fragment in M ax which is at least as expressive as F (lines 7-8 and 11-12).
Finally, the algorithm removes from M ax every fragment that is strictly less expressive than F (lines 9-10), before returning the desired list of fragments M ax (line 13).
The algorithm, run on the list of inter-definabilities in Table I and Table II, and on modality hLi as input parameters, returned the three maximal fragments OBEDO, BEDALEDO, and BALBEDO.
In the light of the interdefinabilities in Table I, we can replace these three fragments with equivalent fragments featuring the smallest set of modalities, namely, OBEO, BEAED, and BABE, respectively.
Now, in order to establish the optimality of the set  of inter-definabilities, for each such fragment F, we provide an F-bisimulation that breaks hLi.
In what follows, thanks to the next proposition, in our proofs we can safely assume that for each interval [a, b] and Allen's relation RX , there exists an interval [c, d] such that [a, b]RX [c, d].
Proposition 1.
Let D be a dense linear order without least and greatest elements, and let [a, b] [?]
I(D).
Then, there exists an interval [c, d] [?]
I(D) such that [a, b]RX [c, d], for each X [?]
{A, L, B, E, D, O, A, L, B, E, D, O}.
A.
An OBEO-bisimulation that breaks hLi Consider the two interval models M and M 0 , defined as M = M 0 = hI(R), V i, where V (p) = {[-a, a] | a [?]
R} (observe that no interval [c, d], with c >= 0, satisfies p).
Moreover, let Z = {([a, b], [a0 , b0 ]) | -a ~ b and - a0 ~ b0 for some ~[?]
{<, =, >}} (see Figure 2).
Lemma 2.
Z is a OBEO-bisimulation.
Proof: Local condition.
Consider a pair ([a, b], [a0 , b0 ]) of Z-related intervals.
The following chain of double implications hold: M, [a, b]  p iff -a = b iff (by the definition of Z) -a0 = b0 iff M, [a0 , b0 ]  p. Forward condition.
Consider the three intervals [a, b], [a0 , b0 ], and [c, d] such that [a, b]Z[a0 , b0 ] and [a, b]RX [c, d] for some X [?]
{O, B, E, O}.
We need to exhibit an interval [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ] and [c, d]Z[c0 , d0 ].
We distinguish three cases.
0 0 * If -a > b and -a > b , then, as a preliminary step, we show that the following facts hold: (i) a < 0 and a0 < 0; (ii) |a| > |b| and |a0 | > |b0 |.
We only show the proofs for a < 0 and |a| > |b| and we omit the ones for a0 < 0 and |a0 | > |b|, which are analogous.
As for the former claim above, it is enough to observe that, if a >= 0, then a >= 0 >= -a > b, which implies b < a, leading to a contradiction with the fact that [a, b] is an interval (thus a < b).
Notice that, as an immediate consequence, we have that |a| = -a holds.
As for the latter claim above, firstly we suppose, by contradiction, that |a| = |b| holds.
Then, -a = |a| = |b| holds and this implies either b = -a, contradicting the hypothesis that -a > b, or b = a, contradicting the fact that [a, b] is an interval.
Secondly, we suppose, again by contradiction, that |a| < |b| holds.
Then, by the former claim, we have that 0 < -a = |a| < |b| holds, which implies b 6= 0.
Now, we show that both b < 0 and b > 0 lead to a contradiction.
If b < 0, then |b| = -b, and thus it holds -a < -b, which amounts to a > b, contradicting the fact that [a, b] is an interval.
If b > 0, then |b| = b, and thus it holds -a < b, which contradicts the hypothesis that -a > b.
This proves the two claims above.
Now, we distinguish the following sub-cases.
- If X = O, then [c, d] is such that a < c < b < d. We distinguish the following cases.
*  * If -c > d, then take some c0 such that a0 < c0 < -|b0 | < 0 (notice also that c0 < -|b0 | <= b0 trivially holds), and d0 such that b0 < d0 < |c0 | = -c0 (the existence of such points c0 , d0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
* If -c = d, then take some c0 such that a0 < c0 < -|b0 | < 0, and d0 = -c0 (the existence of such a point c0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
* If -c < d, then take c0 such that a0 < c0 < -|b0 | < 0, and any d0 > -c0 (the existence of such a point c0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = B, then [c, d] is such that a = c < b < d. We distinguish the cases below.
* If -c > d, then take c0 = a0 and d0 such that b0 < d0 < -a0 = -c0 (the existence of such a point d0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
* If -c = d, then take c0 = a0 and d0 = -c0 (= -a0 > b0 ).
The interval [c0 , d0 ] is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
* If -c < d, then take c0 = a0 and any d0 > -c0 (= -a0 > b0 ).
The interval [c0 , d0 ] is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that c < a < b = d. Notice that |c| = -c > -a = |a| holds, because c < a < 0.
Thus -c > -a > b = d also holds.
Then, take d0 = b0 and any c0 < a0 .
We have that -c0 > -a0 > b0 = d0 .
The interval [c0 , d0 ] is therefore such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = O, then [c, d] is such that c < a < d < b.
Notice that |c| = -c > -a = |a| holds, because c < a < 0.
Thus -c > -a > b > d also holds.
Then, take some d0 such that a0 < d0 < b0 and any c0 < a0 (the existence of such a point d0 is guaranteed by the density of R).
Thus, it holds -c0 > -a0 > b0 > d0 .
The interval [c0 , d0 ] is therefore such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If -a = b and -a0 = b0 , then we have that a < 0 (resp., a0 < 0) and b > 0 (resp., b0 > 0).
Indeed, if a >= 0 held, then b = -a <= 0 <= a would also hold, contradicting the fact that [a, b] is an interval (and thus b > a).
From a < 0 and -a = b, it immediately follows that b > 0.
The facts that a0 < 0 and b0 > 0 can be shown analogously.
Notice also that, from -a = b and -a0 = b0 , it follows that |a| = |b| and |a0 | = |b0 |.
Now, we distinguish the following sub-cases.
- If X = O, then [c, d] is such that a < c < b < d. Notice that -c <= |c| < |a| = |b| = b < d holds.
-4 -3 -2 -1 0  1  2  3  ... p p  R  -3 -2 -1 0  4  R  ...  Z  OBEO-bisimulation.
*  Backward condition.
Since the relation Z is symmetric, the forward condition implies the backward condition, as follows.
Consider a pair ([a, b], [a0 , b0 ]) of Z-related intervals and an interval [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ], for some X [?]
{O, B, E, O}.
We need to find an interval [c, d] such that [a, b]RX [c, d] and [c, d]Z[c0 , d0 ].
By symmetry, ([a0 , b0 ], [a, b]) [?]
Z, as well.
By the forward condition, we know that for every interval [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ], for some X [?]
{O, B, E, O}, there exists an interval [c, d] such that [a, b]RX [c, d] and [c0 , d0 ]Z[c, d].
By symmetry [c, d]Z[c0 , d0 ] also holds, hence the backward condition is fulfilled, too.
It can be easily checked that the given proof of Lemma 2 still works if we substitute Q for R. Corollary 1.
The modality hLi is not definable in the fragment OBEO (and in any of its sub-fragments) over the class of all dense linear orders.
4  5  p  f  hLip  b  a  a  a  !hLip  Z  f hLip  b  hLip  a  b  b  f !hLip  Z  f  Then, take c0 = 0 and any d0 > b0 (> 0).
We have that -c0 < d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = B, then [c, d] is such that a = c < b < d. Notice that -c <= |c| = |a| = |b| = b < d holds.
Then, take c0 = a0 and any d0 > b0 .
We have that -c0 = -a0 = b0 < d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that c < a < b = d. Notice that |c| = -c > -a = |a| holds, because c < a < 0.
Thus -c > -a = b = d also holds.
Then, take d0 = b0 and any c0 < a0 .
We have that -c0 > -a0 = b0 = d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = O, then [c, d] is such that c < a < d < b.
Notice that |c| = -c > -a = |a| holds, because c < a < 0.
Thus -c > -a = b > d also holds.
Then, take d0 = 0 and any c0 < a0 (< 0).
We have that -c0 > d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If -a < b and -a0 < b0 , then the proof proceeds symmetrically to the case when -a > b and -a0 > b0 .
More precisely, the argument used there for modalities hOi and hEi applies now to modalities hOi and hBi, and vice versa.
(See the Appendix for full details.)
3  f a  !hLip  Figure 2.
2  no p-intervals start here  ... p  hLip  1  b  f a  !hLip  b  Z Figure 3.
BEAED-bisimulation.
Proof: It is immediate to check that [-4, -2]Z[-4, 2].
Moreover, it holds that M, [-4, -2]  hLip (as M, [-1, 1]  p) and M 0 , [-4, 2]  !hLip (as no interval [c, d], with c > 0, satisfies p).
Thus, the thesis immediately follows from Lemma 2, because Z is an OBEO-bisimulation that breaks hLi.
B.
A BEAED-bisimulation that breaks hLi In order to define a BEAED-bisimulation that breaks hLi, we will make use of the function f : R - {x [?]
R | x < 1}, defined as follows.
 x - 1 if x <= 1 f (x) = 1 - x1 if x > 1 In particular, we use the properties of f stated by the next lemma, whose straightforward proof is omitted.
(See the Appendix for full details.)
Lemma 3. f is a monotonically increasing bijection from R to {x [?]
R | x < 1} such that f (x) < x for every x [?]
R. The bisimulation that breaks hLi is defined as follows.
We consider two interval models M and M 0 , defined as M = M 0 = hI(R), V i, where V (p) = {[a, b] | a = f (b)} and let Z = {([a, b], [a0 , b0 ]) | a ~ f (b), a0 ~ f (b0 ) for some ~[?]
{<, =, >}} (see Figure 3).
Lemma 4.
Z is a BEAED-bisimulation.
Proof: Local condition.
Consider a pair ([a, b], [a0 , b0 ]) of Z-related intervals.
The following chain of double implications holds: M, [a, b]  p iff a = f (b) iff (by the definition of Z) a0 = f (b0 ) iff M 0 , [a0 , b0 ]  p. Forward condition.
Consider the three intervals [a, b], [a0 , b0 ], and [c, d] such that [a, b]Z[a0 , b0 ] and [a, b]RX [c, d] for some X [?]
{B, E, A, E, D}.
We need to exhibit an interval [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ] and [c, d]Z[c0 , d0 ].
We distinguish three cases.
*  *  If a > f (b) and a0 > f (b0 ), then we distinguish the following sub-cases.
- If X = B, then [c, d] is such that a = c < d < b.
By the monotonicity of f , we have that f (d) < f (b) < a = c. Moreover, by the monotonicity of f , for every interval [c0 , d0 ], with [a0 , b0 ]RB [c0 , d0 ], f (d0 ) < c0 holds, and thus [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that a < c < b = d. Thus, f (d) = f (b) < a < c. For every interval [c0 , d0 ], with [a0 , b0 ]RE [c0 , d0 ], f (d0 ) < c0 holds, and thus [c, d]Z[c0 , d0 ].
- If X = A, then [c, d] is such that c < d = a.
Now, if c < f (d) = f (a), then, by the definition of f and Lemma 3, there exists a point c0 such that c0 < f (a0 ) < a0 .
Thus, the interval [c0 , d0 ], with d0 = a0 , is such that [a0 , b0 ]RA [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If c = f (d) = f (a), then take c0 = f (a0 ) < a0 .
The interval [c0 , d0 ], with d0 = a0 , is such that [a0 , b0 ]RA [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If c > f (d) = f (a), then, by the density of R, the definition of f , and Lemma 3, there exists a point c0 such that f (a0 ) < c0 < a0 .
The interval [c0 , d0 ], with d0 = a0 , is such that [a0 , b0 ]RA [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that c < a < b = d. There are three possibilities.
If c < f (d), then, by the definition of f , there exists a point c0 such that c0 < f (b0 ) < a0 .
Thus, the interval [c0 , d0 ], with d0 = b0 , is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If c = f (d), then the interval [c0 , d0 ], with d0 = b0 and c0 = f (d0 ), is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If c > f (d), then, by the density of R, , there exists a point c0 such that f (b0 ) < c0 < a0 , and the interval [c0 , d0 ], with d0 = b0 , is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = D, then [c, d] is such that c < a < b < d. If c < f (d), then, take c0 = f (a0 ) and any d0 > b0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RD [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If c = f (d) (resp., c > f (d)), then, by the density of R and the monotonicity and the surjectivity of f , there exist two points c0 , d0 such that c0 < a0 < b0 < d0 and c0 = f (d0 ) (resp., c0 > f (d0 )).
Thus, the interval [c0 , d0 ] is such that [a0 , b0 ]RD [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If a < f (b) and a0 < f (b0 ), then we distinguish the following sub-cases.
- If X = B, then [c, d] is such that a = c < d < b.
Now, if c < f (d) (resp., c = f (d), c > f (d)), then, by the density of R and by the monotonicity and the surjectivity of f , there exists a point d0 such that a0 < d0 < b0 and a0 < f (d0 ) (resp., a0 = f (d0 ), a0 > f (d0 )).
Thus, the interval [c0 , d0 ], with c0 = a0 , is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that a < c < b = d.  *  Now, if c < f (d) (resp., c = f (d), c > f (d)), then, by the density of R, there exists a point c0 such that a0 < c0 < b0 and c0 < f (b0 ) (resp., c0 = f (b0 ), c0 > f (b0 )).
Thus, the interval [c0 , d0 ], with d0 = b0 , is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If X = A, then the same argument of the case when a > f (b) and a0 > f (b0 ) (and X = A) applies.
- If X = E, then [c, d] is such that c < a < b = d. Thus, c < a < f (b) = f (d).
For every interval [c0 , d0 ], with [a0 , b0 ]RE [c0 , d0 ], it holds c0 < f (d0 ), and thus [c, d]Z[c0 , d0 ].
- If X = D, then [c, d] is such that c < a < b < d. Thus, by the monotonicity of f , it holds that c < a < f (b) < f (d).
For every interval [c0 , d0 ], with [a0 , b0 ]RD [c0 , d0 ], it holds, by the monotonicity of f , that c0 < f (d0 ), and thus [c, d]Z[c0 , d0 ].
If a = f (b) and a0 = f (b0 ), then we distinguish the following sub-cases.
- If X = B, then [c, d] is such that a = c < d < b.
Thus, by the monotonicity of f , it holds that f (d) < f (b) = a = c. For every interval [c0 , d0 ], with [a0 , b0 ]RB [c0 , d0 ], by the monotonicity of f , we have that f (d0 ) < c0 , and thus [c, d]Z[c0 , d0 ].
- If X = E, then [c, d] is such that a < c < b = d. Thus, c > a = f (b) = f (d) holds.
For every interval [c0 , d0 ], with [a0 , b0 ]RE [c0 , d0 ], we have that c0 > f (d0 ), and thus [c, d]Z[c0 , d0 ].
- If X = A, then the same argument of the case when a > f (b) and a0 > f (b0 ) (and X = A) applies.
- If X = E, then [c, d] is such that c < a < b = d. Thus, c < a = f (b) = f (d).
For every interval [c0 , d0 ], with [a0 , b0 ]RE [c0 , d0 ], c0 < f (d0 ) holds, and thus [c, d]Z[c0 , d0 ].
- If X = D, then [c, d] is such that c < a < b < d. Thus, by the monotonicity of f , it holds that c < a = f (b) < f (d).
For every interval [c0 , d0 ], with [a0 , b0 ]RD [c0 , d0 ], by the monotonicity of f , we have that c0 < f (d0 ), and thus [c, d]Z[c0 , d0 ].
Backward condition.
The backward condition can be immediately verified by observing that the forward condition is satisfied and that Z is a symmetric relation.
As in the case of Lemma 2, it can be easily checked that the proof of Lemma 4 still works if we substitute Q for R. Corollary 2.
The modality hLi is not definable in the fragment BEAED (and in any of its sub-fragments) over the class of all dense linear orders.
Proof: It is immediate to check that [-1, 0]Z[0, 1] (as f (0) = -1 and f (1) = 0).
Moreover, it holds that M, [-1, 0]  hLip (as M, [0.5, 2]  p because f (2) = 0.5) and M 0 , [0, 1]  !hLip (as no interval [c, d], with c > 1, satisfies p because c is not in the image of f for each c > 1).
Thus, the thesis immediately follows from Lemma 4.
C. A BABE-bisimulation that breaks hLi Consider the two interval models M and M 0 , defined as M = hI(R), V i and M 0 = hI(R), V 0 i, respectively, where V (p) = {[a, b] | a, b [?]
Q or a, b [?]
R \ Q} and V 0 (p) = {[a0 , b0 ] | a0 <= 0 and (a0 , b0 [?]
Q or a0 , b0 [?]
R \ Q)}.
Moreover, let Z = {([a, b], [a0 , b0 ]) | a0 <= -1 and M, [a, b]  p iff M 0 , [a0 , b0 ]  p}.
Lemma 5.
Z is a BABE-bisimulation.
Proof: Local condition.
The local condition follows immediately from the definition of Z.
Forward condition.
Consider a pair ([a, b], [a0 , b0 ]) of Zrelated intervals.
By definition of Z, it holds that a0 <= -1 (and thus a0 <= 0).
Let X [?]
{B, A, B, E}.
For every interval [c0 , d0 ], with [a0 , b0 ]RX [c0 , d0 ], it holds that c0 <= -1 (and thus c0 <= 0).
Let Q = R \ Q.
By density and unboundedness of Q and Q, there exist (i) an interval [c00 , d00 ], such that [a0 , b0 ]RX [c00 , d00 ], with c00 , d00 [?]
Q or c00 , d00 [?]
Q, and (ii) an interval [c000 , d000 ], such that [a0 , b0 ]RX [c000 , d000 ], with c000 [?]
S, d000 [?]
S0 for some S, S0 [?]
{Q, Q}, with S 6= S0 .
Therefore, for every [c, d] such that [a, b]RX [c, d], there exists [c0 , d0 ] such that [a0 , b0 ]RX [c0 , d0 ] and [c, d]Z[c0 , d0 ].
Backward condition.
In order to check the backward condition, it is possible to use an argument which is analogous to the one used for checking the forward condition.
Unlike the cases of Lemma 2 and Lemma 4, the proof of Lemma 5 cannot be immediately transferred to Q.
However, it can be easily adapted by providing a partition of Q in two sets Q1 and Q2 which are both dense in Q. Corollary 3.
The modality hLi is not definable in the fragment BABE (and in any of its sub-fragments) over classes of dense linear orders.
IV.
C ONCLUSIONS In this paper, we have extended the results in [8] to obtain the optimal set of inter-definabilities among all modal operators in HS over the class of all dense linear orders.
More precisely, we have provided a characterization of the relative expressive power of all interval logics definable as fragments of HS in the particular case of dense structures, and we have found out that there are exactly 966 expressively different fragments.
Such a classification has a number of important applications, such as, for example, allowing one to properly identify the (small) set of HS fragments for which the decidability of the satisfiability problem is still an open problem.
A natural question that arises is: how do the interdefinabilities change when other classes of linear orders are considered?
Interesting (open) cases include, among others, the class of all discrete linear orders and the class of all finite linear orders.
R EFERENCES [1] D. Della Monica, V. Goranko, A. Montanari, and G. Sciavicco, "Interval temporal logics: a journey," Bulletin of the European Association for Theoretical Computer Science, vol.
105, pp.
73-99, 2011.
[2] B. Moszkowski, "Reasoning about digital circuits," Tech.
Rep. STAN-CS-83-970, Dept.
of Computer Science, Stanford University, Stanford, CA, 1983.
[3] C. Zhou and M. R. Hansen, Duration Calculus: A formal approach to real-time systems, ser.
EATCS Monographs in Theoretical Computer Science.
Springer, 2004.
[4] I. Pratt-Hartmann, "Temporal prepositions and their logic," Artificial Intelligence, vol.
166, no.
1-2, pp.
1-36, 2005.
[5] J. F. Allen, "Maintaining knowledge about temporal intervals," Communications of the ACM, vol.
26, no.
11, pp.
832- 843, 1983.
Proof: It is immediate to check that [-1, 0]Z[-1, 0].
Moreover, it holds that M, [-1, 0]  hLip (as M, [0, 1]  p) and M 0 , [-1, 0]  !hLip (as no interval [c, d], with c > 0, satisfies p in M 0 ).
Thus, the thesis immediately follows from Lemma 5.
[6] ----, "Towards a general theory of action and time," Artificial Intelligence, vol.
23, no.
2, pp.
123-154, 1984.
Theorem 1.
Table I and Table II depict a complete set of optimal inter-definabilities for the modality hLi.
[8] D. Della Monica, V. Goranko, A. Montanari, and G. Sciavicco, "Expressiveness of the interval logics of Allen's relations on the class of all linear orders: Complete classification," in IJCAI, July 2011, pp.
845-850.
Proof: Suppose that there exists an optimal interdefinability for hLi which is not listed in Table I or Table II.
Let us denote by hLi  F such an inter-definability.
F must be a (not necessarily strict) fragment of one of the fragments returned by Algorithm 1 (i.e., OBEO, BEAED, and BABE), as such an algorithm returns the set of all maximal HS fragments not containing the modality hLi, as definable according to the inter-definabilities of Table I and Table II.
Then, by Corollaries 1-3, hLi is not definable by F, yielding a contradiction.
[7] J. Halpern and Y. Shoham, "A propositional modal logic of time intervals," Journal of the ACM, vol.
38, no.
4, pp.
935- 962, 1991.
[9] Y. Venema, "Expressiveness and completeness of an interval tense logic," Notre Dame Journal of Formal Logic, vol.
31, no.
4, pp.
529-547, 1990.
[10] P. Blackburn, M. de Rijke, and Y. Venema, Modal Logic.
Cambridge University Press, 2002.
[11] M. Hennessy and R. Milner, "Algebraic laws for nondeterminism and concurrency," Journal of the ACM, vol.
32, no.
1, pp.
137-161, 1985.
A PPENDIX Full proof of Lemma 1.
Proof: Notice that it is enough to verify the interdefinability equations relative to hLi, as the others follow by symmetry.
*  *  hLip [?]
hOi(hOi> [?]
[O]hDihOip).
Firstly, suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
We want to prove that M, [a, b]  hOi(hOi> [?]
[O]hDihOip) holds as well.
By M, [a, b]  hLip, it follows that there exists an interval [c, d] in M such that b < c and M, [c, d]  p. Consider an interval [a0 , c], with a < a0 < b (the existence of such a point a0 is guaranteed by the density of the linear order).
It is such that [a, b]RO [a0 , c] and it satisfies: - hOi>, as [a0 , c]RO [b, d], and - [O]hDihOip, as every interval [e, f ], with [a0 , c]RO [e, f ], is such that e < c < f .
Thus, by density, there exists an interval [e0 , f 0 ] such that [e, f ]RD [e0 , f 0 ] and [e0 , f 0 ]RO [c, d], which implies M, [e, f ]  hDihOip, which, in turn, implies M, [a0 , c]  [O]hDihOip.
Hence, M, [a0 , c]  hOi> [?]
[O]hDihOip and M, [a, b]  hOi(hOi> [?]
[O]hDihOip).
Secondly, let us assume that M, [a, b]  hOi(hOi> [?]
[O]hDihOip) for an interval [a, b] in a model M .
That means that there exists an interval [c, d] such that [a, b]RO [c, d] and that (i) M, [c, d]  hOi>, and thus there exists a point e > d, and (ii) M, [c, d]  [O]hDihOip.
The interval [b, e] is such that [c, d]RO [b, e], and thus, by (ii), it satisfies hDihOip.
Therefore, there exists an interval [f, g] such that [b, e]RD [f, g], and a p-interval [h, i] with [f, g]RO [h, i].
Since h > b, we conclude that M, [a, b]  hLip.
hLip [?]
hBi[D]hBihDihBip.
Suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
Thus, there exists an interval [c, d] in M such that b < c and M, [c, d]  p. It can be easily checked that [a, b]RB [a, c].
We show that [a, c] satisfies [D]hBihDihBip.
First, every interval [e, f ], with [a, c]RD [e, f ] is such that e < c. Let us consider the interval [e, d].
First, we observe that [e, f ]RB [e, d] holds.
Moreover, by the density of M , there exists a point d0 , with c < d0 < d, such that [e, d]RD [c, d0 ] holds and [c, d0 ] satisfies hBip.
Thus, M, [e, f ]  hBihDihBip, hence the thesis.
Now, suppose that M, [a, b]  hBi[D]hBihDihBip for an interval [a, b] in a model M .
That means that there exists a point c > b such that the interval [a, c] satisfies [D]hBihDihBip.
As a particular instance of the latter formula, every interval [e, f ] such that b < e < f < c (the existence of such an interval [e, f ] is guaranteed by the density of M ) must satisfy hBihDihBip which  *  *  means that there exists a point g > f such that M, [e, g]  hDihBip, which implies, in turn, the existence of two points h, i, with e < h < i < g, such that M, [h, i]  p. Since h > b, we have that M, [a, b]  hLip.
hLip [?]
hOi[E]hOihOip.
Suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
Thus, there exists an interval [c, d] in M such that b < c and M, [c, d]  p. Consider the interval [a0 , c], with a < a0 < b (the existence of such a point a is guaranteed by the density of M ).
It holds that [a, b]RO [a0 , c].
We prove that M, [a0 , c]  [E]hOihOip.
Indeed, for every interval [e, c], with [a0 , c]RE [e, c], by the density of M , there exist a point f , with e < f < c, and a point g, with c < g < d, such that the interval [f, g] satisfies hOip as [f, g]RO [c, d].
Thus, M, [e, c]  hOihOip, M, [a0 , c]  [E]hOihOip, and M, [a, b]  hOi[E]hOihOip.
Now, suppose that M, [a, b]  hOi[E]hOihOip for an interval [a, b] in a model M .
That means that there exists an interval [c, d] such that [a, b]RO [c, d] and M, [c, d]  [E]hOihOip.
As a particular instance, the interval [e, d], for some e such that b < e < d (the existence of such a point e is guaranteed by the density of M ), satisfies hOihOip, that implies the existence of an interval [f, g], with f > e(> b), satisfying p. It immediately follows that M, [a, b]  hLip.
hLip [?]
hOi(hOi> [?]
[O]hBihOihOip).
Suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
Thus, there exists an interval [c, d] in M such that b < c and M, [c, d]  p. Consider the interval [a0 , c], with a < a0 < b (the existence of such a point a is guaranteed by the density of M ).
This interval is such that [a, b]RO [a0 , c] and it satisfies: - hOi>, as [a0 , c]RO [b, d], and - [O]hBihOihOip, as every interval [e, f ], with [a0 , c]RO [e, f ], is such that e < c < f .
Thus, the interval [e, c] is such that [e, f ]RB [e, c], and, by the density of M , there exists an interval [g, h] such that [e, c]RO [g, h] and [g, h]RO [c, d].
This implies M, [e, c]  hOihOip, which, in turn, implies M, [a0 , c]  [O]hBihOihOip.
Hence, M, [a0 , c]  hOi> [?]
[O]hBihOihOip and M, [a, b]  hOi(hOi> [?]
[O]hBihOihOip).
Now, suppose that M, [a, b]  hOi(hOi> [?]
[O]hBihOihOip) for an interval [a, b] in a model M .
That means that there exists an interval [c, d] such that and that (i) [a, b]RO [c, d], (ii) M, [c, d]  hOi>, and thus there exists a point f > d, and (iii) M, [c, d]  [O]hBihOihOip.
By the density of M , there exists a point e, with b < e < d. The interval [e, f ] is such that [c, d]RO [e, f ], and thus, by item (iii) above, it satisfies hBihOihOip, which implies the existence of an interval [g, h], with g > e(> b), satisfying p. It immediately  *  follows that M, [a, b]  hLip.
hLip [?]
hOi[O][L]hOihOip.
Suppose that M, [a, b]  hLip for an interval [a, b] in a model M .
Thus, there exists an interval [c, d] in M such that b < c and M, [c, d]  p. Consider the interval [a0 , c], with a < a0 < b (the existence of such a point a is guaranteed by the density of M ).
This interval is such that [a, b]RO [a0 , c] and it satisfies [O][L]hOihOip.
Indeed, every interval [e, f ], with [a0 , c]RO [e, f ], is such that e < c. Thus, every interval [g, h], with [e, f ]RL [g, h], satisfies hOihOip (by the density of M , there exist g < i < h and c < j < d such that both [g, h]RO [i, j] and [i, j]RO [c, d] hold).
Thus, we have that M, [a0 , c]  [O][L]hOihOip, which implies M, [a, b]  hOi[O][L]hOihOip.
Now, suppose that M, [a, b]  hOi[O][L]hOihOip for an interval [a, b] in a model M .
That means that there exists an interval [c, d] such that [a, b]RO [c, d] and M, [c, d]  [O][L]hOihOip.
As a particular instance, by the density and the unboundedness of M , there exists an interval [e, f ], such that b < e < d < f and M, [e, f ]  [L]hOihOip, which, in its turn, together with the density assumption, implies the existence of an interval [g, h], with b < g < h < e, that satisfies hOihOip.
Thus, there exists an interval [i, j], with i > g(> b), which satisfies p. It immediately follows that M, [a, b]  hLip.
Last case of the proof of Lemma 2.
Proof: If -a < b and -a0 < b0 , then the following facts hold: (i) b > 0 (otherwise, -a < b <= 0 would hold, which implies a > 0 >= b, contradicting the fact that [a, b] is an interval), (ii) |b| = b (this follows directly from b > 0), and (iii) |a| < |b| (otherwise, |a| >= |b| = b would hold, which implies either a >= b, contradicting the fact that [a, b] is an interval, or -a >= b, contradicting the hypothesis that -a < b).
Now, we distinguish the following sub-cases.
* If X = O, then [c, d] is such that c < a < d < b.
We distinguish the cases below.
- If -c < d, then take some d0 and c0 such that |a0 | < d0 < |b0 | = b0 and -d0 < c0 < |a0 | = -c (the existence of points c0 , d0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If -c = d, then take some d0 such that |a0 | < d0 < |b0 | = b0 and c0 = -d0 (the existence of such a point d0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If -c > d, then take some d0 and c0 such that |a0 | < d0 < |b0 | = b0 and c0 < -d0 (the existence of points c0 , d0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
*  *  *  If X = E, then [c, d] is such that c < a < b = d. We distinguish the following cases.
- If -c < d, then take d0 = b0 and some c0 such that -d0 < c0 < a0 (the existence of such a point c0 is guaranteed by the density of R).
The interval [c0 , d0 ] is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If -c = d, then take d0 = b0 and c0 = -d0 (= -b0 < a0 ).
The interval [c0 , d0 ] is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
- If -c > d, then take d0 = b0 and any c0 < -d0 (= -b0 < a0 ).
The interval [c0 , d0 ] is such that [a0 , b0 ]RE [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If X = B, then [c, d] is such that a = c < b < d. Notice that -d < -b < a = c. Then, take c0 = a0 and any d0 > b0 .
It holds that c0 = a0 > -b0 > -d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RB [c0 , d0 ] and [c, d]Z[c0 , d0 ].
If X = O, then [c, d] is such that a < c < b < d. Notice that -d < -b < a < c. Then, take some c0 such that a0 < c0 < b0 (the existence of such a point c0 is guaranteed by the density of R) and any d0 > b0 .
It holds that c0 > a0 > -b0 > -d0 .
The interval [c0 , d0 ] is such that [a0 , b0 ]RO [c0 , d0 ] and [c, d]Z[c0 , d0 ].
Proof of Lemma 3.
Proof: Let f 0 : {x [?]
R | x <= 1} - {x [?]
R | x <= 0} and f 00 : {x [?]
R | x > 1} - {x [?]
R | 0 < x < 1} be defined as f 0 (x) = x - 1 and f 00 (x) = 1 - x1 , respectively.
Clearly, f 0 and f 00 are bijective functions.
Moreover, it is easy to verify that f 0 and f 00 are such that (i) they are monotonically increasing and (ii) f 0 (x) < x (resp., f 00 (x) < x) for every x [?]
domf 0 (resp., x [?]
domf 00 ).
Observe that domf 0 and domf 00 (resp., codomf 0 and codomf 00 ) partition domf (resp, codomf ).
Clearly, f is well defined.
To verify that it is an injection, consider x, x0 [?]
R, with x 6= x0 .
If x, x0 <= 1 (resp., x, x0 > 1), it holds f (x) = f 0 (x) 6= f 0 (x0 ) = f (x0 ) (resp., f (x) = f 00 (x) 6= f 00 (x0 ) = f (x0 )), as f 0 (resp., f 00 ) is an injection; if x <= 1 and x0 > 1, then it holds f (x) = f 0 (x) 6= f 00 (x) = f (x0 ), as the codomains of f 0 and f 00 are disjoint sets.
Surjectivity of f follows from the surjectivity of f 0 and f 00 .
Thus f is bijection.
To prove that it is monotonically increasing, consider x, x0 [?]
R, with x < x0 .
If x, x0 <= 1 (resp., x, x0 > 1), it holds f (x) < f (x0 ), as f 0 (resp., f 00 ) is monotonically increasing; if x <= 1 and x0 > 1, then it holds f (x) < f (x0 ), as every element in the image of f 0 is less than every element in the image of f 00 .
Finally, from the fact that f 0 (x) < x for every x [?]
R, with x <= 1, and that f 00 (x) < x for every x [?]
R, with x > 1, it follows f (x) < x for every x [?]
R.
Hypothetical Reasoning From Situation Calculus to Event Calculus Alessandro Provetti  CIRFID - Universita di Bologna Via Galliera 3/a, Bologna I-40121 ITALY provetti @cird unibo it :  Abstract  Pinto and Reiter have argued that the Situation Calculus, improved with time handling axioms, subsumes the features of linear time temporal formalisms such as Event Calculus and Interval Logic.
In this note we nd answers to some of their remarks by showing a modied version of Event Calculus that seems to match Situation Calculus handling of hypothetical reasoning and projection.
Further consideration on semantics and expressive power of Event Calculus put forward by Pinto and Reiter are discussed in the light of recent proposal for an unifying semantics for languages for time and actions.
1 Introduction  In their very recent production, Reiter and Pinto7, 8] have introduced an upgraded version of Situation Calculus (SC) which makes it possible: to represent dates and time-stamp actions and situations which actually occurred in the world to represent actual situations as a branch of the tree of possible developments of things that Situation Calculus handles.
This new features are obtained by adding new predicate denitions and introducing a new sort of constants for representing dates, a convenient ordering, and functions such as Start(action) or End(action), linking actions to their dates.
Pinto and Reiter argue that the improved version matches the so-called linear time formalisms, viz.
Allen's Interval Logic and the Calculus of Events(EC) of Kowalski and Sergot3], on their own ground: representing actions and change over time.
Nonetheless, the resulting Situation Calculus maintains intact its native characteristics(set out in 5]) of dealing with alternative, hypothetical Work done during author's stay at Computer Science Department of University of Texas at El Paso, which is gratefully acknowledged.
:  plans/sequences of actions and projecting their effects.
Another point raised by Pinto and Reiter is on semantics: they present a logic programming implementation of a subset of the formalism which enjoys a clear completion-based semantics, in contrast with EC relying on Negation as Failure.
In this paper it will be counter-argued that Situation Calculus specic -and indeed desirable- features are easily implementable in a linear-time formalism like Event Calculus.
In chapter 2 a simple version of EC is presented which departs from the original version criticized by Pinto et al.
but can be taken as representative of current versions of EC.
In chapter 3 new predicates are introduced for allowing reasoning about a ctional sequence of actions and projecting the value of uents.
This simulation can be either performed in the future, for exploring the result of alternative plans or starting from a date in the past, which allows for counterfactual reasoning.
In chapter 4 the declarative semantics aspect is discussed if an EC axiomatization is seen as a logic program, then the most common declarative semantics agree, yielding what is believed a clear semantics.
Indeed, a new semantics is proposed by translating EC axiomatizations to the language A of Gelfond and Lifschitz 1], which enjoys a semantics conceived for actions and change.
A translation from a domain description EC-style to one in A is proposed which maps also the closed-world assumption into the target axiomatization.
This technical result is kept for a full version of the paper, while it would be necessary to dene a similar translation from Pinto and Reiter's formalisms to A itself it will then result very interesting to compare the two axiomatizations and their models within the same language.
This approach is specular to that of Kartha in 2] on translating A to chosen nonmonotonic formalisms In the end, the author argues for a substantial equivalence of the two (improved) formalisms.
In the rest of the paper acquaintance with Situation Calculus and the semantics of Logic Programming is assumed.
2 The Event Calculus of the 90s  The Event Calculus has been proposed by Kowalski and Sergot 3] as a system for reasoning about time and actions in the framework of Logic Programming.
Event Calculus is based on an ontology of events, assumed as primitive.
These events are represented by means of constants that uniquely identify them.
The second ontology is that of uents 1, which represents descriptions of the reality being modeled.
A uent holds over time from the moment when an event initiates it, i.e.
the event makes it true in the world.
Events may also terminate, i.e.
make false in the world, uents.
The Event Calculus is based on forward default persistence: a uent holds over time until a terminating event is recorded.
Since the rst proposal, a number of improved formalization have steamed, in order to adapt the calculus to dierent tasks.
Hence, the reduced version of Shanahan in11] in presented, since it can be taken as a common-core denition embedded in the latest applications2.
Events are represented by sets of instantiations like the following: Happens(E1) Date(E1  T1) Act(E1 Unstack(B )) Notice that there are both event-tokens, labeled with the constants E1  E2 : : : and events-types named by Unstack, Stack etc.
The eect of an actiontype(its meaning) is understood by looking at the Initiates=Terminates axioms where it appears.
The denitions of Initiates and Terminates are for expressing domain knowledge.
A convenient example is the Block World, as both Shanahan and Pinto et al.
use it: Initiates(e On(x y))  Act(e Move(x y))  Initiates(e Clear(z ))  Act(e Move(x y)) Date(e t) HoldsAt(On(x z ) t) z 6= y T erminates(e Clear(y))  Act(e Move(x y)) T erminates(e On(x y))  Act(e Move(x z )) z 6= y Elsewhere called properties or relationships.
This version is even more simplied, as it assumes events are recorded in the database in the same order as they happened in reality.
For discussing a fuller formalization, the reader is invited to consult late works of Sergot10] and Sripada13].
1 2  Starting from a database of events and a domain description by Initiates=Terminates the axioms of EC makes it possible to derive atoms:  Holds(F T ) which are understood as "uent F is true at time T".
Axiom ECI means that a uent holds at a certain time if an event happened earlier initiated the uent itself and there is no evidence in the database of the uent stopping to hold in the meantime.
In other words, in the interval between the initiation of the uent and the time the query is about, no terminating events must happen.
This is made sure by axiom ECII .
The forward default persistence rule is implemented by using Negation as Failure on Clipped in ECI.
(ECI ) HoldsAt(f t)  Happens(e) Initiates(e f ) Date(e ts ) ts < t not Clipped(ts  p t) (ECII ) Clipped(ts  f t)  Happens(e ) Terminates(e  f ) Date(e  t ) ts < t  t fit The predicates < and fi establish an ordering on events.
We stipulate that temporal constants T1  T2 T3 : : : are mapped on naturals, and that the ordering relations are also mapped on the same relations on naturals, thus inheriting their properties.
In chapter 3, an improved version of the axioms will be presented in order to deal with hypothetic events.
The hypothetic events have no timestamping, so that the problem of integrating the linear order of actual events and the order on those hypothetical is not addressed directly.
2.1 The Assumption Underlying Event Calculus  EC is a formalism based on negation-as-failure.
This device implements the implicit assumptions on the knowledge of the domain that are used by EC.
Techniques are available, viz.
explicit negation, for making these closure assumptions explicit.
Let us list these assumptions, taking advantage of the discussions in 9, 11]: It is assumed that no events occur other than those which are known to occur.
It is assumed that all the events are timestamped.
These two assumptions seems too strong for real applications such as database updates in fact, they are lifted in enriched versions of EC.
It is assumed that no types of events can aect a given uent other than those which are known to do so This assumption can be made explicit by resorting to classical negation with these axioms: :Initiates(e f )  not Initiates(e f )  :Terminates(e f )   not Terminates(e f ) This approach is semantically founded on the Answer Sets semantics of Gelfond and Lifschitz and, for matter or generality, won't be used in the rest of the paper.
It is assumed that uents persist until an event happen that inuence them.
Conversely, It is assumed that every uent has an explanation in terms of events.
That is, at least one initiating event is necessary for making a uent true.
This is particularly interesting for generating explanations of uents by abducing events11].
If observations on the value of uents can be introduced in the formalization, i.e.
HoldsAt updates are allowed, a transformation of the axioms is necessary for giving consistent answers, at cost of a loss of elegance Sripada13] presents a version of the calculus for accommodating such updates.
3 Hypothetical Reasoning in EC  In this section we dene new predicates (on top of those already existing) for performing projection of hypothetical sequences of actions.
The purpose is that eectively illustrated by Pinto and Reiter7]: By preserving the branching state property of the Situation Calculus, we can express and answer a variety of hypothetical queries, although counterfactuals cannot be expressed.
For example "At time Tp in the past, when you put A on B, could A have been put on C instead?"
can be simply expressed as: during(Tp  s) ^ actual(s)  possible(put(A C ) s): "If I had performed put(A C ), would F have been true?"
V holds(F do(put(A C ) Sp)) possible(put(A C ) Sp ): None of these features is possible in linear temporal logics.
We need the branching structure of the situation calculus, coupled with a linear time line in that branching structure.
In the following, the new axioms and a modied and enriched version of the old ones will be illustrated, so that to deal with the sample queries proposed.
3.1 The new predicates  The ideas motivating the new predicates denition are the following: to rewrite situation calculus axioms within EC, in order to carry out projection to provide a link between the point in time t where the simulation begins and the value of uents in the simulation.
That is, uents that are true at t are still true during the simulation as long as an event does not terminate them.
To this extent, the eect of the simulation depends from the time it starts to make it possible both to project in the future and to reason hypothetically about a sequence of actions to this extent, the eect of a simulation does not depend from the time it starts.
HypHolds  The new predicate HypHolds is the counterpart of Situation Calculus Holds and it is understood as follows: a) HypHolds(F E type T ) is true if -has E type been performed at time T - F would be true thereafter.
(EC 1) HypHolds(f Res(e type t))  MayHappen(e type t) Initiates(e type f t) (EC 2) HypHolds(f Res(e type t))  MayHappen(e type t) not Terminates(e type f t) HoldsAt(f t) Now the predicate is dened for an arbitrary sequence of actions performed starting from T : b) HypHolds(F Res(An  Res(: : : Res(A1  T ) : : :))) is true if -has the sequence of actions A1 : : :An been performed starting from T - then F would be true thereafter.
In practice T replaces S0 , thus linking the chain of actions to the starting point of the simulation.
(EC 3) HypHolds(f Res(e type s))  HypMayHappen(e type s) HypInitiates(e type f s) (EC 4) HypHolds(f Res(e type s))  HypMayHappen(e type s) HypHolds(f s) not HypT erminates(e type f s)  Starting the simulation with t = 0, where each uent is false (by NAF) is a way to study in insulation the net eect of a plan.
MayHappen  In order to ensure that an action(i.e.
a type of event) can be performed at a certain time or in a certain state of aairs, the predicate MayHappen and HypMayHappen are introduced: MayHappen(E type t)  HoldsAt(C1  t) ::: HoldsAt(Cn  t) For instance: MayHappen(Move(a b) t)  HoldsAt(Clear(b) t) For each MayHappen instantiation, a relative instantiation of HypMayHappen is made For instance: HypMayHappen(Move(a b) s)  HypHolds(Clear(b) s)  HoldsAt and Clipped  The modications to these predicates are not substantial, some folding operation has been carried out and the arity of Initiates and Terminates has been increased to accommodate the parameter time.
As far as it goes, this version is expected to give the same results as Shanahan's in terms of success of HoldsAt queries.
Initiates and Terminates  Also for these predicates duplication is necessary in order to handle both dates and situations.
The new denition of Initiates and HypInitiates are like in this example: Initiates(e On(x y) t)  Act(e Move(x y)) Date(e t)  Initiates(e Clear(z ) t)  Act(e Move(x y)) HoldsAt(On(x z ) t) Date(e t) z 6= y HypInitiates(Move(x y) On(x y) s) HypInitiates(Move(x y) Clear(z ) s)  HypHolds(On(x z ) s) z 6= y A similar transformation must be applied to the denition of Terminates.
3.1.1 The new predicates at work  The rst question addressed by Pinto and Reiter: "At time Tp in the past, when you put A on B, could A have been put on C instead?"
translates into the following: ?
; MayHappen(Put(A C ) Tp ) Conversely, the second example: "At time Tp in the past, when you put A on B, could A have been put on C instead?"
translates into: ?
; HypHolds(On(A C ) Res(P ut(A C ) Tp))  4 Comparing the Semantics  Pinto and Reiter7] have compared the standard "rst-order + circumscription" semantics with that of EC: One advantage of this is the clean semantics provided by our axiomatization, in contrasts to the event calculus reliance on the Negation as failure feature of logic programming, whose semantics is not well understood.
The argument is rather appropriate, EC has been natively dened within Logic Programming 3, 10, 4] and the use of negation as failure for implementing default persistence is somehow intrinsic to EC.
It is nonetheless the case to notice that the set of axioms described in this paper (PEC ) form together a stratied logic program in the sense of Apt et al.6], under the following stratication 3: <p = fHoldsAt HypHolds MayHappen HypMayHappen Initiates HypInitiatesg < fClipped T erminates HypTerminatesg < f< fig < fHappens Act Dateg On stratied programs the semantics common in literature hold a unique minimal model.
This is the case for Przymusinki's perfects models semantics6] by taking the partition as an ordering over predicates the same goes for Apt et al.
6] iterated Fixpoint technique and for Gelfond and Lifschitz's Stable Models semantics.
The resulting, minimal and unique model of these semantics should carry an unambiguous meaning for EC4 .
Taking <p as a circumscribing policy, the perfect model results in a model of prioritized circumscription CIRC (PEC  <p ) for the theory PEC  it may be rewarding to compare the respective circumscriptive 3 This stratication is in fact redundant, but ts better intuition on layers of predicates.
To the extent of dening the declarative semantics predicates < and can be dened as a set of ground instances on time constants.
4 Notice in passing that Conjecture 1 of Apt et al.
in 6] ascribes to stratied programs the completeness of SLDNF resolution.
models of two intuitively equivalent theories in EC and SC.
This has not yet been carried out to author's knowledge.
4.1 Alternative Semantics  Beside the stratication-based semantics discussed above, there have been eorts to provide alternative semantics for event calculi a rst attempt is probably that of Shanahan12], who discussed a characterization in terms of circumscription.
In this section it is proposed an alternative approach by translation of Event Calculus formalizations to the language A of Gelfond and Lifschitz1], which enjoys a declarative semantics purported to actions and uents..
The translation  transforms a set of event descriptions in terms of Happens, Date etc.
into a correspondent set of A axioms.
The result sought after is soundness and completeness of the translation of an EC domain description D and of a query ?
; HoldsAt(F T ) into an domain description  (D) and a v-proposition F after CD (T ) such that:  D `EC HoldsAt(F T ) ()  (D) j=A F after CD (T ) where the chronicle CD (T ) is the list of actions happened before T in D and ordered by means of their dates.
The proof of this proposition will be included in the full version of paper.
The advantages of the translation are twofold: EC is given a new semantics and, in principle, at least a signicant class of A axiomatizations might be eectively computed in Prolog by dening a reverse translation to EC programs.
As soon as a similar translation from extended SC to A will become available, it will be possible to compare the two languages within the same semantical framework.
5 Conclusion  Similarities and dierences between Event Calculus and Situation Calculus have been subject of much attention in the latest literature4, 7, 8].
On the one hand, Pinto and Reiter have successfully implemented the treatment of time into SC thus matching the results obtainable with EC.
This work, on the other hand, has shown an improved version of EC which performs hypothetical reasoning on the eect of actions, one of the features that motivated Situation Calculus at its birth5].
Far this undertake from being nished, the author argues for a substantial equivalence of the two formalisms on the ground of expressive power, clear semantics and computational properties.
As for exibility, extended versions of Event Calculus existing in the literature for dealing with compound events, temporal granularities and continuous processes are quite encouraging, as well as applications to abductive planning, deductive databases and process modeling in areas such as engineering and Law.
As for elegance, tastes probably matter.
The present author feels easier at Event Calculus because of a more intuitive ontology of events and dates rater than actions, situations and dates5 , because of a plain computational value of the axiomatization and because the closed-world based semantics need not careful metatheoretical specications(circumscription) to yield the expected results.
This is not to say that all the aws of EC Pinto and Reiter point to can be easily xed.
As an instance, the aim to provide names for intervals of time bounded by events partially known has resulted in the rst formalization of EC allowing unintended models, as shown in 7].
The quest for improving EC is helped by such criticisms, as long as they recognize the long way EC has gone since 1986.
Acknowledgments  My thanks to Michael Gelfond, Chitta Baral, Stefania Costantini, Gaetano Lanzarone, Paulo Azevedo and Angelo Montanari.
References  1] Michael Gelfond and Vladimir Lifschitz.
Representing Actions and Change by Logic Programs.
In The Journal of Logic Programming., Vol.
17(2,3,4),november 1993. pages 301-355.
2] G. Neelakantan Kartha.
Soundness and Completeness Theorems for Three Formalizations of Action.
Proc.
of IJCAI'93 Conference, 1993. pages 724{729.
3] Robert Kowalski and Marek Sergot.
A Logicbased Calculus of Events.
New Generation Computing, volume 4 pages 67{95.
Ohmsha Ltd and Springer Verlag, 1986 4] Robert Kowalski.
Database Updates in the Event Calculus.
Journal of Logic Programming, volume 12, June 1992, pages 121{146.
5] John McCarthy and Patrick Hayes.
Some philosophical problems from the standpoint of articial intelligence.
In B. Meltzer and D. Michie, editors, Machine Intelligence, volume 4, pages 463{ 502.
Edinburgh University Press, Edinburgh, 1969.
6] Jack Minker, editor.
Foundations of Deductive databases and Logic Programming.
Morgan Kaufmann Publ., 1988.
7] Javier Pinto and Raymond Reiter.
Adding a Time Line to the Situation Calculus.
Working Papers of Common Sense '93, The second AAAI symposium on logical formalizations of common sense reasoning.
Austin(Tx), January 1993.
See 9] for a discussion on the ontologies of such formalisms 5  8] Javier Pinto and Raymond Reiter.
Temporal Reasoning in Logic Programming: A Case for the Situation Calculus.
Proceedings of ICLP'93 Conference.
Budapest, June 1993.
9] Alessandro Provetti.
Action and Change in Logic Programming: Event Calculus, Situation Calculus and A .
Manuscript.
Spring 1993.
10] Marek J. Sergot.
(Some topics in) Logic Programming in AI.
Lecture notes of the GULP advanced school on Logic Programming.
Alghero, Italy, 1990.
11] Murray P. Shanahan.
Prediction is Deduction but Explanation is Abduction.
Proc.
of IJCAI'89 Conference.
Detroit, 1989. pages 1055{1050.
12] Murray P. Shanahan.
A Circumscriptive Calculus of Events.
Imperial College Dept.
of Computing Technical Report.London, 1992.
13] Sury Sripada.
Temporal Reasoning in Deductive Databases.
PhD Thesis in Computing.
Imperial College, London, 1991.
A presentation of this work can be found in the Proc.
of IJCAI'93, pages.
860{865.
Relaxation of Temporal Planning Problems * Martin C. Cooper  Frederic Maris  Pierre Regnier  IRIT University of Toulouse Toulouse, France {cooper, maris, regnier}@irit.fr  Abstract--Relaxation is ubiquitous in the practical resolution of combinatorial problems.
If a valid relaxation of an instance has no solution then the original instance has no solution.
A tractable relaxation can be built and solved in polynomial time.
The most obvious application is the efficient detection of certain unsolvable instances.
We review existing relaxation techniques in temporal planning and propose an alternative relaxation inspired by a tractable class of temporal planning problems.
Our approach is orthogonal to relaxations based on the ignore-all-deletes approach used in non-temporal planning.
We show that our relaxation can even be applied to nontemporal problems, and can also be used to extend a tractable class of temporal planning problems.
Temporal planning, relaxation, monotonicity.
I.
INTRODUCTION  Propositional non-temporal planning consists in finding a sequence of actions which transforms an initial state into a goal state.
Each action can be executed only if a set of conditions is satisfied and the effect of its execution is to instantaneously change the truth values of a subset of the propositional variables describing the state of the world.
It is well known that propositional planning is PSPACEComplete [2].
In temporal planning, actions have a duration, and the moments at which conditions must hold or at which changes to the values of state variables occur are not necessarily simultaneous.
Indeed, in the PDDL 2.1 temporal framework [17] [10], conditions can be imposed at the beginning, at the end or over the whole duration of an action, while effects can occur at the beginning or end of the action.
In this framework, the PSPACE-complete complexity of classical planning can be preserved only when different instances of the same action cannot overlap; if they can overlap, testing the existence of a valid plan becomes an EXPSPACE-complete problem [18].
II.
TEMPORAL PLANNING  We*study temporal propositional planning in a language based on the temporal aspects of PDDL2.1.
A fluent is a positive or negative atomic proposition.
As in PDDL2.1, we consider that changes to the values of fluents are instantaneous but that conditions on the value of fluents may be imposed over an interval.
An action a is a quadruple *  This work is supported by ANR Project ANR-10-BLAN-0210.
<Cond(a), Add(a), Del(a), Constr(a)>, where the set of conditions Cond(a) is the set of fluents which are required to be true for a to be executed, the set of additions Add(a) is the set of fluents which are established by a, the set of deletions Del(a) is the set of fluents which are destroyed by a, and the set of constraints Constr(a) is a set of constraints between the relative times of events which occur during the execution of a.
An event corresponds to one of four possibilities: the establishment or destruction of a fluent by an action a, or the beginning or end of an interval over which a fluent is required by an action a.
In PDDL2.1, events can only occur at the beginning or end of actions, but we extend this language so that events can occur at any time provided the constraints Constr(a) are satisfied.
Note that Add(a) [?]
Del(a) may be non-empty.
Indeed, it is not unusual for a durative action to establish a fluent at beginning of the action and destroy it at its end.
We can also observe that the duration of an action, the time between the first and last events of the action, does not need to be explicitly stored.
We use the notation a - f to denote the event that action a establishes fluent f, a - !f to denote the event that a destroys f, and f |- a and f -| a, respectively, to denote the beginning and end of the interval over which a requires the condition f. If f is already true (respectively, false) when the event a - f (a - !f) occurs, we still consider that a establishes (destroys) f. We use the notation t(E) to represent the time in a plan at which an event E occurs.
For a given action a, let Events(a) represent the different events which constitute its definition, namely (a - f) for all f in Add(a), (a - !f) for all f in Del(a), (f |- a) and (f -| a) for all f in Cond(a).
The definition of an action a includes constraints Constr(a) on the relative times of events in Events(a).
As in PDDL2.1, we consider that the length of time between events in Events(a) is not necessarily fixed and that Constr(a) is a set of interval constraints on pairs of events, such as t(f -| a) - t(f |- a) [?]
[a, b] for some constants a,b.
We use [aa(E1,E2), ba(E1,E2)] to denote the interval of possible values for the relative distance between events E1,E2 in action a.
A fixed length of time between events E1,E2 can be modeled by setting aa(E1,E2) = ba(E1,E2) and open-ended intervals by setting aa(E1,E2) = -[?]
or ba(E1,E2) = [?].
We now introduce two basic constraints that all temporal plans must satisfy.
In general a plan may contain multiple instances of the same action which we can represent by a multi-set A. inherent constraints: [?]a[?
]A, a satisfies Constr(a), i.e.
[?
]E1,E2 [?]
Events(a), t(E1) - t(E2) [?]
[aa(E1,E2), ba(E1,E2)].
contradictory-effects constraints: [?]ai,aj[?
]A, for all positive fluents f [?]
Del(ai) [?]
Add(aj), t(ai - !f) [?]
t(aj - f).
i [?]
j, Add(ai) [?]
Add(aj) [?]
S = [?
], i.e.
no fluent of S can be established by two distinct actions of A.
Definition 1.
A temporal planning problem <I,A,G> consists of a set of actions A, an initial state I and a goal G, where I and G are sets of fluents.
If a set of actions is EU relative to the set of sub-goals (recursively defined as the minimum set of fluents which belong to G or to the conditions of some action which establishes a sub-goal) of a problem, then we can determine in polynomial time a set of actions which are necessarily present in a temporal plan.
In general, other actions may be required to re-establish fluents which were present in I but have been destroyed by another action.
There also remains the problem of determining how many times each action must occur and then scheduling these action-instances in order to produce a valid temporal plan.
These problems can be solved in polynomial time if we also impose monotonicity of fluents [6].
Definition 2.
P = <A',t>, where A' is a multi-set of actions {a1,...,an} and t is a real-valued function on Events(A') (the union of the multisets Events(a) for a [?]
A'), is a (temporal) plan for the problem <I,A,G> if (1) each element of A' is an instance of an action in A, (2) P satisfies the inherent and contradictory-effect constraints on A'; and when P is executed (i.e.
fluents are established or destroyed at the times given by t) starting from the initial state I: (3) [?
]ai [?]
A', each f [?]
Cond(ai) is true when it is required, (4) all goals g [?]
G are true at the end of the execution of P. (5) P is robust under infinitesimal shifts in the starting times of actions.
Definition 4.
A fluent f is -monotone if, after being destroyed f is never re-established in any temporal plan.
A fluent f is +monotone if, after having been established f is never destroyed in any temporal plan.
A fluent is monotone if it is either + or -monotone.
A plan P is minimal if no subset of P is a valid plan.
Condition (5) means that we disallow plans which require perfect synchronization between different actions.
This condition can be imposed within PDDL2.1 [11].
We require that in all plans fluents are established strictly before the beginning of the interval over which they are required.
The only exception to this rule is when a fluent f is established and required by the same action a.
We allow the possibility of perfect synchronization within an action, which means that we can have t(a - f) = t(f |- a).
Similarly, fluents can only be destroyed strictly after the end of the interval over which they are required.
The only exception to this rule is when a fluent f is required and destroyed by an action a, in which case we can have t(f -| a) = t(a - !f).
A temporal planning problem <I,A,G> is positive if there are no negative fluents in the conditions of actions nor in the goal G. It is well known that any planning problem can be transformed into an equivalent positive problem in linear time [13].
Thus, in this paper, we only consider positive temporal planning problems <I,A,G>.
By this assumption, G and Cond(a) (for any action a) are composed of positive fluents.
By convention, Add(a) and Del(a) are also composed exclusively of positive fluents.
The initial state I, however, may contain negative fluents.
III.
EU MONOTONE PLANNING  In this section, we introduce the notions of establisheruniqueness and monotonicity of fluents.
Together, these two conditions are sufficient for the existence of a polynomialtime algorithm for temporal planning [6].
Establisheruniqueness is similar to post-uniqueness in SAS+ planning [14] restricted to Boolean variables.
Definition 3.
A set of actions A={a1,...,an} is establisherunique (EU) relative to a set of positive fluents S if for all  Example 1: In fairly obvious contexts, the fluents alive or brand-new are -monotone, whereas the fluents dissolved, cooked, graduated, born and extinct are all +monotone.
If A is a set of actions, we use the notation Del(A) to represent the union of the sets Del(a) ([?]
a [?]
A).
Add(A), Cond(A), Constr(A) are defined similarly.
The following lemma follows trivially from Definition 4.
Lemma 1.
If f [?]
Add(A) [?]
Del(A), then f is both -monotone and +monotone.
We now introduce three other types of constraints.
The -authorisation (resp, +authorisation) constraint is applied only to -monotone (resp, +monotone) positive fluents f, whereas the causality constraint is applied to all monotone fluents.
-authorisation constraints on the positive fluent f: for all ai[?
]aj [?]
A, if f [?]
Del(aj) [?]
Cond(ai), then t(f -| ai) < t(aj - !f); for all ai [?]
A, if f [?]
Del(ai) [?]
Cond(ai), then t(f -| ai) <= t(ai - !f).
+authorisation constraints on the fluent f: [?]ai,aj[?]
A, if f[?]
Del(aj)[?
]Add(ai), then t(aj - !f) < t(ai - f).
causality constraints on the positive fluent f: for all ai[?
]aj [?]
A, if f [?]
(Cond(aj) [?]
Add(ai))\I, then t(ai - f) < t(f |- aj); for all ai [?]
A, if f [?]
(Cond(ai) [?]
Add(ai))\I then t(ai - f) <= t(f |- ai).
If A is EU relative to the set of sub-goals, all sub-goals are monotone and all sub-goals in I are -monotone, then the temporal planning problem <I,A,G> is equivalent to solving the STP[?]
(Simple Temporal Problem with disequality constraints) composed of the inherent, contradictory-effect, authorisation and causality constraints [6], and can hence be  solved in polynomial time [15].
It is clearly polynomial-time to detect whether all actions are EU.
On the other hand, the very general definition of monotonicity of fluents implies that this is not the case for determining whether fluents are monotone.
Indeed, determining whether a fluent is monotone is PSPACE-hard if overlapping instances of the same action are not allowed in plans and EXPSPACE-complete otherwise [6].
We will return to the detection of monotonicity later in this paper.
However, this is not an issue for the definition of a relaxation, since it is relatively easy to construct a relaxed instance in which all fluents are monotone.
For example, Lemma 1 tells us that eliminating f from Del(a) for all a renders f monotone.
In the next section we describe a stronger form of relaxation which allows us to retain the destruction of fluents.
IV.
TEMPORAL RELAXATION  We first show that the standard form of relaxation used in propositional planning, consisting of simply ignoring all destructions of fluents and then trying to attain the goals by successively applying all relaxed actions whose conditions are satisfied [1], does not directly generalize to temporal planning.
An important aspect of temporal planning, which is absent from non-temporal planning, is that certain temporal planning problems, known as temporallyexpressive problems, require concurrency of actions in order to be solved [7].
A typical example of a temporallyexpressive problem is cooking: several ingredients must be cooked simultaneously in order to be ready at the same moment.
A subclass of temporally expressive problems, known as temporally-cyclic, require cyclically-dependent sets of actions in order to be solved [5].
A simple example of a temporally-cyclic problem is the building of two pieces of software by two different subcontractors, each needing to know the specification of the other program in order to complete their own program by building the interface with the other program.
We can model this by two durative actions, action A1 (A2) having spec1 (spec2) as an effect at its beginning and spec2 (spec1) as a condition at its end.
It is easy to see that neither action can occur in a plan without the other and that they must overlap.
The standard form of relaxation, as described above, would not be able to accept either of the two actions since it tries one action at a time.
Thus, certain proposed relaxations, although very useful in guiding heuristic search [9] [8], do not produce a valid relaxation for temporally cyclic problems.
Different solutions exist to get round the problem of temporal cycles.
For example, there is a polynomial-time algorithm to transform a temporally-cyclic problem into an equivalent acyclic one [5].
Other transformations have been proposed in the literature [16] [3] which also eliminate the possibility of temporal cycles, although this was not an explicitly-stated aim in the descriptions of these transformations: temporal cycles are avoided by decomposing durative actions into instantaneous actions denoting the start and end of the action.
Intermediate conditions can also be managed by splitting actions into component actions enclosed within an "envelope" action  [19].
In each case, ignoring deletes in the transformed problem is a valid relaxation.
In this section, we present an alternative form of relaxation, inspired by EU monotone planning, consisting of an STP[?]
instance which has a solution if the original temporal planning instance has a solution.
By applying the following simple rule until convergence we can transform (in polynomial time) any temporal planning problem P into a relaxed version P' which is EU relative to the set of sub-goals S: if a sub-goal fluent f is established by two distinct actions, then delete f from the goal G and from Cond(a) for all actions a.
As a consequence, f is no longer a sub-goal.
Clearly, P' is a valid relaxation of P. From now on we assume the temporal planning instance is EU relative to S. We denote by Aind the set of actions which have been detected as indispensable in all plans [4].
Establisheruniqueness implies that we can easily identify many such actions, in particular actions which establish sub-goals not present in the initial state I [6].
We cannot assume in the STP[?
], which we call TR (for Temporal Relaxation), that a single instance of each action will be sufficient.
For each indispensable action a and for each event E [?]
Events(a), we introduce two variables tfirst(E), tlast(E) representing the times of the first and last occurrences of event E in the plan.
The constraints of TR include versions of the internal, contradictory-effects, authorization and causality constraints (which we give below) together with the obvious intrinsic constraint: [?]a[?
]Aind, for all events E [?]
Events(a), tfirst(E) <= tlast(E).
We make the assumption that no two instances of the same action can overlap, to conserve the PSPACE complexity of classical planning [18].
Under this assumption, we know that for E1,E2 [?]
Events(a), the first occurrences of E1,E2 in a plan correspond to the same instance of action a.
A similar remark holds for the last occurrences of E1,E2.
This means that we can apply in TR each inherent constraint in Constr(a) independently to the values of tfirst(E) and tlast(E) (E [?]
Events(a)).
inherent constraint: [?]a[?
]Aind, [?]
E1,E2 [?]
Events(a), tfirst(E1) - tfirst(E2) [?]
[aa(E1,E2), ba(E1,E2)] and tlast(E1) - tlast(E2) [?]
[aa(E1,E2), ba(E1,E2)].
The contradictory-effects constraints in TR are as follows: contradictory-effects constraints: [?]ai,aj[?
]Aind, for all positive fluents f [?]
Del(ai) [?]
Add(aj), tL1(ai - !f) [?]
tL2(aj - f), [?
]L1,L2 [?]
{first,last}.
For each positive fluent f which is known to be  -monotone (resp, +monotone), we apply in TR the  following modified version of the -authorisation constraints (resp, +authorisation constraints):  -authorisation constraints on f: [?]
ai[?
]aj [?]
Aind, if f [?]
Del(aj)  [?]
Cond(ai), then tlast(f -| ai) < tfirst(aj - !f); for all ai [?]
Aind, if f [?]
Del(ai) [?]
Cond(ai), then tlast(f -| ai) <= tfirst(ai - !f).
+authorisation constraints on f: [?]ai,aj[?]
Aind, if f [?]
Del(aj) [?]
Add(ai) , then tlast(aj - !f) < tfirst(ai - f).
We check that every condition and every goal can be established, i.e.
Cond(Aind) [?]
I [?]
Add(A) and G [?]
I\Del(Aind) [?]
Add(A).
If not, we consider that the relaxation TR has no solution.
We also apply in TR the following causality constraints for each positive fluent f. causality constraints: [?]
ai[?
]aj [?]
Aind, if f [?]
(Cond(aj) [?]
Add(ai))\I then tfirst(ai - f) < tfirst(f |- aj); for all ai [?]
Aind, if f [?]
(Cond(ai) [?]
Add(ai))\I then t first(ai - f) <= t first(f |- ai).
We also apply the following goal constraints for each g [?]
G. goal constraints: [?]ai,aj[?
]Aind, if g [?]
Del(aj) [?]
Add(ai), then tlast(aj - !g) < tlast(ai - g).
Of course, the causality and goal constraints are necessary conditions for the existence of a plan only if the temporal planning instance is EU relative to (Cond(Aind)\I) [?]
(G[?]Del(A)).
But this follows from the fact that we assume that the instance is EU relative to the set of all sub-goals.
If for an action a [?]
Aind, all fluents in Add(a) are known to be monotone, then only one instance of a occurs in minimal plans [6]; hence, for each event E [?]
Events(a), we replace the two variables tfirst(E), tlast(E) in the above constraints by a unique variable t(E).
Clearly, TR is a valid relaxation since the constraints of TR must be satisfied by any valid plan.
We state this formally in the form of a proposition.
Proposition 1.
Let <I,A,G> be a temporal planning problem which is EU relative to its set of sub-goals S. Let Aind [?]
A be a set of indispensable actions, i.e.
actions which necessarily occur in all plans.
If the temporal relaxation TR has no solution, then the temporal planning problem <I,A,G> has no solution.
Under assumptions of establisher-uniqueness and monotonicity, TR is in fact a solution procedure for the tractable class described by Cooper et al.
[6].
Example 2: We now show that, even in non-temporal propositional planning, the temporal relaxation TR can detect unsolvable problems.
In this example, all actions are instantaneous and hence we present it in the form of a non temporal planning problem P with initial state I={j,m,d}, goal G={g} and the following three actions:  Buy: j, m - h, !d, !m Sell: h - m, !h Mort2: d, h - m, !d, g We can interpret the fluents as follows: j = I have a job, m = I have money, d = I am debt-free, h = I own a house, g = I have taken out a second mortgage.
For example, the action Buy is possible only if I have a job and money to put down a deposit on a house; the result is that I own a house but I am in debt and no longer have money.
The goal is to take out a second mortgage via the action Mort2.
This problem has no solution, but this fact is not detected by the standard relaxation of non-temporal planning problems consisting of ignoring all destructions of fluents.
To set up TR, we first determine the indispensable actions Aind = {Buy, Mort2} easily identified as indispensable by the rules given by Cooper et al.
[4] since they establish the subgoals h and g, respectively, not present in the initial state.
Observe that Aind is EU relative to the set of sub-goals.
The STP[?]
TR contains the constraints: tfirst(d -| Mort2) < tlast(d -| Mort2) and tfirst(d -| Mort2) = tfirst(h |- Mort2) by intrinsic and internal constraints in Mort2; tfirst(Buy - h) = tfirst(Buy - !d) by an internal constraint in Buy; tfirst(Buy - h) < tfirst(h |- Mort2) by the causality constraint on h; tlast(d -| Mort2) < tfirst(Buy - !d) by the -authorisation constraint, since d is -monotone (by Lemma 1).
This set of five constraints has no solution, from which we can deduce that P has no solution.
This example shows that temporal relaxation can be useful even in non-temporal planning problems.
Example 3: We now give a generic example involving the choice between two alternatives in which the temporal relaxation TR can detect unsolvable problems that cannot be detected by ignoring deletes.
This simple example consists of a non-temporal planning problem with initial state I={f}, goal G={g,h} and the following two actions: B: f - !f, g C: f - !f, h The fluents have many possible interpretations, including: f = I have a packet, g = I have sent the packet to Destination1, h = I have sent the packet to Destination2.
Clearly this problem has no solution, but this is not discovered by the ignoring-deletes relaxation (which cannot take into account the fact that I no longer have the packet once I have sent it somewhere).
On the other hand, TR detects unsolvability as follows.
Firstly, note that the problem is establisher-unique, both actions are indispensable (since they both establish fluents in G\I) and all fluents are both + and -monotone by Lemma 1.
Since all fluents in Add(B) and Add(C) are monotone, TR has a single variable t(E) for each event E. Since f is -monotone, TR contains the two authorisation constraints: t(f - C) < t(B - !f) and t(f - B) < t(C - !f).
TR also contains the inherent constraints t(f - B) = t(B - !f) and  t(f - C) = t(C - !f), which contradiction.
immediately leads to a  The above examples show that the EU monotone relaxation TR can be stronger than any relaxation based on ignoring deletes.
To see that ignoring deletes can be stronger than EU monotone relaxation, consider a problem in which the unique goal g is produced by a unique action a such that Cond(a) = {f} where the fluent f is produced by two distinct actions b and c. In the EU monotone relaxation, the fluent f is deleted from Cond(a), since it is established by two distinct actions, and the relaxed version of the problem is immediately solvable by a plan containing the single action a.
Ignoring deletes, on the other hand, can detect the unsolvability of the original problem in certain cases, for example, if Cond(b) and Cond(c) both contain fluents that are not in I [?]
Add(A).
An obvious application of temporal relaxation is the detection of indispensable actions [4].
Let P[-a] represent the planning problem P without a particular action a.
If the temporal relaxation of P[-a] has no solution, then we can conclude that a is an indispensable action for P. In the following sections we investigate other applications of temporal relaxation concerning the detection of different forms of monotonicity.
The basic idea is that if H is a hypothesis to be tested and H can be expressed as the conjunction of STP[?]
constraints, then we can add H to the constraints of the temporal relaxation TR to obtain an STP[?]
instance TR[H]: if TR[H] has no solution then H cannot be true in any solution to the planning problem.
In each case, the complexity of solving TR[H] is O(n3) time and O(n2) space, where n is the total number of events in the actions in A.
This follows almost directly from the fact that the set of authorisation, inherent, contradictory-effects and causality constraints are STP[?]
[15].
An instance of STP[?]
can be solved in O(n3+k) time and O(n2+k) space [12], where n is the number of variables and k the number of inequations (i.e.
constraints of the form xj - xi [?]
d).
Here, the only inequations are the contradictory-effects constraints of which there are at most n2, so k=O(n2).
V.  DETECTING MONOTONICITY OF FLUENTS  The detection of the monotonicity of fluents is essential for the recognition of instances of the polytime-solvable class of temporal planning problems described by Cooper at al.
[6].
To detect the +monotonicity of a fluent f it suffices to give a proof that f cannot be destroyed in a plan after being established.
Rules to provide such a proof, based on knowledge of the monotonicity of another fluent were given by Cooper et al.
[6].
In this section, we give a more general proof rule which involves solving an STP[?]
for each pair of actions a,b such that f [?]
Add(a) [?]
Del(b).
To try to prove that b cannot destroy f after a establishes f, we set up a relaxation TR[Before(a,f,b)] consisting of the temporal relaxation TR of the planning problem together with a single hypothesis constraint: Before(a,f,b) = {t first(a - f) < t last(b - !f)}.
To detect the -monotonicity of a fluent f we need to prove that f cannot be established in a plan after being destroyed.
In the corresponding STP[?]
TR[After(a,f,b)], the hypothesis is: After(a,f,b) = {tfirst(b - !f) < tlast(a - f)}.
Lemma 2.
Suppose that the set of actions A is EU.
If TR[Before(a,f,b)] has no solution for any pair of actions a,b [?]
A such that f [?]
Add(a) [?]
Del(b), then f is +monotone.
If TR[After(a,f,b)] has no solution for any pair of actions a,b [?]
A such that f [?]
Add(a) [?]
Del(b), then f is -monotone.
We can extend the polytime-solvable class of temporal planning problems described by Cooper et al.
[6], using temporal relaxation to detect monotonicity of fluents.
This new bigger class P is still polytime-solvable.
Each temporal relaxation can be solved in O(n3) time and O(n2) space, where n is the total number of events in the actions in A.
The number of temporal relaxations to solve, in order to prove that a temporal planning problem belongs to P, is proportional to the number of triples (a,f,b) such that a,b [?]
A and f [?]
Add(a) [?]
Del(b).
The number of pairs (f,b) such that b [?]
A and f [?]
Del(b) is bounded above by n. If A is establisher-unique, then there is at most one action that a [?]
A such that f [?]
Add(a).
Therefore, the complexity of recognizing P is O(n4) time and O(n2) space.
This can be compared with the O(n2) time and O(n) space complexity to recognize the subclass of P defined by simple rules for the recognition of monotonicity based on knowledge of the monotonicity of only one other fluent [6].
VI.
EXTENDING MONOTONICITY  In this section we introduce notions which extend the notion of monotonicity by considering only minimal plans, thus allowing us to define a larger tractable class of temporal planning than the class P described in the previous section.
Definition 5.
A fluent f is -monotone* if, after being destroyed f is never re-established in any minimal temporal plan.
A fluent f is +monotone* if, after having been established f is never destroyed in any minimal temporal plan.
A fluent is monotone* if it is either + or -monotone*.
Example 4.
To give an example of a monotone* fluent which is not monotone, consider the following planning problem in which all actions are instantaneous: Start_vehicle: e - f Drive: f - g, !f Unload: g - h with I = {e}, G = {h}.
The fluents represent that I have the ignition key (e), the engine is on (f), the destination has been reached (g) and that the package has been delivered (h).
There is only one minimal plan, namely Start_vehicle, Drive, Unload, but there is also the non-minimal plan Start_vehicle, Drive, Start_vehicle, Unload in which the fluent f is established, destroyed and then re-established.
Hence f is -monotone* but not -monotone.
We make the assumption in the remainder of this section that no two instances of the same action can overlap in a plan.
We cannot hope to detect all monotone* fluents in polynomial time since the detection of monotonicity itself is PSPACE-complete [6].
However, we will show that many monotone* fluents can be detected in polynomial time.
We begin with a simple lemma to detect certain +monotone* fluents.
Lemma 3.
If A is EU, then for all a [?]
A such that Add(a) [?]
Cond(A) = [?
], all f [?]
Add(a) [?]
(G\I) are +monotone*.
Proof: Any plan must contain an instance of action a since a establishes a goal f [?]
G\I and A is EU.
Since Add(a) [?]
Cond(A) = [?
], all instances of a except the last can be deleted without affecting the validity of a plan.
Thus a minimal plan contains exactly one instance of a.
Furthermore, no fluent f [?]
Add(a) [?]
(G\I) can be destroyed in a plan after being established by this last instance of a.
Hence f is +monotone*.
We say that an action-instance a usefully produces a fluent h during the execution of a plan if h was false just before being established by a.
We say that a usefully produces the required fluent h if a usefully produces h and either h [?]
G or the fluent h is the condition of some action c in the plan such that t(a - h) < t(h |- c).
We can now state the following general proposition.
Proposition 2.
Suppose that the set of actions A is EU relative to the set of sub-goals and let a [?]
A be the unique action that establishes sub-goal f. (a) If [?
]b [?]
A such that f [?]
Del(b), there is no minimal plan in which the last instance of b destroys f after a establishes f, and such that these instances of a and b usefully produce required fluents, then f is +monotone*.
(b) If [?
]b [?]
A such that f [?]
Del(b), there is no minimal plan in which the last instance of a establishes f after b destroys f, and such that these instances of a and b usefully produce required fluents, then f is -monotone*.
Proof: (a) Let P be a minimal plan in which the last instance of b destroys f after a establishes f. Then, by the hypothesis of the proposition, either the last instance of b in P or the first instance of a in P does not usefully produce a required fluent.
Hence P cannot be minimal, since we could delete the last instance of b or the first instance of a from P to leave another valid plan.
This contradiction shows that f is +monotone*.
The proof of case (b) is similar.
We now give a lemma which allows us to deduce one of the hypotheses of Proposition 2 and hence to deduce that a fluent f is +monotone* or that it is -monotone*.
To simplify the expression of the lemma, we suppose that there is a goalachieving action aG that must be executed at the end of all plans and such that Cond(aG)=G.
This simply means that goal fluents h do not need to be treated as special cases.
Lemma 4.
Suppose that A is EU relative to the set of subgoals S and let a [?]
A be the unique action that establishes fluent f [?]
S. Let b [?]
A be such that f [?]
Del(b).
(a) Let h [?]
S [?]
Add(a) and h' [?]
S [?]
Add(b).
If any of the following conditions hold, then there is no minimal plan P in which the last instance of b usefully produces the required fluent h' and destroys f after the first instance of a usefully produces the required fluent h and establishes f: (1) either one of h, h' belongs to I and is -monotone*.
(2) for all actions c,c' such that h [?]
Cond(c), h' [?]
Cond(c'), TR[Before(a,f,b) [?]
For(a,first,h,c) [?]
For(b,last,h',c')] has no solution, where For(x,L,h,c) = {tL(x- h) < tlast(h |- c)}.
(3) h' is monotone* and for all actions c,c' such that h [?]
Cond(c) and h' [?]
Cond(c'), TR[Before(a,f,b) [?]
Once(b) [?]
For(a,first,h,c) [?]
For(b,last,h',c')] has no solution, where Once(x) = {tfirst(E) = tlast(E) | E [?]
Events(x)}.
(b) Let h [?]
S [?]
Add(a) and h' [?]
S [?]
Add(b).
If any of the following conditions hold, then there is no minimal plan P in which the last instance of a usefully produces the required fluent h and establishes f after the first instance of b usefully produces the required fluent h' and destroys f: (1) either one of h, h' belongs to I and is -monotone*.
(2) for all actions c,c' such that h [?]
Cond(c), h' [?]
Cond(c'), TR[After(a,f,b) [?]
For(a,last,h,c) [?]
For(b,first,h',c')] has no solution.
(3) h is monotone* and for all actions c,c' such that h [?]
Cond(c) and h' [?]
Cond(c'), TR[After(a,f,b) [?]
Once(a) [?]
For(a,last,h,c) [?]
For(b,first,h',c')] has no solution.
Proof: (a) We suppose that A is EU relative to S, f [?]
S [?]
Add(a) [?]
Del(b), h [?]
S [?]
Add(a) and h' [?]
S [?]
Add(b).
Suppose that in a minimal plan P the last instance of the action b destroys f after f is established by a, that the first instance of a usefully produces the required fluent h and the last instance of b usefully produces the required fluent h'.
We will show, in each case, that there is a contradiction.
(1) If h [?]
I and h is -monotone*, then by the definition of -monotone*, no action can usefully produce h in P. A similar argument holds for h'.
(2) If TR[Before(a,f,b) [?]
For(a,first,h,c) [?]
For(b,last,h',c')] has no solution for all actions c,c' such that h [?]
Cond(c), h' [?]
Cond(c'), then it cannot be the case that the first instance of a usefully produces the required fluent h in P and the last instance of b usefully produces the required fluent h' in P. (3) If h' is monotone*, then only the first instance of b can usefully produce h' in P. Hence there can only be one instance of action b in P, since we assume that the last instance of b usefully produces h in P. The result follows from the same argument as in case (2) with the extra constraint Once(b) that there is only one instance of b in P. The proof of part (b) of the lemma is similar.
Example 5.
Consider the following EU temporal planning problem in which all actions are instantaneous: a: p - f, e b: p, e - g, !f c: f - p with I={f} and G={g}.
One interpretation of these actions and fluents is: Have_Engine_checked (a), Drive (b),  Take_Petrol (c), Have_petrol (p), At_garage (f), Engine_OK (e), Arrived (g).
The fluent f is not monotone since there is a plan c, a, b, a (in which the last action is clearly redundant) which establishes, destroys, and establishes f. However, f is -monotone* since in a minimal plan action a cannot usefully produce a fluent h [?]
Add(a) = {f, e} after action b has destroyed f. In the case h=f, this is by Lemma 4(b)(2): c is the only action such that f [?]
Cond(c), and TR[After(a,f,b) [?]
For(a,last,f,c)] has no solution.
(Note that since g, p are monotone by Lemma 1, we impose in TR that the actions b and c, which establish g and p, occur only once).
In the case h=e, this is by Lemma 4(b)(3) since e is monotone* (by Lemma 1) and TR[After(a,f,b) [?]
Once(a)] has no solution.
The notions +monotone* and -monotone* allow us to define a tractable class of temporal planning problems which is considerably larger than the EU monotone class given by Cooper et al.
[6].
We state without proof the following theorem, which follows immediately by the same argument as in the proof of the equivalent result for monotone (instead of monotone*) fluents [6], but this time considering only the minimal plans of a temporal planning problem.
Theorem 1.
Given a positive temporal planning problem <I,A,G>, define S' recursively to be the minimum set of fluents not in I which belong to G or to the conditions of some action which establishes a fluent of S'.
Let Aind [?]
A be the set of actions which establish at least one fluent in S'.
Suppose that all constraints in Constr(Aind) are interval constraints, the set of actions Aind is establisher-unique relative to S', each fluent in Cond(Aind) [?]
G is monotone* and each fluent in I [?]
(Cond(Aind) [?]
G) is -monotone*.
Let TR* be a version of TR in which the +authorisation (-authorisation) constraints are applied to +monotone* (-monotone*) fluents.
Then <I,A,G> has a temporal plan P if and only if (1) G [?]
(I\Del(Aind)) [?]
Add(Aind) (2) Cond(Aind) [?]
I [?]
Add(Aind) (3) all g [?]
G [?]
Del(Aind) [?]
Add(Aind) are +monotone* (4) TR* has a solution.
Theorem 2.
Let P* be the class of positive temporal planning problems <I,A,G> in which all constraints in Constr(A) are interval constraints, A is EU, all fluents in Cond(A) [?]
G are monotone* and all fluents in I [?]
(Cond(A) [?]
G) are -monotone*, where monotonicity* of all fluents can be deduced from Lemmas 1, 2, 3 and 4.
Then P* is tractable.
Proof: To prove tractability we have to give polynomialtime algorithms for both resolution and detection of temporal planning problems from the class P*.
We consider first the resolution of a temporal planning problem <I,A,G> in P*.
Since A is establisher unique, in linear time we can find the set Aind of actions described in the statement of Theorem 1.
By establisher-uniqueness, all actions in Aind are indispensable.
We can check conditions (1)-(3) of Theorem 1 in linear time.
We can then solve TR*, and hence <I,A,G>, in O(n3) time and O(n2) space [12], where n is the total number of events in the actions in A.
The number of temporal relaxations to solve, in order to prove that a temporal planning problem belongs to P*, is proportional to the number of septuplets (a,f,b,c,h,c',h') such that a,b,c,c' [?]
A, f [?]
Add(a) [?]
Del(b), h [?]
Add(a) [?]
Cond(c) and h' [?]
Add(b) [?]
Cond(c').
Assuming A is establisher-unique, the number of triples (a,f,b) satisfying a,b [?]
A and f [?]
Add(a) [?]
Del(b) is bounded above by n. The number of pairs (c,h) such that c [?]
A and h [?]
Cond(c) is again bounded above by n. Therefore, the number of relaxations to be solved is O(n3).
Each temporal relaxation can be solved in O(n3) time and O(n2) space [12].
It follows that the complexity of recognizing P* is O(n6) time and O(n2) space.
VII.
EXAMPLE OF EU MONOTONE* PLANNING Several examples of temporal planning problems from the chemical or pharmaceutical industries fall into the class of EU monotone problems [6].
However, as Examples 4 and 5 have shown, even in simple problems, fluents may be monotone* rather than monotone.
We conclude this paper with the description of a planning domain in which we need to detect monotone* fluents in order to prove tractability.
Available(c) MAKE-AND-TIME-CONCRETE(c)[30] At-factory(m) Fluid(c) !Available(c)  !Fluid(c) At-factory(m)  CLEAN(m)[4] Empty(m)  DRIVE(m,s)[6] !At-factory(m)  At(m,s) Delivered(m,c,s) Fluid(c)  Fluid(c) Empty(m)  At(m,s)  At-factory(m)  Fluid(c) USE(c)[4]  On(m,c) LOAD(m,c)[5] !Empty(m)  Used(c)  UNLOAD(m,c,s)[7]  On(m,c) !On(m,c)  Delivered(m,c,s)  The Temporal Cement Factory planning domain allows us to plan concrete mixing, delivery and use.
An action of duration 30 time units makes and times a batch of concrete which is fluid from time unit 3 to 30 (after which it sets).
At the same time, a concrete-mixer must be cleaned, in order for the concrete to be loaded, then driven to a building site, where it is unloaded.
The concrete must then be used while it is still fluid.
This set of actions A (illustrated in the plan shown in the figure) are all indispensable and the set of fluents appearing in the figure is the set S of sub-goals.
The initial state I and the goal G are given by: I = {At-factory(m), Available(c)}, G = {Delivered(m,c,s), Used(c)}  For all ai [?]
aj [?]
A, we have Add(ai) [?]
Add(aj) [?]
S = [?].
Hence, by Definition 3, the set of actions A is EU relative to S. We can immediately remark that no actions delete the fluents Used(c), Delivered(m,c,s) and At(m,s), and no actions add the fluents Available(c) and At-factory(m).
Thus, by Lemma 1, these fluents are both -monotone and +monotone.
By Lemma 2, we can deduce that On(m,c) is -monotone since the temporal relaxation TR[After(LOAD(m,c),On(m,c),UNLOAD(m,c,s))] has no solution.
Similarly, Fluid(c) is also -monotone by Lemma 2.
We can deduce that Empty(m) is -monotone* by Lemma 4(b)(2), because the relaxation detects that a=CLEAN(m) cannot establish f=Empty(m), after b=LOAD(m, c) destroys Empty(m), and also usefully establish h=Empty(m) for c= LOAD(m, c).
This is because in TR there is only one instance of LOAD(m, c) since Add(LOAD(m))={On(m,c)} and, as we have just seen, On(m,c) is monotone.
We can now apply Theorem 1, since A is EU, all fluents are monotone* and all fluents in I are -monotone*.
It follows that TR* is a solution procedure for this problem.
The problem <I,A,G> has a solution-plan, found by TR*, shown in the figure.
We represent non-instantaneous actions by a rectangle.
The duration of an action is given in square brackets after the name of the action.
Conditions are written above an action, and effects below.
Causality constraints are represented by bold arrows, and -authorisation constraints by dotted arrows.
This example can be extended to the case in which there are several sites, several batches of concrete and several mixers.
It is monotone and remains EU provided that the goals (via the fluents Delivered(m,c,s)) specify which mixer m is to deliver which batch c to which building site s. As another example involving monotone* fluents, consider the example given in a previous paper [6] involving the synthesis of a chemical using catalysers, where it was assumed that all catalysers are destroyed during the chemical reaction.
However, if any of the catalysers are not destroyed by the chemical reaction they catalyze, then they can theoretically be used many times.
Nevertheless, in a minimal plan, a second utilisation of a catalyser is not necessary and the rules given in Section V allow us to detect that all fluents are monotone*.
VIII.
CONCLUSION We have given a novel form of relaxation which can be used in temporal planning.
It can detect unsolvable problems which cannot be detected by relaxations based on ignoring all destructions of fluents.
It has applications in detecting indispensable actions and monotone fluents.
This led to an extended notion of mononicity which allowed us to define a large tractable class of temporal planning problems whose recognition algorithm is based on our temporal relaxation.
REFERENCES [1]  [2] [3]  [4]  [5]  [6] [7]  [8]  [9]  [10]  [11]  [12]  [13] [14]  [15] [16]  [17] [18] [19]  Bonet B., Loerincs G. and Geffner H. "A Robust and Fast Action Selection Mechanism for Planning", AAAI-97/IAAI-97, 714-719, 1997.
Bylander T. "The Computational Complexity of Propositional STRIPS Planning".
Artificial Intelligence, 69(1-2), 165-204, 1994.
Coles A., Fox M., Long D. and Smith A.
"Planning with Problems Requiring Temporal Coordination", Proc.
of AAAI 2008, 892-897, 2008. Cooper M.C., de Roquemaurel M. and Regnier, P. "A weighted CSP approach to cost-optimal planning", Artificial Intelligence Communications, 24(1) 1-29, 2011. Cooper M.C., Maris F. and Regnier P. "Managing Temporal Cycles in Planning Problems Requiring Concurrency", Computational Intelligence, 29(1), 111-128, 2013. Cooper M.C., Maris F. and Regnier, P. "Tractable monotone temporal planning", Proc.
ICAPS 2012.
Cushing W., Kambhampati S., Mausam and Weld D.S.
"When is Temporal Planning Really Temporal?
", IJCAI'2007, 1852-1859, 2007.
Do M.B.
and Kambhampati S. "Sapa: A Multi-objective Metric Temporal Planner", Journal of Artificial Intelligence Research 20, 155-194, 2003.
Eyerich P., Mattmuller R. and Roger G. "Using the Context-enhanced Additive Heuristic for Temporal and Numeric Planning", Proc.
ICAPS 2009.
Fox M. and Long D. "PDDL2.1: An Extension to PDDL for Expressing Temporal Planning Domains", Journal of Artificial Intelligence Research 20, 61-124, 2003.
Fox M., Long D. and Halsey K. "An Investigation into the Expressive Power of PDDL2.1", Proc.
of 16th European Conference on Artificial Intelligence, pp.
328-342, 2004.
Gerevini A. and Cristani M. "On Finding a Solution in Temporal Constraint Satisfaction Problems", Proc.
15th International Joint Conference on Artificial Intelligence, IJCAI'1997, 1460-1465, 1997.
Ghallab M., Nau D.S.
and Traverso P. Automated Planning: Theory and Practice, Morgan Kaufmann, 2004.
Jonsson P. and Backstrom C. "State-variable planning under structural restrictions: Algorithms and complexity", Artificial Intelligence, 100(1-2), 125-176, 1998.
Koubarakis M. "Dense Time and Temporal Constraints with [?
]", KR'1992, 24-35, 1992.
Long D. and Fox M. "Exploiting a graphplan framework in temporal planning", Proc.
13th International Conference on Automatic Planning and Scheduling, 52-61, 2003.
McDermott D. "PDDL, The Planning Domain Definition Language".
Technical Report, http://cs-www.cs.yale.edu/ homes/dvm/, 1998.
Rintanen J.
"Complexity of concurrent temporal planning", Proc.
17th ICAPS, 280-287, 2007.
Smith D.E.
"The Case for Durative Actions: A Commentary on PDDL2.1", Journal of Artificial Intelligence Research 20, 149-154, 2003.
Using Constrained Resolution for Abductive Temporal Reasoning Nicolas Chleq  INRIA Sophia-Antipolis BP 93 { 06902 Sophia Antipolis Cedex { France chleq@sophia.inria.fr  Abstract  We describe in this article an abductive procedure based on a constrained resolution principle.
The choice of constrained resolution is motivated by the whish to gain full advantage of using reified temporal logics.
For this purpose, it is interesting to deal eciently with temporal ordering and equality relation between instants.
The constrained resolution principle described here is a solution to this point.
It is an instance of the more general constrained resolution principle of H.J.
Burckert.
It also relies on the work done in the area of temporal constraint propagation.
For the purpose of temporal reasoning it is also necessary to cope with temporal persistency of known and deduced facts.
This point is solved by handling persistency in an abductive fashion.
1 Introduction  This article describes a resolution-based abductive procedure.
This procedure is based on works done in the area of abductive logic programming and uses a constrained resolution principle.
Such a resolution principle is necessary in order to be able to deal with any reified temporal logic based on instants.
For the purpose of this paper, we use it on a simple temporal logic based on a simple and nave ontology.
It is also suciently expressive for practical use, but this gain on expressiveness is due to an increased complexity of the language itself (more axioms), hence a more complex reasoning task.
The use of abduction in temporal reasoning has been motivated by 12].
This reasoning method is complementary to prediction as it allows to deal with persistency and produce explanation, while retaining a very intuitive form for causal rules eect if causes.
Abduction has also been applied to planning with temporal formalisms such as the Event Calculus 5, 10].
Most abductive procedure are based on resolution, and practical use of abduction relies on the feasibility of resolution based reasoning for temporal reasoning.
Though it is not necessary to argue again on the usefulness of a resolution principle, practical use of this method is not straightforward.
In particular, some features of the formul on which this method is applied can suer from great eciency problems.
Equality relation and self-resolving clauses are some examples of these problematic features.
Most of these problems are to be solved by adapted strategies and specialized inference rules.
A lot of work has been done on the combination of the resolution principle with some particular \algorithmic" theories: for example the Theory Resolution of Stickel 14], and the Constrained Resolution of Burckert 2].
In the next section, we begin by an informal presentation of a temporal logic.
This logic is used throughout this paper, and its features are representative of most reified temporal logics.
It also illustrates the need of a specialized resolution principle, which I describe as an instance of Burckert's one.
The rest of the paper is devoted to abductive reasoning, and focuses on the abductive procedure we developed as an extension of the abductive logic programming procedure described in 7].
2 Reified Temporal Logics  Reified temporal logics are sorted predicate calculi: one of the sorts is used for time points or time intervals.
A formal description of these logics is given in 13].
They are usually based on two primitive entities: instants as in McDermott's logic 9], or intervals as in Allen's one 1].
The basic construct h  ti of these logics associates a formula with a temporal entity t, this last one being either an instant or an interval depending on the kind of logic.
The intuitive meaning of this expression is that the formula is true at the instant denoted by the term t, or true throughout the interval denoted by t. These languages can express the truth of such-and-such proposition over time, they are hence good candidates for the expression of temporal knowledge.
2.1 A temporal logic  The logic we use is a two-sorted predicate calculus, where time is the sort of all expressions denoting time instants, and proposition is the sort of all terms associated with temporal entities.
It is based on in-  f]t1 t2] pg !
t1 < t2 f]t1 t2] pg !
begin(t1  p) f]t1 t2] pg !
end(t2  p) f]t1 t2] pg !
persist(t1  t2 p) persist(t1  t4 p) ^ (t1 fi t2 < t3 fi t4) !
persist(t2  t3 p) persist(t1  t3 p) ^ (t1 < t2 fi t3) !
true(t2  p) persist(t1  t2 p) ^ begin(t3  p) !
(t3 fi t1 ) _ (t2 < t3 ) persist(t1  t2 p) ^ end(t3 p) !
(t3 < t1) _ (t2 fi t3) begin(t1  p) !
(8t2 > t1 persist(t1  t2 p) _ (9t3 (t1 < t3 < t2 ) ^ end(t3  p))) begin(t1  p) ^ persist(t1  t2 p) ^ end(t2 p) !
f]t1 t2] pg  ( A1 ) (A2 ) (A3 ) (A4 ) (A5 ) (A6 ) (A7 ) (A8 ) (Ap ) (A9 )  Figure 1: Some axioms of the temporal logic.
stants as the primitive temporal entity, and intervals are written with two instants as their lower and upper bounds.
The simplest expression associates a proposition with an instant or an interval: ft P g means that P holds at time t, and f]t t ] P g means that P holds throughout the interval ]t t ].
Instants are taken from a set that we want to be dense, so that we are able to speak of an instant between any two other instants: the set of rational numbers suits our need.
We divide the set of propositions into the ephemeral ones, used to describe \instantaneous" phenomena, and durable ones.
Propositions of the first class are always associated with instants by expressions of the form ft pg, while propositions of the second type are associated with intervals by expressions of the form f]t t ] pg.
The set of durable propositions can be refined similarly to the classification established by Shoham 13].
For our purpose, we are only interested in the liquid propositions in this taxonomy, or homogeneous in ETL 11]: we call these propositions stable and this means that their truth throughout an interval implies their truth at all instants within the interval.
The truth of p at one instant t, as a consequence of the truth of p over an interval comprising t, is expressed by true(t p).
The set of stable propositions is a subset of the set of durable ones.
An instant can be represented by five means: a number, a variable, a symbolic constant, an arithmetic expression such as t + n where t is an instant and n a number, and a functional term f(t1  : : : tn).
We use two relation symbols for the ordering of instants: < and fi.
Between these ordering relations and expressions of the form fI P g, we propose axiom A1 in figure 1.
Another useful feature for exibility of a temporal logic as a knowledge expression language, is the ability to give partial information about truth periods.
For this purpose, we introduce the following expressions: begin(t, p) means that one of the truth period of proposition p begins at the instant t. When the 0  0  0  beginning of the interval is known by this way, the term e(t p) refers to the end (the upper bound) of this interval.
The axiom A2 establishes the relationship with the expression fI pg where I is an interval.
end(t, p) means that one of the truth period of p ends at the instant t. In the same way as above, the term b(t p) refers to the lower bound of this interval.
This expression is formally defined by axiom A3 .
persist(t1, t2 , p) means that the interval ]t1 t2] is included in one of the truth period of p. This expression is defined by the two axioms A4 and A5 .
The maximality of truth period expressed by formulae like f]t t ] pg entails that the lower bound of these intervals are really the time when the proposition becomes true, and that the upper bounds are the instants when the proposition ceases to be true.
This entails that overlapping truth periods of the same proposition lead to a contradiction between the truth inside one of the intervals, and the non-truth outside the other one.
We suggest axioms A7 and A8 to express that overlapping of distinct truth periods is not allowed for a durable proposition.
Axiom A9 completes the definition of the logic and enables to deduce a complete truth period from partial information.
0  2.2 Example  We propose to illustrate the use of this logic by the well known \Yale Shooting Problem" which is written in figure 2.
We can deduce from this example that the gun will become unloaded at time 4 because of the firing.
We express it by end(4 loaded) and the proof of it involves reasoning about the temporal persistency of loaded.
The truth period of this proposition begins at time T1 because of the loading action on the gun.
Then, thanks to axiom Ap , it will last as long as needed, provided it is not interrupted.
At this moment, the upper bound of the persistence can not be fixed, but we can assume it to be at least equal to  fT1  loadingg true(2 alive) f4 pull;triggerg T1 < 2 R1 : 8t ft loadingg !
begin(t loaded) R2 : 8t ft unloadingg ^ true(t loaded) !
end(t loaded) R3 : 8t ft pull;triggerg ^ true(t loaded) !
end(t loaded) R4 : 8t ft pull;triggerg ^ true(t loaded) ^ true(t alive) !
end(t alive) Figure 2: The Yale Shooting Problem.
loading and pull-trigger are ephemeral propositions, and loaded and alive are stable.
4.
It can not be greater than 4 because of axiom A7 .
Thus, the only solution is that this upper bound is equal to 4.
3 The constrained resolution principle  In this section, we focus on the ability to do resolution-based reasoning with some temporal logic similar to the one described in the previous section.
The main problem of these languages comes from the use of equality and ordering relation symbols.
The usual axiomatization of the ordering relation fi, which describes the transitivity, reexivity and antisymmetry involves some self-resolving clauses.
This feature entails that for some queries the resolution process may spend a lot of time with repeated use of these clauses, without any way to know whether or not these inferences are relevant for the original query.
Our solution is an instance of the more general resolution principle proposed by H.J.
Burckert 2].
This constrained resolution principle is introduced in the framework of a particular logic, called logic with restricted quantifiers.
In this logic, quantifiers are associated with formul interpreted as restriction on the variables of the overall formula.
Clausal formul with restriction are noted C k R , which means 8X R !
C, where X is the vector of variables in C. T denotes the theory of restriction formul: it is given in such a way that (un)satisfiability and validity of these formul can be decided by an algorithmic mean.
Burckert simply assumes given a class of models for the restriction theory T .
The RQ-resolution principle is given by: fP (x1 	 	 	  xn)g   C k R f:P (y1 	 	 	  yn)g   D k S R ^ S ^ ; is T -satisfiable C  D k R^S ^; (1) where ; is the conjunction of equations x1 = y1 : : : xn = yn .
One of the completeness result from 2] says that given an unsatisfiable set of clauses, it is possible to derive by RQ-resolution an empty clause 2 k R such that T j= 9(R).
For the purpose of temporal reasoning, we consider that the restriction theory T is the theory where fi is interpreted as an ordering relation between time  instants and = means that two instants are at the same position on the time line.
To enable the use of constrained resolution, one first needs to have a constrained clausal form of the input formul.
For example, axiom A1 in Figure 1 produces the following constrained clause:  f]t1 t2] pg k :(t1 < t2 ) while axiom A6 is transformed in: true(t2  p)  f]t1 t3] pg k (t1 < t2 fi t3 ) The constrained forms of the axioms have a restriction which is a conjunction of temporal constraints.
However, some of these constraints are negative literals.
To simplify the use of constrained resolution, we choose to assume that fi is a total ordering relation.
This allows to use rewriting rules such as :(t < t ) !
t fi t to eliminate negative constraints.
We also split clauses with disjunctive restriction: C k R1 _ R2 !
f C k R1  C k R2 g 0  0  3.1 Deciding satisability  Provided that the restrictions of clauses are conjunction of positive litterals, it is possible to use temporal constraint propagation techniques to decide satisfiability.
Thus, the satisfiability of a conjunction of temporal expressions is equivalent to the global consistency of the constraints network built from these expressions.
For our problem, we are interested in both the symbolic and numeric relationships between instants.
We choose to rely on the formalism of Simple Temporal Problem (STP) studied by Dechter 3].
In this formalism, a constraint between two instants is represented by an edge between two nodes representing the instants, the label of the edge being a numeric interval.
Such a constraint is written x : a b] : y where x and y are two instants, a and b are two numbers belonginq to R   f;1 +1g.
This constraint means that a fi y ; x fi b.
A set of these constraints gives a network of binary constraints, such that an O(n3) path consistency algorithm is a complete decision procedure for the global consistency of the constraint set.
All expressions comparing instants denoted with numbers, variables, constants and arithmetic terms can be expressed within this constraint formalism.
Some simplification rules for unification 8], especially the ones for decomposition of functional terms,  are used inside the constraint solver when an equality is encountered.
The purpose is to: (1) handle non-arithmetic functional terms involved in equations by simplifying these equations (2) identify equations that involve variables so that they are used to instantiate the resolvent clause.
This keeps the set of constraints as small as possible.
Thus, given the set of constraints R ^ S ^ ; of rule (1), the satisfiability test produces a pair h C i where  is a substitution and C is a set of constraints such that (R ^ S ^ ;)  C. Then, the resolution principle is formulated as a variant of Burckert's one.
This gives: fP (x1 	 	 	  xn)g   C k R f:P (y1 	 	 	  yn)g   D k S R ^ S ^ ; is satisfiable (C   D) k ; (2) where ; is the set fx1 = y1  : : : xn = yn g, and h ; i is the pair resulting from the satisfiability test of R ^ S ^ ;.
0  0  4 Abductive temporal reasoning  This section describes an extension of the abductive logic programming procedure described by Kakas et Mancarella in 7].
This extension handles constrained resolution and, contrary to the original one, can handle non ground abducible litterals.
The original abductive procedure is an extension of SLD-resolution, and is inspired from the first one described by Eshghi and Kowalski in 4] to handle negation as failure in a abductive fashion.
The definition assumes a logic program P (a set of clauses of the form C  L1 : : :Ln , where C is the head and L1 : : :Ln the body), a set H of predicate symbols called abducible predicate, and a set IC of integrity constraints (clauses with empty head).
The purpose of the original procedure is to find, for a query Q, a set " of hypotheses (ground instances of abducible predicates) such that there exists a stable model M 6] of P   " such that M j= Q and M j= IC.
4.1 Denition of the procedure  The particular features of the procedure are the following:  we use the ability for a refutation using constrained resolution to produce \conditional answers", as it is done in Constraint Logic Programming.
For this purpose, we consider that, at the end of an abductive refutation, the ground temporal constraints in the restriction of the derived empty clause represent, if they are not satisfied, some additional ordering hypotheses which can be assumed if they are consistent  in the same way, it is possible to force a failure in a derivation by assuming some additional constraints.
When an empty clause is derived,  the constraint part of this empty clause can be made unsatisfiable.
The simplest possibility is to add a new temporal constraint to the current set of hypothesis such that the constraints set of the empty clause becomes inconsistent The procedure builds interleaved sequences of states.
The first sequence form is called an abductive refutation where each state has the form hGi  "ti "i $i  Iii.
At the beginning, G0 is the original query.
Gi is a goal clause, "i is a set of constraints, and "i is the current set of hypotheses.
The set Ii is initialized with the integrity constraints in IC and is used to collect new integrity constraints from the failure in the consistency check part of the procedure.
Denition 1 Let G be a goal clause of the form B .
An abductive refutation of G is a finite sequence of tuple:      G1  "t1 "1 $1 I1 : : : Gn "tn "n $n In where Gi is a goal clause, "ti is a set of ground constraints, "i is a set of ground literals, $i is a substitution, Ii is a set of integrity constraints, G1 = G $1 =  I1 = IC Gn = 2 k R such that either T  "tn j= R or "tn ^ R is T satisfiable and for each i = 1 : : : n, Gi has the form L L k R where L is the selected literal, and the  next state Gi+1  "ti+1 "i+1 $i+1  Ii+1 is obtained 0  according to one of the following rules: (A1 ) L is positive, C is the resolvent of Gi and of a variant of some clause in P on the selected literal L with the pair h ;i, then:  Gi+1 = C "ti+1 = "ti $i+1 =   "i+1 = "i Ii+1 = Ii  (A2 ) L is either positive and abducible or negative, L unifies with an element of "i with the pair h ;i, (R ^ ;) is T -satisfiable, then:  Gi+1 = L k (R ^ ;) "ti+1 = "ti "i+1 = "i $i+1 =  Ii+1 = Ii 0  (A3 ) L is either positive and abducible or negative, neither L nor its negation unifies with an element of "i, and there exists a consistency derivation from hF0 "ti "i   fLg Ii i to hfg "t "  I i then: 0  0  0  Gi+1 = L k R "ti+1 = "t "i+1 = " $i+1 =  Ii+1 = I where  is a substitution which maps each variable of L to a new skolem constant, and F0 is the set of all resolvents of the clause L  with clauses of Ii .
0  0  0  0  A consistency derivation implements the test of consistency of an hypothesis.
It is very similar in essence to a negation as failure call in logic programming.
The aim is to check whether an assumption is consistent with the program P and the current set of hypotheses " and of temporal constraints "t. A consistency derivation is a sequence of states of the form hFi  Dit Di  Ii i, where Fi is a set of goal clauses, Dit is the set of temporal constraints, and Di the set of current hypotheses.
The set Ii collects the failed goals during the test, so that they will be used with further hypotheses.
Denition 2 A consistency derivation is a finite sequence of tuple      F1 D1t  D1  I1 : : : Fm  Dmt  Dm  Im such that for each i 2 1 m], Fi is a set of goal clauses and has the form f L L k R g  Fi , Fm is the empty set, Dit is a set of ground temporal constraints, Di is a set of ground literals, and Ii is a set of integrity constraints, and L is selected  in the body of L L k R .
Fi+1  Dit+1 Di+1  Ii+1 is obtained according to one 0  0  0  of the following rules: (C1) there exists in Fi an empty clause C = 2 k R , then: 0  Fi+1 = Fi ; fC g Di+1 = Di Dit+1 = Dit   fD g Ii+1 = Ii where D is a ground constraint such that R ^ D is inconsistent, and Dit+1 is T 0  0  0  0  satisfiable.
(C2) L is positive, C is the set of all resolvents of clauses in P with the clause L L k R on the literal L, then: 0  Fi+1 = C   Fi Dit+1 =Dit Di+1 = Di I  i Ii+1 = I   f L L k R g ifif CC 6= =  i 0  0  (C3) L is either positive and abducible or negative, C is the set of all resolvents of L L k R with elements of Di on the literal L, then: 0  Fi+1 = C   Fi Dit+1 = Dit Di+1 = Di Ii+1 = Ii   f L L k R g 0  0  (C4) L is either positive and abducible or negative, L is ground, the opposite of L is in Di , then:  Fi+1 = Fi Di+1 = D  Dit+1 = Dt Ii+1 = Ii  0  0  0  (C5) L is either positive and abducible or negative, L is ground, and theret exists an abductive refutation from h:L Di  Di  Iii to the state h 2 k R  Dt D  $  I i then: 0  0  0  0  Fi+1 = Fi Ii+1 = I  0  0  0  Di+1 = D  0  and either Dit+1 = Dt if T  Dt j= R , or Dit+1 = Dt ^ R if T  Dt 6j= R and Dt ^ R is T -satisfiable.
0  0  0  0  0  0  0  0  0  For our purpose, the logic program P is made of the constrained clause form of the axioms of Figure 1 together with rules describing domain relationships, such as the clauses of Figure 2 for the YSP example.
Axioms A1 , A7, and A8 are integrity constraints in the set IC.
The predicate symbol persist is abducible: this means that whenever a new persistency hypothesis is needed, the consistency check will try to refute goals of the form begin(t p) and end(t p) where t falls within the period of the persistency assumption.
Of course, the aim is that these refutations fail so that the assumption does not violate integrity constraints.
4.2 Example  Recall the YSP example of Figure 2.
The query Q =end(t p), means that we are interested in finding when the gun will cease to be loaded.
Rule R3 yields the goal true(4 loaded).
Axiom A6 produces the goal persist(t1  t2 loaded) k t1 < 4 fi t2 where the literal persist(t1  t2 loaded) is abducible.
We begin a consistency derivation with a set of temporal ordering assumptions "t = fS1 < 4 fi S2 g, and a set of hypotheses " = fpersist(S1  S2  loaded)g, where S1 and S2 are new temporal constants.
The set of goals that we want to fail is: 8 :persist(S1  S2 loaded) k >  9 > > < = 2 k S 2 fi S1  F1 = > end(t loaded) k S1 fi t < S2  > : begin(t loaded) k S1 < t fi S2   The first clause in F1 disappears because the opposite of the literal :persist(S1  S2  loaded) is in ", and the second clause also disappears when we add the ordering constraints S1 < S2 to the set "t. At the end of the consistency derivation the set of clauses is empty, and the temporal ordering constraints in "t force S2 to be equal to 4 and S1 to T1 .
The primary abductive refutation ends and yields the substitution ft 7!
4g as an answer to the query Q.
One limitation of the procedure lies in the ability to handle repeated events: although the logic is able to describe those situations, the refutation procedure must be protected for infinite queries by a bound on the depth of the refutation.
It should be noted that those queries do not lead to subsumption between the current goal and one of its ancestors: it appears to be a \translation" on the time line.
At this moment, we do not have any mean to identify this relationship, nor can we characterize \translated" goals with respect to their utility in the refutation process.
5 Conclusions  In this paper, we describe an abductive procedure using a constrained resolution principle.
Such a resolution principle is very useful in the area of  temporal reasoning.
Constrained resolution allows an important gain on eciency by reducing nondeterminism, which is otherwise too much a trouble in pure resolution-based reasoning methods.
The abductive procedure is based on work done by kakas and Mancarella on abductive logic programming.
This procedure can be used to handle persistency as an assumption, and for planning problems where the set of computed hypotheses and temporal constraints describes a plan to achieve the requested goal.
References  1] James F. Allen.
Towards a general theory of action and time.
Artificial Intelligence, 23(2):123{ 154, 1984.
2] Hans-Jurgen Burckert.
A Resolution Principle for a Logic with Restricted Quantifiers, volume 568 of Lecture Notes in Artificial Intelligence.
Springer-Verlag, Berlin Heidelberg, 1991.
3] Rina Dechter, Itay Meiri, and Judea Pearl.
Temporal constraints networks.
Artificial Intelligence, 49:61{95, 1991.
4] K. Eshghi and R. A. Kowalski.
Abduction compared with negation by failure.
In G. Levi and M. Martelli, editors, Logic Programming: Proc.
of the Sixth International Conference, pages 234{254.
MIT Press, Cambridge, MA, 1989.
5] Kave Eshghi.
Abductive planning with event calculus.
In Proc.
of the 5th Int.
Conf.
on Logic Programming, pages 562{579, 1988.
6] Michael Gelfond and Vladimir Lifschitz.
The stable model semantics for logic programming.
In Proc.
of ICLP'88, pages 1070{1080, 1988.
7] A. C. Kakas and P. Mancarella.
On the relation between truth maintenance and abduction.
In Proc.
of PRICAI'90, pages 438{443, 1990.
8] A. Martelli and U. Montanari.
An ecient unification algorithm.
ACM Trans.
Programming Languages and Systems, 4(2):258{282, 1982.
9] Drew V. McDermott.
A temporal logic for reasoning about processes and plans.
Cognitive Science, 6:101{155, 1982.
10] Lode Missiaen.
Localized Abductive Planning with the Event Calculus.
PhD thesis, K.U.
Leuven, September 1991.
11] Erik Sandewall.
Non-monotonic entailment for reasoning about time and action Part I : Sequential actions.
Research Report LiTH-IDA-R-8827, Linkoping University, September 1988.
12] Murray Shanahan.
Prediction is deduction but explanation is abduction.
In Proc.
of the 11 th Int.
Joint Conference on Artificial Intelligence (IJCAI), pages 1055{1060, 1989.
13] Yoav Shoham.
Temporal logics in AI: Semantical and ontological considerations.
Artificial Intelligence, 33:89{104, 1987.
14] Mark E. Stickel.
Automated deduction by theory resolution.
Journal of Automated Reasoning, 1:333{355, 1985.
Reasoning about Plan Revision in Agent Programs Natasha Alechina University of Nottingham, UK  TIME 2012, Leicester 14 September 2012  Natasha Alechina  Reasoning about plan revision  TIME 2012  1 / 46  What this talk is about  verification (of agent programs with changing plans) transition systems correspond to agent program execution model-checking agent programs joint work with Brian Logan, Mehdi Dastani and John-Jules Meyer on a theorem-proving approach (using dynamic logic) main extension: explicit operator for ahaving a plana  Natasha Alechina  Reasoning about plan revision  TIME 2012  2 / 46  Transition systems  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  3 / 46  Dynamic logic ha; bip, hc; dip  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  4 / 46  Having and executing a plan  Plan(a;b) a  b  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  5 / 46  What is an agent?
many definitions of aagenta in the literature a key ideas include: autonomy: an agent operates without the direct intervention of humans or other agents situatedness: an agent interacts with its environment (which may contain other agents) reactivity: an agent responds in a timely fashion to changes in its environment proactivity: an agent exhibits goal-directed behaviour  Natasha Alechina  Reasoning about plan revision  TIME 2012  6 / 46  What I will mean by an agent  a computational system whose behaviour can be usefully characterised in terms of propositional attitudes such as beliefs and goals and which is programmed in an agent programming language which makes explicit use of propositional attitudes  Natasha Alechina  Reasoning about plan revision  TIME 2012  7 / 46  What is an agent programming language?
Belief, Desire and Intentions (BDI) framework, (Bratman 1987) BDI agent programming languages are designed to facilitate the implementation of BDI agents: programming constructs corresponding to beliefs, desires and intentions agent architecture or interpreter enforces relationships between beliefs, desires and intentions and which causes the agent to choose actions to achieve its goals based on its beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  8 / 46  3APL  one of the first agent programming languages PRS (Georgeff and Ingrand 1988), very rich.
I will talk about a more modern and less rich langauge, 3APL 3APL is a BDI agent programming language proposed in (Dastani et al.
2003) I present a cut-down version of 3APL (mostly regarding the language for beliefs, but also distinction between external and internal actions, not considering messages etc.)
Natasha Alechina  Reasoning about plan revision  TIME 2012  9 / 46  3APL beliefs  the beliefs of a 3APL agent represent its information about its environment and itself beliefs are represented by a set of positive literals the initial beliefs of an agent are specified by its program e.g., the agent may initially believe that itas in room1 and its battery is charged: Beliefs: room1, battery  Natasha Alechina  Reasoning about plan revision  TIME 2012  10 / 46  3APL goals  the agentas goals represent situations the agent wants to realise (not necessarily all at once) goals are represented by a set of arbitrary literals the initial goals of an agent are specified by its program e.g., the agent may initially want to achieve a situation in which both room1 and room2 are clean Goals: clean1, clean2  Natasha Alechina  Reasoning about plan revision  TIME 2012  11 / 46  Declarative goals  the beliefs and goals of an agent are related to each other if an agent believes p, then it will not pursue p as a goal if an agent does not believe that p, it will not have a p as a goal  these relationships are enforced by the agent architecture  Natasha Alechina  Reasoning about plan revision  TIME 2012  12 / 46  3APL basic actions  basic actions specify the capabilities of the agent (what it can do independent of any particular agent program) 2 types of basic actions: belief test actions: test whether the agent has a given belief belief update actions: aexternala actions which change the agentas beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  13 / 46  Belief test actions  a belief test action D?
tests whether a boolean belief expression D is entailed by the agentas beliefs, e.g.
: (room2 and -battery)?
tests whether the agent believes it is in room2 and its battery is not charged  Natasha Alechina  Reasoning about plan revision  TIME 2012  14 / 46  Belief update actions  belief update actions change the beliefs (and goals) of the agent a belief update action is specified in terms of its pre- and postconditions (sets of literals), e.g.
: {room1} moveR {  }, {-room1, room2}  an action can be executed if one of its pre-conditions is entailed by the agentas current beliefs executing the action updates the agentas beliefs to make one of the postconditions entailed by the agentas beliefs (actions non-deterministic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  15 / 46  Belief entailment  a belief query (a belief test action or an action precondition) is entailed by the agentas belief base if all positive literals in the query are contained in the agentas belief base, and for every negative literal a p in the query, p is not in the belief base i.e., we use entailment under the closed world assumption  goal entailment corresponds to a formula being classically entailed by one of the goals in the goal base  Natasha Alechina  Reasoning about plan revision  TIME 2012  16 / 46  Belief update  executing a belief update action adds all positive literals in the corresponding postcondition to the belief base, and for every negative literal a p in the postcondition, p is removed from the agentas belief base  goals which are achieved by the postcondition of an action are dropped for simplicity, we assume that the agentas beliefs about its environment are always correct and its actions in the environment are always successful  Natasha Alechina  Reasoning about plan revision  TIME 2012  17 / 46  Abstract plans  unlike basic actions, abstract plans cannot be directly executed by the agent.
abstract plans provide an abstraction mechanism (similar to procedures in imperative programming) which are expanded into basic actions using plan revision rules if the first step of a plan D is an abstract plan IaE, execution of D blocks.
Natasha Alechina  Reasoning about plan revision  TIME 2012  18 / 46  3APL plans  plans are sequences of basic actions and atomic plans composed by plan composition operators: sequence: aD1 ;D2 a (do D1 then D2 ) conditional choice: aif D then {D1 } else {D2 }a conditional iteration: awhile D do {D}a  e.g., the plan: if room1 then {suck} else {moveL; suck} causes the agent to clean room1 if itas currently in room1, otherwise it first moves (left) to room1 and then cleans it  Natasha Alechina  Reasoning about plan revision  TIME 2012  19 / 46  3APL PG rules planning goal rules are used for plan selection based on the agentas current goals and beliefs a planning goal rule Is a I, | D consists of three parts: Is: an (optional) goal query which specifies which goal(s) the plan achieves I,: a belief query which characterises the situation(s) in which it could be a good idea to execute the plan D: a plan  a PG rule can be applied if Is is entailed by the agentas goals and I, is entailed by the agentas beliefs applying the rule adds D to the agentas plans Natasha Alechina  Reasoning about plan revision  TIME 2012  20 / 46  Example 3APL PG rules clean2 <- battery | if room2 then {suck} else {moveR; suck} states that aif the agentas goal is to clean room2 and its battery is charged, then the specified plan may be used to clean the rooma an agent can generate a plan based only on its current beliefs (reactive invocation), e.g., the rule: <- -battery | if room2 then {charge} else {moveR; charge} states aif the battery is low, the specified plan may be used to charge ita  Natasha Alechina  Reasoning about plan revision  TIME 2012  21 / 46  Example 3APL PR rules a plan revision rule pj = Dj a I,j | D 0 j can be applied if Dj is in the plan base, I,j is entailed by the agentas beliefs and Dj is not executable, in other words the first action of Dj is either a belief update or belief test action which is not executable in the current belief state, or an abstract plan for example, if moveR fails, the agent may execute a slow but reliable version of the action, slowR: charge <- room1 | {slowR; charge}  Natasha Alechina  Reasoning about plan revision  TIME 2012  22 / 46  Operational semantics we define the operational semantics of 3APL in terms of a transition system states are agent configurations hD, Il, I i where D, Il are sets of literals representing the agentas beliefs and goals, and I  is a set of plan entries representing the agentas current active plans (annotated by the goals which they were adopted to achieve) each transition corresponds to a single step in the execution of the agent different execution strategies give rise to different semantics for simplicity we focus on non-interleaved executionai.e., the agent executes a single plan to completion before choosing another plan Natasha Alechina  Reasoning about plan revision  TIME 2012  23 / 46  Formal entailment definitions |=cwa (belief entailment for closed world assumption): D |=cwa p iff p a D D |=cwa ap iff p 6a D D |=cwa D and D iff D |=cwa D and D |=cwa D D |=cwa D or D iff D |=cwa D or D |=cwa D D |=cwa {D1 , .
.
.
, Dn } iff a1 a$?
i a$?
n D |=cwa Di |=g (goal entailment): Il |=g p iff p a Il Il |=g ap iff ap a Il Il |=g D or D iff Il |=g D or Il |=g D  Natasha Alechina  Reasoning about plan revision  TIME 2012  24 / 46  Belief update function let a be a belief update action and D a belief base such that D |=cwa precj (a) intuitively, D |=cwa precj (a) if it contains all positive literals in precj (a) and does not contain the negative ones the result of executing belief update action a with respect to D (assuming precj (a) holds and the action results in the postj,i becoming true) is defined as:  Tj,i (a, D) = (D aS {p : p a postj,i (a)}) \ {p : a p a postj,i (a)} intuitively, the result of the update satisfies (entails under |=cwa ) the corresponding postcondition postj,i (a) Natasha Alechina  Reasoning about plan revision  TIME 2012  25 / 46  Transitions: belief test actions  belief test actions D |=cwa I, hD, Il, {I,?
; D .
Is}i aa hD, Il, {D .
Is}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  26 / 46  Transitions: belief update actions  belief update actions when the corresponding goal not achieved yet: D |=cwa preci (Ia) Ti,j (Ia, D) = D 0 Il 0 = Il \ {D | D 0 |=cwa D} D 0 6|=cwa Is hD, Il, {Ia; D .
Is}i aa hD 0 , Il 0 , {D .
Is}i belief update actions when the corresponding goal is achieved: D |=cwa preci (Ia) Ti,j (Ia, D) = D 0 Il 0 = Il \ {D | D 0 |=cwa D} D 0 |=cwa Is hD, Il, {Ia; D .
Is}i aa hD 0 , Il 0 , { }i  Natasha Alechina  Reasoning about plan revision  TIME 2012  27 / 46  Transitions: plans conditional choice D |=cwa D hD, Il, {(if D then D1 else D2 ); D .
Is}i aa hD, Il, {D1 ; D .
Is}i D 6|=cwa D hD, Il, {(if D then D1 else D2 ); D .
Is}i aa hD, Il, {D2 ; D .
Is}i conditional iteration  D |=cwa D hD, Il, {(while D do D1 ); D .
Is}i aa hD, Il, {D1 ; (while D do D1 ); D .
Is D 6|=cwa D hD, Il, {(while D do D1 .
Is); D}i aa hD, Il, {D .
Is}i Natasha Alechina  Reasoning about plan revision  TIME 2012  28 / 46  Transitions: PG rules  planning goal rules Is a I, | D Il |=g Is Dcwa |= I, hD, Il, {}i aa hD, Il, {D .
Is}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  29 / 46  Transitions: PR rules  plan revision rules pj = Dj a I,j | D 0 j ai D 6|=cwa preci (Ia) D |=cwa I,j hD, Il, {Dj = Ia; D .
Is}i aa hD, Il, {D 0 j .
Is}i D 6|=cwa I, D |=cwa I,j hD, Il, {Dj = I,?
; D .
Is}i aa hD, Il, {D 0 j .
Is}i D |=cwa I,j hD, Il, {Dj = IaE; D .
Is}i aa hD, Il, {D 0 j ; D .
Is}i where IaE is the name of an abstract plan.
Natasha Alechina  Reasoning about plan revision  TIME 2012  30 / 46  State of the art  State of the art in model-checking agent programs  Model-checking AgentSpeak (Promela, Spin) Rafael H. Bordini, Michael Fisher, Carmen Pardavila, Michael Wooldridge: Model checking AgentSpeak.
AAMAS 2003:409-416 General platform for model-checking BDI agents (AIL and AJPF) Louise A. Dennis, Michael Fisher, Matthew P. Webster, Rafael H. Bordini: Model checking agent programming languages.
Autom.
Softw.
Eng.
19(1): 5-63 (2012) Work with Goal, 3/2APL,...  Natasha Alechina  Reasoning about plan revision  TIME 2012  31 / 46  State of the art  Challenges In common with general model-checking: scalability issues In common with general (software) model-checking: hard to deal with an infinite number of possible inputs/events, first-order properties I think there is still no system specification language at the right level of abstraction Beliefs, goals, plans, etc.
are treated as just ordinary data structures: same as lists of strings or some other adumba values However, they do have some logical structure (e.g.
closure under the agentas reasoning rules) and connections to each other, which should be used, in a transparent fashion (use something more like Maude?)
The most interesting logical challenge here I think is the logic of having committed to a set of intentions Natasha Alechina  Reasoning about plan revision  TIME 2012  32 / 46  State of the art  What does having a set of intentions mean  If an agentas set of intentions is {a; b; c, d; e; f } then it is easy to figure out what the possible actions by the agent are (a and d); for more general plans it is more complicated, but also well defined no logic with explicit adopted plans (in the logical language), apart from TCS11 (for single agent/single plan) and a paper in informal proceedings of DALT 2009. there are logics with explicit strategies (Simon and Ramanujam 2008,2009), but strategies and plans are not exactly the same and logics have no ahe has adopted this strategya operator  Natasha Alechina  Reasoning about plan revision  TIME 2012  33 / 46  State of the art  Verification by theorem proving  State properties of the system as axioms (completely axiomatise the operational semantics) Prove that the desired property logically follows from them This is a more complex problem than model-checking, but it is easier to deal with first-order, infinite domains, etc.
Natasha Alechina  Reasoning about plan revision  TIME 2012  34 / 46  Logic  Signature of an agent program The signature of an agent program R is defined as R = hP, PG, AZ Act, Plani PR, Ac, Ac, P is a set of belief and goal atoms PG is a set of planning goal rules, ri = Isi a I,i | Di PR is a set of plan revision rules, pj = Dj a I,j | Dj0 Ac is a set of belief update actions occurring in the plans of PG and PR rules AZ is a set of abstract plans occurring in the plans of PG and PR Ac rules Act is the set of specifications for belief update actions Ac Plan is the set of all possible D .
Is pairs where Is is one of the agentas goals and D is a plan occurring in PG and PR rules or a suffix of such a plan  Natasha Alechina  Reasoning about plan revision  TIME 2012  35 / 46  Logic  Language of PDL-3APL  program expressions: AZ | I'r i | I'p | D1 ; D2 | D1 aS D2 | Da D ::= Ia a Ac | t(D) | aE a Ac j formula: D ::= Bp | Gp | G a p | x | P Is D | P |AZD | D1 aSS D2 | hDiD  Natasha Alechina  Reasoning about plan revision  TIME 2012  36 / 46  Logic  Models of PDL-3APL AZ Act, Plani be the signature of an agent Let R = hP, PG, PR, Ac, Ac, program.
A PDL-3APL model M relative to R is defined as M = (W , V , RIa , Rt(D) , RIaE , RI'r i , RI'p j ) where W is a non-empty set of states.
V = (Vb , Vg , Vc , Vp ) such that for every s a W : Vb (s) = {p1 , .
.
.
, pm : pi a P} is the set of the agentas beliefs in s; Vg (s) = {( a )u1 , .
.
.
, ( a )un : ui a P} is the set of the agentas goals in s (note that Vg assigns literals rather than propositional variables); Vc (s) is either an empty set or {x}; Vp (s) is either the empty set or a singleton set {D .
Is}, where D is the agentas plan in s and Is is the goal(s) achieved by this plan  RIa , Rt(D) , RIaE , RI'r i , RI'p i are binary relations on W Natasha Alechina  Reasoning about plan revision  TIME 2012  37 / 46  Logic  Conditions on models  C1 Vg (s) aS Vb (s) = a and {p : a p a Vg (s)} a Vb (s) C2 If Vp (s) = {Ia; D .
Is}, Vb (s) |=cwa preci (Ia) and x 6a Vc (s), then there is an RIa transition to a state s0 where Vb (s0 ) = Ti,j (Ia, Vb (s)), Vg (s0 ) = Vg (s) \ ({p : p a Vb (s0 )} aS { a p : p 6a Vb (s0 )}) and if Vb (s0 ) 6|=cwa Is, Vp (s0 ) = {D .
Is}.
If Vb (s0 ) |=cwa Is, x a Vc (s0 ) and Vp (s0 ) = {}.
C3aC10 similarly correspond to operational semantics in non-x states  Natasha Alechina  Reasoning about plan revision  TIME 2012  38 / 46  Logic  Conditions for exceptional states  Condition for non-executable actions: if Vp (s) = {Ia; D .
Is}, Vb (s) 6|=cwa preci (Ia), and x 6a Vc (s), then there is an RIa transition to a state s0 where x a Vc (s0 ).
Condition for executing in exceptional states: if x a Vc (s) then there are RIa , RIaE and Rt(D) transitions from state s to itself Condition for PR rules: if x a Vc (s), Vp (s) = {Dj .
Is}, Vb (s) |=cwa I,j , then there is a RI'p j transition to a state s0 where Vp (s0 ) = {Dj0 .
Is} and x 6a Vc (s0 ) (where pj = Dj a I,j | Dj0 ).
Natasha Alechina  Reasoning about plan revision  TIME 2012  39 / 46  Logic  Satisfaction  M, s |= Bp iff p a Vb (s) M, s |= Gp iff p a Vg (s) M, s |= G a p iff a p a Vg (s) M, s |= x iff x a Vc (s) M, s |= P Is D iff Vp (s) = {D .
Is} M, s |= P iff Vp (s) = {} M, s |= AZD iff M, s 6|= D M, s |= D1 aSS D2 iff M, s |= D1 and M, s |= D2 M, s |= hDiD iff there exists s0 such that RD (s, s0 ) and M, s0 |= D.  Natasha Alechina  Reasoning about plan revision  TIME 2012  40 / 46  Logic  Translation into PDL  fb : fb (p) = Bp; fb (D and D) = fb (D) aSS fb (D); fb (D or D) = fb (D) a" fb (D) fg (p) = Gp; fg ( a p) = G a p fp : fp (Ia) = Ia fp (D?)
= t(D) fp (IaE) = IaE fp (D1 ; D2 ) = fp (D1 ); fp (D2 ) fp (if D then D1 else D2 ) = t(D); fp (D1 )) aS (t(AZD); fp (D2 )) fp (while D do D) = (t(D); fp (D))a ; t(AZD).
Natasha Alechina  Reasoning about plan revision  TIME 2012  41 / 46  Logic  Axioms A1 Bp a AZGp A2 G a p a Bp 0  A3a P Is D a AZP Is D 0 where D 0 6= D or Is0 6= Is W A3b P a" D.IsaPlan P Is D BA1 AZx aSS P Is (Ia; D) aSS fb (preci (Ia)) aSS D aSS D 0 a hIai( (fb (postij (Ia))aSSAZfb (Is)aSSP Is DaSSD)a"(fb (postij (Ia))aSSfb (Is)aSSx aSSPaSSD 0 )) where D, D 0 are any formulas not containing plan expressions or literals in fb (postij (Ia)), and in addition D 0 does not contain x AZ BA2a AZx aSS P Is D a [u]aL where D 6= u; D 0 and u a Ac aS Ac BA2b AZx aSS P Is D a [t(D)]aL if D does not start with a belief test action D?
or a conditional plan test on D where D = D or D = AZD  Natasha Alechina  Reasoning about plan revision  TIME 2012  42 / 46  Logic  Axioms continued  V V 0 Is (Ia; D) aSS f (prec (Ia)) aSS BA3 AZx aSS P D aSS b j i j j Dj a [Ia]( W Is Wj ( fb (postij (Ia)) aSS AZfb (Is) aSS P D aSS Dj )0 a" j ( fb (postij (Ia)) aSS fb (Is) aSS x aSS P aSS Dj )) where Dj and Dj0 are any formulas not containing plan expressions or literals in fb (postij (Ia)), and in addition Dj0 does not contain x BA4 AZx aSS P Is (D?
; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D aSS Dnp ) V BA5 AZx aSS P Is (Ia; D) aSS i AZfb (preci (Ia)) aSS Dnx a h[Ia]i(x aSS Dnx ) BA6 AZx aSS P Is (D?
; D) aSS AZfb (D) aSS Dnx a h[t(D)]i(x aSS Dnx ) BA7 AZx aSS P Is (IaE; D) aSS Dnx a h[IaE]i(x aSS Dnx ) BA8 x aSS D a h[u]iD where u is Ia, t(D) or IaE  Natasha Alechina  Reasoning about plan revision  TIME 2012  43 / 46  Logic  Axioms continued CP1 AZx aSS P Is (Dif ; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D1 ; D aSS Dnp ), where Dif is of the form if D then D1 else D2 CP2 AZx aSS P Is (Dif ; D) aSS AZfb (D) aSS Dnp a h[t(AZD)]i(P Is D2 ; D aSS Dnp ), where Dif is as in CP1 CP3 AZx aSS P Is (Dwh ; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D1 ; Dwh ; D aSS Dnp ), where Dwh is of the form while D do D1 CP4 AZx aSS P Is (Dwh ; D) aSS AZfb (D) aSS Dnp a h[t(AZD)]i(P Is D aSS Dnp ), where Dwh is as in CP3 CP5 AZx aSS (P Is Dif a" P Is Dwh ) aSS AZfb (D) a [t(D)]aL where Dif and Dwh are as above PG1 P aSS fg (Isi ) aSS fb (I,i ) aSS Dnpx a h[I'r i ]i(AZx aSS P Isi Di aSS Dnpx ) PG2 AZP a" AZfg (Isi ) a" AZfb (I,i ) a [I'r i ]aL PR1 x aSS P Is Dj aSS fb (I,j ) aSS Dnpx a h[I'p j ]i(AZx aSS P Is Dj0 aSS Dnpx ) PR2 AZx a" AZP Is Dj a" AZfb (I,j ) a [I'p j ]aL Natasha Alechina  Reasoning about plan revision  TIME 2012  44 / 46  Logic  Translation of the program  tr (R) = (aSi (I'r i ; fp (Di ))  S  aSj (I'p j ; fp (Dj0 )))+  Theorem: tr (R) picks out exactly those paths in a model which correspond to an execution of the program Can verify liveness and safety properties by checking whether htr (R)iD and [tr (R)]D are entailed by the formulas describing initial conditions complications: encoding plan expressions; encoding properties which hold along a path (Fahad Khan 2012, Regular Path Temporal Logic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  45 / 46  Logic  Conclusions  agent programs can be verified just as ordinary programs however they have additional properties which it may be possible to expoit one of the properties is having an explicit set of plans, which seems to be an interesting logical property may be also of interest for game logics (being able to say athis player is going to play this strategya rather than aif this player plays this strategya)  Natasha Alechina  Reasoning about plan revision  TIME 2012  46 / 46
A Proper Ontology for Reasoning About Knowledge and Planning Leora Morgenstern  IBM T.J. Watson Research Center P.O.
Box 704, Yorktown Heights, N.Y. 10598 leora@watson.ibm.com will be successful.
Abstract:  Research on the knowledge preconditions problems for actions and plans has sought to answer the following questions: (1) When does an agent know enough to perform an action?
(2) When can an agent execute a multi-agent plan?
It has been assumed that the choice of temporal ontology is not crucial.
This paper shows that this assumption is wrong and that it is very di cult to develop within existing ontologies theories that can answer both questions (1) and (2).
A theory of linear time does not support a solution to the knowledge preconditions problem for action sequences.
A theory of branching time solves this problem, but does not support a solution to the knowledge preconditions problem for multi-agent plan sequences.
Linear time supports prediction, but does not support hypothetical reasoning branching time supports hypothetical reasoning, but does not support prediction.
Since both prediction and hypothetical reasoning are essential components of the solution to the knowledge preconditions problems, no comprehensive solution has yet been proposed.
To solve this problem, we introduce a new temporal ontology, based on the concept of an occurrence that is real relative to a particular action.
We show that this ontology supports both hypothetical reasoning and prediction.
Using this ontology, we dene the predicates needed for the proper axiomatization for both knowledge preconditions problems.
1 Introduction  Intelligent agents not only possess knowledge, but they reason about the knowledge that they possess.
This sort of introspection is particularly crucial for planning.
Agents are not capable of performing every action, so an agent who constructs a plan must reason about his ability to perform the actions in his plan.
Since the ability to perform many actions rests directly upon an agent's knowledge, he must reason about whether he has that knowledge, or how he can get that knowledge.
For example, an agent who plans to perform the sequence of actions: (open up safe, remove money) must know that he knows the combination of the safe in order to predict that his plan  There has been a fair amount of research in the eld of knowledge and planning in the last 15 years.
Most of this work (Moore, 1980], Konolige, 1982]) has focussed on the knowledge preconditions problem for actions: what does an agent need to know in order to perform an action?
This question is only part of the story, however: if an agent does not know enough to perform an action, he will presumably not just drop his goal.
Instead, he will either plan to get the information, possibly by asking another agent, or by delegating the task to another more knowledgeable agent.
In either case, he will have to construct a more complex multi-agent plan.
This gives rise to the knowledge preconditions problem for plans: what does an agent have to know in order to successfully execute a plan?
For example, if I don't know the combination of the safe, I may ask Bob to tell me the combination.
To predict that this plan will work, I must know that Bob knows the combination, that he will tell it to me, and so on.
Presumably, the knowledge preconditions for this sort of plan are weaker than for my plan to open the safe { but they are di cult to make explicit.
In Morgenstern, 1988], we studied the knowledge preconditions problem for plans in detail, and furnished axioms giving su cient knowledge preconditions for various sorts of plans, including sequences, conditionals, and loops.
However, as noted there, these axioms are overly strong they entail that an agent has su cient knowledge to execute a plan even when intuition tells us otherwise.
For example, what seems to be a straightforward or \natural" way of axiomatizing the knowledge preconditions for plan sequences entails that an agent could always do a sequence of actions as long as he could perform the rst action, but (and this is the crucial point) he never actually did.
This was true even if the second action was impossible to perform.
The theory is still valid for forward reasoning planning however, it is clearly undesirable to have a theory that legitimates degenerate plans.
This paper addresses and solves this problem.
We had previously suggested that the problem was most probably due to the use of linear time, and claimed that using a more sophisticated temporal ontology such as branching time would solve the prob-  lem.
As we will show in this paper, branching time is also not su cient.
We need to construct a new and richer underlying temporal ontology.
This paper is structured as follows: We briey describe the logical language used, and give a natural language characterization of the solution to the knowledge preconditions problems.
Next we show that formalizing these axioms in a linear theory of time will not work.
The following section shows that the seemingly obvious solution { recasting these axioms using a branching theory of time { does not work either.
Finally, we introduce a new temporal ontology, called relativized branching time, which takes elements of both branching and linear times and is based on the notion of the \most real" world, relative to a particular action.
We show that this temporal ontology can be used to construct a correct theory of knowledge preconditions for actions and plans.
2 The Logical Language  We will be working in a logical language L, an instance of the rst order predicate calculus.
(What follows is terse and incomplete, due to space considerations.
L is modeled on the logic used in Morgenstern, 1988] ) L is distinguished by the following features: 1] L contains a 3-place predicate Know.
Know(a,p,s) means that agent a knows the sentence represented by the term p in the situation (\time-point") s. When we say that the term p represents a sentence, we are indicating that a quotation construct is present in L. Thus: 2] L allows quotation.
We can use a term or a w in L and talk about that term or w in L. We do this by associating with each term or w of L the quoted form of that term or w.
In general, we will denote the term representing a w or term as that w or term surrounded by quotation marks.
Some notes on quotation: unrestricted use of quotation can lead to paradox Montague, 1963] some sort of resolution is necessary.
Here we choose: 3] L is interpreted by a three-valued logic, which is transparent to the user and ignored in the remainder of this paper.
4] Quantication into quoted contexts is a somewhat messy enterprise, involving some sort of quasi-quotes.
We use the notation of Davis, 1990] : The delimiters ^^ and ## are used when the variables that are quantied into quoted contexts range over strings @ is used for variables that range over objects other than strings.
The partial function h maps a string onto the term it represents it is abbreviated as the .
(the period).
Those unfamiliar with quasi-quotation should just ignore these symbols.
As we have indicated, and will be arguing at greater length, the choice of a temporal ontology will be crucial for our endeavor.
Nevertheless, there are some elements that will be present in any choice.
They  are: 5] The basic building block is the situation, or time point.
(How these points are organized is the crux of the dierences between approaches).
Intervals of time are indicated by a pair of time-points, the starting time and the ending time.
An action or event is a collection of intervals { intuitively those intervals in which the action takes place.
An event is an action restricted to a particular agent (the performing agent).
The function Do maps an agent and an action onto an event.
Actions and events can be structured using standard programming language constructs.
A plan is any structure of events, e.g., Sequence(Do(Susan(ask(Bob,combination)), Do(Bob(tell(Susan, combination)))) A restricted subset of actions are primitive: - they cannot be further decomposed.
Other actions are complex and are built  up out of primitive actions using our programming language structures.
In all formulas of the theory and metatheory, all variables are assumed to be universally quantied unless otherwise indicated.
3 What We Want to Say  In English, the solution to the knowledge preconditions problem for actions can be stated as follows: it is assumed that all agents know how to perform the basic action types of primitive actions.
In order to know enough to perform a primitive action, then, one must only know what the parameter of the action is.
That is, one must know of a constant equivalent to the parameter.
Thus, for example, suppose that dial is a primitive action.
Then one knows how to dial the combination of a safe if one knows of a sequence of digits equivalent to the combination of the safe.
The knowledge preconditions for complex actions are given recursively in terms of the knowledge preconditions for primitive actions.
If an action is complex, an agent must explicitly know its decomposition into primitive actions, and know how to perform the decomposition.
Moreover, if one cannot perform an action, one generally constructs some multiple agent plan whose end result is the achievement of the original goal.
The solution to the knowledge preconditions problem for plans can therefore be stated as follows: An agent knows how to execute a plan if he knows how to perform all of the actions of the plan for which he is the performing agent, and can predict that the other agents in the plan will perform their actions when their time allows.
For example, Susan can execute the plan sequence sequence(do(Susan, ask(Bob, combination)), do(Bob, tell(Susan, combination))) if Susan can ask Bob for the combination, and she knows that as a result of her asking him for the combination, he will tell it to her.
Note that in order for Susan to predict that Bob will tell her the combination, she must know that Bob in fact knows it, and that he is willing to  share the information.
The above natural language description is a succinct summary of the observations of Moore, 1980] (for primitive actions) and Morgenstern, 1988] (for complex actions and multi-agent plans).
The di culty now is in formalizing this { correctly { within a formal logic.
It is necessary to formalize prediction { knowing that an event will happen in the future { and the notion of vicarious control { controlling a plan even if you are not involved in it.
The problem addressed in this paper arises in the characterization of the knowledge preconditions for complex plans in terms of primitive plans.
We focus here on sequences of plans.
We would like to say that an agent knows how to perform a sequence of actions if he knows how to perform the rst action, and as a result of performing the rst action, he will be able to perform the second action.
Similarly, an agent knows how to execute a sequence of plans if he can execute the rst, and as a result of the rst plan's occurrence, he can execute the second.
We turn to the formalization of these principles in the next section.
4 Diculties With Linear Time  One of the simplest ways to view time is as a straight line - i.e., the standard time line of school history books.
There is a total ordering on time points or situations.
We call this representation of time \linear time."
An interval of time is a segment of the time line as mentioned in Section 2, intervals are denoted by their start and end points.
An action is a collection of intervals Occurs(act1,s1,s2) is true i (s1,s2) is an element of act1.
The knowledge preconditions for primitive actions are omitted here.
They can be found in Morgenstern, 1988].
The axiom for one simple case can be found in this paper's appendix.
We focus here on complex actions.
Recall that we would like to say that an agent knows how to perform a sequence of act1, act2 if he knows how to perform act1 and knows that as a result of performing act1, he will know how to perform act2.
A reasonable try at the knowledge preconditions axiom for action sequences might thus be: Axiom 1: (Knows-how-to-perform(a,act1,s1) & (Occurs(do(a,.act1),s1,s2) ) Knows-how-to-perform(a,act2,s))) ) Knows-how-toperform(a,`sequence(^act^ ^act2^)',s1)  Despite this axiom's plausibility, it does not say what we want.
It allows agents to know how to perform some very odd action sequences.
In particular, it entails that an agent knows how to perform a sequence of two actions if (s)he knows how to perform the rst act but does not perform this act { even if (s)he doesn't know how to perform the second act!
For example, consider the agent Nancy Kerrigan, the  Figure 1: McDermott's branching time.
Real chronicle in bold  action sequence (ice skate, build atom bomb) , and the situation S1 representing January 7, 1994.
It is clear that on January 7, Nancy Kerrigan knew how to ice skate.
We know, however, that due to injuries, she did not skate on that day.
Then the statement  Knows-how-to-perform(Kerrigan,`sequence(ice skate, build atom bomb)', S1 is true, since the second con-  junct of the left-hand side of the axiom is vacuously true.
The problem, when we examine this anomaly more closely, seems to be that material implication is being used to capture the notion of \as a result of performing action 1."
The truth is that material implication is quite dierent from, and much stronger than, the notion of result.
This is the reason it is so much more di cult to modify Axiom 1 than one might suppose.
It is not merely that we have somehow missed something in the formalization.
The problems inherent in material implication have appeared in many suggested modications of this axiom as well, since material implication plays a central role in these axioms as well.
This problem strikes a familiar chord.
In fact, there are many types of reasoning, such as counterfactual reasoning, and concepts in temporal reasoning, such as prevention and causality, that would seem to be straightforward to implement, but which fail due to the very strong nature of material implication.
One approach to solving such problems has been to examine these concepts within the framework of a richer ontology.
Often, the ontology chosen has been branching time McDermott, 1982].
We examine the knowledge precondition problems in the context of branching time in the next section.
5 Diculties With Branching Time  In branching time, time points are ordered by a partial order as opposed to a total order.
There is a unique least point, and one cannot have s1 s2 and s3 s2 unless either s1 s3 or s3 s1 (that is, every child has at most one parent).
Thus, while one could visualize linear time as a straight line, the best way to visualize branching time is as a sideways tree (See Figure 1).
Conceptually, the branch points correspond to action choice points each branch represents a dierent action performed.
Following Mc<  <  <  <  Dermott 1982], any linearly ordered set of points (or path), beginning with the least point, and without gaps, is called a chronicle.
There ia s one chronicle that is designated as the \real chronicle" this corresponds to the way the world is.
A time point is called real if it lies on the real chronicle.
An interval is called real if it contains only real time points.
We introduce the predicate Real-occurs:  Definition:  Real-occurs(act,s1,s2) Occurs(act1,s1,s2) & Real( (s1, s2) ).
,  Since we used linear time in the last section, the  Occurs predicate used there corresponds to the Realoccurs predicate of this section.
Axiom 1 is now cor-  rect.
The left-hand conjunct is not vacuously true in the Nancy Kerrigan example, above the axiom now says: if Nancy Kerrigan knew how to ice skate on January 7, and in any possible world resulting from her skating on January 7, she knew how to build an atom bomb, then she knows how to perform the sequence of actions.
In fact, it is safe that assume that in no possible world resulting from Nancy Kerrigan's skating did she know how to build an atom bomb thus she does not know how to perform the sequence of actions.
This is just what we would anticipate.
Indeed, the fact that the axiom now works is to be expected Moore 1980] used branching time (his temporal ontology was a variation of the situation calculus) and was able to correctly formalize knowledge preconditions for action sequences.
The problem now is that branching time cannot be used for formalizing knowledge preconditions for plans.
The reason, briey, is that in order for an agent to reason that he can execute a multiagent plan, the agent must be able to predict that other agents will perform certain actions.
Predicting means knowing that an event will actually occur - i.e., that the occurrence will be part of the real chronicle.
But suppose, now, that an agent, Susan, is reasoning about her ability to execute sequence(pln1, pln2).
E.g., assume that Susan is reasoning about her ability to execute the plan sequence(Do(Susan,ask(Bob,combination)),Do(Bob,tell (Susan,combination))).
We assume that pln1 is a  single action where Susan is the performing agent pln2 is a single action where Bob is the performing agent.
Then Susan must know that she can perform pln1 1 and that as a result of performing pln1, Bob will perform pln2.
That is, she must know that in any possible world resulting from the event Do(Susan,ask(Bob,combination)), Bob will perform Do(Bob,tell(Susan,combination)).
But this is impossible by nature of the denitions: Bob can only really perform pln2 in the one real chronicle, not in every branch in which Susan performs pln1.
Moreover if In order to reason about plan execution, one must reason not only about knowledge preconditions, but also physical and social feasibility.
When all three are satisfied, an agent can-perform an action.
See Appendix.
1  Figure 2: Branching time doesn't support hypothetical  reasoning: Bob doesn't \really" tell Susan the number when Susan asks for it (non-bold segments)  Susan doesn't perform pln1, then Bob's performance of pln2 will only occur in non-real chronicles!
This situation is shown in Figure 2.
Thus, we are now in a situation that is precisely the opposite of the situation that occurred in linear time.
The theory based on linear time is too liberal it entails that agents know how to perform sequences of two actions even if they do not know how to perform the second action.
The theory based on branching time, on the other hand, is too restrictive.
It is virtually impossible to prove, under reasonable assumptions, that an agent can execute a standard sequence of plans, such as asking a friend for a piece of information, and receiving that information.
More formally, consider the following axioms:  Axiom 2:  Can-execute-plan(a,`sequence( ^pln1^,^pln2^)',s1) , Know(a,`Vicarious-control(@a, #pln1#,@s1)',s1) & Know(a,`Occurs(^pln1^,@s1,s2))Vicariouscontrol(@a,# pln2 #,s2)',s1)  Axiom 3:  actors(pln) = f a g & Can-perform(a,`action(@a, ^pln ^ )',s) ) Vicarious-control(a,pln,s)  Axiom 4:  actors(pln) 6= f a g & 9 s2 Real-occurs(.pln,s,s2) ) Vicarious-control(a,pln,s) .
Vicarious-control, in the axioms above, can be  thought of meaning \one of the following: I can do it or it will happen."
That is, one vicariously controls a plan if one can count on it happening.
I can count on my xing myself a scrambled egg in the morning because I know how to perform the action thus, by Axiom 3, I vicariously control it.
I can count on the sun rising this morning because I can predict that it will happen thus, by Axiom 4, I vicariously control it.
Axiom 2 states that I can count on a sequence of  plans if I can count on the rst plan, and as a result of the rst plan's occurrence, I can count on the second.
Now consider the plan sequence  sequence(do(Susan,ask(Bob,comb)), do(Bob, tell(Susan,comb))).
It can easily be seen that under most normal sets of assumptions, Can-executeplan(the above plan) cannot be proven using Axioms  1 through 4.
This is just one anomalous case.
Similar problems occur with conditional plans, and in cases where agents are not directly involved in any aspect of their plan { i.e., when the entire plan consists of actions that have been delegated.
The problem arises whenever one must predict that an action will take place if a piece of a plan has occurred.
6 A Solution That Works: Branching Time With Relativized Real States  Thus far, we have demonstrated that linear time is di cult to use to formalize knowledge preconditions because it does not allow for generalized hypothetical reasoning that branching time is likewise di cult because it emphasizes hypotheticals too strongly and does not allow for generalized prediction.
What we want is a theory that supports both hypothetical reasoning and prediction.
2 That is, we would like to develop a theory in which we can say: given that act1 has occurred, act2 will surely occur.
This \sureness" or \realness" is relative to the action that has occurred.
We call this relativized branching time.
To capture this concept, we modify the ontology of branching time as follows.
We introduce a collec(to be read as \more real tion of partial orders than" ) on branch segments of our tree.
There is a partial order at each branching point  is <r  <ri  i  <r  2 Other, less satisfactory approaches are possible.
We could use linear time, but introduce an explicit predicate Causes and thus eliminate the problems of material implication.
Our axiom on knowledge preconditions for action sequences would then read: (Know-how-to-perform(a,seq(act1,act2),s) & Causes(act1,Know-how-to-perform(a,act2))) ) Know-how-to-perform(a,seq(act1,act2),s) .
But there are several problems with this strategy: We need to give a semantics to Causes.
If we cannot, the theory is somewhat bogus if we reduce Causes to material implication, the problems return through the back door.
Moreover, sometimes the fact that one knows how to perform an action act2 after performing an action act1 does not mean that performing act1 caused the agent to know how to perform act2.
One can imagine a situation in which I know that I will be told the combination of the safe at some point late in the day.
In the meantime, I spend my day chopping wood.
Now, it is perfectly plausible that I will know how to open the safe after I chop wood { but I would not want to say that the wood chopping caused me to know how to open the safe.
Another approach would be to develop an ontology using only \axiomatically possible worlds."
The disadvantages here would be that it would be non-intuitive and hard to modify.
the collection of for all .
Where no confusion will result, we will simply write for .
has the following properties: For each branch point i with n branch segments 1    , 9!
3 1.
1  ;1 +1    <ri  i  <r  b  bn  <ri  <r  bj  bj <r b  bj <r bj  bj <r bj  bj <r bn  (existence and uniqueness of least element under <r ) 2.
8k l = 6 j :bk <r bl :bl <r bk (Other than the least element, branches are incomparable.)
This bj is the \most real branch " at point i.
Intuitively, it is the branch most likely to occur at time i. i  is the unique minimal element in the partial order induced by .
3 Note also that condition (2) may be dropped if we wish to model a world in which there are dierent levels of preferred occurrences relative to some action.
For example, condition (2) would most likely be dropped in a theory that allowed for defeasible reasoning.
If one originally inferred that some action would happen because it was on the most preferred branch, and then had to retract that conclusion, it would be helpful to know which of the remaining branches was most likely to occur, and make new predictions based on this information.
We can use the notion of a most real branch to dene the concept of a most real path at a point s. Specically, dene a path in a tree as a sequence of branches 1 ,    where for each , 2 (1 ; 1), the endpoint of is the starting point of +1 .
Definition: ( 1,    ) is the most real path i for all 2 (1,j) is the most real branch segment relative to 's starting point.
Thus, for example, in Figure 3, the path ( 0 , 2 , 6 , 11, 13, 14) is the most real path at the point 0 because all the branch segments are the most real at their starting points.
On the other hand, the path ( 0 , 2 , 6 , 7, 10) is not most real at 0 because ( 6 , 7) is not the most real branch segment at 6 .
Let 0 be the root of a branching tree structure.
Note that the most real path at 0 corresponds precisely to McDermott's real chronicle.
Our move to a richer temporal ontology has thus lost us nothing in expressivity.
We now extend the relation to range over subtrees in the obvious way.
We thus have the following: Denition of for subtrees: Assume 1 2, where 1 has the endpoints ( 1 ) and 2 has the endpoints ( 2 ).
Let 1 be the subtree rooted at 1 and 2 be the subtree rooted at 2 .
Then 1 2. bj  <ri  b  bj  bi  i  j  bi  b  i  bi  bj  bi  bi  s  s  s  s  s  s  s  s  s  x  s  s  s  s  s  <rs  b  s  s  s  <r  <r  b  b  s s  t  s s  b  s  t  t  s  <rs t  We have imposed the condition of uniqueness for ease and simplicity of presentation but this condition is not strictly necessary.
It is likely that in complex domains with varying degrees of granularity of representation, there can be several most preferred branches.
For example, if Susan asks Bob for the combination, the branch in which he answers her orally and the branch in which he answers her in writing could both be most preferred branches.
We deal with this in the longer version of this paper.
3  Goal(a,act,s) & Can-perform(a,act,s) ) 9 s2 Real-wrt(s,s2) & Occurs(do(a,act),s,s2)  We can now formalize the concept of relativized prediction as follows:  Axiom 4'  actors(pln) 6= f a g& 9 s2 Real-wrt(s,(s,s2)) & Occurs(pln,s,s2) ) Vicarious-control(a,pln,s).
Using this axiomatization of the solution to the knowledge preconditions problem, we can build a theory of commonsense reasoning in which benchmark planning problems can be solved.
As an example, we consider the example of section 3, in which Susan plans to learn the combination of a safe by asking a cooperative agent Bob.
Consider a situation 1.
Assume that Bob in 1 knows the combination of some safe and that Susan knows this fact in 1.
Consider, further, a common set of social protocols governing agents' behavior, as discussed in Morgenstern, 1988] or Shoham, 1993].
Examples of such protocols are: that cooperative agents will accept one another's goals if possible, and that cooperative agents are constrained to tell the truth to one another.
Assume that these protocols hold for Susan and Bob in 1, that Susan and Bob are aware of these facts, and that both obey the S4 axioms of knowledge.
Then we have the following theorem: S  Figure 3: relativized branching time: at each branch-  ing point, there exists a unique preferred branch (in bold).
Note that since (so,s2) is more real than (s0,s19), the tree rooted at s2 is more real than the tree rooted at s19.
See Figure 3 for examples of these denitions.
Using this ontology, we can now introduce the concept of a state that is real relevant to some point in time.
Specically, we introduce the predicate Realwrt(s1,s2), which is given by the following metatheoretic denition: Denition: j= Real-wrt(s1,s2) i s2 is a point on where is the most real branch point originating from s1.
We extend Real-wrt to range over intervals in the obvious way.
Specically: bj  bj  Definition: Real-wrt(s1,(si,sj)) , 8 s 2 (si,sj) Real-  wrt(s1,s)  Those causal rules which have action occurrences in their consequent must now be written in terms of this predicate.
In general, where before we would have: Holds(uent,s1) ) 9 s2 Occurs(act,s1,s2)  we would now have:  Holds(uent,s1) ) 9 s2 Real-wrt(s1,s2) & Occurs(act,s1,s2)  and where before we would have: Occurs(act1,s1,s2) ) 9 s3 Occurs(act2,s2,s3)  we would now have:  Occurs(act1,s1,s2) ) 9 s3 Real-wrt(s2,s3) & Occurs(act2,s2,s3).
In the above transformation rules, the term  Holds(uent,s1) is really just syntactic sugar in fact,  in our notation, the situation is just another argument to the predicate.
Here is an example of a transformation: Where before we had Goal(a,act,s) & Can-perform(a,act,s) ) 9 s2 Occurs(do(a,act),s,s2)  we would now have:  S  S  S  Theorem: Can-execute-plan(Susan, sequence( do(Susan,ask(Bob,comb)), tell(Susan,comb)))  do(Bob,  We sketch the main points of the proof.
Axiom numbers refer to the axioms listed in the appendix.
We rst prove the following lemmas: Lemma1: If A and B are cooperative agents, then A can tell P to B i A knows P. Proof: By Axiom 5, an agent A can perform the ac-  tion of telling P to B i the knowledge preconditions, the physical preconditions, and the social protocols are all satised.
We assume for simplicity that the physical preconditions are satised (Axiom 6).
Moreover, all agents always know how to perform the simple act of uttering a string.
(Axioms 7 and 8).
It remains to satisfy the social protocol.
By Axiom 9, the social protocols are satised i agent A tells the truth { i.e., if he knows P. Thus, if A knows P, the social protocols are satised, and since the knowledge and physical preconditions are satised, he can tell P to B. Conversely, if he can tell P to B, the social protocols must be satised, and thus he must know P. 2 Lemma2: Assume A and B are cooperative agents.
If A asks B to do Act1, and B can do Act1, then B will subsequently perform Act1  Formally,  Cooperative(a,b,s1) & Occurs(do(a,ask(b,act1)),s1,s2) ) 9s3 Real-wrt(s2,s3) & Occurs(do(b,.act1),s2,s3)  Proof: Axiom 10 tells us that cooperative agents adopt one another's goals.
That is, if A asks B, during some interval (s1,s2) to do some act, it is then B's goal in s2 to do this action.
Moreover, we have from Axiom 11 that if an agent has a goal of performing a certain action, and he can perform that action, he will subsequently perform the action.
2 Note that Axiom 11 explicitly uses the concept of relativized realness.
Neither a stronger nor a weaker concept will su ce.
If Axiom 11 had read: Goal(a,act,s) & Can-perform(a,act,s) ) 9 s2 Real(s2) & Occurs(do(a,.act),s,s2) then it would be false.
On the other hand, if Axiom 11 had read: Goal(a,act,s) & Can-perform(a,act,s) ) 9 s2 Occurs(do(a,.act),s,s2)  it would not be strong enough to prove Lemma 2.
Indeed the proof of Lemma 2 depends on the ontology developed here.
It seems unlikely that it could be proven in a standard McDermott-type branching logic.
The proof of the theorem then goes as follows: By protocol (Axiom 14), agents can ask other cooperative agents for information.
Moreover, the physical preconditions and knowledge preconditions are satised (Axioms 12 and 13).
Thus, Susan can perform the rst part of her plan.
Thus, Susan can vicariously control the rst part of her plan (Axiom 3).
We must now show that if she performs this part, Bob will perform the second part.
First we must show that Bob can perform the action of telling Susan the combination.
By assumption, Bob knows the combination in S1.
Moreover, agents do not forget (Axiom 15).
Thus, Bob knows the combination in any situation subsequent to S1.
Therefore, by Lemma 1, he can perform the action of telling Susan the combination in S1.
Now, using Lemma 2, we can show that if Susan asks Bob the combination, he will subsequently tell it to her.
This means that Susan vicariously controls the second part of the plan (Axiom 4') by Axiom 2, Susan can execute the plan consisting of the sequence (Do(Susan,ask(Bob,combination)),Do(Bob, tell(Susan,combination))).
2 Again, this proof will not hold in a branching temporal logic.
Note, however, that the theory is not too powerful.
In particular, it will not entail degenerate plans like Nancy Kerrigan's plan, above.
Thus, the theory based on relativized branching time avoids both the problems of linear time and of standard branching time.
7 Conclusion and Further Directions  In the late seventies and early eighties, many researchers (Allen, 1984], McDermott, 1982]) argued for the importance of a correct ontology of time.
The pendulum shifted somewhat subsequently, with McDermott 1984] arguing that some ontological distinc-  tions were not all that crucial.
In particular, he argued that the dierence between linear and branching time was not that great, and would probably not make much of a dierence in temporal reasoning.
We have shown that, contrary to McDermott's hopes, this distinction is crucial for theories of knowledge and planning, and that in fact, neither ontology is adequate for such theories.
Linear time does not allow hypothetical reasoning, and thus cannot properly handle knowledge preconditions for action and plan sequences.
Branching time can handle hypothetical reasoning, but it cannot handle prediction properly, especially in hypothetical reasoning contexts.
(Recently, Pinto and Reiter 93] have also noted the problems of using standard branching time.)
Thus, those who ignore the issue of ontology do so at their own peril: all researchers who have used standard ontologies for reasoning about knowledge and planning have developed theories that are inadequate in some respect.
We have developed a dierent ontology for time, relativized branching time, which allows for relativized realness.
This allows prediction in hypothetical contexts, and thus allows the proper axiomatization of knowledge preconditions.
The resultant theory can handle standard benchmark problems correctly, while avoiding the anomalies of previous theories.
Relativized branching time appears promising for other research areas as well.
Because it supports certain types of hypothetical reasoning, it may be a suitable ontology for counterfactual reasoning.
In particular, relativized branching time may help give structure to the rather vague concept of \most similar possible worlds" which has been used (see, e.g.
Lewis, 1963]), to explain the semantics of counterfactuals such as \If I had struck a match (at S1), it would have burst into ames."
In our ontology, such a sentence can be analyzed as follows: it is true if given a (typically non-real) branch segment (S1,S2) during which the match is struck, it is true on the most real branch segment of S2 that the match burst into ames.
Most similar can be understood as the most real subtree of the endpoint of a non-real branch.
Such an analysis is very preliminary but suggests promising directions for future research.
8 Acknowledgements:  The author thanks the anonymous reviewers for comments on an earlier draft of this paper.
9 Bibliography  Allen, 1984] Allen, James: Toward a General Theory of Action and Time, Articial Intelligence, vol.
23, no.
2, 1984, pp.
123-154 Davis, 1984] Davis, Ernest: Representations of Commonsense Knowledge, Morgan Kaufmann, Los Altos, 1990  Konolige, 1982] Konolige, Kurt: A First Order Formalizationof Knowledge and Action for a Multi-agent Planning System, J.E.
Hays and D. Michie, eds.
Machine Intelligence 10, 1982 Lewis, 1963] Lewis, David: Counterfactuals, Oxford, 1963 McDermott, 1984] McDermott, Drew: The Proper Ontology for Time, unpublished, 1984 McDermott, 1982] McDermott, Drew: \A Temporal Logic for Reasoning About Processes and Plans," Cognitive Science, 1982 Montague, 1963] Montague, Richard: Syntactical Treatments of Modality with Corollaries on Reexion Principles and Finite Axiomatizability, in Acta Philosophica Fennica, fasc.
16, pp.
153-167, 1963 Moore, 1980] Reasoning About Knowledge and Action, SRI TR 191, 1980 Morgenstern, 1988] Morgenstern, Leora: Foundations of a Logic of Knowledge, Action, and Communication, NYU Ph.D. Thesis, Courant Institute of  Mathematical Sciences, 1988 Pinto and Reiter, 1993] Pinto, Javier and Raymond Reiter: Adding a Time Line to the Situation Calculus Shoham, 1993] Shoham, Yoav: Agent-Oriented Programming, Articial Intelligence, 1993  10 Appendix:  Below, a list of the axioms and denitions used in the proofs of the lemmas and main theorem of Section 6.
All variables are assumed to be universally quantied unless otherwise noted.
Axioms 1 through 4' are taken from sections 4 through 6 of this paper.
Axiom 1: (Knows-how-to-perform(a,act1,s1) & (Occurs(do(a,.act1),s1,s2) ) Knows-how-to-perform(a,act2,s))) ) Knows-how-toperform(a,`sequence(^act^ ^act2^)',s1) Axiom 2: Can-execute-plan(a,`sequence( ^pln1^,^pln2^)',s1) , Know(a,`Vicarious-control(@a, #pln1#,@s1)',s1) & Know(a,`Occurs(^pln1^,@s1,s2))Vicariouscontrol(@a,# pln2 #,s2)',s1) Axiom 3: actors(pln) = f a g & Can-perform(a,`action(@a,^pln ^ )',s) ) Vicarious-control(a,pln,s) Axiom 4': actors(pln) = 6 f a g & 9 s2 Real-wrt(s,s2) & occurs(pln,s,s2) ) Vicarious-control(a,pln,s) .
Axiom 5: Can-perform(a,act,s) , Know-how-to-perform(a,act,s) & Physsat(a,act,s) & Socialsat(a,act,s)  An agent can perform an action if the knowledge preconditions, the physical preconditions, and the social  protocols are all satised.
Axiom 6: Physsat(a,`tell(@b,#p#)',s)  For the sake of this paper, it is assumed that there are no physical preconditions for communicative actions.
In reality, there are a variety of preconditions, including being at the same place as the hearer (or being connected in some way).
Axiom 7: Primitive-act(`tell')  The simple locutionary action of just uttering a string is considered to be primitive, with correspondingly simpler knowledge preconditions.
Axiom 8: Primitive-act(f) ) Know-how-to-perform(a,^f^(^x1,  ,^xn)',s) where all of x1    xn are constants.
An agent knows how to perform any primitive action if all the arguments are constant.
Axiom 9: Cooperative(a,b,s) ) Socialsat(a,`tell(@b,#p#)',s) , Know(a,p,s)  Cooperative agents are constrained to tell the truth.
Axiom 10: Cooperative(a,b,s1) Occurs(do(a,ask(b,info)),s1,s2) ) Goal(b,tell(a,info),s2)  ^  If one agents asks a cooperative agent for information, the second agent will subsequently have the goal of giving over the information.
The above axiom has quite a bit of syntactic sugar in it.
The term \info" is shorthand for what is really going on: Agent a is asking agent b to tell him a string of the form: `Equal(term,p)', where p is a constant.
Agent b adopts the goal of telling him a string of that form.
In Morgenstern 1988], this axiom is presented without any syntactic sugar.
Axiom 11: Goal(a,act,s) & Can-perform(a,act,s) ) 9 s2 Real-wrt(s,s2) & Occurs(do(a,.act),s,s2))  If an agent has the goal of performing an act, and can perform the act, he will perform the act.
Note the crucial use of the Real-wrt predicate.
Axiom 12: Primitive-act(`ask')  Asking is a primitive action.
Axiom 13: Physsat(a,ask(b,info),s)  The physical preconditions of asking for information are always satised.
Axiom 14: Cooperative(a,b,s) ) Socialsat(a,ask(b,info),s)  If agents are cooperating, it is always all right to ask for information.
Axiom 15: Know(a,#p#,s) ) 8 s2  s Know(a,#p#,s2)  This is the axiom of perfect memory.
Agents never forget.
2012 19th International Symposium on Temporal Representation and Reasoning  TVICS: An Efficient Traffic Video Information Converting System Hang Yue  Peter Z. Revesz  Mid-America Transportation Center Civil Engineering Department University of Nebraska-Lincoln Lincoln, NE 68588, USA (until April 30th, 2012) Email: yuehang366@gmail.com  Computer Science & Engineering Department University of Nebraska-Lincoln Lincoln, NE 68588, USA Email:revesz@unl.cse.edu  Abstract a This paper presents a new system called TVICS that converts traffic video data into vehicular motion information in spatio-temporal databases.
The TVICS system interpolates the vehicular trajectory data (time, location and velocity), which are extracted from video, and integrates them with spatial road information for the storage of dynamic transportation environments.
TVICS can avoid the storage issues caused by traffic videos with their associated large data size.
Moreover, users can manage and operate multiform and multidimensional traffic data in a spatio-temporal transportation environment.
Experimental results show that TVICS has a high accuracy in transportation applications.
traffic videos is defined on the physical level, which does not allow the expression of high-level spatio-temporal relationships among traffic data [5, 6].
Therefore, it is difficult for current video database systems to quickly scan traffic video data and find the desired transportationrelated spatio-temporal query results.
We have looked at alternatives for storing video data.
First, we can recognize that once the video cameras collect discrete vehicular trajectory data (some number of frames per second), and the trajectory data can be interpolated into continuous traffic data.
Data model can describe the movement of vehicles with some functions of a temporal parameter t and spatial parameters.
Second, such continuous traffic data can be conveniently stored in various types of spatio-temporal databases.
For example, constraint databases can describe continuous spatiotemporal data in arbitrarily high-dimension [7].
At the same time, constraint databases allow various high-level query languages, including SQL and Datalog and their extensions [7].
The aim of this paper is to describe the development and features of an efficient Traffic Video Information Converting System (TVICS).
Our TVICS system can convert traffic video data into spatio-temporal transportation databases.
The system allows the users to choose various data interpolation options.
In addition, we integrate into the system not only standard SQL queries but also high-level queries that are specifically designed for transportation-related applications.
Keywords a GIS; traffic video; spatio-temporal database; vehicular velocity interpolation; transportation  I.
INTRODUCTION  In this paper we consider transportation applications.
Some transportation-related applications, such as urban planning, require only static spatial databases or geographic information systems (GISs).
For instance, Miller [1] used a GIS for the evaluation of traffic analysis zone (TAZ) effects, the design of optimal zoning systems, and the derivation of better zonal distance measures.
In addition, various intelligent transportation systems (ITS) often use static GIS map databases for location referencing and frequently exchange spatial information with other map databases [2].
However, more interesting transportation applications need to consider the values of traffic parameters that vary continuously over time.
Spatial database systems deal with these data sets in an inefficient way via discrete time points or intervals.
Given traffic dataas multiform and multidimensional nature, more efficient traffic data archiving is needed to add a temporal dimension to GIS-based transportation management systems.
Today, video cameras are widely used for traffic monitoring and data collection.
The combination of space and time is a defining feature of digital video [3].
However, considering the large space and expensive cost in traffic video storage, traffic video data are usually saved into video segments, scenes, shots, or frames [4].
Moreover, in current video management systems the storage manner of  1530-1311/12 $26.00 AS 2012 IEEE DOI 10.1109/TIME.2012.9  II.
OVERVIEW OF THE TVICS SYSTEM  The overall design and data management plan of the TVICS system are illustrated in Fig.
1.
The TVICS system can optimize traffic data completeness and offer high-level spatio-temporal queries of transportation data.
The design and development of the TVICS system consists of the following four main parts: x Data extraction: by the video-capture methods [8, 11], traffic video data extraction provides vehicular trajectory data (i.e.
vehicular instantaneous location, time, and speed data points).
141  x  x  Data interpolation: discrete vehicular velocity points with different time intervals are interpolated into continuous instantaneous velocity by the linear and nonlinear data models.
Data integration: both of the highway spatial data of GIS shape-files and the continuous vehicular  x  trajectory data are transformed and integrated into spatio-temporal databases.
Data retrieval: a high level traffic information query interface guides the users in performing spatio-temporal queries of the integrated dynamic transportation information.
Figure 1.
Overview of the TVICS system  III.
DATA EXTRACTION x  A. Trajectory Data Extraction Steps Today, when high resolution cameras, good quality video-capture cards, and advanced video-capture-based approaches are available, it is increasingly cost-effective to extract accurate multiple-vehicular trajectory data.
For instance, the advanced machine vision system in the Next Generation Simulation (NGSIM) program [8] can automatically extract vehicle trajectories from video data.
The machine vision algorithms [9, 10] concerning vehicle detection and tracking were developed to obtain the comprehensive dataset about vehicle trajectory at 10 frames per second.
The software Vehicle Video-capture Data Collector (VEVID) [11] can digitize full-motion video at a higher frame rate (up to 30 frames per second).
Wei et al.
[11] described a general approach to extract vehicular trajectory data from video for traffic modeling.
Fig.
2 shows the five steps about traffic data collection and extraction using the video-capture method.
x Step 1: to measure the distances between the reference points of the urban street.
x Step 2: to set up a camera in an elevated position above the urban street.
x Step 3: to digitize a segment of video into Audio Video Interleave (AVI) or Video for Windows with a user specified frame rate.
x Step 4: to put the AVI file and the distance information about the reference points in the software (VEVID or advanced machine vision system) to extract vehicular trajectory data.
Step 5: to implement the vehicular trajectory data storage.
B.
Current Data Archiving Methods Traffic data collection technology has advanced faster than the technology of transportation databases into which data are properly archived and from which all data can be conveniently retrieved [12].
Some researches [8, 11] developed the approaches to extract vehicular trajectory data with small time intervals (e.g.
0.1 s) from video for traffic modeling.
The studies [13, 14] used vehicular trajectory data extracted from video to calibrate transportation microscopic simulation, such as lane changing models, lane-choice models, car-following models, and lane-vehicle-allocation models.
However, discrete vehicular trajectory data are stored in flat-files or relational databases, and these vehicular motion data are separated from highway spatial data in GIS.
This separation causes a loss of information about the spatial relationships between the moving vehicles and the highways, and also leaves undefined the spatio-temporal relationships between the moving vehicles.
Existing transportation databases fail to properly keep spatiotemporal relationships among traffic data and also fail to provide high-level spatio-temporal queries, such as queries that involve multiform and multidimensional traffic data.
Take, for example, traffic spatio-temporal queries that aggregate traffic data by any time period, lane, and vehicle type or vehicular queries that track certain vehicles for a driver behavior analysis.
142  where Si is defined as a third degree polynomial below in Eq.
(2): si ( x)  ai ( x  xi )3  bi ( x  xi )2  ci ( x  xi )  di (2)  where i = 1, 2,..., n-1; xi is the interval value; and ai, bi, ci, and di are the coefficients in the ith piece; and the coefficients on the cubic polynomials (ai, bi, ci, and di) are the weights of interpolating known data.
The first and second derivatives of these na1 equations (Il rl A rl A rl Il) are fundamental to the process, and they are: 3ai ( x  xi )2  2bi ( x  xi )  ci  s 'i ( x)  s ''i ( x) 6ai ( x  xi )  2bi  (3) (4)  The curve S(x), the first derivative S'(x), and the second derivative S''(x) must be continuous across its entire interval [x1, xn], and each sub-function must join at the data knots; that is (forI' rl A rl A rl Il): Si ( xi )  Figure 2.
Traffic data collection and extraction using video-capture techniques.
S ''i ( xi ) S ''i 1 ( xi )  Spatio-temporal databases can integrate a dynamic temporal effect with a description of spatial dimensions [15, 28].
However, in terms of tracking moving vehicles in a visual road network, the current studies [16, 17] mainly focused on the accuracy discussion about snapping discrete GPS points to a certain road segment.
Vehicular data with high accuracy, extracted from video, were not discussed for the development of transportation systems, and need to be adapted for such a task.
IV.
ai  ci  M i 1  M i 6h  bi  Mi 2  yi 1  yi M  2M i  ( i 1 )h h 6  di  yi  Given the slopes in x1 and xn are known, i.e.
s '1 ( x1 ) k1 and s 'n ( xn ) k2 , the exact-slope spline is an  In Yue et al.
[18], the authors developed continuous time-mean speed estimation models for transportation applications in spatio-temporal databases, on the basis of the statistical interpolation methods.
In order to achieve moving vehicles within dynamic transportation databases, cubic-splines are used to interpolate discrete vehicular velocity data into continuous instantaneous velocity.
Cubic-splines are typical numerical analysis methods for data interpolations.
There are four types of cubicsplines, and they are the exact-slope spline, natural spline, zero-slope spline, and not-a-knot spline.
The common function of cubic-spline S(x) in [19] is:  S ( x)  h xi  xi 1  the above derivations, the results ( Il rl A rl A rl Il ) are concluded below:  A.
Data Interpolation Methods  if x1 d x d x2 if x2 d x d x3 .
.
.
if xn 1 d x d xn  S 'i ( xi ) S 'i 1 ( xi )  The piecewise function S(x) interpolates all discrete data points, S(xi) = yi for Il rl A rl A rl Iland si(xi) = yi in every interval.
When substituting M i S ''i ( xi ) and h into  DATA INTERPROLATION  A s1 ( x) Adeg s ( x) Adeg 2 Adeg Adeg .
AZ Adeg .
Adeg .
Adeg AdegE sn 1 ( x)  Si 1 ( xi )  optional approach to interpolate data.
The not-a-knot spline does not specify any extra conditions at the end points, and this method requires that the third derivative of the spline S '''( x) is continuous at x2 and xn-1.
The natural spline has the known condition that is s ''1 ( x1 )  s ''n ( xn ) 0 .
And the zero-slope spline has the zero slopes in x1 and xn, i.e.
s '1 ( x1 ) s 'n ( xn ) 0 .
B.
Data Sample From the NGSIM program, US 101 (Hollywood Freeway) in Los Angeles, CA is chosen as the test bed.
This test bed involves GIS shape-files (a shape-file generally contains important spatial information and geometry features) and multiple vehicular trajectory data extracted from video (time, location, velocity, vehicle class, lane identification, etc.).
The vehicle trajectory data was collected by the video cameras on the south-bound road  (1)  143  zero-slope spline is the best approach to interpolate individual vehicular velocity.
The second option is the natural spline, and it has higher accuracy than the not-aknot spline.
This conclusion does not correspond to the contrast result of the three models in interpolating the function y = xe-x (the zero-slope spline is the worst interpolation model for this mathematical function interpolation) [19].
It means that vehicular velocity data have specific characteristics, and the vehicular velocity characteristics are different from the non-linear characteristics of general mathematical functions.
In comparison to the piecewise linear model, the three cubic splines are significantly better for vehicular speed interpolation in small time intervals, i.e.
0.2 s and 0.3 s. However, in a larger time interval (0.7 s), the three cubic splines lose their superiority.
Even these splines are a little worse than the piecewise linear model in a 1.0 sa time interval.
In addition, the piecewise linear model sometimes performs better than some of the more complex interpolation methods in earlier experiments on various spatio-temporal interpolation problems [20].
between 7:50 am and 8:05 am on June 15, 2005.
We used the trajectory data from the first video camera.
To achieve a tolerance (e) of Aa 1.0 mph (i.e.
Aa 0.447 m/s), practical use is made of the knowledge that most velocity distributions have standard deviations (s) of approximately 5.0 mph.
With 95% confidence, the formula N rl 1.962s2/e2 = 96 (1.96 is the .975 quartile of the standard normal distribution), so we randomly take 96 vehiclesa trajectory data with a time interval 0.1 s from 1736 vehicles of NGSIM.
TABLE 1.
INTERPOLATION MODEL ESTIMATION  Time interval (sec) t = 0.2 t = 0.3 t = 0.5 t = 0.7 t = .0  Figure 3.
Cubic-spline interpolation.
C. Velocity Interpolation Estimation Fig.
3 illustrates the accuracy estimation method about vehicular instantaneous speed via Root Mean Square Error (RMSE).
RMSE and its mean are defined in the following two equations: n  AS (Y  YE ) i  n  P  j 1  96  Not-aknot Iz (ft/s) 0.1302 0.2493 0.5432 0.9882 1.4495  Natural Iz (ft/s) 0.1294 0.2469 0.5324 0.9770 1.4335  Zeroslope Iz (ft/s) 0.1292 0.2461 0.5292 0.9725 1.4367  (Note that 1.0 ft/s = 0.3048 m/s)  2  V.  (5)  DATA INTEGRATION  The integration of highway spatial data and vehicular trajectory data creates the dynamic transportation environment in spatio-temporal databases.
The highway spatial data come from the transformation of GIS shapefiles.
The trajectory data transformation consists of two parts: the linear approximation of vehicular instantaneous velocity and the determination of instantaneous motion direction.
96  AS RMSE  linear Iz (ft/s) 0.1937 0.3347 0.5895 1.0075 1.3559  i  i 1  RMSE  Piecewise-  j  (6)  where n is the number of the speed data points in the jth vehicle; Lsi is the speed value from the cubic-spline interpolation models; Yi is the raw speed point; and Iz is the mean of RMSE about 96 vehicles' speed.
Our study gives the calculation results concerning four data interpolation models of individual vehicular velocity in Table 1, such as the piecewise-linear, not-a-knot spline, natural spline, and zero-slope spline.
The comparison of data interpolation models does not include the exact-slope spline.
The reason is that the acceleration values, i.e.
the slopes of vehicular speed data, are usually unknown conditions, and they are calculated by speed and time values.
In terms of the estimation results of the three cubicspline models, the error values in Table 1 show that the  A.
Linear Approximation of Velocity The curves in computer software systems are not absolute non-linear; instead, they are some approximate linear data.
By using the velocity points per 0.1 s from the cubic-spline data interpolation method, the piecewiselinear approximation algorithm [18, 28] automatically create the piecewise-linear functions with a high accuracy.
A smaller error threshold (I") in the piecewise-linear algorithm can produce more sub-functions for more accurate speed curve approximation.
From the above data source in Section 4.2, the velocity data of one vehicle  144  (vehicle ID: 2531; vehicle class: auto; and total 300 velocity points in 30 s) are illustrated in Fig.
4.
With the 30 secondsa data sample and the error threshold I" = 0.05 as the input conditions, the piecewiselinear algorithm produces velocity approximations as shown in Fig.
5.
The plot of the velocity approximation is the piecewise-linear function including 180 sub-functions.
RMSE(ft/s)  0.08  0.04 0.02  60 55  0 1 12 23 34 45 56 67 78 89 100 111 122 133 144 155 166 177  Velocity (ft/s)  0.06  50  Function  45  Figure 6.
Velocity estimation (I" = 0.05).
40  B. Vehicular Motion Direction  35  On the basis of the above velocity interpolation methods, the velocity over continuous time can offer vehicular motion distance.
In order to determine vehicular motion direction, the statistical linear regression is used to analyze the longitude and latitude of vehicular location points.
For example, the first sub-function (time from 0 to 1.2 s) in Fig.
5 estimates the vehicular velocity as 39.61 ft/s, so the moving distance is 39.61 ft/s *1.2 s = 47.532 ft.
Fig.
7 gives the direction estimation of the vehicle during the short time interval (1.2 s).
The closer the value of R2, the coefficient of determination , is to 1.0, the better the linear regression fits the data.
The value of R2 is 0.9684, and the calculations about 96 vehiclesa velocity subfunctions show that the range of R2 values is between 0.9221 and 0.9865.
Thus, the location linear regression for vehicular motion direction is an effectual estimation.
30 0  5  10  15  20  Time (second)  25  30  Longitude (feet)  Figure 4.
Individual vehicle velocity sample.
Figure 5.
Velocity approximation (I" = 0.05).
Fig.
6 shows the accuracy estimation of every subfunction via RMSE.
The RMSE has the same function as Eq.
(5), but where n is the number of the data points around a sub-function of the piecewise-linear function; Lsi is the velocity calculated by the sub-function; and Yi is the velocity of the data point.
Most of the RMSE values are very close to 0 ft/s.
Moreover, the RMSE values concerning just a few sub-functions are more than 0.02 ft/s.
When using the error threshold I" = 0.5 as the input condition, the piecewise-linear algorithm creates 48 subfunctions with RMSE value range between 0.2 and 0.45 ft/s.
By using I" = 0.05, the calculation results show that the RMSE values of 96 vehiclesa velocity data are less than 0.11 ft/s (i.e.
0.335 m/s).
1,945 1,940 1,935 1,930 1,925 1,920 1,915 1,910 1,905 1,900 20.1  y = -35.247x + 2651.3 RA, = 0.9684  20.3  20.5 20.7 Latitude (feet)  20.9  21.1  Figure 7.
Location linear regression.
VI.
DATA RETERIVAL  Spatio-temporal databases can offer not only distancebased static data operations as GISs do [21] but also dynamic or temporal operations.
In the experimental case the test-bed spatial data represent the US 101 highway in TVICS, and the input constraint relations are: 145  x  Sum_timeB (sum_max (t4)):- TimeB2 (id, x4, t4).
Car (id, x, y, t), which stores the multiple vehicular motion information at moving location (x, y) and time t. The velocities of the vehicles are described by piecewise-linear functions.
x Road (x, y), which records the static transportation network.
Below we give some example queries: Query 6.1 Find the locations of car 1 at times 6.5 s, 8.5 s, 10.505 s, 12.51 s, and 14.49 s, respectively.
This query is expressed in Datalog [7] as follows:  The output results are those times when the cars reach the road location 167.3 ft and pass the road location 203.0 ft.
The output results also include the sum of these times, which are respectively 87.16 s and 122.17 s. The average travel time is (122.17 a 87.16)/12 = 2.9175 s, hence the space-mean speed is (230 a 167.3)/2.9175 = 21.491 ft/s (i.e.
6.55 m/s).
The storage of space-mean speed is continuous in the TVICS system.
Different results about space-mean speed and travel time can be retrieved from TVICS by changing the location values on the road segment.
Location (x, y): - Car (id, x, y, t), id = 1, t = 6.5.
Location (x, y): - Car (id, x, y, t), id = 1, t = 8.5.
Location (x, y): - Car (id, x, y, t), id = 1, t = 10.505.
Location (x, y): - Car (id, x, y, t), id = 1, t = 12.51.
Location (x, y): - Car (id, x, y, t), id = 1, t = 14.49.
Query 6.3 Find the spacing between car2 and car6 at time 10.5 s. The Datalog query is given below: Spacings (t, s):- Car (2, x2, y, t), Car (6, x6, y, t), s + x6a x2 = 0, t =10.5.
Spacing (t, min(s)):- Spacings (t, s).
In Fig.
8 (a) the moving vehicles are shown in the management of linear programming queries (MLPQ) [30], and Fig.
8 (b) illustrates the result of the above query.
The output result is 154.57 ft, and the different spacing values can be retrieved from databases by inputting different time values.
Query 6.2 Find the vehicular travel times for space-mean speed calculation when 12 cars pass the roadway segment (the location range of road segment is between 150 ft and 600 ft on the horizontal axis).
Since the space-mean speed is computed as the length of roadway segment divided by the average time required to travel the segment [12, 22], Query 4.2 can be expressed in Datalog as follows:  Query 6.4 Find the volume at location 610.45 ft with the time interval between 30 s and 50.9 s. The Datalog query is designed below: Reach_line (id, x, t1):- Car (id, x, y, t1), x = 610.45, t1 > 30, t1 < 50.9.
Reach_time (id, max (t1)):- Reach_line (id, x, t1).
Car_time (id, t2):- Reach_time (id, t2), t2 > 30, t2 < 50.9.
Volume (id):- Car_time (id, t2).
//query time when cars reach location 167.3 ft SpaceA (id, x1, t1):- Car (id, x1, y, t1), x1 >= 167.3.
TimeA1 (id, x2, min (t1)):- SpaceA (id, x2, t1).
TimeA2 (id, x2, t2):- TimeA1 (id, x2, t2), x2 = 167.3.
Sum_timeA (sum_min (t2)):- TimeA2 (id, x2, t2).
The volume query results depend on the inputting location x and time intervals.
The TVICS outputs 5 as the above volume query result and car id numbers (including cars 6, 7, 9, 10, and 11).
//query time when cars pass location 203 ft SpaceB (id, x3, t3):- Car (id, x3, y, t3), x3 <= 203.
TimeB1 (id, x4, max (t3)):- SpaceB (id, x4, t3).
TimeB2 (id, x4, t4):- TimeB1 (id, x4, t4), x4 =203.
(a)  (b)  Figure 8.
Dynamic transportation databases: (a) moving vehicles in MLPQ; (b) individual car tracking and query  146  VII.
Efficient data operations require data consistency and data synchronization in databases by minimizing or avoiding data redundancy [29].
In relational databases traffic data redundancy often causes data anomalies, data corruption, and data retrieval errors.
For example, updating a certain volume value needs to change the values of other traffic parameters [12], such as average daily traffic (ADT), average weekly traffic (AWT), annual average daily traffic (AADT), and annual average weekly traffic (AAWT).
It is difficult for existing transportation management systems to keep data synchronization between volume values and the above four traffic parameters.
The frequent operations of traffic data in databases easily cause data inconsistency or anomalies and data retrieval errors.
By using new traffic data models, spatio-temporal databases just request the collection and storage of individual vehicular time, location, and instantaneous velocity.
Traffic aggregate data can be retrieved from TVICS by database query designs.
Therefore, TVICS provides traffic data archiving methods that can solve the above problems concerning traffic data redundancy.
DISCUSSION OF RESULTS  A.
Data Completeness Data completeness requires that database schema should include all information in the data source to meet the current and future demands of various data users.
Traffic stream is observed at each spatial point within some distance interval over time, not just at one spatial point [22].
Fig.
9 shows the traffic stream over continuous time and space as a set of steps.
Each step represents the occurrence of an individual vehicle and the edge of each step represents the trajectory of the vehicle.
Existing transportation software systems [24-27] store just discrete traffic aggregate data, such as volume, density, headway, queue length, spacing etc.
in relational databases.
Aggregate data incompleteness in space and time causes the insufficient performance of traffic engineering models in transportation software systems.
For example, due to the lack of volume over continuous time and space, not all travelers can gain desired travel time query information from volume-based travel time estimation models in advanced traveler information systems (ATIS) [28].
TVICS, developed based on MLPQ, is the first traffic management system that can offer traffic aggregate data over continuous space and time.
Complete traffic aggregate data are useful data sources for the description of traffic flow phenomena and for the calculation of various transportation engineering models.
TVICS can be particularly advantageous in understanding highway flow breakdown, i.e.
incident detection, and dynamical traffic congestion, because a detailed picture of traffic parameters over both time and space is better than these parameters in time alone.
VIII.
CONCLUSIONS  Video cameras can easily collect traffic information, but storing the raw video data generally requires a huge storage space.
The TVICS system is recommended to overcome the storage problem by converting traffic videos into a spatio-temporal database.
Since TVICS was developed on top of the MLPQ system, it allows high-level Datalog and SQL queries, including specific predefined queries related to traffic management.
The TVICS queries can search the complete continuous motion information of the moving vehicles.
As a further work, we plan to analyze different traffic situations that result in heavy traffic congestions or collisions [31].
The ultimate goal of traffic management systems is to improve the road conditions for vehicles and their drivers.
ACKNOWLEDMENT The authors gratefully acknowledge Laurence R Rilett for his comments about interpolation model estimation and pointing out some related references.
REFRENCES [1] H. J. Miller, aPotential Contributions of Spatial Analysis to Geographic Information Systems for Transformationa, Geographical Analysis 31, pp.
373-399, 1999.
[2] A. J. Butler and K. J. Dueker, aImplementing the enterprise GIS in transportation database designa, URISA Journal, Vol.
13, No.
1, 2001.
[3] Y. Gong, aAudio and Visual Content Summarization of a Video Programa, Chapter 10 in: Handbook of Video Databases: Design and Applications, B. Furht and O.
Figure 9.
Traffic stream with a spatio-temporal pattern [23].
B.
Data Redundancy Discrete traffic aggregate data archives cause not only the loss of a large amount of aggregate traffic data, but also the increase of data redundancy in databases.
Aggregate data are a typical data redundancy in databases, and it means that some data are stored for multiple times.
147  Marques (Eds.
), 2003.
[4] H. D. Wactlar, M. G. Christel, Y. Gong and A. G. Hauptmann, aLessons Learned from Building a Terabyte Digital Video Librarya, IEEE Computer, Vol.
32, pp.66-73, 1999.
[5] Y.
A. Aslandogan and C. T. Yu, aTechniques and Systems for Image and Video Retrievala, IEEE Transactions on Knowledge and Data Engineering, Vol.
11, pp.56-63, 1999.
[6] J. Agma, M. Traina and C. Traina Jr., aSimilarity Search in Multimedia Databasesa, Chapter 29 in: Handbook of Video Databases: Design and Applications, B. Furht and O. Marques (Eds.
), 2003.
[7] P. Kanellakis, G. Kuper, P. Z. Revesz, aConstraint Query Languagesa, Journal of Computer and Systems Sciences, Vol.
51, No.
1, pp.
26-52, 1995.
[8] Cambridge Systematics, Inc.
Prepared for Federal Highway Administration.
NGSIM U.S. 101 Data Analysis (7:50 a.m. to 8:05 a.m.), December 2005.
[9] A. Skabardonis and V. Alexiadis, aTraffic Data through the Berkeley Highway Laboratorya, Workshop on Traffic Modeling, Sedona, AZ, Sept. 2005.
[10] Z. Kim, G. Gomes, R. Hranac and A. Skabardonis, aA Machine Vision System for Generating Vehicle Trajectories over Extended Freeway Segmentsa, the 12th World Congress on Intelligent Transportation Systems, 2005.
[11] H. Wei, C. Feng, E. Meyer, and J. Lee, aVideo-CaptureBased Approach to Extract Multiple Vehicular Trajectory Data for Traffic Modelinga, Journal of Transportation Engineering, Vol.
131, No.
7, 2005.
[12] R. P. Roess, E. S. Prassas, and W. R. McShane, Traffic Engineering, 4th Edition, Pearson Prentice Hall, 2011.
[13] R. H. Tao, H. Wei, Y. H. Wang, and V. P. Sisiopiku, aModeling Speed Disturbance Absorption Following Statecontrol Action-expected Chains: Integrated Car-following and Lane-changing Scenariosa, the 83rd Annual Meeting of Transportation Research, Washington, D.C. 2004.
[14] H. Wei, Observed Lane-choice and Lane-changing Behaviors on an Urban Street Network Using VideoCapture-based Approach and Suggested Structures of their Models.
Ph.D. dissertation, Univ.
of Kansas, KS, 1999.
[15] C. X. Chen, Data Models and Query Languages of Spatiotemporal Information.
Ph.D. Dissertation, University of California, Los Angeles, CA, 2001.
[16] H. Yin, O. Wolfson, aA Weight-Based Map Matching Method in Moving Objects Databasesa, the 16th International Conference on Scientific and Statistical Database Management, 2004.
[17] J. Liu, O. Wolfson, and H. Yin, aExtracting Semantic Location from Outdoor Positioning Systemsa, International Workshop on Managing Context Information and Semantics in Mobile Environments, 2006.
[18] H. Yue, E. Jones, and P. Z. Revesz, aLocal Polynomial Regression Models for Average Traffic Speed Estimation and Forecasting in Linear Constraint Databasesa, 17th International Symposium on Temporal Representation and Reasoning, Paris, France, 2010.
[19] G. Recktenwald, Numerical Methods with MATLAB: Implementation and Application, Prentice Hall, 2000.
[20] L. Li and P. Z. Revesz, aInterpolation Methods for Spatiotemporal Geographic Dataa, Computers, Environment and Urban Systems, Vol.
28, No.
3, pp.
201-227, 2004.
[21] H. Yue and E. Jones, aArchiving Capability of Spatiotemporal Data in Different Highway Railroad Grade Crossing (HRGC) Databasesa, Annual Intelligent Transportation System Conference, Houston, USA, 2010.
[22] B. S. Kerner, Introduction to Modern Traffic Flow Theory and Control: The Long Road to Three-Phase Traffic Theory, Springer, 2009.
[23] W. Leutzbach, Introduction to the Theory of Traffic Flow, Springer, Berlin, 1988.
[24] H. Al-Deek and A. Abd-Elrahman, aAn Evaluation Plan for the Conceptual Design of the Florida Transportation Data Warehousea, University of Central Florida, Technical Report No.
16-50-706, 2002.
[25] J. Dahlgren, R. C. Garcia and S. Turner, Completing the Circle: Using Archived Operation Data to Better Link Decision to Performance, California Path Research Report No.
UCB-ITS-PRR-2001-23, September 2001.
[26] H. X. Liu, R. He, Y. Tao and B.
Ran, aA Literature and Best Practices Scan: ITS Data Management and Archivinga, University of Wisconsin at Madison Technical Project No.
0092-02-11, May 2002.
[27] H. Yue and R. Yang, aDevelopment of Intelligent Transportation Systems (ITS) and Plan of Integrated Information Systema, Journal of Wuhan University of Technology, Oct. 2005.
[28] H. Yue.
aAdvanced Traveler Information Inquiry, Archiving, and Decision Making Systema, the 4th Chinese Oversea Student aChunHui Cupa Entrepreneurship Competition, Project Presentation, Dec. 2009.
[29] A. Schwinn and J. Schelp, aData Integration Patternsa, Business Information Systems Conference, Colorado Springs, USA, 2003.
[30] P. Z. Revesz, Introduction to Database: From Biological to Spatio-Temporal, Springer, New York, 2010.
[31] S. Anderson and P. Z. Revesz, aEfficient Max Count and Threshold Operators of Moving Objectsa, Geoinformatica, Vol.
13, No.
4, pp.
355-396, 2009.
148
titative temporal information 7].
Moreover, we are also applying LaTeR to model-based diagnosis of dynamic systems.
In both cases, LaTeR high-level language provide a useful interface for obtaining a loosely coupled integration, and LaTeR's e	cient treatment of queries (and updates) provides crucial advantages.
A discussion on such applications can be found in 5].
A prototype of LaTeR has been implemented in C on Sun workstations, under the UNIX operating system.
References  1] J. Allen.
Maintaining knowledge about temporal intervals.
Communications of the ACM, 26:832{ 843, 1983.
2] J. Allen.
Time and time again: the many ways to represent time.
Int.
J.
Intelligent Systems, 6(4):341{355, 1991.
3] R. Arthur and J. Stillman.
Temporal reasoning for planning and scheduling.
Technical report, AI Lab, General Elettric Research Center, 1992.
4] V. Brusoni, L. Console, B. Pernici, and P. Terenziani.
LaTeR: a general purpose manager of temporal information.
In Methodologies for Intelligent Systems 8, pages 255{264.
Lecture Notes in Computer Science 869, Springer Verlag, 1994.
5] V. Brusoni, L. Console, B. Pernici, and P. Terenziani.
Dealing with time in knowledge based systems: a loosely coupled approach.
In Proc.
FLAIRS '95, Melbourne, FL, 1995.
6] V. Brusoni, L. Console, and P. Terenziani.
On the computational complexity of querying bounds on dierences constraints.
Articial Intelligence (to appear), 1995.
7] L. Console, B. Pernici, and P. Terenziani.
Towards the development of a general temporal manager for temporal databases: a layered and modular approach.
In Proc.
of the Int.
Work.
on an Infrastructure for Temporal Databases, Arlington, Texas, 1993.
8] E. Davis.
Constraint propagation with interval labels.
Articial Intelligence, 32:281{331, 1987.
9] T. Dean and D. McDermott.
Temporal data base management.
Articial Intelligence, 32:1{ 56, 1987.
10] R. Dechter, I. Meiri, and J. Pearl.
Temporal constraint networks.
Articial Intelligence, 49:61{ 95, 1991.
11] A. Gerevini and L. Schubert.
E	cient temporal reasoning through timegraphs.
In Proc.
13th IJCAI, pages 648{654, Chambery, 1993.
12] H. Kautz and P. Ladkin.
Integrating metric and qualitative temporal reasoning.
In Proc.
AAAI 91, pages 241{246, 1991.
13] J. Koomen.
The TIMELOGIC temporal reasoning system.
Technical Report 231, Computer Science Department, University of Rochester, Rochester, NY, March 1989.
14] L. McKenzie and R. Snodgrass.
Evaluation of relational algebras incorporating the time dimension in databases.
ACM Computing Surveys, 23(4):501{543, 1991.
15] I. Meiri.
Combining qualitative and quantitative constraints in temporal reasoning.
In Proc.
AAAI 91, pages 260{267, 1991.
16] R. Snodgrass, editor.
Proc.
of the Int.
Work.
on an infrastructure for Temporal Databases.
1993.
17] A. Tansell, R. Snodgrass, J. Cliord, S. Gadia, and A. Segev.
Temporal Databases: Theory, design and implementation.
Benjamin Cummings, 1993.
18] P. VanBeek.
Approximation algorithms for temporal reasoning.
In Proc.
11th IJCAI, pages 1291{1297, 1989.
19] P. VanBeek.
Temporal query processing with indenite information.
Articial Intelligence in Medicine, 3:325{339, 1991.
20] M. Vilain.
A system for reasoning about time.
In Proc.
AAAI 82, pages 197{201, 1982.
21] M. Vilain and H. Kautz.
Constraint propagation algorithms for temporal reasoning.
In Proc.
AAAI 86, pages 377{382, 1986.
22] M. Vilain, H. Kautz, and P. VanBeek.
Constraint propagation algorithms for temporal reasoning: a revised report.
In D.S.
Weld and J. de Kleer, editors, Readings in Qualitative Reasoning about physical systems, pages 373{381.
Morgan Kaufmann, 1989.
23] Ed Yampratoom and J. Allen.
Performance of temporal reasoning systems.
SIGART Bulletin, pages 26{29, 1993.  long less than 100 and more than 75% for sequences long from 100 to around 200.
A more detailed evaluation of the results can be found in 6].
5 Comparisons with Related Work  Dierent criteria can be considered in order to compare the temporal managers developed in the articial intelligence literature.
A rst important criteria concerns completeness.
In LaTeR, as in many articial intelligence approaches, we choose to retain completeness.
since it seems important to us in order to provide users and applications with uncontestable and reliable results.
This rises a trade-o between expressive power and computational complexity of complete temporal reasoning.
As e.g.
in Timegraph 11] and in Tachyon 3] we chose to limit the expressive power in order to retain tractability.
In particular, the expressive power of LaTeR is comparable to that of Tachyon, which deals with temporal constraints that can be mapped onto conjunctions of bounds on differences, too.
In 23], Allen distinguishes between two dierent class of temporal managers: (i) managers that use a constraint satisfaction technique at assertion time, building an all-to-all graph with the constraints between each pair of temporal entities in the knowledge base (ii) managers that build partial graph structures, which need further processing at query time.
For instance, Allen classied TimeLogic 13], MATS 12] and Tachyon 3] as systems of the rst type, and Timegraph 11] and TMM 9] as systems of the second type.
In 23], Allen, considering only atomic queries (i.e., queries for extracting the constraints between two entities in the graph, or yes/no queries without conjunction) pointed out that the approaches computing the all-to-all graph are more e	cient than those computing only partial graphs when dealing with queries.
In fact, in these approaches, queries can be answered in constant time, by reading the values from the graph, while in the approaches in (ii) some further reasoning may be needed.
On the other hand, the approaches in (i) are less e	cient when dealing with assertions (updates), since the whole all-to-all graph has to be computed after each assertion.
LaTeR is a system computing the all-to-all graph (which is the minimal network in the case of LaTeR) that reconciles the advantages of both types of approaches, thanks to its e	cient treatment of complex queries and of assertions as hypothetical queries.
This  result has been obtained via the treatment of complex types of queries.
As shown in van Beek's work 19], as soon as one considers non-atomic queries (even only conjunctions of yes/no queries), two problems arise: on the one hand, the distinction between queries about necessity and queries about consistency is needed on the other hand, constraint propagation may be required.
Van Beek's work has two major limitations with respect to the work in this paper: (i) it deals with qualitative information only and (ii) it performs constraint propagation on the whole network (global propagation) both for queries about necessity and queries about consistency (notice, however, that Van Beek allows the use of all logical connectives in the query language, although answering queries becomes exponential).
On the other hand, we showed that propagation is needed only for queries about consistency (and hypothetical queries, which are not considered in 19]) and, even in such a case, local propagation is su	cient.
Thus, LaTeR retains the e	cient query processing typical of approaches computing the all-to-all graph also in case complex queries.
Furthermore, since in LaTeR assertions followed by queries can be simulated by hypothetical queries (which are answered by local temporal reasoning), LaTeR does not have to recompute the whole all-to-all graph at each assertion, so that also assertions are managed e	ciently.
Besides providing the computational advantages above, LaTeR treatment of dierent (and complex) types of queries seems to us a main feature of the system in itself, since queries (and assertions) constitute the main way of interacting with temporal managers.
Thus, we believe that the expressive query language (and manipulation language) constitutes an advantage of LaTeR with respect to the other systems in the literature.
For instance, high-level interface languages are widely used in the temporal databases community.
However, most of the approaches to temporal databases only deal with time stamps associated with information and do not consider temporal relations between entities (see, e.g., 14]), so that temporal constraint propagation is not needed.
6 Conclusions  In the paper we showed how queries on an heterogeneous temporal knowledge base can be answered e	ciently, independently of the dimension of the knowledge base Currently, LaTeR is being loosely coupled with Oracle, in order to extend relational databases to deal also with (possibly imprecise) qualitative and quan-  the consistency of the knowledge base and thus consistency must be checked after each update and before answering the queries following the update itself.
Since answering queries in an inconsistent knowledge base is meaningless, the consistency check must be performed anyway.
Moreover, the minimal network of the updated knowledge base can be produced by the same algorithms that check consistency.
This means that the presence of updates does not aect the e	ciency of our approach: consistency has to be checked anyway but this produces the minimal network and queries can be answered e	ciently given the minimal network (see the previous section).
Our approach, on the other hand, suggests an e	cient way for dealing with a class of updates, specifically updates that add new constraints (which are the most common in many applications, see the discussion in 5]).
In fact, in such a case one can answer the queries following an update as hypothetical ones.
More specically, a query Q following an update U can be answered as the hypothetical query: Q if U which only involves local propagation.
If a query Q follows a sequence of updates U1  : : : Uh , this can be simulated as the query Q if U1  : : :Uh .
The advantage of such an approach is that during a session of interleaved queries and updates all the operations can be performed with local propagation and the actual update of the knowledge base (which can be very costly) can be delayed with respect to the query process (e.g., performed once and o-line at the end of the session).
Dealing with updates as hypothetical queries can provide signicant computational advantages.
However, when the sequence of updates and queries becomes very long and the updates involve signicant parts of the knowledge base, such advantages may be lost.
A detailed evaluation of the such computational advantages and trade-os can be found in 6] where we compare: the case where the minimal network is recomputed after each update (and then queries are answered with local propagation as discussed in the previous section) the case where queries are dealt with as hypothetical ones.
The evaluation is performed by taking into account three dierent parameters: The length of the sequences (\k" in (7)) The average dimension of updates/queries (we assume that updates and queries have the same  average dimension), i.e., the average ratio between the dimension of queries/updates and the dimension of the knowledge base How extensive the updates are, that is: how many entities involved in the i ; th update were not involved in the previous ones.
At one extreme, all the updates may involve the same set of variables (i.e., the same part of the knowledge base is repeatedly changed) at the other extreme, each update may involve a part of the knowledge base that was not involved by any previous update and thus the updates in the sequence tend to involve larger and larger parts of the knowledge base as the length of the sequence increases (in general, both extreme cases are unlikely taking this as a parameter allows us to consider all possibilities).
Two dierent evaluations are then performed: First of all we evaluated the break-even point between the two approaches that is: the maximum length of the sequence for which dealing with updates as hypothetical queries provides advantages, given the average dimension and extension of the updates or, conversely, which is the maximum dimension for the updates for which there are advantages, given the length of the sequence.
For example, it turned out that for a sequence of 40 updates and queries in which one half of the variables involved in each update was not involved by previous ones (so that the updates tend to extend to signicant parts of the knowledge base), dealing with updates as hypothetical queries provides advantages when the average dimension of each update/query is less that 7% of the knowledge base.
Conversely, when the average dimension of each query/update is 1% of the knowledge base, the approach is advantageous when the length of the sequence is less than 320.
From our experience in the practical application of LaTeR (see 5]), these dimensions are realistic in the sense that it is common that the dimension of updates/queries is around 1% of the dimension of the knowledge base and in any case never more than 5%.
We evaluated how big the computational advantage is.
For example, when the average dimension of update/queries is 1% of the knowledge base (and one half of the variables involved in each update were not involved in previous ones), the advantage is around 90% if the sequence is  Each one of the constraints in (6), taken in isolation, is consistent with (5), but the conjunction in (6) is inconsistent with (5).
Thus constraint propagation is needed in order to check whether a set of constraints is consistent with a given knowledge base.
However, we proved that global propagation of the constraints in the query to the whole knowledge base is not needed for computing the answer.
In fact, since the minimal network is available and since the goal is not to update the whole knowledge base but just to answer the query, local propagation is su	cient (local propagation concerns only the variables in the query).
More formally, we proved the following theorem (the proof can be found in 6]):  Theorem 1 Let S be a set of variables, K:B: a set  of bounds of dierences on such variables and NS the consistent minimal network computed by the (complete) propagation algorithm.
Let us consider a query MAY (Q) on K:B: (where Q is a conjunction of atomic tests) referring to a set G  S of variables (i.e., all the constraints in the query involve only variables in G).
Let NS be the minimal network obtained by propagating the constraints in Q to NS (i.e., to all the variables - global propagation in S ) and NG the minimal network obtained by propagating the constraints in Q to NG , where NG is the restriction of NS to the variables in G (local propagation) then NS is consistent if and only if NG is consistent.
0  0  0  0  The theorem guarantees that in order to answer MAY queries of the form: MAY (C1 AND C2 : : : AND Cn) it is su	cient to propagate the constraints Ci in the query to the part of the minimal network whose nodes are the variables in the query (i.e., occurring in C1 C2 : : : Cn ).
Therefore conjunctive MAY queries can be answered in a time that is cubic in the number of variables in the query and that is independent of the dimension of the knowledge base.
3.2.3 Hypothetical Queries.
Hypothetical queries are queries of the form Q if C where Q is a query of one of the types discussed in the previous subsections and C is a conjunction of temporal constraints, expressed in LaTeR's high-level language.
For example, given the knowledge base in gure 1, the following queries could be asked:  HowLong John work If Mary work Lasting 4h 50min?
Answer : 5h MUST ( Tom work During Mary work) If Mary work Lasting 4h 50min?
Answer : Y es In principle, an hypothetical query should be answered in 3 steps: (i) adding the constraints C to the temporal knowledge base (ii) computing the minimal network N for the new knowledge base (iii) answering the query Q given N .
However, we proved the following theorem (see 6] for more details): Theorem 2 Given S, NS , G, NG , Q, NS and NG as in Theorem 1, then for each pair of variables hX Y i in G, the maximal admissibility range for X ; Y provided by NG (minimal network computed with local 0  0  0  0  0  propagation) is the same as the maximal admissibility range for X ; Y provided by NS (minimal network computed with global propagation).
0  In other words, as regards the variables in G, local propagation to the part of the minimal network concerning the variables in G produces the same results as global propagation to the whole minimal network.
This means that, for any query Q If C, it is su	cient to proceed as follows: perform local propagation of the constraints in C to the part of the minimal network involving the variables in C fi Q Answer Q as discussed in the previous subsections.
The theorem guarantees that this procedure provides the same result that would be obtained by propagating the constraints in C to the whole knowledge base before answering the query Q.
Thus, also hypothetical queries are answered in LaTeR in a time which is independent of the dimension of the knowledge base (more specically, in a time that is cubic in the number of variables in C fi Q).
4 Dealing with updates  In the practical applications of temporal reasoning queries are interleaved with updates.
In other words, a typical session with a temporal knowledge server could have the form of a sequence: U1  Q1 U2 Q2 : : : Uk  Qk (7) of alternated updates (Ui ) and queries (Qi ).
An update corresponds to the the addition or removal of some temporal assertion.
Each update may aect  MAY ( Tom work During Mary work AND start(John work) After 1620) which involves checking that the conjunction of the two assertions is consistent with the knowledge base.
Given the example in gure 1 the answer to such a query is negative.
Queries about consistency/necessity are mapped into conjunctions of atomic tests each one of which is a check on the distance between two time points (and thus the dierence between two variables in the minimal network).
The mapping is the same used for translating assertions into bounds on dierences sketched in section 2.
For example, the conjunction of atomic tests corresponding to the queries (1) and (2) above are respectively: MUST( 0 < STW ; SMW AND 0 < EMW ; ET W) MAY ( 0 < ST W ; SMW AND 0 < EMW ; ET W ) (STW and ET W are as above SMW and EMW are the starting and ending points of \Mary work").
In other words, high level queries about consistency (necessity) are answered by checking that a conjunction of bounds on dierences (atomic tests) is consistent (follows necessarily) from the constraints in the knowledge base.
Given the minimal network, atomic tests can be performed as local checks on such a network.
However, dierent checks are performed in case of MUST and MAY queries as a result the computational complexity of the cases is dierent, as it will be discussed in the two following subsections.
3.2.1 MUST queries  Let us consider a query about necessity of the form MUST(C1 AND C2 : : : AND C ), where each C is an atomic test of the form c  X ; Y  d .
We distinguish two cases:  (n = 1), i.e., the query involves only one atomic test and thus has the form: MUST(c  X ; Y  d) Let afi b] be the maximal admissibility range for the dierence X ; Y (read from the minimal network).
The query is satised i all the values for X ; Y which satisfy the constraints are in cfi d], that is: MUST (c  X ; Y  d) , cfi d]  afi b] (3) Intuitively, since the maximal admissibility range afi b] includes all the values for X ; Y satisfying the constraints, then any interval cfi d] such that cfi d]  afi b] includes all the values for n  i  i  i  i  i  X ; Y satisfying all the constraints.
A query involving one constraint can thus be answered in constant time with a simple lookup in the minimal network and a containment check.
 (n > 1), i.e., the query involves a conjunction of atomic tests and has the form MUST (C1 AND C2 : : : AND C ).
In this case each one of the C can be checked independently of the others since the following property holds: MUST(C1 AND C2 : : : AND C ) , MUST(C1 ) AND : : :AND MUST(C ) n  i  n  n  Thus a query about necessity can be answered in time linear in the number of constraints (and thus in the number of variables) in the query.
3.2.2 MAY queries  Let us consider a query about possibility, i.e., of the form MAY (C1 AND C2 : : : AND C ), where each C is an atomic test of the form c  X ;Y  d .
This case is more complex than the one of MUST queries since the MAY operator does not distribute over a conjunction.
The base case, however, is similar, in the sense that when n = 1, the answer to a query of the form: MAY (c  X ; Y  d) can be provided with a local check on the minimal network.
Let afi b] be the maximaladmissibility range for the dierence X ; Y (read from the minimal network).
The query is satised i there is (at least) a value p 2 cfi d] for X ; Y which satises all the constraints, that is: MAY (c  X ; Y  d) , cfi d] \ afi b] 6= 	 (4) Intuitively, since the maximal admissibility range afi b] includes only values for X ; Y satisfying the constraints in the knowledge base, then any interval cfi d] intersecting afi b] contains at least one value for X ; Y satisfying all the constraints.
The case where the consistency of a conjunction of constraints has to be checked is more complex since atomic tests are not independent of each other.
For instance, consider the knowledge base formed by the following constraints: f0  X ; Z  30fi 5  Z ; W  25fi 10  Y ; X  20fi 15  Y ; Z  30g (5) and the query: MAY (15  Y ; Z  20 AND 15  X ; Z  20) (6) n  i  i  i  i  i  where STW and ET W (SJW and EJW) are the variables associated with the starting and ending points of \Tom work" (\John work") respectively.
Given a knowledge base of temporal information (expressed as bounds on dierences), its consistency must be checked before answering queries (or performing updates), since query processing is not interesting in an inconsistent knowledge base.
LaTeR checks the consistency of a set of bounds on dierences constraints using the complete algorithm discussed in 10], whose complexity is O(N 3), where N is the number of variables.
This algorithm produces the minimal network of the set of constraints, i.e., a compact representation of all the solutions.
More specically, for each pair hXfi Y i of variables, the minimal network provides the maximal admissibility range afi b] for the dierence X ; Y .
In other words afi b] is the set of all and only the values for X ; Y consistent with the knowledge base.
LaTeR keeps track of such a network since, as we shall discuss in the following section, this provides interesting computational advantages during query processing.
3 Ecient Query Answering in LaTeR  At least three dierent types of high-level queries are important for querying a temporal knowledge base: queries for extracting some piece of information from the knowledge base (e.g., the duration of an event or the relation between two events), queries for checking whether a set of temporal constraints is consistent with or follows necessarily from the knowledge base and hypothetical queries.
LaTeR provides a high-level language for expressing all these types of queries.
Queries in the high-level language are then translated into the corresponding low-level queries on bounds on dierences constraints, which are answered eciently, in a time that is independent of the dimension of the knowledge base.
Let us consider the types of queries listed above one at a time.
3.1 Queries for extracting temporal information.
Dierent high-level primitives are provided: When, HowLong, Delay and Relation, which give as answer respectively (1) the temporal location of temporal entities (points or intervals), (2) the duration of time intervals, (3) the delay between two time points and (4) the temporal relations between two temporal entities.
These queries can be answered by a simple lookup in the minimal network.
For example, given the knowledge base in gure 1, the following query could be asked:  HowLong John work?
Answer : 4hfi 50min ; 5h This query can be answered by simply reading in the minimal network the maximal admissibility range of the dierence between the variables corresponding to the end and start of \John work".
As a further example, the following query could be asked: Relation Mary workfi John work Answer : start(Mary work) After start(John work) end(Mary work) non strict Before end(John work) Also in such a case the answer can be read directly from the minimal network (and is then translated in the output format above).
Notice that the answer corresponds to the following relation in Allen's interval algebra: Mary work (During OR Finishes) John work  3.2 Queries about consistency/necessity.
A second important type of query is that of Yes/No queries for asking whether a set (conjunction) of constraints is true in the given knowledge base.
Since in LaTeR temporal information may be imprecise, it is necessary to distinguish whether some conclusion must necessarily hold (i.e., it is entailed by the knowledge base) or whether it may hold (i.e., it is consistent with the knowledge base).
This distinction is similar, e.g., to the one in 19].
Therefore, modal operators must be introduced in the query language in order to distinguish between queries asking whether a set of constraints is possible (consistent) given the knowledge base or whether it follows from the knowledge base.
In LaTeR queries about necessity/consistency are expressed by prexing the MUST or MAY operator to the primitives of the high level manipulation language.
For instance, given the knowledge base in gure 1, one could ask: MUST (T om work During Mary work) (1) MAY (T om work During Mary work) (2) (1) corresponds to asking whether the relation Tom work During Mary work is entailed by the knowledge base (2) asks whether it is consistent with the knowledge base.
Given the knowledge base in gure 1, the answer to (1) is negative while the answer to (2) is positive.
Conjunction is also provided, so that one can ask for the necessity/consistency of a conjunction of temporal constraints.
For example, one could ask the following query:  the approaches that maintain the minimal network and those that perform reasoning at query time 23] discussing how our approach strongly supports the former alternative (since we deal eciently with complex queries and with a class of updates).
2 Representing time in LaTeR  LaTeR is a general purpose manager of temporal  information conceived as a \knowledge server" that can be loosely-coupled with dierent Articial Intelligence and database applications 4, 5].
We believe that a knowledge server must have a predictable behavior.
This has at least two main consequences: (i) from the inferential point of view, complete temporal reasoning must be performed (ii) from the computational point of view, reasoning must be performed in polynomial time.
Moreover, a friendly interface language for interacting with the system must be available in particular, a powerful query language must be provided and query processing must be performed very eciently.
LaTeR is a two-level architecture: the higher level provides the manipulation and query interface language (to which we shall return in the following) the lower level is based on the use of a constraint framework.
LaTeR assumes that time is linear, totally ordered, continuous and metric.
Time points are the basic entities an interval I is dened as a convex set of time points with a starting and an ending point, denoted respectively as start(I) and end(I) (with start(I) < end(I)).
The distance between time points is the basic primitive in our approach and is dened as follows: Given two time points P1 and P2, the assertion distance(P1,P2,afi b]) is true i the distance between P1 and P2 is between a and b, where afi b 2 Rfi a  b:1 The notion of distance is isomorphic to the notion of dierence between reals.
Thus, standard and well-known constraint propagation techniques (see 8] or frameworks such as tcsp and stp 10]) can be used to implement such a notion: the variables correspond to the time points and each assertion distance(P1,P2,afi b]) can be represented as a bound on the dierence between the variables X1 and X2 corresponding to P1 and P2, i.e., as a linear inequality of the form: a  X2 ; X1  b In order to achieve the goal of tractable complete reasoning we limited the expressive power to deal 1 We consider also the case where one of the extremes and b or both of them are not included, i.e.
the range is partially or completely open.
a  only with conjunctions of bounds of dierences, in which complete constraint propagation is performed in O(N 3 ) (where N is the number of variables).
The expressive power of LaTeR's lower level is thus the one of stp 10].
LaTeR provides a high-level interface language for manipulating and querying a temporal knowledge base.
Each assertion in such a language is translated (in constant time) into a set of lower-level constraints (bounds on dierences).
Given the restrictions above on the lower level, we have some restrictions on the expressive power of the interface language.
In particular, the following types of information can be expressed: precise or imprecise location of time points and intervals, precise or imprecise duration of time intervals, precise or imprecise delay between time points, qualitative relations between points, intervals or points and intervals, limiting to the continuous pointisable relations 22] (as discussed in 19] this is not too restrictive in practice since many commonly used relations are indeed continuous pointisable).
Figure 1 provides examples of assertions in LaTeR's high level language (see 4] for a denition of the language).
John work Since 1400 ; 1430 Until 1800 ; 1900 start(Mary work) 10 ; 40 min After start(John work) Mary work Lasting AtLeast 4 hfi 40 min end(Mary work) non strict Before end(John work) Tom work Since 1415 Until 1830 Tom work During John work Figure 1: A simple knowledge base.
For example, the rst assertion localizes (in an imprecise way) the interval of time corresponding to \John work" the second denes a delay between the starting point of \Mary work" and the starting point of \John work" the third denes the duration of \Mary work".
The non strict operator can be used in conjunction with the precedence (and containment) relations to express that the relation itself is not strict (in the example the meaning is that the end of \Mary work" is before or equal the end of \John work").
As an example of the translation of high-level assertions into bounds on dierences, the last assertion in gure 1 is translated into bounds on dierences as follows: (0 < STW ; SJW ) ^ (0 < EJW ; ET W)  Ecient query answering in LaTeR  V. Brusoni and L. Console and P. Terenziani Dip.
Informatica, Universitfia di Torino, Corso Svizzera 185, 10149 Torino, Italy E-mail: fbrusoni,lconsole,terenzg@di.unito.it  Abstract  In the paper we address the problem of answering queries eciently in heterogeneous temporal knowledge bases (in which qualitative and quantitative pieces of information are amalgamated).
In particular, we rst outline a powerful high-level language for querying a temporal knowledge base.
We then show that, in our language, if the minimal network computed during consistency checking is maintained, then queries can be answered eciently in time that depends only on the dimension of the query and is independent of the dimension of the knowledge base.
Finally, we discuss how our approach can deal eciently also with updates and, specically, with sequences of interleaved updates of the knowledge base and queries.
1 Introduction  A lot of attention has been paid in the Articial Intelligence community to the problem of dealing with time 2, 22].
In particular, most articial intelligence approaches focus on reasoning issues 1, 15, 18, 20, 21].
On the other hand, the problems of (i) designing a high level language for manipulating and querying temporal knowledge bases and (ii) answering (complex) queries eciently have been often disregarded.
Some of these problems have been faced in the database community 14, 16, 17] where, however, reasoning and complexity issues received only a limited attention.
The aim of this paper is to reconcile these two complementary tendencies in a general-purpose manager of temporal information: LaTeR (Layered Temporal Reasoner).
In LaTeR heterogeneous temporal information (that is, qualitative and quantitative information) is amalgamated in a principled way startThis work was partially supported by CNR under grant no.
94.01878.CT07.
ing from the notion of distance between time points.
LaTeR, moreover, provides a high-level language for manipulating temporal information the expressive power of the language has been limited in such a way that complete constraint propagation can be performed in polynomial time (section 2 sketches those aspects of LaTeR that are relevant in this paper, see 4, 5] for more details).
The paper denes a powerful query language including modal operators for asking whether a set of assertions follows necessarily from a knowledge base or it is only possibly true and supporting yes/no queries, queries for extracting temporal information and hypothetical queries.
We believe that having a powerful language for querying temporal knowledge bases is fundamental for the practical applicability of managers of temporal information.
The main goal of the paper is to propose an approach for answering queries eciently in a temporal knowledge base (section 3).
Notice that the problem is interesting only in case the knowledge base is consistent since answering queries such as those mentioned above in an inconsistent knowledge base is banal.
We show that in our language, if we maintain the propagated knowledge base (\minimal network") obtained as a result of checking consistency of the knowledge base, then the complexity of answering queries is independent of the dimension of the knowledge base and depends only on the dimension of the query, where the dimension of a knowledge base (query) corresponds to the number of temporal entities involved in the knowledge base (query).
A critical aspect when the minimal network is maintained is that of updating such a network each time the knowledge base is updated (since, in principle, the whole network has to be recomputed after every update).
In the paper we discuss how updates to the temporal knowledge base and interleaved sequences of updates and queries can be dealt with efciently in our approach (section 4).
In section 5 we compare our approach to related ones.
In particular, we consider the trade-o between
2012 19th International Symposium on Temporal Representation and Reasoning  Guarded Ord-Horn: A Tractable Fragment of Quantified Constraint Satisfaction Hubie Chen Departament de Tecnologies Universitat Pompeu Fabra Barcelona, Spain hubie.chen@upf.edu  Michal Wrona Department of Computer and Information Science Linkopings universitet SE-581 83 Linkoping, Sweden michal.wrona@liu.se  as the quantified constraint satisfaction problem (QCSP).
A structure over which the CSP or the QCSP is studied is typically referred to as a constraint language.
Classical examples of problems that follow this paradigm are the 2-SAT and Horn-SAT fragments of propositional logic, and their quantified analogs, Quantified 2-SAT [5] and Quantified Horn-SAT [6]; all of these problems are polynomial-time tractable.
One obtains these problems within the presented framework in particular by taking the constraint language to contain all relations definable by 2-clauses or, respectively, all relations definable by Horn clauses.
Another example of this paradigm is the positive first-order theory of equality [7], which can be obtained by taking the quantified constraint satisfaction problem on the constraint language containing all positively definable relations over equality.
As examples of this paradigm with respect to dense linear orders < without endpoints, consider the following.
* The constraint language with relations {<, <=, =} is known as the point algebra in temporal reasoning; it and extensions thereof have been studied intensely (see for example [8], [4], [9] and the references therein), and both the CSP and QCSP over it are known to be polynomialtime tractable [10].
* Constraints on relations of the form (x < y1 )[?].
.
.[?
](x < yk ) are known as AND/OR precedence constraints, and arise naturally in scheduling applications [3].
* Constraint solving over Ord-Horn clauses is of outstanding importance in temporal and spatial reasoning, as several tractability results there are based into translations into such clauses.
(As a starting point for information on Ord-Horn, we suggest the references [11], [12], [9]).
Ord-Horn clauses are defined as clauses of the form (x1 = y1 [?]
* * * [?]
xk = yk [?]
xRy), where R [?]
{<, <=, =, =} and it is permitted that k = 0 or that xRy is not present.
A structure whose relations are first-order definable over the ordered rationals (Q; <) will here be called a temporal constraint language.
A complete CSP complexity classification of temporal constraint languages was presented by Bodirsky and Kara [13].
This classification result gives a description  Abstract--The first-order theory of dense linear orders without endpoints is well-known to be PSPACE-complete.
We present polynomial-time tractability results for fragments of this theory which are defined by syntactic restriction; in particular, our fragments can be described using the framework of quantified constraint satisfaction over Ord-Horn clauses.
I. I NTRODUCTION The first-order theory of dense linear orders without endpoints is a classical object of study in model theory; it is well-known that this theory is exactly equivalent to the concrete theory of the ordered rationals (Q; <).
The corresponding computational problem of deciding if a sentence belongs to this theory is PSPACE-complete [1, Lecture 21].
This decision problem appears naturally in various areas of computer science: for instance, it forms part of the first-order theories of the rationals and of the reals, which are of interest in computational algebra [2], and many temporal reasoning and related problems studied in scheduling [3] and artificial intelligence [4] admit formulation in this problem.
This theory can also be viewed as the base of and a prototype for (not necessarily linear) orders possessing further structure, such as time intervals, branching time, and spatial regions under the subset ordering.
A natural way to syntactically restrict first-order theories that has proven fruitful in recent complexity studies, and which we pursue in the present work, is the following.
First, expand the structure(s) of interest by first-order definable relations to obtain a structure B; as an example, in the case of the ordered rationals (Q; <), first-order definable relations include those defined by x <= y and (x = y) [?]
(y < z).
Then, consider sentences over the expanded structure, but restrict their syntax so that conjunction ([?])
is the only permitted boolean connective.
In the case where only existential quantification is permitted, this problem is the constraint satisfaction problem (CSP) on B: an instance can be essentially viewed as a prenex formula with only existential quantification, followed by a conjunction of atomic B-formulas, and the problem is to decide if there is an assignment to the variables satisfying all of the atomic formulas, which can be viewed as constraints on the variables.
When both quantifiers are present, this problem is known 1530-1311/12 $26.00 (c) 2012 IEEE DOI 10.1109/TIME.2012.19  99  into LOGSPACE, NLOGSPACE-complete, P-complete, NPcomplete and PSPACE-complete problems.
of the constraint languages whose CSP is polynomial-time tractable, and shows that the remaining languages have an NPcomplete CSP.
The tractable languages include those examples just described.
In contrast to the CSP, where Ord-Horn is tractable, it is known that for the QCSP, there are simple Ord-Horn clauses that (viewed as constraint languages) are intractable [14]; an example is the clause (x = y) [?]
(y = z).
In this paper, we present polynomial-time tractability results for the QCSP on temporal constraint languages defined by Ord-Horn clauses, thus giving extremely positive complexity results on the first-order theory of dense linear orders without endpoints.
We begin by presenting a class of Ord-Horn clauses called Basic Ord-Horn Formulas.
It has been shown algebraically that constraint languages defined by such formulas enjoy the socalled local-to-global property [15].
This is an algorithmically desirable property which (essentially) holds that performing local consistency, a iterative, tractable method of performing local inferences on a conjunction of constraints, results in a computationally wieldy characterization of the global solution space of the constraints.
This property has been intensely studied and is robust in that it admits formulations from multiple viewpoints (see the discussion in [10]); in the finite, this property is exactly the one for which the classical BakerPixley theorem gives logical and algebraic characterizations.
We then define a class of formulas called Guarded OrdHorn (GOH) formulas; these formulas generalize the class of Basic Ord-Horn formulas, and each such formula can be written as the conjunction of Ord-Horn clauses.
The formulas in this class are described using a recursive syntactic definition with Basic Ord-Horn at the base.
Our main tractability result is that constraint languages definable by GOH formulas have a polynomial-time decidable QCSP; in developing this result, we make crucial use of an algebraic characterization of the local-to-global property for Basic Ord-Horn.
An attractive aspect of this tractability result is that the polynomial-time algorithm that we present is conceptually simple and based on novel pebble games.
These pebble games generalize local consistency methods, which have recently received focused attention for the CSP (see [16] for a state-of-the-art result); we believe that this paper will help to bring the study of local consistency methods into focus for the QCSP.
Related work: Quantified constraint satisfaction problems of temporal constraint languages augmented with relations defined by linear inequalities have been studied in [17].
One example of such a problem is the quantified version of the feasibility problem for linear programs.
It is shown that this QCSP is coNP-hard, and contained in PSPACE, but the precise complexity remains open.
The paper presents also a tractable QCSP; the corresponding constraint language does not contain any of the tractable languages presented here.
Charatonik and Wrona [18], [19] studied the QCSP for temporal constraint languages where all relations have a positive first-order definition over the reflexive dense linear order <=.
They showed the complete complexity characterization for the QCSP on these constraint languages and organized them  II.
P RELIMINARIES A. Quantified Constraint Satisfaction Throughout, we assume that each signature is a finite set of relation symbols.
Let t be such a signature.
A first-order t sentence is a quantified constraint sentence if it has the form Q1 v1 .
.
.
Qn vn (ps1 [?]
.
.
.
[?]
psm ), where each Qi is a quantifier from {[?
], [?
]}, and each psi is an atomic t -formula of the form R(x1 , .
.
.
, xk ) where R [?]
t .
Let B be a t -structure with domain B; that is, B has for each relation symbol R in t a relation RB [?]
B k where k is the arity of R; see for example [20].
The quantified constraint satisfaction problem for B, denoted by QCSP(B), is the problem of deciding, given a quantified constraint t sentence Ph, whether or not B |= Ph.
In this paper, we use (Q; <) as a concrete model whose theory is the one of interest.
A temporal relation [13] is a relation R [?]
Qk with a first-order definition in (Q; <); that is, there exists a first-order formula ph(x1 , .
.
.
, xk ) with free variables x1 , .
.
.
, xk such that (a1 , .
.
.
, ak ) [?]
R if and only if ph(a1 , .
.
.
, ak ) is true in (Q; <).
A temporal constraint language is a relational structure B with domain Q where each relation RB of B is a temporal relation.
In this paper we study QCSP(B) only for structures B with a finite signature.
It is well-known and follows from the theorem of RyllNardzewski (see [20]) that all temporal constraint languages are o-categorical.
We say that a k-ary function (also called operation) f : B k - B preserves an m-ary relation R [?]
B m if whenever R(ai1 , .
.
.
, aim ) holds for all 1 <= i <= k, then  R f (a11 , .
.
.
, ak1 ), .
.
.
, f (a1m , .
.
.
, akm ) holds as well.
Let B be a structure, and let ph be a first-order formula with free variables x1 , .
.
.
, xk .
Then we say that f preserves ph (over B) if f preserves the k-ary relation defined by ph over B.
If f preserves all relations of a relational structure B, we say that f is a polymorphism of B (see e.g.
[21] for background on the role of polymorphisms in the study of CSPs).
Unary polymorphisms are called the endomorphisms of B; bijective endomorphisms of B whose inverse is also an endomorphism are called automorphisms of B.
In this paper, use of the term automorphism is assumed to refer to automorphisms of (Q; <), unless otherwise specified.
An orbit is a subset of Q-tuples that is equal to the closure of a tuple t [?]
Qk under all automorphisms.
Example: The operation min : Q2 - Q that maps two rational numbers to the minimum of the two numbers is a polymorphism of the temporal constraint language (Q; <=, <).
It is not a polymorphism of the temporal constraint language (Q; =), since it maps for instance the tuples (1, 0) [?]
= and (0, 1) [?]
= to (0, 0) [?]
/ =.
An interesting relation that is preserved by min is the ternary relation defined by the formula x1 > x2 [?]
x1 > x3 , and the ternary relation U with U (x, y, z) defined by (x = y [?]
y < z) [?]
(x = z [?]
z < y) [?]
(x = y [?]
y = z).
100  Definition 2.1: Let B be any set.
A k-ary operation f : B k - B is called a quasi near-unanimity function (or QNUF) if for all x, y [?]
B we have  Theorem 2.4: [15] For any finite set F of basic OH formulas, there exists a main-injective surjective oligopotent QNUF preserving all formulas in F .
f (x, x, .
.
.
, x, y) = f (x, x, .
.
.
, y, x) = .
.
.
= f (y, x, .
.
.
, x, x) = f (x, .
.
.
, x) .
III.
T RACTABILITY OF G UARDED O RD -H ORN A. Definitions Throughout, we will use GOH as short for Guarded OrdHorn.
Definition 3.1: The set of GOH formulas over a variable set V is defined inductively as follows.
1) Basic OH formulas are GOH.
2) If ps1 and ps2 are GOH formulas, then ps1 [?]
ps2 is a GOH formula.
3) If ps is a GOH formula, then (x1 <= y1 ) [?]
.
.
.
[?]
(xm <= ym )[?]
(x1 = y1 [?]
.
.
.
[?]
xm = ym [?]
ps) is a GOH formula.
Here, it is assumed that the variables xi , yi are contained in V .
We refer to GOH formulas formed according to these rules as formulas of type 1, 2, and 3, respectively.
 Definition 3.2: A relation R [?]
Qn is GOH if there exists a GOH formula ph over the variables {v1 , .
.
.
, vn } such that R(v1 , .
.
.
, vn ) [?]
ph(v1 , .
.
.
, vn ).
A structure B is GOH if it is over a finite signature and each of its relations is GOH, that is, if for every relation symbol S from the signature of B, it  holds that S B is GOH.
We now introduce a normal form for GOH formulas.
Definition 3.3: A GOH formula ph is normal if for each subformula of type 3, it holds that, for each i [?]
[m], the variables xi and yi are different.
 Proposition 3.4: Each GOH formula ph is logically equivalent to a normal GOH formula N (ph).
Proof.
We show how to construct inductively, from any GOH formula ph, a normal GOH formula N (ph).
We consider the three types of GOH formulas in turn.
1) N (ph) = ph 2) N (ps1 [?]
ps2 ) = N (ps1 ) [?]
N (ps2 ) 3) When ph = (x1 <= y1 ) [?]
.
.
.
[?]
(xm <= ym ) [?]
(x1 = y1 [?]
.
.
.
[?]
xm = ym [?]
ps), let i1 , .
.
.
, in be a list of the elements of D = {i | xi , yi are different variables }.
Let N (ph) be the formula (xi1 <= yi1 ) [?]
.
.
.
[?]
(xin <= yin ) [?]
(xi1 = yi1 [?]
.
.
.
[?]
xin = yin [?]
ps), where it is understood that N (ph) = ps if D = [?].
It is clear that any GOH formula ph is equivalent to a normal GOH formula N (ph), over (Q, <).
 Definition 3.5: Let ph be a normal GOH formula.
We define the guards formula of ph, denoted by G(ph), inductively as follows.
We consider the three types of GOH formulas in turn.
1) For a basic OH formula ph: G(ph) = ph 2) G(ps1 [?]
ps2 ) = G(ps1 ) [?]
G(ps2 ) 3) G((x1 <= y1 ) [?]
.
.
.
[?]
(xm <= ym ) [?]
(x1 = y1 [?]
.
.
.
[?]
xm = ym [?]
ps)) = (x1 <= y1 ) [?]
.
.
.
[?]
(xm <= ym ) For an arbitrary GOH formula ph, we define the guards formula of ph as G(ph) = G(N (ph)), where N (ph) is the operator from Proposition 3.4.
   A polymorphism f : B k - B of B is called oligopotent (wrt B) if the mapping f * : B - B defined by f * (x) := f (x, .
.
.
, x) preserves all first-order definable relation of B.
This definition is different from the definition in [22], but equivalent to it (see Proposition 12 in that paper), and more convenient for our purposes.
Theorem 2.2 (follows from Theorem 19 in [22]): Let B be an o-categorical relational structure with an oligopotent k +1ary polymorphism that is a quasi near-unanimity operation, for some k >= 2.
Then every n-ary relation R in B contains all tuples t such that for every subset I of {1, .
.
.
, n} with |I| <= k there is a tuple s [?]
R such that t[i] = s[i] for all i [?]
I.
A simple example of an oligopotent QNUF is the ternary median operation median: Q3 - Q which maps its three arguments to the middle value of those arguments; if two or more arguments are equal to a value c, then the median operation returns c. In particular, median(x, x, x) = x for all x [?]
Q, and hence median is oligopotent.
Let B be a structure with domain B over signature t .
If E [?]
B 2 is an equivalence relation, we write B/E for the factor structure A with signature t , defined as follows.
The domain of A consists of the equivalence classes of E, and for each relation symbol R [?]
t we have RA = {([c1 ], .
.
.
, [ck ]) | (c1 , .
.
.
, ck ) [?]
RB }, where [c] denotes the E-equivalence class of c [?]
D. B.
Basic Ord-Horn Throughout, we use OH as short for Ord-Horn.
Definition 2.3: The set of basic OH formulas over a variable set V is the set containing the following formulas: * x = y, * x <= y, * (x1 = y1 [?]
.
.
.
[?]
xp = yp ), * (x1 = x2 [?].
.
.
x1 = xq )[?
](x1 < y1 )[?
](y1 = y2 [?].
.
.
y1 = yq ).
 It is assumed that the variables x, y, xi , yi are in V .
It has been demonstrated that an oligopotent QNUF with certain desirable properties can be constructed for basic OH formulas.
We describe the result by making use of the following notions from [10, Section 4], adapted to the current context.
Let t [?]
Qk be a tuple, where k >= 3, and let p : [k] - [k] be a permutation such that tp(1) <= * * * <= tp(k) .
If it holds that tp(2) = * * * = tp(k-1) , we say that this value is the main value of t. Not every tuple t [?]
Qk has a main value, but when a tuple has a main value, it is unique.
We define the equivalence relation [?
]m on Qk as follows: t [?
]m t if and only if t = t or t, t have the same main value.
We say that an operation h : Qk - Q is main-injective if for all t, u [?]
Qk , it holds that h(t) = h(u) if and only if t [?
]m u.
101  Clearly, every guards formula is the conjunction of basic OH formulas.
Definition 3.6: Let B be a GOH structure over signature s, and let R(w1 , .
.
.
, wn ) be an atomic formula over s (where the variables w1 , .
.
.
, wn are not necessarily distinct).
We define R(w1 , .
.
.
, wn ) as the formula G(ph(w1 , .
.
.
, wn )), where ph is a GOH formula for RB (as in Definition 3.2).
We extend this notation to quantified constraint sentences by defining, for such a sentence Ph = Qv1 v1 .
.
.
Qvn vn [?
]m i=1 psi , where the psi are atomic formulas, Ph = Qv1 v1 .
.
.
Qvn vn [?
]m  i=1 psi .
We observe that if the sentence Ph is true with respect to a GOH structure B, then the sentence Ph is also true: one can conceive of Ph as a relaxation of Ph.
We will make use of the following consequence of Theorem 2.4.
Corollary 3.7: Let B be a GOH structure over signature s. There exists a main-injective surjective oligopotent QNUF preserving all formulas of the form R(w1 , .
.
.
, wn ), where R(w1 , .
.
.
, wn ) is an atomic formula over s. Proof.
There are clearly a finite number of such formulas of the described form, up to renaming of variables.
Each such formula is the conjunction of basic OH formulas; letting F be the set of all basic formulas that can appear in such a conjunction, the result follows directly from Theorem 2.4.
  corresponding structure pebble is removed.
At the start of the game, no pebbles are in play.
The Duplicator wins if he can play forever in such a way that the mapping from variables to B-elements determined by pebbles is always a partial solution.
The notion of partial solution that we use in formalizing the pebble games used is that of projective homomorphism.
We say that a function f defined on a subset of VPh is a projective homomorphism of Ph if for each atomic formula R(v1 , .
.
.
, vk ) of Ph, there exists an extension of f that satisfies R(v1 , .
.
.
, vk ) over B. Equivalently, such a function f is a projective homomorphism of Ph if for each atomic formula R(v1 , .
.
.
, vk ), there exists a tuple (b1 , .
.
.
, bk ) [?]
RB such that for all vi [?]
dom(f ), it holds that f (vi ) = bi .
We use dom(f ) to denote the domain of a function f .
Similarly, we say that a function f defined on a subset of VPh is a projective homomorphism of Ph if for each formula R(v1 , .
.
.
, vk ) in Ph corresponding to an atomic formula of Ph, there exists an extension of f that satisfies R(v1 , .
.
.
, vk ) over B.
The notion of a (Duplicator) winning strategy for the kpebble game can be formalized in the following way.
Definition 3.8: A winning strategy for the k-pebble game (on Ph) is a set S of projective homomorphisms, each having domain of size less than or equal to k, that satisfies the following conditions.
(1) The partial function with empty domain is an element of S, (2) If f [?]
S and g is a restriction of f , then g [?]
S. (3) If f [?]
S, |dom(f )| < k, v [?]
VPh , and dom(f ) <Ph v, then f can be (v, Qv )-extended in S. We say that an operation f can be (v, Q)-extended in a set of operations S if: * when Q = [?
], there exists an extension g [?]
S of f with domain dom(g) = dom(f ) [?]
{v}, and * when Q = [?
], every extension g of f with domain dom(g) = dom(f ) [?]
{v} is in S.  We next introduce an extension of the k-pebble game where the Spoiler can perform "backmoves" or "backpebbling": he can place a pebble on a variable that does not come after all pebbled variables, and the Duplicator must respond.
Definition 3.9: A winning strategy for the k-pebble game with backmoves (on Ph) is a set S of projective homomorphisms, each having domain of size less than or equal to k, that is a winning strategy for the k-pebble game (Definition 3.8) and in addition satisfy the following condition.
(4) If f [?]
S, |dom(f )| < k, v [?]
Vph , and dom(f ) <Ph v, then there exists an extension g [?]
S of f with domain dom(g) = dom(f ) [?]
{v}.
 The definition of the k-pebble game with backmoves naturally gives rise to an algorithm for deciding whether or not there is a winning strategy for this game.
The algorithm is as follows.
It is clear that, for each fixed k, and any finite structure B, the algorithm runs in polynomial time, measured with  B. Pebble games Throughout this subsection, Ph denotes a quantified constraint sentence Ph = Qv1 v1 .
.
.
Qvn vn ph in prenex form.
We use VPh to denote the set of variables {v1 , .
.
.
, vn } of Ph, and for each variable v [?]
VPh , we use Qv to denote its corresponding quantifier.
We write u <Ph v to indicate that u occurs strictly before v in the quantifier prefix of Ph; we write u <=Ph v to indicate that u <Ph v or u = v. We extend this notation to sets of variables U, W ; we write, for instance, that U <Ph W if u <Ph w for all u [?]
U, w [?]
W , and that U <Ph w for a variable w if U <Ph {w}.
We assume that B is a relational structure and that Ph is a quantified constraint sentence that is an instance of QCSP(B).
Much of the development is relative to the structure B, but we will generally suppress explicitly mentioning the structure B.
In order to establish our tractability result, we will consider a number of pebble games (for more on pebble games in the context of constraint satisfaction, see e.g.
[23]).
The most basic pebble game that we will consider is here referred to simply as the k-pebble game, and is based on the pebble game for quantified constraint sentences defined by Chen and Dalmau [24].
The k-pebble game is played between two players, Spoiler and Duplicator.
Spoiler can use up to k pebbles, and can perform two actions.
First, Spoiler can place a pebble on a variable of the sentence that comes after all variables having pebbles; if it is an existentially quantified variable, Duplicator has to respond by placing a pebble on an element b of the structure B, and if it is a universally quantified variable, the Spoiler also places a pebble on an element b of B of his choosing.
Second, Spoiler can remove a pebble that is on a variable of the sentence, in which case the  102  of S. (2') If f [?]
S and g is a restriction of f to a set of the form {v1 , v2 , .
.
.
, vi }, then g [?]
S. (3') If f [?]
S, dom(f ) = {v1 , v2 , .
.
.
, vi }, and i < n, then f can be (vi+1 , Qvi+1 )-extended in S.  Proposition 3.12: A quantified constraint sentence Ph is true if and only if there exists a winning strategy for the truth pebble game on Ph.
We now show that the maximal winning strategy for the k-pebble game with backmoves fully supports any winning strategy for the truth pebble game, in the following sense.
Proposition 3.13: Let Ph be a quantified constraint sentence.
Let S be the strategy computed by the algorithm for the k-pebble game with backmoves (on Ph).
If there exists a winning strategy T for the truth pebble game (on Ph), then S is nonempty and contains all restrictions of operations in T to domains of size less than or equal to k. Proof.
We prove that, at each stage of the algorithm, all such restrictions of operations in T are contained in S. It is clear that, after step (1) is performed, this holds.
We thus show that if this holds, then no such restriction of an operation in T can be removed from S by one of the removal rules in step (2), as follows.
In each of the following arguments, we suppose that f [?]
S is the restriction of an operation h [?]
T .
* All restrictions of f are restrictions of h, and are hence all contained in S. * Let vj [?]
VPh with |dom(f )| < k and dom(f ) <Ph vj .
We make use of properties (2') and (3') of Definition 3.11.
By property (2'), there exists a restriction h1 [?]
T of h / dom(h1 ).
By such that dom(f ) [?]
dom(h1 ) but vj [?]
possibly repeated application of property (3'), one can obtain h2 [?]
T with domain {v1 , .
.
.
, vj-1 } such that h2 extends h1 , and f is a restriction of h2 .
Since h2 can be (vj , Qvj )-extended in T , the operation f can be (vj , Qvj )-extended in S. * Let v [?]
VPh with |dom(f )| < k and dom(f ) <Ph v. We have that h is defined on v, and hence the restriction of h to dom(f ) [?]
{v} is contained in S.   Algorithm for k-pebble game with backmoves.
Input: a quantified constraint sentence Ph 1.
Let S be the set of all projective homomorphisms of Ph having domain of size less than or equal to k, relative to the structure B of interest.
2.
Repeat until no changes are possible: *  If there exists f [?]
S having a restriction g not in S, then remove f from S.  *  If there exists f [?]
S and v [?]
VPh with |dom(f )| < k and dom(f ) <Ph v such that f cannot be (v, Qv )-extended in S, then remove f from S.  *  If there exists f [?]
S and v [?]
VPh with |dom(f )| < k and dom(f ) <Ph v such that there is no extension g [?]
S of f with domain dom(g) = dom(f ) [?]
{v}, then remove f from S.  3.
Return S.  respect to the input Ph.
This algorithm can be applied to temporal constraint languages B by maintaining, at all times, an orbit representative for each orbit that is present in S, and then performing the described computations using the orbit representatives; this is justified by the fact that the set of all projective homomorphisms is closed under automorphism.
Again, for each fixed k and any temporal constraint language B, the algorithm runs in polynomial time in the input Ph.
In the case that, when the algorithm terminates, the set S is nonempty, we call this resulting strategy S the maximal winning strategy.
The following proposition is straightforward to verify.
Proposition 3.10: Let S be the set returned by the algorithm for the k-pebble game with backmoves on a quantified constraint sentence Ph.
* For any winning strategy T for this game (on Ph), it holds that T [?]
S. * If S = [?
], then there is no winning strategy for this game (on Ph).
We consider one more pebble game, the truth pebble game, which characterizes the truth of a quantified constraint sentence.
Definition 3.11: A winning strategy for the truth pebble game (on Ph = Qv1 v1 .
.
.
Qvn vn ph) is a set S of projective homomorphisms, each having domain of the form {v1 , v2 , .
.
.
, vi } for some i >= 0, that satisfy the following conditions.
(1) The partial function with empty domain is an element  It is straightforward to verify that, for an instance Ph of QCSP(B) and a winning strategy S for one of the pebble games considered in this subsection, the closure of S under the surjective polymorphisms of B is also a winning strategy for the pebble game.
In what follows, we will tacitly assume that winning strategies are closed under such polymorphisms.
C. Algorithm In this subsection, we present our algorithm for Guarded Ord-Horn, and prove its correctness.
Before presenting our algorithm, we introduce a couple of notions.
Let us say that a winning strategy S for the k-pebble game with backmoves (on Ph) implies the equality u = v, where u, v are distinct variables in VPh , if every operation f [?]
103  S with domain dom(f ) = {u, v} has the property that f (u) = f (v).
Our algorithm will detect implied equalities and simplify quantified sentences; the notion of simplification used is as follows.
Let u <Ph v be two variables in VPh .
We use Ph[u - v] to denote the sentence obtained from Ph by eliminating v and its quantifier from the quantifier prefix, and by replacing every instance of v in the quantifier-free part with u.  with backmoves that does not imply any equalities, then the sentence Ph has a winning strategy for the truth pebble game.
We establish Theorem 3.14 via a sequence of lemmas.
In what follows, we assume that the hypotheses of Theorem 3.14 are in effect.
We will make use of the following notion.
Relative to a sentence Ph, let us say that a projective homomorphism f is exinjective ("existentially injective") when for all pairs of variables u, v [?]
dom(f ), if u <Ph v and Qv = [?
], then f (u) = f (v).
We say that a set of projective homomorphisms is exinjective if all of the projective homomorphisms it contains are exinjective.
Lemma 3.15: If the sentence Ph has a winning strategy S for the k-pebble game with backmoves that does not imply any equalities, then this sentence has an exinjective winning strategy for the k-pebble game.
In the proof of this lemma, we will use the notation c, where c [?]
Q, to denote the k-tuple (c, .
.
.
, c) [?]
Qk having all entries equal to c. We will also make use of the following type of operation.
For a constant c [?]
Q, define pc : Q2 - Q to be a surjective operation such that pc (x, y) < pc (x , y  ) if and only if either (1) x < x , or (2) x = x = c and y < y  ; it is easy to see that such operations exist.
See Fig.
1 for an illustration of such an operation.
In this illustration, if we link (x, y), (u, v) [?]
Q2 by an arc from (x, y) to (u, v) then this means that f (x, y) < f (u, v); if (x, y) is linked to (u, v) by an undirected line, then f (x, y) = f (u, v).
Algorithm for QCSP(B) where B is a GOH-structure.
Input: a quantified constraint sentence Ph 1.
Run the algorithm for the k-pebble game with backmoves on Ph, where k is the arity of the QNUF from Corollary 3.7; let S be the result.
2.
If S = [?
], return FALSE.
Otherwise, check to see if S implies any equalities.
If it does, let u = v be an implied equality, with u <Ph v; replace Ph with Ph[u - v]; and return to step 1.
3.
Return TRUE.
Clearly, this algorithm runs in polynomial time: each time it performs a replacement of Ph, one variable is eliminated (and the sentence is shortened), and so it loops at most |VPh | times; and, as previously discussed, the algorithm for the k-pebble game with backmoves runs in time polynomial in the size of the input sentence.
We thus turn to discuss the correctness of the algorithm.
When the algorithm detects an implied equality u = v, with u <Ph v, the variable v must be existentially quantified, since a function with domain {u} can be (v, Qv )-extended in a winning strategy for the pebble game.
Also, in this case, by Proposition 3.13, all functions f contained in winning strategies for the truth pebble game on Ph that are defined on {u, v} set f (u) = f (v).
Since a winning strategy for the truth pebble game on Ph must be a winning strategy for the truth pebble game for Ph, this property also holds for all functions f contained in winning strategies for the truth pebble game on Ph, and so the sentence Ph[u - v] is true if and only if the sentence Ph is true.
We have thus shown that the replacement step preserves the truth of the sentence; it follows by Proposition 3.13 that if the algorithm returns "FALSE", then the input sentence was indeed false.
It remains to show that if the algorithm returns "TRUE", then the sentence is true.
To demonstrate this, it suffices to provide a proof of the following theorem.
Theorem 3.14: Let B be a GOH structure, let k be the arity of the QNUF from Corollary 3.7, and let Ph be a quantified constraint sentence that is an instance of QCSP(B).
If the sentence Ph has a winning strategy for the k-pebble game  c  Fig.
1.
An illustration of an operation pc .
Observe that all such operations pc preserve all basic OH formulas.
We present the following sub-lemma.
Lemma 3.16: Let R be a relation defined by a basic OH formula and c [?]
Q be a constant.
Then pc preserves R. Proof.
In what follows, we write phR for a GOH formula defining R. Moreover, tx denotes a coordinate of t [?]
R that corresponds to a variable x occurring in phR .
A basic OH formula is in one of four forms.
If phR is an equality, then R is preserved by all functions and hence by pc .
We now consider the case where phR is of the form x <= y.
Let t, u [?]
R. Then, by the definition of pc , it is not hard to see that pc (tx , ux ) <= pc (ty , uy ).
Thus pc (t, u) is in R and pc preserves R. If phR is of the form (x1 = y1 [?]
.
.
.
[?]
xp = yp ) and t [?]
R, then there is i [?]
[p] such that txi = tyi .
Assume without loss  104  of generality that txi < tyi .
Let u [?]
R be any tuple.
We now show that pc (t, u) is in R and thereby that R is preserved by pc .
To see this observe that pc (txi , uxi ) < pc (tyi , uyi ).
Finally, let phR be of the form (x1 = x2 [?]
.
.
.
[?]
x1 = xq ) [?]
(x1 < y1 ) [?]
(y1 = y2 [?]
.
.
.
[?]
y1 = yq ).
If t [?]
R, then we have one of the following situations: * there is i [?]
[q] such that tx1 = txi ;  * there is i [?]
[q ] such that ty1 = tyi ; * tx1 < ty1 .
Let u [?]
R. To show that pc (t, u) [?]
R regardless of the reason why t [?]
R we use the same argument as in the case where phR is of the form (x1 = y1 [?]
.
.
.
[?]
xp = yp ).
For each type of a basic OH formula phR we showed that R is preserved by pc .
Thus we proved the lemma.
  By making use of automorphisms and the fact that S is a winning strategy, we can obtain a homomorphism a1 [?]
S with dom(a1 ) = dom(f ) where a1 (y) = -a and a1 = a elsewhere.
Observe that a1 is exinjective, and hence any restriction thereof is also exinjective.
We claim that there is an extension c1 of a1 with dom(c1 ) = dom(a1 ) [?]
{v} where / {-a, a}.
Let b [?]
S be an extension of a1 with c1 (v) [?]
dom(b) = dom(a1 ) [?]
{v}.
If b does not satisfy the desired property, then b(v) [?]
{-a, a}.
Let b1 [?]
S be the restriction of a1 to the set J = {w [?]
dom(a1 ) | a1 (w) = b(v)}.
By the induction hypothesis, b1 can be extended to an exinjective b1 [?]
S with dom(b1 ) = dom(b1 ) [?]
{v}.
By backpebbling, b1 can be extended to an operation b2 [?]
S with dom(b2 ) = dom(f )[?]{v}.
Consider the function pb(v) (b, b2 ).
The function b is equal to b(v) at J [?]
{v}; on that set, the function b2 is equal to b(v) on J, and to a different value at v. We can thus take c1 = pb(v) (b, b2 ).
After application of an automorphism, we have obtained an operation c1 having dom(c1 ) = dom(f ) [?]
{v} where c1 (y) = / {-a, a}, and c1 = a elsewhere.
By a similar -a, c1 (v) [?]
argument, we can obtain an operation c2 having dom(c2 ) = / {-a, a}, and c2 = dom(f ) [?]
{v} where c2 (y) = a, c2 (v) [?]
-a elsewhere.
Suppose that one of the values c1 (v), c2 (v) is strictly greater than a, and that the other is strictly less than -a.
Let d1 , d2 [?]
{c1 , c2 } be such that d1 (v) > a and d2 (v) < -a.
We can find automorphisms g1 , g2 such that g1 (d1 ) is positive on v, and negative elsewhere; and, g2 (d2 ) is positive everywhere.
Consider the function g = q(g1 (d1 ), g2 (d2 ), h, .
.
.
, h), where q is the QNUF from the formulation of Theorem 3.14.
On dom(f ), this g is equal to q(0), since on these variables the values that q is applied to yield the main value 0.
On the other hand, g(v) is not equal to q(0), since on v both g1 (d1 ), g2 (d2 ) are positive, and hence there is no main value.
In other cases, we will demonstrate that there are automorphisms g1 , g2 each of which fixes both -a and a such that g = q(g1 (d1 ), g2 (d2 ), h, .
.
.
, h) is not equal to q(0) on v; this suffices, since for such automorphisms g is equal to q(0) elsewhere.
If both d1 (v), d2 (v) are strictly greater than a, then one can take both g1 , g2 to be the identity automorphisms, as then the tuple q is applied to will have no main value.
Similarly, if both d1 (v), d2 (v) are strictly less than -a, then one can take both g1 , g2 to be the identity automorphisms.
The remaining case is where one or both of d1 (v), d2 (v) is in the interval (-a, a).
Suppose that d1 (v) [?]
(-a, a).
The automorphism g2 can be defined so that g2 (d2 (v)) = 0.
Then, g1 can be defined so that g1 (d1 (v)) is positive if g2 (d2 (v)) is positive, and negative if g2 (d2 (v)) is negative.
The argumentation for the subcase where d2 (v) [?]
(-a, a) is similar.
  Proof.
(Lemma 3.15) Let S  be the set containing all projective homomorphisms in S that are exinjective.
We will show that S  gives the desired exinjective winning strategy.
Let us consider the properties of Definition 3.8.
It is clear that S  inherits properties (1) and (2) from S. Also, S  inherits the property (3) in the case that Qv = [?].
It thus suffices to prove the following claim.
Claim: if f [?]
S is exinjective, |dom(f )| < k, v [?]
VPh , Qv = [?
], and dom(f ) <Ph v, then there is an exinjective extension g [?]
S of f with dom(g) = dom(f ) [?]
{v}.
We prove the claim by induction on |dom(f )|.
For |dom(f )| = 0, the claim is obvious.
For |dom(f )| = 1, the claim follows from the hypothesis that S does not imply any equalities.
So, we suppose that |dom(f )| >= 2.
As S is a winning strategy for the k-pebble game, there exists an extension h [?]
S of f with dom(h) = dom(f ) [?]
{v}.
Let I = {w [?]
dom(f ) | h(v) = f (w)}.
We now consider two cases; it can be remarked that if I = [?
], then one can simply take g = h. Case I = dom(f ): let u [?]
dom(f ) \ I, that is, let u [?]
dom(f ) be a variable such that h(v) = f (u).
Let h1 be the restriction of h to dom(f ) \ {u}.
By the induction hypothesis, there exists an exinjective extension h2 of h1 whose domain dom(h2 ) is equal to dom(h) \ {u} = (dom(f ) [?]
{v}) \ {u}.
By applying a backmove to h2 , we obtain an extension h3 of h2 with dom(h3 ) = dom(h).
Consider the function ph(v) (h, h3 ).
Recall that the definition of the polymorphism pc , where c [?]
Q, is above Lemma 3.16.
The function h is equal to h(v) at I [?]
{v}; on I [?]
{v}, the function h3 is equal to h(v) on I, but equal to a value different from h(v) at v. Hence, the function ph(v) (h, h3 ) is exinjective, but there exists an automorphism b such that b(ph(v) (h, h3 )) = f on dom(f ), and so we can take g = b(ph(v) (h, h3 )).
Case I = dom(f ): let us assume that h is equal to 0 everywhere on its domain; for other values, the same argument will apply under translation by an automorphism.
Observe that, since f is exinjective, all variables of dom(f ), except for possibly the earliest one, are universally quantified.
Let y be the latest occurring variable in dom(f ), which must be universally quantified.
Fix a > 0 to be a positive constant.
Lemma 3.17: If the sentence Ph has an exinjective winning strategy for the k-pebble game then this sentence has an exinjective winning strategy for the truth pebble game.
Proof.
Let S be an exinjective winning strategy for the kpebble game.
Let T be the set containing all exinjective  105  functions f from a subset of VPh to Q such that every restriction of f to a set of size <= k is contained in S. Every function in T is a projective homomorphism by Theorem 2.2.
Clearly, T is non-empty, as S [?]
T , and is closed under restriction.
We will prove the following claim.
Claim: for every function f [?]
T and variable v [?]
VPh with dom(f ) <Ph v, the function f can be (v, Qv )-extended in T .
This claim suffices to give the lemma, as then the set of functions in T having domain of the form {v1 , v2 , .
.
.
, vi } forms the desired exinjective winning strategy for the truth pebble game.
The claim is clear when Qv = [?]
by the definition of T , so let Qv = [?].
We prove the claim by induction on |dom(f )|.
The base case |dom(f )| < k is clear by definition of T , so suppose that |dom(f )| >= k. Let u1 , .
.
.
, uk be distinct elements from dom(f ), and for each i [?]
[k] define fi to be the restriction of f to dom(f ) \ {ui }.
Each fi has, by induction, an exinjective extension gi [?]
T defined on (dom(f ) \ {ui }) [?]
{v}.
Let g be the function on dom(f )[?
](v) defined by g(u) = q(f (u)) for all u [?]
dom(f ), and g(v) = q(g1 (v), .
.
.
, gk (v)).
By the QNUF identities and the fact that each gi is in T , we obtain that g is in T .
Since each of the gi is exinjective, for all i, j [?]
[k] with j = i, it holds that gj (v) = gj (ui ) = f (ui ).
It follows that the tuple (g1 (v), .
.
.
, gk (v)) cannot have as main value any of the values f (u1 ), .
.
.
, f (uk ).
Hence, the function g is exinjective.
 Lemma 3.18: If the sentence Ph has an exinjective winning strategy for the truth pebble game then that strategy is a winning strategy for the truth pebble game on Ph.
Proof.
Let R(t) be an atomic formula from the quantifier-free part of Ph, where t is a tuple of variables, and let ph(t) be the normal GOH formula for R(t).
Let ph (t) be the guards formula of ph(t); the formula ph (t) is the formula for R(t).
The formula ph(t) can be viewed as the conjunction of GOH formulas of types 1 and 3.
We show that each such formula is satisfied by any f [?]
S whose domain contains the variables of t, which suffices.
A basic OH formula is satisfied by f because f satisfies the corresponding identical subformula in ph (t).
Now consider a formula  Proof.
If the algorithm returns "FALSE", falsity of the input sentence follows directly from Proposition 3.13.
If the algorithm returns "TRUE", truth of the input sentence follows directly from Theorem 3.14 and Proposition 3.12.
 ACKNOWLEDGMENT Hubie Chen is supported by the Spanish program "Ramon y Cajal" and MICINN grant TIN2010-20967-C04-02.
R EFERENCES [1] D. Kozen, Theory of Computation.
Springer, 2006.
[2] S. Basu, R. Pollack, and M.-F. Roy, Algorithms in Real Algebraic Geometry, 2nd edition.
Springer-Verlag, 2009.
[3] R. H. Mohring, M. Skutella, and F. Stork, "Scheduling with and/or precedence constraints," SIAM J.
Comput., vol.
33, no.
2, pp.
393-415, 2004.
[4] M. Broxvall and P. Jonsson, "Point algebras for temporal reasoning: Algorithms and complexity," Artif.
Intell., vol.
149, no.
2, pp.
179-220, 2003.
[5] B. Aspvall, M. F. Plass, and R. E. Tarjan, "A linear-time algorithm for testing the truth of certain quantified boolean formulas," Inf.
Process.
Lett., vol.
8, no.
3, pp.
121-123, 1979.
[6] M. Karpinski, H. K. Buning, and P. H. Schmitt, "On the computational complexity of quantified horn clauses," in CSL, 1987, pp.
129-137.
[7] D. Kozen, "Positive first-order logic is NP-complete," IBM Journal of Research and Development, vol.
25, no.
4, pp.
327-332, 1981.
[8] P. van Beek, "Reasoning about qualitative temporal information," Artificial Intelligence, vol.
58, pp.
297-326, 1992.
[9] M. Fisher, D. Gabbay, and L. Vila, Eds., Handbook of Temporal Reasoning in Artificial Intelligence.
Elsevier, 2005.
[10] M. Bodirsky and H. Chen, "Qualitative temporal and spatial reasoning revisited," in CSL'07, 2007, pp.
194-207.
[11] B. Nebel and H.-J.
Burckert, "Reasoning about temporal relations: A maximal tractable subclass of Allen's interval algebra," JACM, vol.
42, no.
1, pp.
43-66, 1995.
[12] P. Balbiani, J.-F. Condotta, and L. F. del Cerro, "Tractability results in the block algebra," J. Log.
Comput., vol.
12, no.
5, pp.
885-909, 2002.
[13] M. Bodirsky and J. Kara, "The complexity of temporal constraint satisfaction problems," Accepted for publication in the Journal of the ACM, 2009, an extended abstract appeared in the proceedings of STOC'08.
[14] M. Bodirsky and H. Chen, "Quantified equality constraints," SIAM Journal on Computing, vol.
39, no.
8, pp.
3682-3699, 2010.
[15] M. Wrona, "Syntactically characterizing local-to-global consistency in ord-horn," in the proceedings of 18th International Conference on Principles and Practice of Constraint Programming.
[16] L. Barto and M. Kozik, "Constraint satisfaction problems of bounded width," in Proceedings of FOCS'09, 2009.
[17] K. Subramani, "On a decision procedure for quantified linear programs," Ann.
Math.
Artif.
Intell., vol.
51, no.
1, pp.
55-77, 2007.
[18] W. Charatonik and M. Wrona, "Tractable quantified constraint satisfaction problems over positive temporal templates," in LPAR, 2008, pp.
543-557.
[19] ----, "Quantified positive temporal constraints," in CSL, 2008, pp.
94- 108.
[20] W. Hodges, A shorter model theory.
Cambridge: Cambridge University Press, 1997.
[21] A. Bulatov, A. Krokhin, and P. G. Jeavons, "Classifying the complexity of constraints using finite algebras," SIAM Journal on Computing, vol.
34, pp.
720-742, 2005.
[22] M. Bodirsky and H. Chen, "Oligomorphic clones," Algebra Universalis, vol.
57, no.
1, pp.
109-125, 2007.
[23] V. Dalmau, P. G. Kolaitis, and M. Y. Vardi, "Constraint satisfaction, bounded treewidth, and finite-variable logics," in Proceedings of CP'02, 2002, pp.
310-326.
[24] H. Chen and V. Dalmau, "From pebble games to tractability: An ambidextrous consistency algorithm for quantified constraint satisfaction," in CSL, 2005, pp.
232-247.
(x1 <= y1 ) [?]
.
.
.
[?]
(xm <= ym ) [?]
(x1 = y1 [?]
.
.
.
[?]
xm = ym [?]
ps) of type 3.
It suffices to show that each inequality xi <= yi is satisfied in a way that x and y are set to different values.
Let u, v [?]
VPh be such that {u, v} = {xi , yi } and u <Ph v. Note that xi , yi are distinct variables, since ph(t) is a normal GOH formula.
We claim that Qv = [?
], which suffices, as the strategy S is exinjective.
Suppose for a contradiction that Qv = [?].
Then the restriction of f to {u} can be extended to a function g [?]
S with dom(g) = {u, v} such that g does not satisfy xi <= yi , contradicting that S is a winning strategy for Ph.
 We can now conclude our main polynomial-time decidability result.
Theorem 3.19: Let B be a GOH structure.
The problem QCSP(B) is polynomial-time decidable.
106
Time and Uncertainty in Reasoning about Order Robert A. Morris and Dan Tamir Florida Institute of Technology Melbourne, FL 32901 email:morris@cs.
t.edu  Abstract  The ability to intelligently order events is important for planning and scheduling in the presence of uncertainty about the expected duration of those events.
This paper presents a time-based theory of an agent in a dynamic environment, and a framework for reasoning for the purpose of generating eective orderings of events.
1 Setting the Stage In this study, the interest is in the role of time in the ability of intelligent agents to plan or schedule events, especially actions, events of which they are the agent.
Researchers in AI have, for a number of years, oered analyses and computational models of the temporal reasoning underlying these abilities.
These models have explained the intuitive complexity of reasoning about time in terms of proving the consistency of a set of temporal constraints, an inherently intractable problem.
This study adds further complexity by folding into the framework a dynamically changing environment, wherein temporal knowledge becomes outdated, as well as being partial and incomplete.
How, we ask, can an agent utilize the information found in such an environment in order to eectively solve planning and scheduling problems?
The impetus for this investigation is a system which provides a solution to the dicult problem of scheduling telescope observations  Kenneth M. Ford  University of West Florida Pensacola FL 32514 email: kford@ai.uwf.edu 1].
This solution required attention be given to the fact that the duration of a repeating event may be dierent on dierent occasions.
This made any generated schedule \fragile", which means that there was a tendency for it to \break" during execution.
The novelty of the approach of the researchers was the integration of statistical information about past occurrences of events in order to predict how well a schedule will stand up against a contrary night sky.
This allowed for sensitive locations in the schedule to be identied, and made it feasible to maintain a library of contingency schedules.
We feel this approach to solving planning and scheduling problems in a changing world can be extended and generalized to other problems with similar, dynamic environments.
One objective of this study is to perform these transformations.
The objectives of this paper consist of Constructing an abstract representation of the intelligent behavior which is manifested in the telescope scheduling example, as well as others Proposing a formal representation of the knowledge required to realize this behavior and Presenting a computational model of learning the requisite knowledge based on statistical evidence inferred from the experience of temporal duration and order.
2 Abstract Representation of Behavior The interest here is in systems embedded in a dynamic environment with feedback in the form of rewards.
It is desirable for the system to learn from these rewards in order to maximize its rewards over the long run.
Traditionally, such a system is modeled in terms of state transition networks, consisting of states, actions and state-transition functions.
Here, an alternative model is presented with an underlying temporal ontology.
Specically, there are events represented by their durations, and a single atomic temporal ordering relation, immediately precedes (<).
Given a set E = fA B C g of events, if an agent prefers a certain ordering of their occurrences, say, A < B < C (\A immediately before B immediately before C ") to another, the reason may have to do with constraints which lead to a preference for that order.
There are many varieties of constraints possibly underlying this preference.
Here the interest is in criteria for orderings that are based on temporal constraints.
One example of such a constraint involves minimizing the overall extent of the performance of all the tasks.
By overall extent is meant the interval of time it takes all the events in E to complete.
On this criterion, an ordering of E which is expected to minimize the overall extent of E will be the most preferred ordering.
Another criterion for ordering will be in terms of minimizing the overall duration uncertainty of the set of tasks.
Intuitively, duration uncertainty is manifested in terms of a relative lack of condence concerning how long an event, or a set of events, will take.
If it is possible to predict that one ordering of the tasks will exhibit less duration uncertainty than another, then choosing the ordering with less uncertainty will be preferred.
This is analogous to taking a \sure bet", even if the payo is less than another choice which  is less likely.
The inability to predict how long an event will last on a given occasion (duration uncertainty) is a pervasive feature of common sense experience.
Things that happen in a given day, e.g., breakfast, driving to work, faculty meetings, going to the dentist, exhibit varying amounts of duration uncertainty.
Duration uncertainty is undesirable to a rational agent because it leads to failure in the completion of plans and schedules, and the need for time-consuming repair and revision.
To satisfy one or the other of these constraints, an agent can choose to order the occurrences of the events in such a way that events in close temporal proximity share one or more stages.
Informally, a stage of an action or event E is an action or event which occurs as part of the occurrence of E .
For example, \preparing the cleaning utensils" can be viewed as a stage in most or all cleaning actions.
Often, an event can be \sliced" in dierent ways to uncover its stages.
Suppose two cleaning room actions, clean kitchen (K ) and clean bath (B ) are performed together, say K < B .
There will be a tendency for the preparation stage of B to not be required (or be simplied) hence the overall duration of performing both should be reduced.
Furthermore, since the duration uncertainty of the whole will be a function of the duration uncertainty of the dierent stages, there's a chance that duration uncertainty can also be reduced as a result of this pairing.
This situation is illustrated in Figure 1.
In this gure, stage S1 of K is shared with B .
The temporal eect of sharing stages is that the events can be viewed as overlapping in time.
Notice that when speaking of such relations, there is no assumption of convexity (no interruption) with respect to the intervals making up the durations of the events.
It follows that an agent should be able to more accurately predict how long the bathroom cleaning will take when preceded by the  K B  S1 S1  Figure 1: Eect of Pairing Similar Events in Close Temporal Proximity kitchen cleaning action than it could predict its duration in isolation, or when preceded by a event sharing no stages with it.
The point of the examples, then, is that events that share stages will tend to be mutually inuencing with respect to duration, especially when paired in close temporal proximity.
This sort of information would be useful for an agent who is either lacking the requisite knowledge about the events for which it needs to nd an intelligent ordering, or in which the environment is constantly changing, making its knowledge outdated.
Consider, for example, a robot assigned the task of delivering mail in a dynamically changing environment.
Oces may move, for example, or construction to dierent parts of the complex may require dynamically revising the routes, and hence possibly the order, in which mail is delivered.
Similarly, it may be equipped with only a crude or outdated map of its environment.
We proceed to formalize a model of an agent in a dynamically changing environment.
The model is based on the familiar idea of using a network to store temporal information.
Here, the nodes, or variables represent events in terms of their durations, and the arcs store values which represent the eect of orderings of events on the durations of events that follow them in close temporal proximity.
Denition 1 (Duration Network )A Duration Network N is a set of variables V = V1 : : : Vn , and a set of labeled edges E =  '$ &% '$ &% -2  '$ &% '$ &% V =6  2 ( ( ( ( ( V1 = 4 ((( 0 ;; C C QQ CC QQ ;; CC 0 Q -1 C ; C ;; QQQ 0 CC CC ; QQ C Q  V3 = 5  -1  V4 = 2  Figure 2: Instantiated Duration Network  instantiation of  fhVi  Vj i : 8Vi Vj 2 V g. An N is a function I : V fi E !
Z , such that, all Vi  Vj 2 V , Eij 2 E :  for  I (Vi) > 0 I (Eij )  0 and Let Eij = hVi  Vj i.
Then jI (Eij )j < I (Vi) and jI (Eij )j < I (Vj ).
A duration network is a complete network in which the variables stand for events, and their values are durations of these events.
The labels on the arcs represent the eect of sharing stages on durations.
A negative value for I (hVi  Vj i) represents the advantage of performing Vi and Vj together by virtue of their sharing a stage the negative value is the \reward" for doing them in close temporal proximity.
Figure 2 depicts an instantiated duration graph.
To illustrate the meaning of the graph, consider the nodes V1 and V2 .
The order V1 < V2 < V3 would yield a \reward" of 2 time units.
This means that the overall duration of performing this sequence would be 4 ; 2 + 6 + 0 + 5 = 13 time units.
Compared with performing V1 < V3 < V2, which has overall duration 4 ; 1 + 5 + 0 + 6 = 14 time units, the rst ordering would have the smaller overall extent.
It is useful to distinguish what we will call legs of a tour of a duration network N .
Intuitively, if a tour is a complete path through the network, a leg of the tour is any subpath of that path.
More formally, we use the notion of sub-sequence of a sequence (using the notation t v t) to characterize tour legs.
If t = hVt1  Vt2  : : : Vtn i is a tour through N , then, for example, hVt3  Vt4  Vt5 i is a leg.
To relate a leg to its tour, we use t=hVti  : : :Vti +mi to mean \the part of t consisting of the indicated leg".
Denition 2 (Process/Tour of a Duration Network)A k-process of a duration network N = (V E ) is a sequence P = hI1 I2 : : :  Iki of instantiations of N .
A tour t of a duration network N with variables V = fV1 : : : Vn g is a permutation of V .
We write t = hVt1  : : :  Vtn i to enumerate the elements of t. Denition 3 (Cost of a Tour/Tour Series)Given an Instantiation I and tour t = hVt1  : : :  Vtn i, the cost of a tour in I (c(t I )) is c(t I ) = I (Vt1 )+I (hVt1  Vt2 i)+: : :+I (hVtn;1  Vtn i)+I (Vtn ) Given a k-process P = hI1 : : :Ik i and a sequence of corresponding tours T = ht1 : : :  tk i, called a tour series, the cost of the series T in process P (C (T P )) is X C (T P ) = c(ti Ii) 0  1ik  More generally, we can introduce the notion of \cost of a leg L = hVti  : : :Vti+m i of a tour t in I " as follows: ( 6v t c(t=L I ) = c(L I0) :: Lotherwise Finally, we can speak of the cost of a leg in a tour series T and a process P :  C (T=hVti  : : :Vti+m i P )  as the sum of the costs of this leg in all the tours in the series containing this leg.
The interest now is to dene a set of oneperson games involving tours of the duration graph.
The specic goal of interest is to nd a tour series Tmest of length k which is an agent's estimate of the minimal tour series Tmin .
The latter is the tour series which, given a duration network N and k-process P , incurs the minimum cost over all possible tour series.
Other goals are of course possible.
One is to minimize the standard deviation from the mean of tour durations in the series.
Another goal is to complete as many of the events (i.e., visit as many of the variables) as possible, given rigorous time constraints (i.e.
cost).
Other versions of the game dier on assumptions concerning either the agent's initial knowledge of N , its abilities to update the knowledge based on experience in the form of tours it has made, or on the properties of P .
The interest is in nding denitions of P which characterize properties and relations of the abstract world which are homomorphic to those properties and relations which occur in real world planning and scheduling domains.
First, let us say that an instantiation I is totally repeating in P = hI1 I2 : : : Imi if 9i ji 6= j I = Ii = Ij 2 P .
We can rene this to \repeats n times" in an obvious way.
Two total repetitions of I , say Im and Ip are n units apart if km ; pk = n. If n = 1, then the repetitions will be said to be consecutive.
I will be said to be p-periodic in P if any pair of occurrences of I in P repeat r units apart, where r is a factor of p. Similarly, I is almost periodic in P if there exists a p such that any pair of occurrences of I in P occur a distance apart which is \close" to being a factor of p. We assume this notion of being almost periodic is intuitive enough to remain qualitative, although obviously it can be made more precise.
Finally, we can dene a notion of a partially repeating instantiation  in P , and derivative notions, in terms of instantiations that share some of their values.
Secondly, a process will be said to be invariant if the values of the dierent instantiations do not dier a great deal.
We distinguish two kinds of invariance, duration and path invariance.
First, consider total duration invariance.
We can draw an even ner distinction between weak and strong total duration invariance.
We can express strong invariance in terms of mean, or average duration, and standard deviation.
Thus, let the mean duration of an event represented by Vi in a process P be the average duration of Vi over all instantiations in P .
Let VPi be a variable denoting the standard deviation from the mean.
We say that a process P is -invariant if for each Vi , the value of VPi is less than .
Finally, we say that a process P is totally invariant if there exists a  which is close to 0 such that P is -invariant.
Path invariance means that there is never a large dierence in the cost among dierent paths through N throughout a process P .
More precisely, let c(t1 I ) and c(t2 I ) be the costs of any two of the n!
tours through a duration network N with n variables, given I .
Then path invariance implies that the the dierence between these values is not greater than some small value .
Strong invariance is a global property of a process: intuitively, it says that the duration of any variable or edge of a duration network never strays excessively from the mean.
This does not allow a \real good" path ever to become \real bad", although it may become less good.
Weak invariance is a strictly local phenomenon: it constrains every pair Ii Ii+1 of consecutive instantiations in P to be \close in their assignments" to all elements of N .
(This notion can be made precise in an obvious manner.)
Thus, weak invariance allows for a good path to become bad over the long run.
We can generalize any of these notion of invariance to (partial) invariance, in which a  subset of I exhibits invariance.
Again, for our purposes, it is enough to leave this intuitive notion qualitative.
We view the world as exhibiting varying degrees of invariance and periodicity.
An intelligent agent can learn and apply knowledge about invariance and periodicity in order to make plans which are intelligent.
This is the case although the knowledge the agent has is incomplete, and partial, and the world is in constant ux.
In the next section, we consider this capability in the context of constructing the tour series Tmest.
3 Computational Theory As noted, the ability of an agent to eectively solve the class of problems abstractly characterized as a traversal of a duration network depends on The goal of the game The properties of P  and Assumptions about the agent's knowledge of N and P .
For example, if the agent is given the requisite knowledge to determine P , then it does not matter whether P exhibits any invariance or periodicity: the agent will be able to \precompute" an optimal Tmest based on an exhaustive search of each instantiation.
The case to be examined here is the one in which the knowledge the agent has of P is, at best, partial.
In this section, we describe a version of the game in which 1.
The agent has, initially, an \abstract map" of N  2.
The agent has no quantitative knowledge about P  3.
P exhibits total strong duration and path invariance.
4.
The goal of the game is for the agent to construct Tmest .
We next present a computational theory which explains and realizes this behavior.
To solve for a goal, given the initial constraints, the agent needs to have a means to learn and apply knowledge it discovers about P to select a tour tj , given t1 : : : tj 1, as part of a series.
To make use of the rewards aorded by certain paths, we introduce the notion of relative mean duration: Denition 4 (Relative Duration) Let N = (V E ) be a duration network, T = ht1 : : :tk i be a tour series and P = hI1 : : : Ik i be a process.
The relative duration of an event Vi with respect to an event Vj in an instantiation In and corresponding tour tn (rd(hVi  Vj i tn In)) is c(tn=hVi  Vj i In) + c(tn=hVj  Vii In ).
Furthermore, the relative mean duration of an event Vi with respect to an event Vj over a set of k occurrences of Vi and Vj (rmdViVj (I T ))is ;  C (T=hVi Vj i I ) + C (T=hVj  Vii I ) k Let rmdViVj (I T ) denote the standard deviation of rmdViVj (I T ).
If I and T are given, the notation for these values is simplied to rmdViVj and rmdVi Vj .
Intuitively, relative duration is the cost of the leg Vi < Vj or Vj < Vi in a tour, given an instantiation of the variables and the edge connecting them.
Since the relation of \sharing a stage" is symmetrical, these costs are assumed to be identical e.g., any reward for pairing cleaning actions K and B in immediate temporal proximity will be collected, whether the order be K < B or B < K .
Relative mean duration, then, consists of the average relative duration of pairs of events over a set of tours in a series.
Assuming P exhibits total duration and path invariance, an agent can incrementally  '$ &% '$ &%  '$ &% '$ &%  8 (((( V2 ((( ( V1 11 ;; CC QQ CC QQ ;; CC 8 Q ; 8 CC CC ; QQQ 6  CC ;; V3  6  QQ C Q  V4  Figure 3: A Possible -Graph Associated with Figure 2  learn the requisite knowledge for constructing Tmest on the basis of computing and storing relative mean durations.
This information will be stored in what will be called a -network: Denition 5 Given a duration network N and a process P , a -network for N = (V E ) is a weighted undirected network with the following characteristics.
Each vertex is labeled by one of the elements in a set V .
Each edge (Vi  Vj ) is labeled.
The value of the label represents rmdViVj .
Figure 3 is an example of a -network corresponding to the duration network in the previous gure.
The labels on each edge represent values for rmdViVj .
These values would be accurate, for example, at the end of a kprocess P consisting of k repetitions of the instantiation depicted in the previous gure.
With the information in the -network, an agent can determine the next best tour in Tmest .
Let us assume that the process P exhibits strong duration and path invariance, but incorporates no assumptions about periodicity.
The method TS for constructing Tmin is summarized in Figure 4.
For the sake of simplicity, there is an assumption of a \learn-  UpdateMean(var :  ; graph t : tour I :  instantiation k : index)  Algorithm TS Input:  A process P = hI1 : : :  Iki A Duration Network N = (V E ), V = fV1  V2  : : :  Vn g, initialized by an instantiation Iinit A -network = (V  E ), where V = V and E = E .
For each edge Eij in , let v(Eij ) represent the value of the label on that edge.
Initially, this value is 0.
Output: The updated -network , which now contains statistical information about P based on its having executed a tour series Tmest = htmest1  : : :tmestk i and C (Tmest I ).
For each edge Eij in do v(Eij )   rd(hVi  Vj i Iinit) k   1 Tmest   hi  loop  tk   HamiltonPath( ) UpdateMean(  tk  Ik k) Tmest   Tmest + htk i /* hui + hvi = hu vi */ k  k+1 until k = p Return and C (Tmest P ) Figure 4: Algorithm for Constructing a Tour Series which Minimizes Overall Extent  begin For each edge Eij = hVi  Vj i in do rmdViVj   c(tk =hVi  Vj i I ) + c(tk =hVj  Vii I ) if rmdViVj > 0 then v(Eij )   (k 1)v(Eijk)]+rmdViVj end ;  Figure 5: Updating Algorithm for -graph ing phase" in which the agent is supplied values for one instantiation Iinit of N .
This can be viewed as, e.g., a robot being supplied a \map" of the world it needs to navigate repeatedly.
The main loop iteratively generates tk , the next tour in the series, from by performing a Hamilton Tour of this network, and updates based on information it has acquired about Ik as the result of its tour tk .
The Hamilton tour gives the best estimate of the tour with the lowest overall extent.
The \nal score" of the game is the overall cost of the tour series Tmest.
The UpdateMean Algorithm records the cost of tk as the result of Ik , by updating the -network accordingly.
The procedure is summarized in Figure 5.
This procedure simply updates the mean relative duration rmdViVj for each edge in , based on the result of the cost of traversing this edge in Ik by tour tk (if this tour contains this leg if not, then this cost is 0 and no updates are made).
This algorithm, we claim, realizes behavior which, under the constraints posed by this version of the game, is useful in the generation of intelligent orderings of a set of events.
As a variation on the game, suppose the agent is interested, not in reducing overall extent, but rather in reducing the duration uncertainty associated with a set of events.
This would be the case, e.g., if the agent has no constraints on the time of the completion  of a set of tasks, but wanted to be reasonably sure, at each moment in every tour, on which leg of the tour it is located.
A minor modication of the game in the preceding section will allow the agent to estimate a tour series Tdu, which approximates the tour series which is minimal with respect to duration uncertainty.
Again, let rmdViVj be the standard deviation of the relative mean duration of a set of occurrences of events Vi and Vj in immediate temporal succession.
Imagine modifying the -network so that the labels on each edge Eij stores values of rmdViVj .
We can replace UpdateMean with a procedure, call it UpdateSD, for updating standard deviations, based again on the result of the most recent tour.
Then, applying TS with UpdateSD computes Tdu , which estimates the tour series with the minimal duration uncertainty.
Numerous other enhancements to the representation are possible.
For example, incorporating duration uncertainty as a constraint would lead to a variation of the one-person game in which the agent's goal is to minimize the duration uncertainty associated with a tour.
Another enhancement to the game involves incorporating assumptions regarding periodicity to I would make such information useful to store in a -network.
Relative durations would be further relativized to time periods, which are represented by the index k on the instantiation Ik .
Relative mean durations, and their standard deviations, would be required to reect this relativization.
For this information, it is possible that a quantitative model for probabilistic temporal reasoning such as found in 2], could be applied alternatively, a qualitative model of recurrence, such as 3], might serve the same purpose.
4 Conclusion This paper has provided a framework for developing planning and scheduling systems in a dynamic world.
One primary assumption  motivating this framework is that events tend to exhibit varying degrees of duration uncertainty, and that an intelligent agent needs to confront this uncertainty in planning situations.
One aid in reducing duration uncertainty exploits the fact that events share stages with other events.
References  1] Drummond, M. Bresina, J. Swanson, K., 1994.
Just-In-Case Scheduling.
In Proceedings of the Twelfth National Conference on Articial Intelligence (AAAI94).
AAAI Press/MIT Press, Menlo Park, 1994:1098-1104.
2] Goodwin, Scott D., Hamilton, H. J., Neufeld, E., Sattar, A., Trudel, A.
Belief Revision in a Discrete Temporal Probability-Logic.
Proceedings of Workshop on Temporal Reasoning, FLAIRS94, 3] Morris, R., Shoa, W., and Al-Khatib, L., (1994) Domain Independent Reasoning About Recurring Events.
Forthcoming in The Journal of Computational Intelligence.
2012 19th International Symposium on Temporal Representation and Reasoning  Compositional Refinement for Real-Time Systems with Priorities Abdeldjalil Boudjadar, Jean-Paul Bodeveix, Mamoun Filali IRIT-UPS, Universite de Toulouse Toulouse, France {boudjada, bodeveix, filali}@irit.fr  Si is an abstraction of Si .
With the above fact, checking that S satisfies a property P becomes more tractable and simply consists of checking that each component Si satisfies a property Pi , where P is a composition of Pi .
That is what happen in compositional verification [14] and abstractionbased verification [6].
Defining the parallel composition and finding a suitable refinement relation for real-time systems with communication, priorities and variables is a tough task.
Real-time system properties are often formalized using timeconstraints and priorities.
To consider such concepts, we introduce real-time systems with a global space (variables and clocks) and priorities (static and dynamic).
Similarly to process algebras, to deal with hierarchical design and specifications, real-time formalisms have known a large number of composition approaches.
However, a compositional framework with high-level concepts like variables, communication and priorities is still lacking.
Several works [11], [16], [22], [13] have focused on this subject by analyzing thoroughly the problem and criticizing existing solutions.
In fact, this paper is a follow up of [12] where we have revisited the composition of timed systems, without priorities, and proposed a new communication mechanism for UPPAAL timed automata.
In [12], we have defined an original composition operator endowed with good properties (associativity, refinement, etc.
), and supporting communications via synchronization of actions and shared variables.
Through the introduction of priority, we revisit the framework defined in [12] for reasoning about the composition of timed systems.
Thereafter, our framework, defined with priorities, will be instantiated for UPPAAL timed automata with three priority orders : static priority, priority on channels and priority on processes, where we will analyze different priority relations, and give both operational semantics and refinement of timed automata TA and networks of timed automata NTA (in compositional way).
The rest of our paper is organized as follows: Section 2 presents the existing related work.
In Section 3, we present the formal basis of our work, where we introduce Communicating Labelled Transition Systems with location Invariants and Priorities (CLTSIP).
We give a sufficient condition for the bisimilarity and define an associative product of CLTSIPs.
Moreover, we define ETTSs as CLTSIPs which synchronize on time instants.
Section 4 introduces UPPAAL TA and NTA with committed locations, priority on channels and priority on processes.
Here, we show the compositionality of NTA semantics in terms of ETTSs, where the two corresponding ETTS-based semantics  Abstract--High-level requirements of real-time systems like as time constraints, communications and execution schedulability make the verification of real-time models arduous, where a system is the interaction of a possibly unbounded set of components.
Priorities have been introduced to resolve execution conflicts, and by that, prevent the combinatorial explosion of state space.
In this paper, we are interested in the composition and refinement of timed systems by considering static and dynamic priorities.
Firstly, we propose a revised definition of the product of extended timed transition systems with static and dynamic priorities associated to individual transitions.
Afterwards, we study the (compositional) refinement of compound extended timed systems.
Without sacrificing compositionality, we instantiate this framework for the case of UPPAAL networks of timed automata with static priority Committedness, dynamic priority between channels and priority between processes.
Moreover, we show how to associate an Extended Timed Transition System (ETTS) to timed automata (TA), where an unique generalized dynamic priority system of ETTS is derived from both dynamic priority orders: priority between channels and priority between processes.
Keywords-Timed systems; composition; refinement; priorities.
I. I NTRODUCTION The concurrency theory [25] is an extremely helpful concept whereby the design of complex systems becomes as far as tractable.
It has by now established itself as an extensive research field for mastering the schedulability of executions.
However, concurrency has a real impact on model checking of real-time systems, where conflicts and non-determinism of executions are greatly diverging together with the number of system (competing) processes, which often leads to combinatorial explosion of the state space, the reason for this being that time is considered as part of the state.
To tackle non-determinism and execution conflicts, priorities have been introduced as a scheduling order.
Composition, refinement and model-checking of timed systems with priorities have been intensively studied [9], [18], [22], [3], [17], [16], [13].
The ultimate goal of these work is to deal with details resulted from the use of clock variables and evolutive data structures, required by real-time applications.
Abstraction refinement [19] plays a key role in the design and verification of real-time systems.
It enables to abstract unbounded data structures and implementation details whereby, we are able to perform model checking on a system S  = S1  ...  Sn instead of the original complex system S = S1  ...  Sn , where each 1530-1311/12 $26.00 (c) 2012 IEEE DOI 10.1109/TIME.2012.21  57  priority orders on channels and on processes, and establish their compositional semantics in terms of ETTSs.
are equivalent: a direct one (an ETTS associated to the NTA) and the product of ETTSs, associated to individual timed automata, composed with a restriction.
We also establish an interesting refinement property stating that: the refinement of a NTA consists in the refinements (separately) of its individual TA.
Finally, we show an application of our framework to refine a version of the Alternating Bit Protocol [28], and conclude with future work.
III.
T RANSITION S YSTEM E XTENSIONS In this section, after introducing priorities, we give a brief recall of one of the fundamental models of concurrency, transition systems, originally introduced in [27] and since then studied extensively by [26] and others.
Roughly speaking, transition systems are an elegant model for representing the behavioral aspects.
Due to their safety properties verifiable using model-checking, transition systems have been intensively applied to the modelling of complex systems, as well as for giving semantics to synchronous languages and realtime formalisms.
In what follows, we define composable symbolic transition systems (CLTSIP) as a modeling framework.
Thereafter, we give their associative product and study the refinement of their parallel composition.
II.
R ELATED W ORK Composition and refinement of real-time systems with priorities have been intensively studied [18], [16], [13], [22], [9] during the last two decades.
However, a compositional framework merging different priority systems is still relatively lacking.
Several works of Sifakis [11], [18], [3], Cleaveland [9], [15] and UPPAAL team [16], [17] have focused on the modeling and synthesis of timed systems with priorities.
They represent a common theoretical basis for the modeling with priorities.
The authors of [18] define a design framework for both safety and deadlock-freedom requirements.
The framework consists of a priority system, where an action ai has (dynamic) priority over another action aj once a condition cij is satisfied together with the enabledness of actions.
In the same way, [11] defines a dynamic priority on actions, where an action ai has a priority on an action aj during a certain time interval.
In fact, such dynamic priority relations are a partial function because they are only applied under the satisfaction of an extra condition on comparable actions.
In [16], the authors define an extension of timed automata with a dynamic priority order between actions and another priority order between processes.
They give an efficient algorithm to compute subtractions of DBMs (Difference Bounded Matrices).
The authors define a non compositional semantics of networks of extended TA, in terms of timed transition systems.
Under certain restrictions, they show how an unique generalized priority order can be derived from both action and process priority orders.
In [9], the authors describe a modeling framework for real-time systems, using dynamic priorities, which essentially extends CCS (Calculus of Communicating Systems) algebra [25] with dynamic priorities.
Such a proposal reduces drastically the state space of systems and preserves their functional behavior.
In fact, action priorities are not constant and may change when the system evolves.
Formally, each action priority is inferred from delays preceding that action.
Accordingly, the longer is the delay preceding an action, the lower is its priority.
In this paper, we present a compositional framework for the composition and refinement of timed systems with both static and dynamic priorities.
To this end, we consider an extended structure of timed transition systems ETTS with variables, location invariants and communication where each transition possesses a static priority s and a dynamic one d. We define an associative parallel product of ETTSs together with a compositional refinement property.
Moreover, we instantiate our framework for the case of UPPAAL networks of timed automata, with the static priority committedness and dynamic  A.
Priority Systems Priorities [9], [15], [18], [3], [22], [13] have been introduced as a way to structure and control the usage of shared resources, by specifying that some actions or behavior are privileged over others.
They offer a scheduling order to deal with nondeterminism and execution conflicts.
The BIP language [3] and ACSR algebra [13] provide a powerful mechanism to express different sort of priorities.
Mainly, we distinguish static and dynamic priorities: *  *  Static priorities [12], [7], [4] define an order between transition executions regardless of their enabledness.
With such priorities, non-enabled higher-priority transitions hide enabled lower-priority transitions, which often leads to a deadlock.
In UPPAAL timed automata [4], the static priority is represented by the notion of Committedness (two priority levels) where committed transitions [7], those outgoing from a committed location, have priority over non-committed ones.
Dynamic priorities [22], [18], [9], [16] state that an enabled transition hides a lower-priority transition.
[18] introduces a conditional dynamic priority relation, where an enabled transition hides a lower-priority one if a given condition holds.
Another class of priority relations [11] consists to restrict the applicability of priority to a given time interval.
The semantics of priority relations [11], [18], defined over timed systems, is given by a model transformation where only dynamically higher-priority transitions are held.
Definition 1 (Priority system): A priority system P is a triplet P, fi,  where P, fi is a join semi-lattice, and  : P x P - P is an associative and commutative operator defining the maximum of two values.
We also use i pi to represent the maximum of a finite non empty set of values.
In fact, the join semi-lattice P, fi represents a partially ordered set of priority values, where each subset of P has a least upper bound.
58  *  B. Labelled Transition Systems Labelled transition systems [2] are the reference model used to express and compare behaviors through simulations.
They offer a strong notion of equivalence that can be checked efficiently.
Firstly, let us start with a brief recall of classical labelled transition systems (LTS).
Definition 2 (LTS): A labelled transition system (LTS) over an alphabet S is a tuple Q, Q0 , T r, a, b, l where: 0 * Q is the state space such that Q [?]
Q is the set of initial states, * T r is the set of transitions, * a : T r - Q and b : T r - Q are functions associating, respectively, source and target states to each transition, * l : T r - S is a function associating to each transition a label.
l For the sake of simplicity, we write t : q - q  for t [?]
T r  with a(t) = q, b(t) = q , l(t) = l. If useless, the name of a transition will be omitted.
Moreover, projection functions a, b and l can be omitted and systematically inferred from the transition relation -.
By now, we give LTSs simulation to check that a concrete LTS implements an abstract one.
Definition 3 (Simulation): Given two labelled transition systems Tc = Qc , Q0c , T rc  (concrete) and Ta = Qa , Q0a , T ra  (abstract), Ta simulates Tc through a relation R [?]
Qc x Qa , denoted by Tc  R Ta , if: 0 0 * [?
]qc [?]
Qc , there exists qa [?]
Qa such that R(qc , qa ).
l    * [?
]qc qc qa l, if qc -c qc and R(qc , qa ) there exists qa [?]
l    Qa such that qa -a qa and R(qc , qa ).
Accordingly, two LTSs Ti and Tj are bisimilar through a relation R [?]
Qi x Qj , denoted by Ti ~R Tj , if Ti  R Tj and Tj  R-1 Ti .
*  Static priority expresses that a higher-priority transition hides a lower-priority one.
The hiding is supposed to be static: a non-firable high-priority transition can hide a firable lower-priority transition.
Dynamic priority states that an enabled priority transition hides lower-priority ones.
An enabled transition is firable if it is not hidden by another higher-priority enabled transition.
Throughout this paper, the static priority is considered first.
We have also introduced location invariants over the global space to restrict the set of states, by reducing the global space valuations.
Definition 4 (CLTSIP): Given two priority systems Ps = Ps , fis , s  (static) and Pd = Pd , fid , d  (dynamic), a composable LTS with location invariants and priorities (CLTSIP) over a shared space G, an action language A 1 , a set of one-to-one channels C and a set of synchronization events M is a tuple Q, q 0 , G0 , I, T r, a, b, l where: * * * * * *  *  C. Composable LTS with Location Invariants and Priorities  Q is the set of locations (local states), q 0 is the initial location, G0 is the set of initial global states, I : Q - 2G associates an invariant to each location, T r is the set of transitions, a : T r - Q and b : T r - Q are functions associating, respectively, the source and target locations of each transition, l : T r - LxAxPs xPd is a function associating to each transition the corresponding label, action, static priority value and dynamic one, where L = C?
[?]
C!
[?]
M [?]
{t } is the set of labels.
C!
and C?
correspond respectively to send and receive labels over channels C. M is the set of multiple (many to many) synchronization events and t is the internal event.
Moreover, a CLTSIP must satisfy the wellformedness condition: n-ary synchronization transitions, with a label in M , are supposed to have the lowest static and dynamic priorities.
In this section, we define composable LTS with location invariants and priorities (CLTSIPs), as an extension of labelled transition systems with shared variables, communication, static priority, dynamic priority and location invariants.
Moreover, we specialize both state space and alphabet to allow several communication protocols between transition systems: * via a shared space: we distinguish local and global state spaces, and introduce abstract actions that update the global state space.
These actions can be non-deterministic and blocking.
* via CCS-like channels [25]: we introduce a set C of sendreceive channels, where two transitions synchronize if their actions are complementary.
The resulting transition, of such a synchronization, corresponds to an internal transition in the composition.
* via CSP (Communicating Sequential Processes)-like synchronization [21]: we introduce a set M of many-to-many synchronization events, which enable to model a system transition where all processes perform a lock-step [21].
Throughout this paper, we use such a synchronization to model time-evolution transitions.
Furthermore, to reduce the non-determinism and execution conflicts, we consider the following priority mechanisms.
l/a  Here and elsewhere, we write t : q ---s,d q  for a transition t [?]
T r with a(t) = q, b(t) = q  , l(t) = l, a, s, d.
If not needed, the name of a transition will be omitted.
Again, the set of transitions T r is often denoted by the transition relation -, which enables to omit the projection functions a, b and l. The semantics [[.]]
of the action language A is given by [[.]]
: A - 2GxG .
Let us consider the following predicates: *  *  l/a  A transition t : q ---s,d q  is said to be enabled in a global state G if [?
]G | (G, G ) [?]
[[a]] and G |= I(q  ).
l/a  A transition t : q ---s,d q  is said to be statically hidden     l /a  if [?
]t : q ----s ,d q  such that s [?
]s s .
*  l/a  A transition t : q ---s,d q  is said to be dynamically   l /a  hidden if [?
]t : q ----s ,d q  enabled and non statically hidden such that d [?
]d d .
Accordingly, a transition is said to be hidden if it is statically and dynamically hidden.
1 This action language is abstract here.
It will be made more precise in section IV-B  59  Definition 5 (Semantics of a CLTSIP): Given a global space G, a static priority system Ps = Ps , fis , s , a dynamic priority system Pd = Pd , fid , d  and an action language semantics [[.]]
: A - 2GxG .
The semantics of the CLTSIP Q, q 0 , G0 , I, T r is the LTS: * Q x G, 0 0 0 * {q } x (G [?]
I(q )),   l/a    from a location corresponding to q in the abstract CLTSIP T2 .
The universal quantifier given in Item (2) dissociates the condition on priorities from that of refinement and makes, by that, the proofs further simpler than that of the LTS-based refinement.
Proof.
Straightforward.
1) Restriction of a CLTSIP: The restriction [25] of a CLTSIP, over a set of channels, is a CLTSIP where transitions composable over these channels have been removed together with transitions of lower static priority.
Definition 7 (CLTSIPs restriction): Given a CLTSIP T = Q, q 0 , G0 , I, -- over a shared space G and a set of channels C. Let C  [?]
C, we define the restriction of T over C  , denoted l/a by T \C  , to be the CLTSIP Q, q 0 , G0 , I, {t : q ---s,d q  |    {(q, G), l, (q , G ) | [?
]t : q ---s,d q [?]
T r, G |= I(q), enabled(t, G), !statically hidden(t) and !dynamically hidden(t)} In fact, LTS states correspond to the product of both locations and space valuations of the CLTSIP.
Namely, an enabled transition t, of CLTSIP, is held if it is not statically hidden by a higher-priority transition t , i.e.
s [?
]s s , and if it is not again dynamically hidden by another enabled non-hidden transition, i.e enabled(t , G) [?]
!statically hidden(t ) = d [?
]d d .
Definition 6 (Similarity): A CLTSIP Ti is said to be (bi)similar to CLTSIP Tj if their associated LTSs are (bi)similar.
The presence of both static and dynamic priorities makes the semantics of CLTSIPs rather complex.
It would be much more readable if we could get rid of managing priorities during simulation proofs.
To this end, we consider a sufficient condition for the refinement of CLTSIPs, expressed as the simulation of the corresponding LTSs.
Firstly, we introduce the predicate *  l /a  l[?]
/ C  [?]
[?
]t : q ----s ,d q  , l [?]
C  = s s s}.
In fact, from each location, a transition is held if it is neither labelled by a communication l [?]
C  , nor statically hidden by another communicating transition (over C  ) outgoing from that location.
Theorem 2 (Refinement and restriction): Let Tc , Ta be two CLTSIPs defined on the same set of channels C, then Tc   Ta = Tc \C   Ta \C.
Proof.
It consists to show that each non-hidden concrete transition of Tc \C, labelled by t or m [?]
M , has a corresponding abstract transition non-hidden in Ta \C.
2) Product of CLTSIPs: In what follows, we define an associative n-ary product of CLTSIPs, where locations of composition are simply obtained by the product of individual CLTSIP locations.
Moreover, our product is parameterized by two internal operations defined on the action language: * a1  a2 is used to compose actions associated to sendreceive communication.
* a1  a2 is used to compose actions associated to global synchronizations (lock-step).
This operation is supposed to be commutative, respectively associative, in order to establish the commutativity, respectively associativity, of the product.
Definition 8 (N-ary product of a family of CLTSIPs): Given an indexed family Ti = Qi , qi0 , G0i , Ii , -i 1..n of n CLTSIPs defined over the same shared space G, action language A, static priority system Ps and dynamic priority system Pd , their product   P1..n Ti is defined by the CLTSIP  i Qi  , q10 , .
.
.
, qn0 , i G0i , I, - over G, Ps and Pd where I(q) = i Ii (qi ) and - is the smallest relation such that:  l /a  l/a  Ismax ts (t : q ---s,d q  )  [?
]t : q ----s ,d q  !
(s [?
]s s ) defining a higher static priority transition outgoing from lol/a cation q.
In the same way, Ismax td (t : q ---s,d q  )  l /a  [?
]t : q ----s ,d q  !
((d [?
]d d ) [?]
enabled(t , G)), with (G, G ) [?]
[[a ]], is a predicate defining a higher dynamic priority transition outgoing from location q. Theorem 1 (Refinement of CLTSIPs): Given two CLTSIPs T1 and T2 with their respective static and dynamic priority systems (Ps1 , Pd1 ) and (Ps2 , Pd2 ).
T1 refines T2 through the refinement relations Rl [?]
Q1 xQ2 and Rg [?]
G1 xG2 , denoted T1  Rl ,Rg T2 , if 1) The associated LTSs satisfy the sufficient condition for simulation, i.e: 0 0 * Rl (q1 , q2 ), 0 0 * [?
]x [?]
G1 , [?
]y [?]
G2 | Rg (x, y), *  l/a1  [?
]t : q1 ----s1 ,d1 q1 , [?
]q2 x x y such that (x, x ) [?]
[[a1 ]].
If Rl (q1 , q2 ) and Rg (x, y) then there exist q2 [?]
Q2 , a2 , y  , s2 [?]
Ps2 , d2 [?]
Pd2 such that l/a2  q2 ----s2 ,d2 q2 [?]
(y, y  ) [?]
[[a2 ]] [?]
Rl (q1 , q2 ) [?]
Rg (x , y  ), * [?
]q1 [?]
Q1 q2 [?]
Q2 , Rl (q1 , q2 ) [?]
I2 (q2 ) = I1 (q1 ), 2) For all t1 [?]
T r1 and t2 [?]
T r2 such that Rl (a1 (t1 ), a2 (t2 )) and Rl (b1 (t1 ), b2 (t2 )), then Ismax ts (t1 ) = Ismax ts (t2 ), Ismax td (t1 ) = Ismax td (t2 ).
Roughly speaking, the refinement consists of establishing a mapping between the transitions of refining and refined CLTSIPs.
In fact, from each location q of the concrete CLTSIP T1 , the presence of a transition t1 , with a maximal priority, states the presence of a maximal-priority transition outgoing  ti :qi - --s,d qi l/a  l[?]C![?]C?[?
]{t }  q- --s,d q[i-qi ] l/a  Async(ti )  m/ai  ([?
]i) qi ----si ,di qi m [?]
M m/  J  i ai  q- ------s s  q ,d d i i i    Sync  c?/aj  c!/ai  ti : qi ----si ,di qi tj : qj ----sj ,dj qj (P C) i =  j t /ai aj  q- -----s  60  q[i-qi ,j-qj ] s d i  sj ,di  dj  SR(ti , tj )  where (P C) is a priority condition stating that if static, respectively dynamic, priorities of transitions ti and tj are increased upto the maximum si s sj , respectively di d dj , no new hiding may occur.
For example, the static priority condition for CLTSIP Ti can be formally expressed as  [?
]t : l/a qi ---s,d qi | (s s si ) [?]
(s s si s sj ).
The notation q[i - qi ] states the replacement of the ith location of vector q by location qi .
If we consider UPPAAL TA, in which transition priorities are assigned to channels, then di = dj = di d dj .
About transition rules, Async(ti ) represents internal transitions and potential synchronizations that a CLTSIP may be willing to engage in with its environment.
Rule Sync defines a n-ary synchronization of a set of transitions on the same event m, which will be instantiated by a time-transition in the ETTS.
Rule SR(ti , tj ), for send/receive, corresponds to a synchronized communication of both Ti and Tj on compatible events through a channel c [?]
C. Let us mention that n-ary synchronization transitions, labelled by m, cannot block or be blocked.
One may remark that our product is syntactical, whereby, all of the CLTSIP non-composable transitions are held.
Theorem 3 (Generalized associativity): If  is associative, i.e.
i[?
]I j[?
]Ji ai,j = i[?]I,j[?
]Ji ai,j , the product of CLTSIPs is associative, i.e.
: Pi[?
]I (Pj[?
]Ji Ti,j ) ~ Pi[?]I,j[?
]Ji Ti,j Proof.
It essentially consists of defining an isomorphism between the two structures, state space and transitions, preserving labels and priorities.
 3) Compositional Refinement of CLTSIPs Product: Modelchecking of real-time systems suffers from the state explosion problem, the reason for this being that time is considered as part of the state, leading then to a widely large or even infinite state space of the system.
Abstraction refinement plays a key role in the model-checking of complex systems where unbounded data structures can be abstracted.
However, for compound systems, defining the refinement of the whole system is an arduous task.
In what follows, we show how the (compositional) refinement [19] of CLTSIPs product has been brought to a set of simpler refinements of individual CLTSIPs.
Theorem 4 (Compositional refinement): Given two products of CLTSIPs T1  ...  Tn and T1  ...  Tn defined on the same priority systems (with total orders).
T1  ...  Tn refines T1  ...  Tn , denoted by T1  ...  Tn  [?
]i Rli ,Rg T1  ...  Tn where Rli [?]
Rlj (qi , qj )(qi , qj ) = Rli (qi , qi ) [?]
Rlj (qj , qj ), if:  * [?
]i Ti  Ri ,Rg Ti , l * each concrete transition and its corresponding abstract one have the same priorities (morphism), * refinement preserves deadlock-freeness, where deadlockfreeness is defined by the existence of firable transitions.
Through this theorem, we are able to perform model checking on the composition of CLTSIPs, T1  ...  Tn , instead of the original composition T1  ...  Tn .
In fact, through the last two conditions of this theorem, we may reduce the refinement of CLTSIPs to classical refinement relations of transition systems, and by that, the proof would be much more tractable (note that we do not claim that composition preserves deadlock freeness).
Proof.
Given a transition of the concrete product, it is either asynchronous from some Ti and has a corresponding abstract  transition in Ti with the same priority, which is in turn present in the abstract product, or a synchronization SR of two transitions from Ti and Tj that have abstractions in Ti and Tj which synchronize in the abstract product with the same priority, or again an n-ary synchronization Sync which, as previously stated, leads to an n-ary synchronization in the abstract product.
Moreover, if a concrete transition has priority over ready 2 transitions, then the corresponding abstract one has also priority.
 D. Timed Transition System Extensions Timed transition systems [20] are the reference model to define the semantics of real-time formalisms such as time Petri nets and timed automata.
Basically, a Timed Transition System (TTS) is a labeled transition system where labels can be events or durations.
In this section, we define extended timed transition systems (ETTS) as CLTSIPs which synchronize on time.
ETTS actions are considered as a pair (guard, assignment) of CLTSIPs.
Furthermore, we consider the global state space structured as valued variables.
Definition 9 (ETTS): An Extended Timed Transition System (ETTS) on a set of variables V valued over a domain D, a static priority system Ps , a dynamic priority system Pd and a set of channels C is a CLTSIP over the global space G = DV where the synchronization events m [?]
M are time instants of D = R>=0 .
Its action language is defined as the set of pairs (guard, assignment), where a guard is a predicate over variables of V and an assignment is a partial function mapping variables to expressions built on V. The semantics of an ETTS depends on its action language semantics.
Here, we have chosen the following definition for the (guard, assignment) pairs: Action a:=  language g/ v[?
]V v := ev | aa | j[?
]J aj  Semantics  [[g/ v[?
]V fi v := ev ]](x, x ) = g(x) [?]
v[?
]V x (v) = [[ev ]](x)  The notation g/ v[?
]V states the parallel update of variables of V as an assignment guarded by g. Both action composition operators  and  are left undefined.
Their semantics will be chosen to conform with the semantics of timed automata action composition.
IV.
I NSTANTIATION FOR UPPAAL UPPAAL [4] is an integrated tool environment for modeling, validation and model checking of real-time systems modeled as networks of timed automata.
The tool has been used successfully and routinely for many industrial case studies.
In this section, we consider UPPAAL timed automata (TA) [4] as an instantiation of CLTSIPs.
The UPPAAL language [24] considers 3 priority orders: a static binary priority so-called Committedness associated to locations, a dynamic priority order on channels and another dynamic priority order between 2 Transitions outgoing from the same state and, for dynamic priority, enabled.
61  processes.
In fact, location committedness is a high level mechanism defining two priority levels, where transitions outgoing from committed locations have priority over transitions outgoing from non-committed locations, independently of their enabledness.
* In UPPAAL [4], committedness is associated to states where systems cannot delay if the current state is committed.
* In order to define a compositional semantics of timed automata composition, using a products of TTSs (Timed Transition Systems), [7] proposes a restriction on UPPAAL so that a committed state has always a firable outgoing transition.
* With respect to our previous work [10], we do not require such a restriction but we use a slightly modified structure of TTSs.
Location committedness is considered as a static priority system with two priority values {true, f alse}.
Moreover, the dynamic priority order on channels [11], [18], [16] states that a synchronizing transition t on a channel c, which has priority over a channel c , has priority over transitions composable on c if it is firable, i.e.
the guard of t is satisfied.
We also consider the priority order on TA processes, which is a dynamic relation stating that the executions of a timed automaton have priority over the executions of other TA.
In what follows, we introduce UPPAAL TA with the three priority orders (committedness, priority on channels and priority on TA) and define their ETTS-based semantics, where an unique generalized dynamic priority system is derived from both priority on channels and priority on TA.
To this end, on a composition, static priority is checked first and if the conflict is not solved we may refer to the priority order on channels.
Again, if the choice of a transition from a conflict cannot be made, we compare then the dynamic priorities associated to the involved TA.
of the static priority system with two values.
Moreover, the unique dynamic priority system of ETTS semantics is derived from a merge of both priority orders fic and fita .
Definition 11 (Priority systems corresponding to TA): Given a timed automaton T [?]
TA defined on a total priority order fic on channels and a total priority order fita on elements of TA, where TA is the set of timed automata names, the static priority  system associated to T is defined by Ps = {[?
], }, =,  and the dynamic one is defined by Pd = ({, default} [?]
C) x TA, fid , d  where (x, y) fid (x , y  )  x [?
]c x [?]
(x = x [?]
y fita y  ).
Since the orders fic and fita are total in UPPAAL, the priority order fid is total.
default is the UPPAAL priority level assigned to t -transitions and  is the lowest priority level.
In fact, the static priority system is straightforward, whereas the dynamic priority system consists in checking first the priority on channels and if the choice of a transition cannot be made, we refer then to priorities of the corresponding TA.
By now, we give the semantics of TA in terms of ETTSs where ETTS locations are TA locations.
Definition 12 (ETTS of a TA): Given a set of channels C, a priority order fic on channels, a priority order fita on TA and a set kh of clocks.
The semantics of a timed automaton with committed locations and priorities T = Q, q 0 , K, I, -ta  is defined by the ETTS Q, q 0 , G0 , I, - over the global space kh - D, static priority system Ps and dynamic priority system Pd where G0 = kh x {0} and - is the smallest relation such that: q- ----ta q g/t /r  g/t /fix[?
]r x:=0  q- ---------q[?
]K,(default,T ) q  ----  g/l/r  q l[?
]C ta q g/l/fix[?
]r x:=0 q[?
]K,(l,T )  q- --------- q[?
]K  A. TA with Committed Locations and Priorities Timed automata [1] have been introduced as a modeling framework to support the description and analysis of timed systems.
In fact, a timed automaton is structured as a finitestate machine extended with a finite collection of real-valued clocks initialized to zero and increased synchronously.
Definition 10 (TA with committedness and priorities): Given a set of clocks kh, a set of channels C, a priority order fic on channels of C and a priority order fita on TA, a timed automaton with committedness and priorities is a tuple Q, q 0 , K, I, - where: 0 * Q is a set of locations where q [?]
Q is the initial location, * K [?]
Q is a set of committed locations, kh-D * I : Q - 2 associates a clock invariant (a set of clock valuations) to each location, kh-D * -[?]
Q x 2 x 2kh x S x Q is the transition relation defined with a clock guard, a reset set and an event l [?]
S. S = C?
[?]
C!
[?]
{t } is the set of transition labels.
[?
]/t /skip  q- ------,(default,T ) q  Tau  Com q  Empty  q	[?
]K [fix[?
]kh x:=x+d]I(q)/d/fix[?
]kh x:=x+d  q- ----------------------[?
],(,T ) q  Time  For transition rules T au and Com, both guards and labels of T transitions are still unchanged in the corresponding ETTS transitions.
The semantics of a reset r consists in a parallel reinitialization of clocks x [?]
r. Moreover, the static priority of each ETTS transition corresponds to the committedness of the TA source location q, whereas the dynamic priority is the pair of label l for a communication, respectively default for internal and Empty transitions and  for Time transitions, and the name of the automaton T .
Empty transitions are not firable and especially introduced to hold the committedness of TA locations, when that locations do not have outgoing transitions.
From each non committed location q, we may perform a Time-transition adding an amount d, respecting the invariant of q, to each clock x [?]
kh.
One may distinguish that no transition can be blocked by Time-transitions because they have the lowest static and dynamic priority values.
g/l/r  We write q ---- q  for (q, g, r, l, q  ) [?]-.
Different semantics of TA with priorities in terms of TTS have been proposed [19], [23], [29], [5].
Here, we define the semantics of TA with priorities in terms of ETTSs where committedness is an instance  Simulation: a timed automaton Tc refines another TA  62  Ta if the simulation relation holds between their associated ETTSs: Tc   Ta  ET T S(Tc )   ET T S(Ta ).
qi [?]
K i [?
]/t /skip  q -------,(def ault,Ti ) q fi  B.
Networks of TA with Committedness and Priorities In order to model concurrency and communication, TA have been extended with parallel compositions, giving rise to the NTA.
Several semantics for TA composition have been studied [4], [7], [16], [23], [29] and various parallel composition operators have been proposed, the well known ones are those of CCS [25] and CSP [21].
The UPPAAL language [24] has adopted the CCS parallel composition which allows interleaving of actions as well as hand-shake synchronization.
In this section, to compare NTA through simulation and bisimulation relations, we define their semantics in terms of ETTS and establish a compositionality result.
Definition 13 (Networks of timed automata): A network of timed automata with committed locations, priority on channels fic and priority on TA fita is a finite collection of TA.
First, let us choose the following action language and its underlying semantics for ETTS.
q  The semantics of NTA is parameterized by the way guarded actions are composed on a send/receive synchronization, i.e.
(gs /as )  (gr /ar ).
The semantics [[a  a]], depends on the semantics chosen for TA composition, is still unspecified.
Definition 14 (NTA semantics): Given a set of clocks kh, a set of channels C, a priority order fic on C and a priority order fita on timed automata, the semantics of an 0 NTA  N = Qi , qi , Ki , Ii , -i 1..n is defined by the ETTS  i Qi , q10 , .
.
.
, qn0 , kh x {0}, I, -  over the global space kh - D, static and dynamic priority  systems Ps and Pd given in Definition 11 where I(q) = i Ii (qi ) and - is the smallest relation such that: g/t /r   j  q j [?]
K j = qi [?]
K i  g/t / x[?
]r x:=0  q ----------qi [?
]Ki ,(def ault,Ti ) q[i - qi ] gi /c!/ri  g/t /r  Taui  gj /c?/rj  qi ------i qi qj ------j qj i = j g/r = gi /ri  gj /rj  q [?]
Kk = (qi [?]
Ki [?]
qj [?]
Kj ) k k q -----qi [?
]Ki [?
]qj [?
]Kj ,(c,max(Ti ,Tj )) q   i qi [?]
Ki xi :=xi +d -------------[?
],(,max({Ti |i[?
]1..n}) g/d/  Time  J  i  q    where, for rule SRi,j (c), q  = q[i - qi , j - qj ] and for Time transitions, the guard g = [ i xi := xi + d]I(q) states that the location invariant I(q) should be respected after updating clocks.
Such an invariant corresponds to the intersection of individual TA location invariants.
Through rule Tau, an internal (statically) non-hidden transition of a TA corresponds to an internal transition of the ETTS semantics.
Hiding is not local, i.e not only attached to a given TA.
In fact, from each TA location, after checking that such a location of the NTA state vector does not have the weakest committedness, we check then whether the current TA transition is not hidden by another transition outgoing from that location.
Rule SRi,j (c) describes the synchronization of TA Ti and Tj on a channel c, where the input transition guard is only checked after taking into account the effect of the output transition action.
Such a synchronization is held if either the send or the receive transition is not statically hidden.
The dynamic priority of the resulting transition corresponds to that of channel c and the maximum process priority of both Ti and Tj .
Finally, both Empty and Time rules have been earlier explained.
Definition 15 (NTA refinement): The refinement between networks of timed automata is defined as the refinement between their associated ETTSs.
Formally, given two NTA Nc and Na ; then: Nc   Na  ET T S(Nc )   ET T S(Na ).
Accordingly, we establish the following theorems: Theorem 5 (Compositionality of NTA semantics): The ETTS of a NTA is bisimilar to the restriction to Time and Tau-transitions of the product of ETTSs associated to individual TA, i.e.
ET T S(N T A) ~ Pi ET T S(T Ai )\C.
Proof.
It is direct because we have the same composition rules in both sides.
The difference resides in the occurrence of unmatched communication transitions in the ETTSs product, but these transitions will be suppressed by the restriction.
This proof has been formalized and validated using the C OQ theorem prover.
 Theorem 6 (Refinement and parallel composition): Given 2 networks of TA N = T1 , .., Tn  and N  = T1 , .., Tn  defined on the same set of channels, N refines N  if:  * [?
]i Ti  Ri ,Rg Ti , l  * channel priority orders of N and N are equivalent, * each concrete process and its corresponding abstract one have the same priority (morphism),    * [?
]q q , Rl (q, q ) = Comm(q) = Comm(q ), * refinement preserves deadlock-freeness.
Proof.
It follows from theorems 4 and 5 together with the restriction theorem 2.
Action language a:= a  a | j[?
]J aj | (g/r) | (g/c := c + d) | (g/skip) Semantics a  a is still unspecified fi [[j aj ]](x, x ) = j [[aj ]](x, x ) fi fi   [[g/r]](x, x ) = g(x) [?]
c[?
]r x (c) = 0 [?]
c[?
]r / x (c) = x(c)   [[g/c := c + d]](x, x ) = g(x) [?]
x (c) = x(c) + d [[g/skip]](x, x ) = g(x) [?]
(x = x)  qi -----i qi  Empty  SRi,j (c)  C. Experiments In this section, we give an application of our compositional framework to refine a version of the well known Alternating  63  Bit Protocol [28] (ABP).
In fact, we aim to verify that the number of correctly received messages is less than the number of correctly sent ones, and their difference is bounded by one.
To send a new message, the TA Sender synchronizes with the TA Mmedium on channel send and increments the shared variable s. The TA Receiver receives the sent message via a synchronization with the Mmedium on channel receive and updates the shared variable r by adding one.
The intended property is represented by the auxiliary Boolean variable Ok  s == r [?]
s == (r + 1).
This property cannot be verified using the UPPAAL toolbox on the NTA formed by Sender, Receiver, Mmedium, Amedium because of the unboundedness3 of s and r. To deal with the unboundedness, a clever idea consists in the replacement of both Sender and Receiver automata by finite abstractions, where the evolutions of variables s and r are respectively modeled by two shared Boolean variables b1 = (s == r), initialized to true, and b2 = (s == r+1), initialized to f alse, with a slight modification of the corresponding involved transitions.
The abstraction refinement of processes Mmedium and Amedium is the identity relation.
Accordingly, the new property Ok = b1 [?]
b2 can be checked.
The abstraction refinement of each TA by its corresponding finite abstraction has been checked using a manual proof of the refinement ref in between their ETTSbased semantics, where both local and global spaces have been considered.
The local space refinement Rl consists in: (a) the correspondence of local states; (b) the identity of local variables values.
However, for the global space, the refinement Rg consists to: (a) match the values of b1 and b2 of the abstract system to the corresponding expressions computed through s and r in the concrete system; (b) check the identity between the other shared variables values.
We may write then ref in = RlSender [?
]RlReceiver [?
]RlM medium [?
]RlAmedium [?
]Rg .
This result has been checked using UPPAAL and a manual proof of refinement using observers.
Acknowledgment.
We wish to thank the anonymous referee for his scrutinous reading and valuable remarks.
R EFERENCES [1] R. Alur.
Timed automata.
In 11th International Conference on Computer Aided Verification, volume 1633 of LNCS, pages 8-22.
1999.
[2] A. Arnold.
Finite transition systems: semantics of communicating systems.
Prentice Hall International Ltd., Hertfordshire, UK, 1994.
[3] A. Basu, M. Bozga, and J. Sifakis.
Modeling heterogeneous real-time components in BIP.
In SEFM'06, pages 3-12.
IEEE Computer Society, 2006.
[4] G. Behrmann, A. David, and K. G. Larsen.
A Tutorial on Uppaal.
Department of computer science, Aalborg university, 2004.
[5] J. Bengtsson and W. Yi.
Timed automata: Semantics, algorithms and tools.
In Lectures on Concurrency and Petri Nets, pages 87-124. volume 3098 of LNCS, Springer-Verlag, 2004.
[6] B. Berard, M. Bidoit, A. Finkel, F. Laroussinie, A. Petit, L. Petrucci, and P. Schnoebelen.
Systems and Software Verification - Model-Checking Techniques and Tools.
Springer-Verlag Berlin, 2001.
[7] J. Berendsen and F. Vaandrager.
Compositional Abstraction in RealTime Model Checking.
In FORMATS'08, pages 233-249, 2008.
[8] B. Berthomieu, J. Bodeveix, M. Filali, H. Garavel, F. Lang, F. Peres, R. Saad, J. Stoecker, F. Vernadat, P. Gaufillet, and F. Lang.
The syntax and semantics of FIACRE.
Technical report, 2009.
[9] G. Bhat, R. Cleaveland, and G. Luttgen.
Dynamic priorities for modeling real-time.
In FORTE X/PSTV XVII '97, Osaka, pages 321- 336.
Chapman and Hall, 1996.
[10] J. P. Bodeveix, A. Boudjadar, and M. Filali.
An alternative definition for timed automata composition.
In ATVA'11, pages 105 -119, Taiwan, 2011.
LNCS 6996.
[11] S. Bornot, G. Gossler, and J. Sifakis.
On the construction of live timed systems.
In TACAS'00, pages 109-126, 2000.
[12] A. Boudjadar, J.-P. Bodeveix, and M. Filali.
Revising and extending the UPPAAL communication mechanism.
In SC'12, volume LNCS 7306, pages 114 - 131.
Springer Heidelberg, 2012.
[13] P. Bremond-Gregoire, I. Lee, and R. Gerber.
ACSR: An algebra of communicating shared resources with dense time and priorities.
In CONCUR, pages 417-431, 1993.
[14] E. M. Clarke, D. E. Long, and K. L. McMillan.
Compositional model checking.
In LICS'89, pages 353-362, 1989.
[15] R. Cleaveland, G. Luttgen, and V. Natarajan.
Priority in process algebras.
Information and Computation, 87:58-77, 1999.
[16] A. David, J. Hakansson, K. G. Larsen, and P. Pettersson.
Model checking Timed Automata with Priorities Using DBM Subtraction.
In FORMAT'06, pages 128-142.
LNCS volume 4202, 2006.
[17] E. Fersman, P. Pettersson, and W. Yi.
Timed Automata with asynchronous processes: Schedulability and decidability.
In TACAS'02, pages 67-82.
Volume LNCS 2280, Springer-Verlag, 2002.
[18] G. Gossler and J. Sifakis.
Priority systems.
In FMCO'03, pages 314- 329, 2003.
[19] F. He, H. Zhu, W. Hung, X.
Song, and M. Gu.
Compositional abstraction refinement for timed systems.
In TASE'10, pages 168 -176, 2010.
[20] T. A. Henzinger, Z.
Manna, and A. Pnueli.
Timed transition systems.
1992.
[21] C. A. R. Hoare.
Communicating Sequential Processes.
Prentice-Hall, 1985.
[22] P.-A.
Hsiung and S.-W. Lin.
Model checking timed systems with priorities.
In RTCSA'05, pages 539-544, USA, 2005.
[23] H. E. Jensen, K. G. Larsen, and A. Skou.
Scaling up Uppaal: Automatic Verification of Real-Time Systems using Compositionality and Abstraction.
In FTRTFT'00, pages 19-30, 2000.
[24] K. G. Larsen, P. Pettersson, and W. Yi.
Uppaal in a nutshell.
In Journal on software tools for technology transfert, 1997.
[25] R. Milner.
Communication and Concurrency.
Prentice Hall Ltd., 1989.
[26] M. Nielsen, G. Rozenberg, and P. Thiagarajan.
Transition-systems, event structures, and unfoldings.
Information and Computation, 118:191 - 207, 1995.
[27] M. Nielsen, G. Rozenberg, and P. S. Thiagarajan.
Elementary transition systems.
Theoritical Computer Science, pages 3-33, 1992.
[28] G. J. Veltink and S. Mauw.
Algebraic Specification of Communication Protocols.
Cambridge Tracts in Theoretical Computer Science No.
36, 2008.
[29] S. Yovine.
Model checking Timed Automata.
In Lectures on Embedded Systems.
Lecture Notes in Computer Science 1494, Springer-Verlag, 1998.
V. C ONCLUSION In this paper, we have studied the refinement and composition of different timed systems with priorities.
For the parallel composition operator we have defined, we give a corresponding (compositional) refinement relation.
As a semantic model, our compositional framework has been successfully instantiated to define a compositional semantics of networks of timed automata, in which an unique generalized dynamic priority system of ETTS is defined from both NTA priority orders (channels, TA) with an important refinement property stating that: if each individual TA of an NTA refines another individual TA of another NTA, then the ETTS corresponding to the semantics of the first NTA refines the ETTS corresponding to the semantics of the second NTA.
Furthermore, the theorems established within our framework have been proved 4 .
In the future, we wish to extend our framework by other concepts, like assume-guarantee properties, in order to model and to analyze the semantics of the Fiacre language [8].
3 In fact, it is checked upto the size of UPPAAL integers, then UPPAAL throws an out of range exception.
4 Proofs will be available in the forthcoming PhD thesis of Abdeldjalil Boudjadar.
64
An algebraic approach to granularity in time representation Jerome Euzenat INRIA Rhone-Alpes, IMAG-LIFIA 46, avenue Felix Viallet, 38031 Grenoble cedex, France Jerome.Euzenat@imag.fr  Abstract Any phenomenon can be seen under a more or less precise granularity, depending on the kind of details which are perceivable.
This can be applied to time.
A characteristic of abstract spaces such as the one used for representing time is their granularity independence, i.e.
the fact that they have the same structure at different granularities.
So, time "places" and their relationship can be seen under different granularities and they still behave like time places and relationship under each granularity.
However, they do not remain exactly the same time places and relationship.
Here is presented a pair of operators for converting (upward and downward) qualitative time relationship from one granularity to another.
These operators are the only ones to satisfy a set of six constraints which characterize granularity changes.
1 .
Introduction "Imagine, you are biking in a flat countryside.
At some distance ahead of you there is something still.
You are just able to say (a) that a truck (T) is aside a house (H), it seems that they meet.
When you come closer to them (b) you are able to distinguish a bumper (B) between them, and even closer (c), you can perceive the space between the bumper and the house."
This little story shows the description of the same reality perceived at several resolution levels: this is called granularity.
Granularity would not be a problem if different individuals, institutions, etc.
would use the same granularity.
This is not the case and, moreover, these individuals communicate data expressed under different granularities.
There could be a problem if, for instance, someone at position (a), asked "how would you call that which is between H and T?"
because at that granularity, the description of the scene would assume that there is nothing between H and T. The study of granular knowledge representation thus tries to express  how the same phenomenon can, in some sense, be consistently expressed in different manners under different granularities.
This is achieved through operators which, for a situation expressed under a particular granularity, can predict how it is perceivable under another granularity.
coarser (a)  (b) upward  downward  T  H B  (c) finer  Figure 1.
The same scene under three different granularities.
This is taken as a spatial metaphor for time granularity and is used throughout the paper.
Granularity can be applied to the fusion of knowledge provided by sources of different resolution (for instance, agents -- human or computers -- communicating about the same situation) and to the structuring of reasoning by drawing inference at the right level of resolution (in the example of figure 1, the first granularity is informative enough for deciding that the truck driving wheel is on the left of the house -- from the standpoint of the observer).
On one hand, in [10], granularity is expressed granularity between two, more or less detailed, logical theories.
On the other hand, the physical time-space and its representation have been well-studied because many applications require them.
A very popular way to deal with time is the representation of relationships between time intervals [2].
To our knowledge, qualitative time granularity has never been studied before.
Jerry Hobbs [10] introduced granularity in an abstract way  (i.e.
not connected to time) and [11, 4] introduced operators for quantitative time granularity which share a common ground with ours (see SS7).
The paper first recalls some basics about time representation (SS2).
This section can be skipped by those who already know the subject.
Then, the usual interpretations of time and granularity in this context are introduced.
Afterwards, required properties for granularity change operators in the classical time algebra are presented (SS3).
This part is very important since, once accepted the remainder is directly deduced.
The only set of operators (for instant and interval algebra) satisfying the required properties are thus deduced in SS4.
The results concerning the relationship between granularity and inference are then briefly presented (SS5).
The proofs of all the propositions, but the "only" part of the first one, can be found in [6].
The main results (but those of SS5) are from [7].
2 .
Background Classical notions about temporal algebras, neighborhood structures and instant-interval conversions are presented here.
2.1.
Temporal algebra  reciprocal: x2 r-1x1 after (>)  x1/x2  simultaneously (=)  =  Table 1.
The 3 relationships between instants x1 and x2.
x3 > = <  > > > <=>  relation: x1 r x2 before (b) during (d) overlaps (o) starts (s) (and finishes before) finishes (f) (and start after) meets (m)  x1/x2  = > = <  < <=> < <  Table 2.
Composition table between instant relationships.
It is sometimes possible to deduce the relationship between two instants x and z, even if it has not been provided, by propagating the otherwise known relationships.
For instance, if x is simultaneous ({=}) to  reciprocal: x2 r-1x1 after contains overlapped by started by (and finishes after) finished by (and starts before) met by e  equals (e)  There has been considerable work carried out on qualitative time representation.
We recall here several notions about the algebra of topological and vectorial relationships holding between time entities.
An instant is a durationless temporal entity (also called time point by analogy with a point on a line).
It can be numerically represented by a date.
Qualitatively representing these instants requires identifying them and putting them in relation.
There are three possible mutually exclusive relationships between instants.
They are called <<before>> (<), <<after>> (>) and <<simultaneously>> (=).
The set {<, =, >} is called A3.
relation (r): x1 r x2 before (<)  y which is anterior ({<}) to z, then x is anterior to z; this is called composition of temporal relations.
The composition operator x3 is represented by a composition table (table 2) which indeed indicates that =x 3< gives {<}.
A (continuous) period is a temporal entity with duration.
It can be thought of as a segment on a straight line.
A numerical representation of a period is an interval: a couple of bounds (beginning instant, ending instant) or a beginning instant and a duration.
Intervals can be manipulated through a set of 13 mutually exclusive temporal relationships between two intervals (see table 3); this set is called A13.
Table 3.
The 13 relationships between two intervals x1 and x2.
The composition operator x 13 is represented by a composition table [2], similar to the table 2, which allows to deduce, from a set of intervals and constraints between these intervals, the possible relations between any two of these intervals.
2.2.
Extensions of notations Let G be either A1 3 or A3 , [?]
be the logical disjunction and x be the composition operator on G, the following notations are used (in a general manner, <2G [?]
x> is an algebra of binary relationships).
The lack of knowledge concerning the actual position of some temporal entity x with regard to the temporal entity y is expressed by a sub-set r of G which is interpreted as the disjunction of the relations in r: xry =  [?]
xry  r[?
]r  Thus, x{b m}y signifies that the temporal entity x is anterior to or meets the temporal entity y.
The following conventions are used below: * When a result is valid for both algebras, no distinction is made between the temporal entities concerned.
The base sets (A13, A3, and maybe others), as well as the composition x and reciprocity -1 operators are not distinguished;  *  * *  The letter r represents a sub-set of the corresponding base set of relations (r[?
]G); the letter <<r>> represents a relationship.
r -1 represents the set of relations reciprocal of those contained in r: {r-1; r[?]r}.
r1xr2 represents the distribution of x on [?
]:  x+> and y=<y- y+> is expressed by a quadruple (r1, r2, r3, r4) of relationships between the extremities defined as so:  U  considering that x - < x + and y - < y + , each possible relationship between the bounding instants are expressible with such a quadruple (see table 4).
The symbol = is used such that =x is the expression of an interval as a couple of extremities and =r a relationship between intervals expressed as a quadruple.
= is extended towards sets of relations such that =r is a set of quadruples.
Thus:  r1 x r 2 =  r1 x r2 r1 [?
]r1 ,r 2 [?
]r 2  2.3.
Neighborhood structure Two qualitative relations between two entities are called conceptual neighbors if they can be transformed into one another through continuous deformation of the entities [9].
A conceptual neighborhood is a set of relations whose elements constitute a connected subgraph of the neighborhood graph.
DEFINITION (conceptual neighborhood): A conceptual X neighbor relationship is a binary relation NG on a set G X of relations such that NG (r 1 ,r 2 ) if and only if the continuous transformation of an entity o1 in relationship r 1 with another entity o2 can put them in relation r2 without transition through another relation.
>  =  <  d f  (a) b  m (b)  o  s  e si  di  oi  mi  bi  fi  Figure 2.
Neighborhood graphs for (a) instant-to-instant relations, (b) interval-to-interval relations.
The neighborhood graph is made of relations as nodes and conceptual neighborhood as edges (reciprocal relationships are denoted with an "i" added at the end for the sake of readability).
The graph of figure 2a represents the graph of A conceptual neighborhood N3 between instants (the only continuous deformation is translation).
The graph of A Figure 2b represents the conceptual neighborhood N13 for the deformation corresponding to the move of an extremity of an interval (more generally, the deformation corresponds to moving a limit).
Throughout the paper, the only considered transformation A is the continuous move of a limit (called A-neighborhood in [9]).
The influence of this choice is acknowledged when it matters.
2.4.
Conversion from interval to instant formalisms Relationships between intervals can be expressed in function of the relationships between their bounding instants (see table 4): any relationship between x=<x -  <x- x+ > (r1, r2, r3, r4) <y- y+ >  %0 x - r1 y - [?]
x - r2 y + [?]
x + r3 y - [?]
x + r4 y +  [?
]n [?]
< x - x + > [?]
U ( ri1 , ri2 , ri3 , ri 4 ) [?]
< y - y + > [?
]i =1 [?]
{  [?]
}  n  [?]
x - ri1 y - [?]
x - ri2 y + [?]
x + ri3 y - [?]
x + ri 4 y + i =1  xr y  x -r1y -  x -r2y +  x + r3y -  x + r4y +  b d o s f m e m-1 f-1 s-1 o-1 d-1 b-1  < > < = > < = > < = > < >  < < < < < < < = < < < < >  < > > > > = > > > > > > >  < < < < = < = > = > > > >  Table 4.
The 13 relationships between intervals expressed through relationships between interval extremities.
Since any formula representing relationship between four instants x-, x+, y- and y+ respecting the properties of intervals (x-<x+ and y-<y+ ) can be expressed under that form, the inverse operation = is defined.
It converts such an expression between bounding instants of two intervals into a set of relations expressing the disjunction of relations holding between the intervals.
Of course, both operators (= and =) are inverse.
3 .
Requirements for granularity change operators We aim at defining operators for transforming the representation of a temporal situation from one granularity to another so that the resulting representation should be compatible with what can be observed under  that granularity.
The requirements for building such operators are considered here.
The first section concerns what happens to classical models of time and to temporal entities when they are seen through granularity.
The second one provides a set of properties that any system of granularity conversion operators should enjoy.
These properties are expressed in a sufficiently abstract way for being meaningful for instants and periods, time and space.
3.1.
Granularity change operators Time is usually represented under a particular granularity.
Thus, the time representation system presented so far is an adequate representation for time at any granularity (as far as only qualitative properties are considered).
For instance, the three situations of figure 1 can be expressed in the same formalism with objects and qualitative relations between them.
If we only consider the position of the objects along the horizontal line, the three elements (T, B and H) are related to each other in the way of figure 1c by T{m}B (the truck meets its bumper) and B{b}H (the bumper is before the house).
We aim at elucidating the relationship between two representations of the same reality under two different granularities.
As a matter of fact, the situations of figure 1 cannot be merged into one consistent situation: figures 1b and c together are inconsistent since, in (b), B{m}H and, in (c), B{b}H which, when put together, gives B{}H. First, the reasons for these problems are examined before providing a set of properties that granularity change operators must satisfy.
Time is usually interpreted as a straight line, instants as points and intervals as segments.
Under a numerical light, granularity can be defined as scaling plus filtering what is relevant and what is not (discretizing).
However, granularity is a special filter since, as the name indicates, it filters on size.
For the time concern, the granularity of a system can be defined as the duration of the smallest relevant event (relevance being defined independently beforehand).
But what happens to non relevant events?
There are two solutions: * they can vanish; * they can remain with size 0, i.e.
as instants.
In both cases, these solutions share additional consequences (for symbolic representations): if, under a coarse granularity, one observes that some event is connected to another this can be wrong under a finer granularity since a non relevant laps of time could be relevant here.
In another way, when communicating the same observation, it must be taken into account that the short laps of time may be non relevant (and thus that the relationship between the event can be disconnected).
This  is what happened for the relationship between B and H, which is {b}, in Figure 1c, and becomes {m}, in 1b.
In order to account for this situation, which appears to be regular, we need a downward (resp.
upward) operator which, from a relationship observed a some particular granularity, is able to provide a set of relationships at a finer (resp.
coarser) granularity which represents what can be perceived under that last granularity.
The purpose here, is not to design granularity conversion operators which can make events vanish or turn into instants (see [5]) but rather operators which can account for the possibility of having, under a finer granularity, new space between two entities, and, vice-versa, that a space can become non relevant under a coarser granularity.
These operators are called upward and downward granularity conversion operators and noted by the infix g | g' and g'| g operators (where g and g' are granularities such that g is finer -- more precise -- than g', i.e.
that the size of relevant events is smallest in g than in g').
The following g- g' operator will be used for any of them when the property holds for both (then there is no constraint upon g and g').
As usual, the notation g-g' introduced for the conversion of a single relationship is extended towards sets: g-g' r =  U g- g'  r.
r[?
]r  3.2.
Properties for granularity change operators Anyone can think about a particular set of such operators by imagining the effects of coarseness.
But here are provided a set of properties which should be satisfied by any system of granularity conversion operators.
In fact, the set of properties is very small.
But next section shows that they are sufficient for constraining the possibility for such operators to only one (plus the expected operators corresponding to identity and conversion to everything).
Self-conservation Self-conservation states that whatever be the conversion, a relationship must belong to its own conversion.
It is quite a sensible and minimal property: the knowledge about the relationship can be less precise but it must have a chance to be correct.
(1) r [?]
g-g'r (self-conservation) Neighborhood compatibility A property considered earlier is the order preservation property [10] which states (a part of this):  x > y = !
(g - g' x < g - g' y) (order preservation) However, this property has the shortcoming of being vectorial rather than purely topological.
Its topological generalization, is reciprocal avoidance: x r y = !
(g - g' x r-1 g - g' y) (reciprocal avoidance) Reciprocal avoidance, was over-generalized and caused problems with auto-reciprocal relationship (i.e.
such that r=r -1 ).
The neighborhood compatibility, while not expressed in [5] has been taken into account informally: it constrains the conversion of a relation to form a conceptual neighborhood (and hence the conversion of a conceptual neighborhood to form a conceptual neighborhood).
(2) [?
]r, [?]r',r"[?
]g-g'r , [?]r1,...rn[?
]g-g'r such that X  r1=r', rn=r" and [?]i[?
][1,n-1] NG (ri,ri+1) (neighborhood compatibility) This property has already been reported by Christian Freksa [9] who considers that a set of relationships must be a conceptual neighborhood for pretending being a coarse representation of the actual relationship.
(2) is weaker than the two former proposals because it does not forbid the opposite to be part of the conversion, but, in such a case, it constrains whatever be in between the opposite to be in the conversion too.
Neighborhood compatibility seems to be the right property, partly because, instead of the former ones, it does not forbid a very coarse grain under which any relationship is converted in the whole set of relations.
It also seems natural because granularity can hardly be imagined as discontinuous (at least in continuous spaces).
Conversion-reciprocity distributivity An obvious property for such an operator is symmetry.
It is clear that the relationships between two temporal occurrences are symmetric and thus granularity conversion must respect this.
(3) (g-g' r-1) = (g-g' r)-1 (distributivity of g-g' on -1) Inverse compatibility Inverse compatibility states that the conversion operators are consistent with each other, i.e.
that, if the relationship between two occurrences can be seen as another relationship under some granularity, then the inverse operation from the latter to the former can be achieved through the inverse operator.
(4)  r[?]
I g ' | g r ' and r [?]
I g ' | g r '  r '[?
]g | g' r  r '[?
]g | g ' r  (inverse compatibility)  For instance, if someone in situation (b) of figure 1 is able to imagine that, under a finer granularity (say situation c), there is some space between the bumper and the house, then (s)he must be whiling to accept that if (s)he were in situation (c), (s)he could imagine that there is no space between them under a coarser granularity (as in situation b).
Cumulated transitivity A property which is usually considered first is the full transitivity: g- g'*g'- g" r = g- g" r This property is too strong; it would for instance imply that: g- g'*g'- g r = r Of course, it cannot be achieved because this would mean that there is no loss of information through granularity change: this is obviously false.
If it were true anyway, there would be no need for granularity operators: everything would be the same under each granularity.
We can expect to have the cumulated transitivity: g' g" = g" g" g' g" g| *g'| r g| r and |g'* |g r = |g r  However, in a purely qualitative calculus, the amounts of granularity (g) are not relevant and this property becomes a property of idempotency of operators: (5)  |*|=| and |*| = |  (idempotency)  At first sight, it could be clever to have non idempotent operators which are less and less precise with granularity change.
However, if this applies very well to quantitative data, it does not apply for qualitative: the qualitative conversion applies equally for a big granularity conversion and for a small one which is ten times less.
If there were no idempotency, converting a relationship directly would give a different result than doing it through ten successive conversions.
Representation independence Representation independence states that the conversion must not be dependent upon the representation of the temporal entity (as an interval or as a set of bounding instants).
Again, this property must be required: (6)g-g' r = = g-g' =r and g-g' r= = g-g' = r (representation independence) Note that since = requires that the relationships between bounding instants allows the result to be an interval, there could be some restrictions on the results (however, these restrictions correspond exactly to the vanishing of an interval that which is out of scope here).
4 .
The granular system for time relations Once these six properties have been defined one can start generating candidate upward and downward conversion operators.
However, these requirements are so precise that they leave no place for choice.
We are showing below by starting with the instant algebra that there is only one possible couple of operators.
Afterwards, this easily transfers to interval algebra.
4.1.
Conversion operators for the instant algebra The 64(=2 3 .2 3 ) a priori possible operators for converting < and = can be easily reduced to six: the constraint (1) restricts the conversion of < to be {<}, {<=}, {<>} or {<=>} and that of {=} to be in {=}, {<=}, {=>} or {<=>}.
The constraint (2) suppresses the possibility for < to become {<>}.
The constraint (3) has been used in a peculiar but correct way for eliminating the {<=} (resp.
{=>}) solutions for =.
As a matter of fact, this would cause the conversion of =-1 to be {=>} (resp.
{<=}), but =-1 is = and thus its conversion should be that of =.
<\= {<} {<=} {<=>}  {=} Id b d  {<=>} a g no info  Table 5.
The six possible conversion operators for = and <.
There are still six possible conversion operators left (Id, a, b, g, d and NI).
Since the above table does not consider whether the operators are for downward or upward conversion, this leaves, a priori, 36 upwarddownward couples.
But the use of property (4) -- the putative operators must be compatible with their inverse operator (and vice-versa) -- reduces them to 5: Id-Id, ab, g-g, d-d and NI-NI.
The solution Id-Id cannot be considered as granularity since it does not provide any change in the representation.
The solution NI-NI is such that it is useless.
The d-d pair has the major flaw of not being idempotent (i.e.
d *d [?]
d ): as a matter of fact, the composition of d with itself is NI, this is not a good qualitative granularity converter (this violates property 5).
There are two candidates left: the g-g has no general flaw, it seems just odd to have an auto-inverse operator (i.e.
which is its own inverse) since we all know the asymmetry between upward and downward conversion: it could be a candidate for upward conversion (it preserves the equality of equals and weakens the assertions of difference) but it does not fit intuition as a downward  conversion operator (for the same reasons).
Moreover, g does not respect vectorial properties such as orderpreservation (g is just b plus the non distinction between < and >).
Thus the a -b pair is chosen as downward/upward operators.
The main argument in favor of a-b is that they fit intuition very well.
For instance, if the example of figure 1 is modeled through bounding instants (x - for the beginning and x + for the end) of intervals T+ , B-, B+ and H-, it is represented in (c) by T+=B- (the truck ends where the bumper begins), B-<B+ (the beginning of the bumper is before its end), B+<H(the end of the bumper is before the beginning of the house) in (b) by B+ =H - (the bumper ends where the house begins) and in (a) by B-=B+ (the bumper does not exist anymore).
This is possible by converting with the couple a-b which allows to convert B+<H- into B+=H(= [?]
b<) and B-=B+ into B-<B+ (< [?]
a=), but not with the use of g as a downward operator.
Thus the following result is established: PROPOSITION: The table 6 defines the only possible non auto-inverse upward/downward operators for A3.
relation: r < = >  g|  g'r  <= = >=  g|  g'r  < <=> >  Table 6.
Upward and downward granularity conversions between instants.
The operators of table 6 also satisfy the properties of granularity operators.
PROPOSITION: The upward/downward operators for A3 of table 6 satisfy the properties (1) through (5).
4.2.
Conversion operators for the interval algebra By constraint (6) the only possible operators for A13 are now given.
They enjoy the same properties as the operators for A3.
PROPOSITION: The upward/downward operators for A13 of table 7 are the only one to satisfy the property (6) with regard to the operators of A3 of table 6.
PROPOSITION: The upward/downward operators for A13 of table 7 satisfy the properties (1) through (5).
The reader is invited to check on the example of figure 1, that what has been said about instant operators is still valid.
The upward operator does not satisfy the condition (2) for B-neighborhood (violated by d, s and f) and C-neighborhood (o, s and f).
This result holds since the corresponding neighborhoods are not based upon  independent limit translations while this independence has been used for translating the results from A3 to A13.
relation: r b d o s f m e m-1 f-1 s-1 o-1 d-1 b-1  g|  g'r  bm dfse o f-1 s m e se fe m e m-1 f-1 e s-1 e -1 -1 o s f e m-1 d-1 s-1 f-1 e b-1 m-1  g|  g'r  b d o osd d f o-1 bmo o f-1 d-1 s e s-1 d f o-1 o-1 m-1 b-1 d-1 f-1 o d-1 s-1 o-1 o-1 d-1 b-1  Table 7.
Upward and downward conversion operators between intervals.
5.
Granularity and inference The composition of symbolic relationship is a favored inference mean for symbolic representation systems.
One of the properties which would be interesting to obtain is the independence of the results of the inferences from the granularity level (property 7).
The distributivity of g - g ' on x denotes the independence of the inferences from the granularity under which they are worked out.
(7) g- g' (r1 x r2) = (g- g' r1) x (g- g' r2) (distributivity of g-g' over x) This property is only satisfied for upward conversion in A3.
P ROPOSITION : The upward operator for A3 satisfies property (7).
It does not hold true for A13 : let consider three intervals x , y and z such that x b y and y d z , the application of composition of relations gives x{b o m d s}z which, once upward converted, gives x{b m e d f s o f-1}z.
By opposition, if the conversion is first applied, it returns x{b m}y and y{d f s e}z which, once composed, gives x{b o m d s}z.
The interpretation of this result is the following: by first converting, the information that there exists an interval y forbidding x to finish z is lost: if, however, the relationships linking y to x and z are kept, then the propagation will take this into account and recover the lost precision: {b m e d f s o f-1}[?
]{b o m d s}={b o m d s}.
However, this cannot be enforced since, if the length of y is so small that the conversion makes it vanishing, the correct information at that  granularity is the one provided by applying first the composition: x can meet z under such a granularity.
However, if (7) cannot be achieved for upward conversion in A13, we proved that upward conversion is super-distributive over composition.
PROPOSITION: The upward operator for A13 satisfies the following property: (8)  (g|g' r1) x (g|g' r2) [?]
g|g' (r1 x r2) (super-distributivity of g|g' over x)  A similar phenomenon appears with the downward conversion operators (it appears both for instants and intervals).
So let consider three instants x, y and z such that x>y and y=z, on one hand, the composition of relations gives x>z, which is converted to x>z under the finer granularity.
On the other hand, the conversion gives x>y and y{<=>}z because, under a more precise granularity y could be close but not really equal to z.
The composition then provides no more information about the relationship between x and z (x{<=>}z).
This is the reverse situation as before: it takes into account the fact that the indicernability of two instants cannot be ensured under a finer grain.
Of course, if everything is converted first, then the result is as precise as possible: downward conversion is sub-distributive over composition.
PROPOSITION: The downward operators for A13 and A3 satisfy the following property: (9)  g|  g g g' (r1 x r2) [?]
( |g' r1) x ( |g' r2) (sub-distributivity of g|g' over x)  These two latter properties can be useful for propagating constraints in order to get out of them the maximum of information quickly.
For instance, in the case of upward conversion, if no interval vanishes, every relationship must be first converted and then composed.
6 .
Further and ongoing works Category theory which is widely used in programming language semantics has been introduced in knowledge representation [1] in order to account for the relation of approximation between, on the one hand, a knowledge base and the modeled domain, and on the other hand, the many achievements of a knowledge base.
Ongoing works tackle the problem of such a categorical semantics for time representation.
It meets the intuition: granular representation is approximation.
This will provide the advantage of allowing the integration of a specialized time representation into a wider context (e.g.
for adding temporal extension to objects represented as  Ps-terms).
Category theory allows to do so in a general way.
works have been done for extending qualitative granularity from time to space and are reported in [6, 7].
7 .
Related works  Acknowledgments  Jerry Hobbs introduced the concept of granularity from the non discernability of particular terms with regard to a given set of predicates (these terms can be substituted in the range of any of the given predicates without changing their validity).
The main difference here is that the granularity is given a priori in the structure of time and the scaling notion while Hobbs defines a granularity with regard to relevant predicates.
To our knowledge there is no other proposal for integrating granularity into qualitative time representation.
There has been tremendous work on granularity in metric spaces.
One of the more elaborate model is that of [11, 4].
It proposes a quantitative temporal granularity based on a hierarchy of granularities strictly constrained (to be convertible, divisible...) which offers upward and downward conversion operators for instants and intervals (instead of their relationships).
[5] offers a more general (i.e.
less constrained) framework for quantitative relationships and thus achieves weaker properties.
Hence, the properties obtained here for qualitative representation are compatible with the quantitative representation of [11, 4].
Others works [3] considered granularity in a hybrid qualitative/quantitative system.
The same effect as presented here could certainly been achieved through the computation of qualitative relationships from quantitative ones (using [11, 4] but not in a pure qualitative fashion.
[8] presents a systems which shares a great deal with ours: they treat granularity changes between several representations expressed in the same classical temporal logic (just like here, we used the classical A3 and A13) and they map these representations to natural numbers instead of real numbers [5].
However, temporal logics and algebra of relations are not immediately comparable so the results are quite different in nature.
It is expected that the categorical framework sketched in SS6 allows to compare the two approaches in depth.
Many thanks to Hany Tolba who carefully commented a longer version of this paper and to one of the reviewers who pointed out interesting connections.
8 .
Conclusion In order to understand the relationships between several granularities, a set of requirements have been established for conversion operators.
The only possible operators filling these requirements have been defined.
Moreover other properties of the operators have been established (preservation of the relationship between points and interval).
These operators can be used for combining information coming from different sources and overcoming their contradictory appearance.
Further  References 1.
2.
3.
4.
5.
6.
Hassan Ait-Kaci, Andreas Podelski, Towards a meaning of LIFE, Journal of logic programming16(3-4):195-234, 1993 James Allen, Maintaining knowledge about temporal intervals, Communication of the ACM 26(11):832-843 (rep. in Ronald Brachman, Hector Levesque (eds.
), Readings in knowledge representation, Morgan Kaufmann, Los Altos (CA US), pp509-521, 1985), 1983 Silvana Badaloni, Marina Berati, Dealing with time granularity in a temporal planning system, Lecture notes in computer science (lecture notes in artificial intelligence) 827:101-116, 1994 Emanuele Ciapessoni, Edoardo Corsetti, Angelo Montanari, P. San Pietro, Embedding time granularity in a logical specification language for sychronous real-time systems, Science of computer programming 20(1):141-171, 1993 Jerome Euzenat, Representation granulaire du temps, Revue d'intelligence artificielle 7(3):329361, 1993 Jerome Euzenat, Granularite dans les representations spatio-temporelles, Research report 2242, INRIA, Grenoble (FR), 1994 available by ftp from ftp.imag.fr as /pub/SHERPA/rapports/rrinria-2242-?.ps.gz  7.
Jerome Euzenat, An algebraic approach to granularity in qualitative time and space representations, Proc.
14th IJCAI, Montreal (CA), 1995 to appear 8.
Jose Luis Fiadeiro, Tom Maibaum, Sometimes "tomorrow" is "sometime": action refinement in a temporal logic of objects, Lecture notes in computer science (lecture notes in artificial intelligence) 827:48-66, 1994 9.
Christian Freksa, Temporal reasoning based on semi-intervals, Artificial intelligence 54(1):199227, 1992 10.
Jerry Hobbs, Granularity, Proc.
9th IJCAI, Los Angeles (CA US), pp432-435, 1985 11.
Angelo Montanari, Enrico Maim, Emanuele Ciapessoni, Elena Ratto, Dealing with time and granularity in the event calculus, Proc.
4th FGCS, Tokyo (JP), pp702-712, 1992
2012 19th International Symposium on Temporal Representation and Reasoning  A Tableau for the Combination of CTL and BCTL* John C. Mc Cabe-Dansted School of Computer Science and Software Engineering University of Western Australia Perth, Australia Email: john@csse.uwa.edu.au  quantifies over a bundle of paths.
Although this bundle is suffix and fusion closed it need not be limit closed.
For example, it may be the case that all paths include a right branch even though at every world there is a path where the next branch goes left; which violates the limit closure property.
An argument for the 2-EXPTIME hardness of the decision problem could be made for BCTL* in a way similar to the argument for CTL* so from a computational complexity point of view, BCTL* is no easier to deal with than CTL*; however, the BCTL* logic is traditionally presented of being of theoretical interest as it is in some ways easier to reason with than CTL*; for example the specification for the tableau for BCTL* proposed by [6] was much simpler than the CTL* tableau [4] that was developed from it.
Another example of BCTL* being easier (though not less computationally complex) to reason with was the discovery of a simple natural deduction system for a fragment of BCTL* [7].
In some cases we are interested only in futures that satisfy some fairness property.
For example, when reasoning about some randomised algorithm it may be desirable to state that a fair coin could always come up either heads or tails but that any plausible future would not have an infinite series of tails.
With BCTL*, we can construct a model with some fairness constraint on the bundle, while in CTL* the obvious attempt to formalise the fair coin would be a paradox.
Every theorem of BCTL* is a theorem of CTL*.
Proving a statement in BCTL* demonstrates that it is true not only in CTL* but would also be true if there was some form of fairness constraint on allowable paths.
Model checking formula CTL* with a bounded number of non-CTL properties is trivially polynomial.
model checking.
Model checking CTL* formulae is most naturally performed by recursively running a Linear Temporal Logic (LTL) model checker [8].
While model checking LTL is PSPACE in general, when the length of the input formula is bounded the complexity it is linear.
For this reason, it is clear that so long as we place any finite bound on the length of the pathformulae, that need to be sent to LTL model-checker, we can model check such CTL* formulae in time linear in the length of the formula (see for example [9], but note that their main result is subtly different).
This is convenient, as it means that we do not need to rigidly adhere to any particular syntactic  Abstract--It is known that there is an exponential decision procedure for CTL.
Given that important properties cannot be expressed in CTL, we seek a pure tableau based decision procedure (that does not rely on translations into automata) that is exponential for formulas that have only a bounded number of non-CTL properties.
In this paper we present such a tableau for a combination of CTL and a bundled variant (BCTL*) of CTL* that is singly exponential for formulae with a bounded number of path-subformulae.
The existing pure tableau for CTL* was built upon the pure tableau for BCTL*, so this paper is also a natural first step towards a pure tableau technique for CTL* that is singly exponential when similarly restricted.
Keywords-Bundled; Exptime; Logic; Tableaux; Temporal;  I. I NTRODUCTION There has been recent renewed interest in decision procedures for the branching time Full Computation Tree Logic (CTL*).
It has long been known that CTL* is decidable and is 2EXPTIME complete, [1] provides a doubly exponential automaton based satisfiability checker, and [2] gives a lowerbound.
These automaton based satisfiability checkers are expected to have performance close to their worst case on average and have not been implemented [3].
Recently, tableau based decision procedures have been proposed that have greater potential for reasonable real world performance, and that have publicly accessible implementations [3], [4].
However, the worst case performance is clearly still 2EXPTIME, whereas Computation Tree Logic (CTL) has a singly exponential decision procedure (see for example [5]).
CTL is similar to CTL*, but the syntax of CTL is more restricted, as CTL pairs each temporal operator with a path-quantifier in such a way that the truth of a CTL formula does not depend on which of many possible futures occurs.
CTL is popular and can express many useful properties, unfortunately CTL cannot represent some important fairness related properties.
Many interesting CTL* formulae are rather close to being CTL formulae, for example most of the sample formulae used in [4].
Thus is it natural to seek decision procedures that are exponential for formulas that are CTL-like, but that do not need to rigidly adhere to the syntactic restrictions of CTL.
The BCTL* logic (also known as [?
]LT F C) is similar to the CTL* but instead of quantifying over all paths, instead 1530-1311/12 $26.00 (c) 2012 IEEE DOI 10.1109/TIME.2012.17  29  II.
BCTL* AND CTL  restriction of CTL* to get model checking performance asymptotically similar to that of CTL.
For example, we can add any property that can be represented by a CTL* formula ph to the syntax of CTL and the resulting language can still be model checked in polynomial time.
A. Syntax Bundles affect the semantics rather than the syntax.
CTL* and CTL have the same syntax as the corresponding BCTL* and BCTL logics.
Where p varies over V the set of variables (or atomic propositions), we define CTL* formulae according to the following abstract syntax:  For formulae with a bounded number of non-CTL properties the decision procedure of [3] already runs in a singly exponential amount of time, as does the tableau for plain CTL of [5].
Both the pure tableau of [4], [6] and the hybrid tableau of [3] have to deal with sets of sets of formulae leading to doubly exponential running time in the worst case.
In the case of [3] the sets of formulae are called "blocks" and represent a disjunction (or conjunction) of formulae that must hold on all (some) futures leaving from a particular state.
It appears that it would be easy for the authors of [3] to show that CTL-like blocks have a unique derivation, and so if we limit the number of non-CTL subformulae we eliminate one exponential from the running time of the hybrid tableau.
However, [3] do not explicitly make this claim or present such a proof.
ph := p | !ph | (ph [?]
ph) | (phU ph) | N ph | Aph .
The !, [?
], N, U and A operators are read as "not", "and", "next", "until" and "all paths".
We define the other operators as abbreviations: [?]
[?]
(p [?]
!p),  [?]
![?
], a [?]
b [?]
!
(!a [?]
!b), "Finally" F a = U a, "Globally/Always" Ga [?]
!F !a, "Weak Until" aW b [?]
aU b [?]
Ga, "Exists a Path" Ea [?]
!A!a, a - b [?]
!a [?]
b and a - b [?]
(a - b) [?]
(b - a).
The syntax of CTL is as follows: ph ::= p | !ph | (ph [?]
ph) | A (phU ps) | AN ph | E (phU ps) .
When combining CTL and BCTL* it can be ambiguous whether we are using the bundled or unbundled semantics.
To address this, whenever using the unbundled semantics we will use underlining, so a CTL "AN " is written instead "AN ".
To emphasise the difference further we will put the path quantifier together with the until operator, as in CTL they cannot be separated.
Thus the CTL A (phU ps) will be written as phAU ps, and similarly for the E operator.
The syntax of our combination of CTL and BCTL* is as follows:  Unlike our paper, [3] uses a hybrid automata based approach.
The pure tableau based decision procedure of [6] for BCTL* requires a doubly exponential amount of time even when the non-CTL properties are bounded.
These two tableau based techniques are very different and are expected to have different real-world running times.
In particular, the requirement of the hybrid automata to build parity games may limit its ability to prove that large but simple formulae are satisfiable quickly [10].
As pure tableau work directly on subformulae of the formulae input by the user, the proofs generated by a pure tableau technique may be more meaningful to the user than a proof generated by translation into automata.
ph := ps | !ph | (ph [?]
ph) | (phU ph) | N ph ps := p | !ps | (ps [?]
ps) | Aph | AN ps | (psEU ps) | (psAU ps) Formulae of the form ps are called state formulae.
Formulae not of the form ps are called path formulae.
We use the following abbreviations for CTL formulae: EN a [?]
!AN !a, EF a [?]
EU a, AF a [?]
AU a, EGa [?]
!AF !a.
In this paper we present a tableau for deciding a combination of CTL and BCTL*.
The combination of CTL and BCTL* allows this tableau to reason about combinations of bundled and unbundled properties (for examples of these, see Section II-D).
We choose this combination for two reasons.
Firstly, we can combine the tableau for CTL and BCTL* in a relatively natural way, unlike some other combinations we have considered.
Secondly, it preserves EXPTIME-ness when the number of path-subformulae is bounded.
The BCTL* tableau considered here can also be considered a simplification of the rather complex tableau for CTL* found in the 42 page paper [4].
B. BCTL-Structures In this section we will define a number of basic terms that we will then use to define BCTL-structures.
Note that BCTL*-structures and BCTL-structures are the same, we will omit the "*" for aesthetic reasons and consistency.
Definition 1.
We say that a binary relation R on S is serial (total) if for every a in S there exists b in S such that aRb.
A transition frame is a pair (W, ), where W is a non-empty set of states and  is a serial relation on W .
We note that when only finite periods of time are considered the bundled and unbundled semantics are equivalent (see for example [11]).
In this case, we can replace pairs of BCTL* operators with the corresponding CTL operators to minimise the number of path subformulae and maximise the performance of this tableau based decision procedure.
Definition 2.
A valuation g is a map from a set of states W to the power set 2V of the variables.
The statement p [?]
g(w) means roughly "the variable p is true at state w".
We will now formalize some notation relating to paths, and which sets of paths can be called bundles.
30  !p  Definition 3.
For any relation R we let R* (respectively Ro ) be the set of finite (resp.
infinite) paths through R. We call an o-sequence s = w0 , w1 , .
.
.
of states a fullpath iff s [?
]o , that is for all non-negative integers i we have wi  wi+1 .
For all i in N we define s>=i to be the fullpath wi , wi+1 , .
.
.
, we define si to be wi and we define s<=i to be the sequence w0 , w1 , .
.
.
, wi .
We say that a set of fullpaths B is fusion closed iff for all non-negative integers i, j and s, p [?]
B we have s0 , s1 , .
.
.
, si , pj , pj+1 , .
.
.
[?]
B if si+1 = pj .
We say that a set of fullpaths B is suffix closed iff for all integers i and s [?]
B we have s>=i [?]
B.
We say a set of fullpaths is a bundle if it is non-empty, suffix closed and fusion closed.
We say a bundle B is on a transition frame (W, ) if B [?
]o and every edge in  appears in B.
!p !p  Figure 1.  p p  Structure on which AF p is false, but AF p can be true.
Although AGF h [?]
AGEN !h is not satisfiable in CTL* it is satisfiable in BCTL*.
This can be easy verified by, for example, entering the formula (AGFh&AGEX-h) into the BCTL* web applet [12].
Although a major reason this combination of BCTL* and CTL was chosen was as a stepping stone to finding an efficient pure tableau decision procedure for CTL*, we now give a number of example formulae that can be reasoned with using this tableau.
One of the possible uses of this tableau is for testing intuitions of the difference between bundled and unbundled semantics.
For example, we would expect EN p - EN p to be valid as every edge in  appears in B.
As B is suffix and fusion closed, we would expect EF p - EF p. Since every path in the bundle B is clearly a path, we would expect EGp - EGp to also be valid.
However, since the difference between bundled and unbundled logics is that the bundle B need not contain all paths, we would expect EGp - EGp to be falsifiable.
In addition to these trivial examples, the tableau we will define in this paper could also reason about more complex examples; such as verifying that E (pU A (pU q)) - (pEU q) is valid.
One example that is good for visualising the difference between bundled and unbundled semantics is !AF p [?]
AF p. This would be satisfied on a binary tree where only the leftmost branch satisfies G!p.
We can construct a bundle which only includes paths that follow the left edge a finite number of times, and so !AF p [?]
AF p is satisfiable (see Figure 1).
The tableau we will define can be used to efficiently reason about some BCTL* formulae.
For a BCTL* formula ps, let ps represent the formula resulting when BCTL operators are replaced with CTL operators.
In many cases ps and ps are equivalent (and we can test whether they are equivalent by testing whether ps - ps is valid).
Say we are attempting to determine whether a BCTL* formula ph is satisfiable.
We can improve the performance of the decision procedure by recursively replacing each subformula ps with ps when these are known to be equivalent.
In general, for any set Ph of BCTL* formula consisting only of BCTL* formulae which are computationally easy to transform into equivalent formulae with only a bounded number of path-subformulae,  We complete this section with our definition of BCTLstructures.
Definition 4.
A BCTL-structure M = (W, , g, B) is a 4-tuple containing a set of states W , a serial binary relation  on W , a valuation g on the set of states W , and B is a bundle on (W, ).
C. Semantics The semantics of the classical operators is similar to the definition in classical logic, although we will use fullpaths in place of worlds, that is: M, s  !ph iff M, s  ph M, s  ph [?]
ps iff M, s  ph [?]
M, s  ps , Both CTL* and BCTL* use the operators from propositional Linear Temporal Logic (LTL), M, s  N ph iff M, s>=1  ph M, s  phU ps iff [?
]i [?]
N s.t.
M, s>=i  ps and [?
]j [?]
N s.t.
j < i == M, s>=j  ph .
We define the semantics of the BCTL* Bundled All Paths operators A and the CTL* All Paths operator A as follows: M, s  Aph iff [?
]p [?]
B s.t.
p0 = s0 , M, p  ph M, s  Aph iff [?
]p s.t.
p0 = s0 , M, p  ph .
The semantics of the CTL operators are defined in terms of the CTL* A operator and the LTL operators as follows: AN ps [?]
AN ps, (phEU ps) [?]
!A!
(phU ps) , (phAU ps) [?]
A (phU ps).
D. Examples of Formulae Now that we have defined the logic, we can revisit the fair coin example.
We can encode the idea that on all paths we expect to always finally have a head toss as AGF h (and the reverse, that we always expect to have have a tail as AGF !h).
We can encode the idea that it is always possible that the next toss is a tail by the formula AGEN !h.
31  CTL Tableau  BCTL* Tableau  Formulas  Formulas  State Formulas  Colours  Hues  CCols  Linear  Exponential  Doubly Exponential  Path Formulas  Hues  Colours  Exponential (State subformulae) X Doubly Exponential (Path)  Figure 2.
For all ps [?]
clph, if d <= ps then d [?]
clph.
For all ps [?]
clph, if ps is not of the form !d then !ps [?]
clph.
(Cl4) For all (aAU b) [?]
clph we have AN (aAU b) [?]
clph.
(Cl5) For all (aEU b) [?]
clph we have EN (aEU b) [?]
clph.
For simplicity, we will only consider sets of formulae that are Maximally Propositionally Consistent, as defined below.
(Cl2) (Cl3)  Combined Tableau  XCols  Shades  Definition 6.
We say that h [?]
clph is Maximally Propositionally Consistent MPC iff for all a, b [?]
clph  Comparison of Tableau  if b = !a then b [?]
h iff a [?]
/ h. if a [?]
b [?]
clph then (a [?]
b) [?]
h - (a [?]
h and b [?]
h).
Since the BCTL* tableau requires doubly exponential time, we wish to avoid using the BCTL* half of the combined tableau technique when possible.
However, the BCTL* part is required to reason about path formula, and to do so it has to be aware of the truth of direct subformulae of pathformulae.
We call the formulae that need to be considered by the BCTL* part of the combined tableau path-sensitive formulae.
(M1) (M2)  testing the satisfiability of the formulae in Ph is at worst singly exponential.
III.
A P RE -TABLEAU FOR BCTL* AND CTL Here we define a tableau CTAB for deciding this combination of CTL and BCTL*.
This tableau is derived from Reynolds' [6] tableau for BCTL* and the decision procedure for CTL defined in [5].
As this paper uses a number of terms, we show how these terms relate in Figure 2, and how they relate to the terms in the tableaux this paper extends.
It is traditional to call the labels of nodes of a tableau colours.
As is common colours of the existing CTL tableaux are sets of state formulae, we call this type of colour a CTL Colour (CCol).
In BCTL* the truth of a formula can depend not only on the initial state s0 but also on the remainder of the path s. For this reason the existing BCTL* tableau needs to consider not only what set of formulae are true along a particular path, but also what types of path start from each world.
For this reason the colours of the BCTL* tableaux are sets of sets of formulae, we call this type of colour an eXtended colour (XCol).
As we will be discussing a number of different types of colours, to reduce ambiguity we will refer the colours used to label the nodes of our new combined tableau as Shades.
The shades are a combination of a CCol and an XCol.
We now fix a formula ph that we are attempting to determine the satisfiability of.
Note that a is satisfiable iff Ea is satisfiable, so we can assume without loss of generality that ph is a state formula.
An important tool in developing a tableau technique that requires a finite amount of space is identifying a finite set of formulae, called the closure set, such that the technique never has to reason about formulae outside this set.
Definition 7.
We define the set P of path-sensitive formulae as the minimal set that satisfies the following: If ps [?]
clph and ps is a path formula then ps [?]
P .
if N ps [?]
clph then ps [?]
P and N ps [?]
P .
if psU th [?]
clph then psU th [?]
P , ps [?]
P and th [?]
P. A hue is roughly speaking a set of formulae that could plausibly hold along a single fullpath.
As mentioned in [6] some hues are not satisfied on any fullpath, but every path corresponds to some hue.
After defining hues we will define XCols (sets of hues roughly representing paths that could start at the same world), and CCols (representing state formulae that could plausibly hold at the same state).
(P1) (P2) (P2)  Definition 8.
A set h [?]
P of path-sensitive formulae is a hue for ph iff (H1) (H2) (H3) (H4)  is MPC; aU b [?]
h then a [?]
h or b [?]
h; !
(aU b) [?]
h then b [?]
/ h; and Aa [?]
h and a [?]
P then a [?]
h.  h h Definition 9 (RN ).
The temporal successor RN relation on hues below is defined as in Reynolds [6]; For all hues a, b h iff the following conditions are satisfied: put (a, b) in RN  Definition 5.
We use a <= b to indicate that a is a subformula of b, and we consider two formulae to be equal if they have the same representation (e.g.
p[?
]q = p[?
]q = q[?]p).
The closure clph of the formula ph is defined as the smallest set that satisfies the following requirements: (Cl1)  h if if if  (R1) (R2) (R3) (R4)  N a [?]
a implies a [?]
b.
!N a [?]
a implies a [?]
/ b. aU b [?]
a and b [?]
/ a implies aU b [?]
b.
!
(aU b) [?]
a and a [?]
a implies !
(aU b) [?]
b.
Definition 10.
We call a set of hues a XCol.
We define a  ph [?]
clph  32  X temporal successor function RN on XCols as follows: given X Y iff a pair of XCols X and Y , we have XRN  (X1)  for all hues g [?]
X there exists h [?]
Y such that h gRN h.  q  Definition 11.
A set of state formulae a is a CCol of ph iff (C1) (C2) (C3) (C4) (C5)  Figure 3.
(CN3)  (Z4)  Full vs. Pseudo Hintikka Structure.
1) there exists a hue x in X such that for every (D, Y ) [?]
h / RN ; or {L} (w ) and every y [?]
Y , the pair (x, y) [?]
2) there exists a formula of the form !AN a in C such that for every (D, Y ) [?]
{L} (w ) we have a [?]
D.  Definition 13.
We call Z = (C, X) a shade if X is a XCol and C is a CCol which satisfy the following conditions.
(Z2) (Z3)  r  Definition 16.
We say that a node w labelled with the shade (C, X) is stepwise-unfulfilled if we cannot find successors for every hue in X and every state formula in C. That is w is stepwise-unfulfilled if:  For all aAU b [?]
C , either b [?]
C or aAU b [?]
D. For all !
(aEU b) [?]
C, either !a [?]
C or !
(aEU b) [?]
D. For all AN a [?]
C, we have a [?]
D.  Note that is CN2 above, we do not need to explicitly state that !b [?]
C, as that is ensured by C5.
(Z1)  q  all labels of (u ), that is Z [?]
{L} (u ) iff there exists v [?]
u such that L (v) = Z.
Informally, it is obvious that if say EN p occurs in a node but we cannot find a temporal successor p then there is something wrong, and that to fix this we need to remove the original node.
C ).
We define a temporal successor relation Definition 12 (RN C C RN on CCols as follows: for all C, D [?]
C, put (C, D) [?]
RN iff  (CN2)  r p'  a [?]
clph and; a is MPC; if aAU b [?]
a then aEU b [?]
a; if aEU b [?]
a then a [?]
a or b [?]
a; if !
(aAU b) [?]
a then !b [?]
a.
Let C be the CCols of ph.
We define a successor relation on C as follows:  (CN1)  p  p  Z and being stepwiseNote the difference between RN unfulfilled above.
The first implements properties that every successor must have, while the second implements properties that some successor must have.
For every hue h in X and for all state formulae a in P we have a [?]
h iff a in C. If Aps [?]
C then for all h [?]
X, we have ps [?]
h. If !Aps [?]
C then there exists h [?]
X such that !ps [?]
h. If p is a path-sensitive variable, then for all h [?]
X, we have p [?]
h iff p [?]
C.  Definition 17.
A frontier node is a node w that has no successors, that is w is empty.
An interior node is a node that is not a frontier node.
A fragment is a pre-tableau such that every node w of the pre-tableau is either stepwisefulfilled or a frontier node.
We say that a pre-tableau    W, , L is a fragment of a pre-tableau  W ,  , L  if T T W, , L is contained in W,  , L a tree-unwinding of W  ,  , L ; that is if [?
]T and L(w) = LT (w) for all w [?]
W .
Z ).
We define a temporal successor relation Definition 14 (RN Z RN on shades as follows: for all pairs of CCols C, D and Z iff (C, D) [?]
XCols X, Y we put ((C, X) , (D, Y )) [?]
RN C X RN and (X, Y ) [?]
RN .
In [5] they define Hintikka structures, which in essence provide a model for the formula under consideration.
However, it is convenient to label every node in the tableau with a unique set (or set of sets) of formulae.
This is easy with the BCTL* tableau of [6]; however, with CTL collapsing nodes with the same label can break a model.
For example, say we have (p - AN !p) [?]
(!p - AN p) [?]
AF q [?]
AF r. Then we see that the structure on the left of Figure 3 models this formula and that the nodes p and p satisfy the same subformulae and so they would have the same label.
Thus collapsing duplicated labels as is done in [6] would result in the structure on the right which does not model the formula.
The solution in [5] is to define pseudo-Hintikka structures, which do not model the formula, but which can be unwound  Definition 15.
Let W be a set of nodes,  be a binary relation on W and the function L from W to shades be a labelling of W with shades.
Then we say W, , L is a pre-tableau iff for all u, v in W , we have u  v == Z Z L (v).
We call the pre-tableau W, RN , I CTAB0 L (u) RN when W is the set of shades and I is the identity function on W .
IV.
P RUNING THE TABLEAU We now show how to prune the tableau.
We now fix a pre-tableau W, , L.
For shorthand we define (u ) to be the set of all successors of u, that is all v [?]
W such that u  v. We let {L} (u ) be the set of  33  Let n be the number of state-subformulae.
The number of CCols is at most 2kn for some constant k. A shade is a combination of a CCol and a XCol.
Thus the number of 3m shades is at most 2kn 22 .
Note that each node in CTAB0 3m is labelled with a unique shade, so it has at most 2kn 22 nodes.
This is singly exponential when the number of path subformulae is bounded (or of order ln n).
For a sketch of how to test that a fragment satisfying pHf3 exists in time polynomial to the number of nodes/shades, see [5].
The remainder of the tests are clearly polynomial.
As with other tableaux, we expect the average case performance to be much better than the theoretical worst case performance.
This worst case bound suggests that the performance of the tableau will be similar to the tableau for CTL when the number of path subformulae is bounded and small.
into a model; the structure on the right can be unwound into a similar to the one on the left.
The only difference between Hintikka structures and pseudo-Hintikka structures relates to the handling of formulae like AF q.
In a pseudo-Hintikka structure we do not require that the structure actually satisfy AF q we only require that we can find some fragment of the structure that can satisfy AF q.
Definition 18.
We say that a hue h is inside a node labelled with a shade Z = (C, X) if h [?]
fi X.
We say that a formula ph is inside the node if ph [?]
C [?]
( X).
Definition 19.
We say that a node w labelled with a shade Z = (C, X) is pseudo-Hintikka-fulfilled (pHf) if it is stepwise-fulfilled and satisfies the following three requirements: (pHf1)  (pHf2)  (pHf3)  for every hue h in X and formula of the form aU b [?]
h there exists a sequence of nodes w, w1 , .
.
.
, wm [?
] (* ) and sequence of hues h * such that: h, h1 , .
.
.
, hm [?]
RN 1) the sequence fulfils aU b, that is, b [?]
hm .
2) each hue hi is inside the node wi .
For every formula of the form (aEU b) in C there exists a sequence of nodes w, w1 , .
.
.
, wm [?]
(* ) such that b is inside wm .
For every formula of the form (aAU b) in C there exists a fragment of Z such that the CCols in the frontier shades of the fragment all contain b and the interior shades all contain a.
(Note that we can use Konig's lemma to show that this fragment is finite.)
VI.
S OUNDNESS CTAB is sound, that is, if it succeeds on ph then ph is satisfiable.
We will now show how to construct a model for the formula from the tableau CTAB.
The details are as in [5] and [6].
Similarly to [5] (but unlike [6]) we will have to unwind the tableau into a tree to ensure that formulae such as AF a are satisfied at the worlds corresponding to nodes w where AF a [?]
w. We assume some arbitrary ordering on the shades, fragments and formulae.
Consider a tableau S, R, L where S is the set of nodes, each labelled with a shade, the relation R forms a tree and all interior nodes of the tree are stepwise-fulfilled.
We define an eventuality in the tree as a tuple w, h, ps where w is a node in the tree and ps is a formula of the form aAU b, aEU b, aU b.
We say w, h, aAU b is fulfilled if b is inside some node of every path starting at w; note that as the interior nodes are stepwise-fulfilled we do not need to consider a in our definition of fulfilled, as we know that a will remain in the tableau until we reach b.
We say w, h, aEU b is fulfilled if b is inside some node reachable from w. The definition of fulfilled for w, h, aU b is similar but we have to follow the hues, or formally there must exist a sequence of nodes w0 , w1 , .
.
.
, wm through the tree and h such that hues h0 , h1 , .
.
.
, hm that form a path through RN for each non-negative integer i <= m we have hi inside wi , have w0 = w and h0 = h. We will now define an unwinding of CTAB into a tree.
Let S  be the set of labels of the nodes in CTAB, that is the shades remaining after pruning.
Consider the following algorithm: 1) We start with S + = {w0 } and R+ = [?
], where w0 is a node labelled with a shade Z = (C, X) satisfying ph [?]
C. 2) We navigate the tree breadth-wise.
When we come across a frontier node w labelled with a shade Z = (C, X) we consider the oldest unfulfilled AU or EU eventuality.
Definition 20.
We say that a pre-tableau is a tableau iff all its nodes are pHf, when S  is taken to be the set of all nodes in the tableau.
The decision procedure is as follows: we begin with the pretableau CTAB0 from Definition 15.
We iteratively remove all nodes that are not pHf until all nodes are pHf.
Note that removing one node may cause another node to become nonpHf, and so one pass is not sufficient.
We say that CTAB succeeds if the resulting tableau contains a node labelled with a shade (C, X) where ph [?]
C. V. C OMPLEXITY Let m be the number of path-subformulae of ph.
We see the number of path-sensitive formulae is at most 3m.
This is because each sensitive formula is either a path formula or a direct subformula of ph, and a formula has at most two direct subformulae (aU b has a and b as direct subformulae).
Since hues are power-sets of sensitive formulae, the number of hues is a most 23m .
Likewise, the XCols are power-sets 3m of hues and we have at most 22 XCols.
34  The tableau is finite so CTAB will halt.
Say that ph is satisfiable.
Then there exists a BCTLstructure (W, , g, B) and path p 0 in B such that p 0  ph.
We will define a translation r from worlds to shades, and show that for each world w in W , the shade r (w) will not be pruned from the tableau.
Hence the set S  of unpruned nodes will be non-empty when CTAB halts, and so CTAB will succeed.
a) If there is no such eventuality, or the eventuality is of the form aU b or aEU b, then for each temporal successor Z  of Z (that is, each Z  [?]
S  Z such that (Z, Z  ) [?]
RN ) we add a successor to  w labelled Z .
b) If the eventuality is of the form aAU b, we add the first fragment satisfying pHf3.
We see that at each step of the algorithm, all of the interior nodes are stepwise fulfilled.
Since there are a finite number of unfulfilled eventualities on each branch of the tree, and the algorithm iteratively fulfils the oldest eventuality first, each eventuality will be fulfilled.
As the algorithm never ends, we define the final tree (ST , RT ) as containing all nodes and edges that are ever added by the algorithm.
Where (ST , RT ) is our final tree we define a BCTLstructure (W, , g, B) as follows: the transition frame (W, R) is simply (ST , RT ), and the valuation g (w) of a world is precisely those atoms p that are inside w. We now define the set of bundled paths B, in a similar fashion to how they were defined in [6].
Definition 25.
We define a function h on paths such that h (p) = {a : a [?]
clph and p  a} As H1-4 are simply properties that any set of formulae that hold along the same path must satisfy, it is clear that the following lemma holds.
Lemma 26.
From the semantics of BCTL*, we see that for each p [?]
B, h(p) is a hue.
Proof: (H1) Since the semantics of the [?]
and !
operators in BCTL* come from classical logic, it is clear that h (p) is MPC.
(H2) If aU b [?]
h (p) then p  aU b and we see that either b is satisfied immediately and so p  b or p  a; hence a [?]
h (p) or b [?]
h (p).
(H3) Likewise if !
(aU b) [?]
h (p) then we see that p  / h (p), demonstrating that H3 aU b and so p  b and so b [?]
is satisfied.
(H4) If Aa [?]
h (p) then p  Aa and so all paths starting at p0 , including p, satisfy a.
We will now define a function from worlds to shades.
This definition uses the function from paths to hues defined in Definition 25.
Definition 21.
We call an o-sequence (w0 , h0 ) , (w1 , h1 ) , .
.
.
a thread through ST iff for all i >= 0: each wi [?]
ST , each hue hi is inside wi , h .
We say (wi , wi+1 ) [?]
RT , and each (hi , hi+1 ) [?]
RN that this is a fulfilling thread iff for all i >= 0 and for all formulae of the form (aU b) in hi , there exists j >= i such that b [?]
hj .
We include a fullpath s = w0 , w1 , .
.
.
in B iff there exists a fulfilling thread (w0 , h0 ) , (w1 , h1 ) , .
.
.
, and we say that this thread justifies s being in B.
It is easy to show that B is a bundle.
Since every aU b eventuality is fulfilled it is easy to see every hue has a fulfilling thread.
Definition 27.
We define a function rX on worlds to sets of hues, rC to sets of state formulae, rZ to shades as follows:  Lemma 22.
For all ps in clph, for all threads m = (w0 , h0 ) , (w1 , h1 ) , .
.
.
justifying s = w0 , w1 , .
.
.
we have  rX (w) = {h(p) : p [?]
B and p0 = w} rC (w) = {a : a is a state-formula in clph  (W, , g, B), s  ps iff ps is inside w0 .
, [?
]s [?]
B with s0 = w [?]
M, s  a} rZ (w) = (rC (w), rX (w)) rS = {rZ (w) : w [?]
W } .
The proof of this lemma is rather mechanical, given the previous results it is easy to prove this recursively, see [6] and [5] for details.
One minor point not covered in [6] or [5] is that the formulae in the [6] style hues and [5] style CCols need to be consistent, for example if we had (qEU p) U (pAU q) in a hue of a node w then we would clearly want to have either (pAU q) or (qEU p) in the CCol of the same node.
This is ensured by P2, P3 and Z1.
We see that for each w [?]
W , rX (w).
Likewise rC (w) is a CCol and rZ(w) = (rC (w), rX (w))  is a shade.
We Z [?]
(rS x rS ) .
It is trivial to see let the tableau be rS , RN the tableau is stepwise-fulfilled.
Showing that the tableau is pHf is also easy, for details on pHf1 see [6] and see [5] for details on pHf2 and pHf3.
Thus no nodes in rS are pruned.
Theorem 23.
The tableau is sound, that is if the tableau succeeds, ph is satisfiable.
VIII.
C ONCLUSIONS AND F UTURE R ESEARCH We have presented a tableau for a combination of CTL and BCTL*.
This tableau is singly exponential when the number of non-CTL operators is bounded; a pure CTL formula will not have any path subformulae.
While this combination has some advantages, it is presented as a step  Obvious from lemma above.
VII.
C OMPLETENESS Lemma 24.
CTAB is complete, that is, if ph is satisfiable then CTAB halts and succeeds on ph.
35  towards finding a pure tableau for a similar combination of CTL and CTL*.
R EFERENCES [1] E. A. Emerson and A. P. Sistla, "Deciding branching time logic," in Proceedings of the 16th annual ACM symposium on Theory on computing (STOC).
New York, NY, USA: ACM Press, 1984, pp.
14-24.
The BCTL* tableau used in this paper can be extended to a CTL* tableau, as was done in [4].
A simple replacement of the BCTL* with the tableau CTL* is not challenging though we note that the specification of the CTL* tableau alone is more lengthy than this paper.
This expansion would provide better performance for CTL-like CTL* formulae; however a simple replacement may not preserve the singly exponential running time for CTL-like formulas.
The worst case bound on the running time of the CTL* tableau is based on a bound on the size of models for CTL* like formulae.
To preserve the singly exponential running time we would need to find a better halting condition.
[2] M. Y. Vardi and L. Stockmeyer, "Improved upper and lower bounds for modal logics of programs," in Proceedings of the 17th annual ACM symposium on Theory of computing (STOC).
New York, NY, USA: ACM, 1985, pp.
240-251.
[3] O. Friedmann, M. Latte, and M. Lange, "A decision procedure for CTL* based on tableaux and automata," in 5th International Joint Conference on Automated Reasoning (IJCAR), ser.
LNCS, J. Giesl and R. Hahnle, Eds.
Springer, 2010, vol.
6173, pp.
331-345.
[Online].
Available: http://dx.doi.org/10.1007/978-3-642-14203-1 28  Another important optimisation would be to convert these tableaux into conventional tableaux rooted with a single formula.
This tableau begins by creating all possible shades.
We define the tableau this way as it simplifies the definition and it does not affect that the worst-case performance results that are the focus of this paper.
However, this form of tableaux for CTL and BCTL* also tends to perform much worse than conventional tableau in the average case [5], [10].
To see why, consider a formula of the form p [?]
!p [?]
ph.
A conventional tableau would end as soon as it found the contradiction, while our tableau would always take longer to reason about p[?]!p[?
]ph than ph.
Although not discussed in this paper, it is known how to implement both the CTL and BCTL* tableaux in a traditional rooted way [5], [10].
We would recommend converting this tableau to a conventional tableau prior to implementation.
[4] M. Reynolds, "A tableau for CTL*," in Proceedings of the 16th International Symposium on Formal Methods (FM), ser.
Lecture Notes in Computer Science, A. Cavalcanti and D. Dams, Eds., vol.
5850.
Springer, 2009, pp.
403-418.
[5] E. A. Emerson and J. Y. Halpern, "Decision procedures and expressiveness in the temporal logic of branching time," in STOC.
ACM, 1982, pp.
169-180.
[Online].
Available: http://dx.doi.org/10.1145/800070.802190 [6] M. Reynolds, "A Tableau for Bundled CTL*," J Logic Computation, vol.
17, no.
1, pp.
117-132, 2007.
[Online].
Available: http://logcom.oxfordjournals.org/ cgi/content/abstract/17/1/117 [7] A. Masini, L. Vigano, and M. Volpe, "A labeled natural deduction system for a fragment of CTL*," in Proceedings of the 2009 International Symposium on Logical Foundations of Computer Science, ser.
LFCS '09.
Berlin, Heidelberg: Springer-Verlag, 2009, pp.
338-353.
[Online].
Available: http://dx.doi.org/10.1007/978-3-540-92687-0 23  Continued research into pure tableaux is important.
[3] note that their hybrid implementation tends to perform better than that of [4]; however, they start with a rooted tableau it is not clear whether this is due to their approach or because they begin with conventional tableaux.
Converting the approach of Reynolds to a conventional tableau, that begins with a single formula, greatly increases the performance a related tableau for BCTL* [10].
This suggests than even when performance is the only concern, research into pure-tableau is still worthwhile.
As pure-tableaux based algorithms work directly on subformulae of the input formula, they have an important advantage over the hybrid technique of [3]: the workings of the algorithm is more easily understood by the user than a parity game solver.
[8] E. A. Emerson and C.-L. Lei, "Modalities for model checking (extended abstract): branching time strikes back," in POPL '85: Proceedings of the 12th ACM SIGACT-SIGPLAN symposium on Principles of programming languages.
New York, NY, USA: ACM, 1985, pp.
84-96.
[9] O. Kupferman and O. Grumberg, "Buy one, get one free!!!"
J. Log.
Comput., vol.
6, no.
4, pp.
523-539, 1996.
[Online].
Available: http://logcom.oxfordjournals.org/content/ 6/4/523.full.pdf [10] J. C. Mc Cabe-Dansted, "A rooted tableau for BCTL*," 2011, Expanded Version, Availiable: http://www.csse.uwa.edu.au/ ~john/papers/Rooted BCTL Tableau.pdf.
[11] ----, "A temporal logic of robustness," Ph.D. dissertation, The University of Western Australia, 2011.
[Online].
Available: http://tinyurl.com/RoCTL11  There has been research into parallelisation of automated reasoning for CTL.
For example, [13] propose a tableau for CTL that is intended to provide good average case performance and is easy to parallelise.
The current CTL* tableaux do not yet exploit parallelisation.
Single core performance of modern CPUs has plateaued.
To exploit future advances in computation power, we will examine the potential to parallelise these tableau based techniques.
[12] ----, "Improved BCTL* applet," 2011, http://www.csse.uwa.
edu.au/~john/BCTL2/.
[13] P. Abate, R. Gore, and F. Widmann, "One-pass tableaux for computation tree logic," in Logic for Programming, Artificial Intelligence, and Reasoning.
Springer, 2007, pp.
32-46.
36

Temporal Implications of Database Information Accountability Kyriacos E. Pavlou and Richard T. Snodgrass Department of Computer Science University of Arizona Tucson, USA {kpavlou}{rts}@cs.arizona.edu  Abstract--Information restriction controls access and renders records immutable; information accountability requires data transparency to easily and efficiently determine when a particular use is appropriate.
Information accountability in the context of relational databases is associated with time in a surprising number of ways, as is summarized in this paper.
Notarization and validation of a database exploit the temporal semantics of a transaction-time database.
A corruption can be associated with multiple times.
Forensic analysis determines the when: bounds on the corruption time, and the where: also specified in terms of time.
These bounds are depicted in a two-dimensional corruption diagram, with both axes denoting time.
The various kinds of corruption events are defined in terms of time.
A parameter termed the regret interval has significant security and performance implications.
This paper emphasizes the deep connections between time and the definition, detection, forensic analysis, and characterized extent of a database corruption within the context of information accountability.
Keywords-information accountability; temporal semantics; transaction-time databases; forensic analysis;  The prevailing approach to achieving privacy and security for databases is information restriction.
For example, ensuring record compliance, or information compliance in general, usually entails rendering retained records immutable and controlling access to them.
We feel that the means of addressing security and compliance should be viewed as constituting a spectrum.
If one asserts that information restriction lies at one end of the spectrum then the question which inevitably arises is what lies at the other end?
In a recent article Weitzner et al.
[1] argue that access control and cryptography are not capable of protecting information privacy and that there is a true dearth of mechanisms for effectively addressing information leaks.
They propose that as an alternative information accountability "must become a primary means through which society addresses appropriate use" [1].
Information accountability assumes that information should be transparent so as to easily determine whether a particular use is appropriate under a given set of rules.
A related concept is continuous assurance technology, defined as "technology-enabled auditing which produces audit results simultaneously with, or a short period of time after, the occurrence of relevant events" [2].
This concept is crucial because it can be used to achieve a meaningful operationalization of information accountability.
Security Information Accountability Provenance  Watermarking  this article  Temporal Databases  Time  Figure 1.
Databases  The context of the present paper.
This paper studies the overlap of time, databases, and security, as shown in Figure 1.
We have encountered time in this context in many different places and under many different guises.
This suggests a deep connection between the general topics of (i) temporal databases and (ii) information accountability.
Our purpose here is to identify the many instances where time appears in the definition and implementation of information accountability and to discuss new time-security interactions we have identified recently as described in Sections VIII-X.
More generally, we hope that the many tantalizing glimpses of a fundamental connection between temporal databases and information security, as seen in this abbreviated trip through the stages of database corruption, detection, and subsequent forensic analysis, will encourage further work within this community to uncover the source(s) of this connection.
I. T HE AUDIT S YSTEM In this section we describe how to audit a database and summarize the tamper detection approach we previously proposed and implemented [3].
We give the gist of our approach, so that its temporal implications can be understood.
Table I lists the audit system execution phases, their subphases, and the actions performed during each.
The Normal Processing execution phase differentiates between the Total Chain Computation and the Tamper Detection and Partial Chain Computation subphases.
In the first subphase transactions are hashed and cumulatively  Table I AUDIT SYSTEM EXECUTION PHASES , SUBPHASES , AND ACTIONS .
Execution Phases  Subphases Total Chain Computation  Normal Processing  Tamper Detection and Partial Chain Computation  Actions - Hashing to create total chain - Notarization of total chain - Re-hashing of total chain - Validation of total chain If required by forensic algorithm: - Hashing to create partial chains - Notarization of partial chains  Corruption Region Analysis  - Running a forensic algorithm to determine where and when  Manual Analysis  - Determining who and why  Forensic Analysis  linked (by increasing transaction commit time) using a cryptographically-strong hash function, and the resulting values are digitally notarized by an external digital notarization service.
In the latter subphase hash values are recomputed and compared with those previously notarized.
It is during validation of the total chain that tampering is detected, when the just-computed hash value doesn't match the one previously notarized.
The validator provides a vital piece of information, that tampering has taken place, but doesn't offer much else.
Since the hash value is the accumulation of every transaction ever applied to the database, we don't know when the tampering occurred, or what portion of the monitored database was corrupted.
We have introduced a variety of database forensic algorithms [4], [5], [6] to provide partial answers to these questions.
Note that certain forensic analysis algorithms require the computation and notarization of one or more partial hash chains during the scan of the entire database that occurs during validation.
Details on performance, clarifications on the role of the external digital notarization service, and all the forensic analysis algorithms are beyond the scope of this paper and can be found elsewhere [5], [6].
II.
T HREAT M ODEL Time is first encountered in the underlying threat model.
We assume a Trusted Computing Base (TCB) consisting of correctly booted and functioning hardware and a correctly installed operating system and DBMS.
More precisely, we assume that the TCB is correctly functioning, the DBMS is created, maintained, and operates in a secure manner, and all network communication is performed through secure channels (such as SSL), ensuring the correctness of the internal state of the DBMS.
A tampering by an adversary ("Bob") occurs at time tc .
This tampering can take many forms.
In general, we assume that an intruder (or an insider) who gains physical access to the DBMS server will have full freedom to corrupt any database file.
III.
TAMPERING The very definition of tampering can be stated in terms of time.
Users and applications modify the database during  normal processing, and later query that data.
So how can tampering be differentiated from normal processing?
To achieve this we introduce transaction-time support to the database.
A transaction-time database records the history of its content [7].
All past states are retained and can be reconstituted from the information in the database.
This is ensured through the append-only property of a transactiontime database: modifications only add information; no information is ever deleted.
Thus the database itself can serve as an audit log.
It is this basic property that we exploit to validate the table.
Fortunately, the SQL:2011 standard and many commercial DBMSes now provide transaction-time support.
Oracle 10g added support for valid-time tables, transaction-time tables, bitemporal tables, sequenced primary keys, sequenced uniqueness, sequenced referential integrity, and sequenced selection and projection, in a manner quite similar to that proposed in SQL/Temporal.
Oracle 11g enhanced support for valid-time queries [8].
Teradata recently announced support in Teradata Database 13.10 of most of these facilities as well [9], as did IBM for DB2 10 [10].
A normal modification of a tuple can only be performed on the most recent version (that with a stop time of "until changed").
The modification changes the stop time to the current time (for deletions or updates) and inserts a new record with the current time as the start time (for insertions or updates).
A modification is considered a tampering or corruption if it (a) changes any tuple with a stop time other than "until changed", (b) inserts a tuple with a start time other than the current time and a stop time other than "until changed", (c) modifies the explicit attributes of any tuple, or (d) physically deletes any tuple.
Note that the first two conditions involve timestamps stored in the database; the second condition explicitly mentions "current time."
Specifically, any modification other than a temporal upward compatible modification [11] is considered tampering.
Section VII will examine a more refined taxonomy of corruptions.
IV.
TAMPER D ETECTION We now examine tamper detection in more detail.
Suppose that we have just detected a corruption event (or CE), which is any event that corrupts the data and compromises the database.
Table II summarizes all the time-related concepts used in this paper.
Time instants are generally denoted by a subscripted t, time intervals by a subscripted I or R. Factors are integers.
A temporal or a spatial bound occurs at a time instant, as does an event.
There exists a one-to-one correspondence between a CE and its corruption time (tc ), which is the actual time instant (in seconds) at which a CE has occurred.
Figure 2 shows that tc marks the transition from a legal database state to an illegal one.
Table II S UMMARY OF TIME - RELATED CONCEPTS .
Symbol CE  Name Corruption event  VE  Validation event  NE  Notarization event  tc tv IV tn IN V  Corruption time Validation time Validation interval Notarization time Notarization interval Validation factor  tl  Locus time  Rs  Spatial detection resolution Notarization factor Temporal detection resolution Time of first validation failure Time of most recent validation success  N Rt tFVF tRVS LTB  Lower temporal bound  UTB  Upper temporal bound  LSB  Lower spatial bound  USB  Upper spatial bound  tb tp Imax  tran  Backdating time Postdating time Transaction max-duration  IR  Regret interval  * IR IRP ts ILH  Regret interval estimate Retention interval Shred time Litigation hold interval  Iqv  Query verification interval  Definition An event that compromises the database The validation of the audit log by the notarization service The notarization of a document (hash value) by the notarization service The time instant of a CE The time instant of a VE The time between two successive VEs The time instant of a NE The time between two successive NEs The ratio IV /IN The time instant that the corruption locus data (lc ) was stored Finest interval chosen to express the spatial bounds uncertainty of a CE The ratio IN /Rs Finest interval chosen to express the temporal bounds uncertainty of a CE Time instant at which the CE is first detected The time instant of the last NE whose revalidation yielded a true result Lower bound of the temporal uncertainty of the corruption region Upper bound of the temporal uncertainty of the corruption region Lower bound of the spatial uncertainty of the corruption region Upper bound of the spatial uncertainty of the corruption region The time a timestamp was backdated to The time a timestamp was postdated to Maximum duration of a transaction Minimal time interval before an adversary can reverse a change Lower bound on the regret interval Length of the retention period The time a tuple is shredded A duration of time specified by a court of law Interval between the time a transaction reads data and the time when tampering is detected  The following discussion relates to our approach to effecting information accountability in relational databases.
A CE is detected during a validation event (or VE ) of the database by the notarization service.
A validation can be scheduled (that is, is periodic) or could be an ad hoc VE.
The time (instant) at which a VE occurs is termed the time of validation event, and is denoted by tv .
If validations are periodic, the time interval between two successive validation events is termed the validation interval, or IV .
The validator compares the hash value it computes over the data with the hash value that was previously notarized.
Tampering is indicated by a validation failure, in which the digital notarization service returns false for the particular query of a hash value and a notarization time.
What is desired is a validation success, in which the notarization service returns true, stating that everything is OK: the data has not been tampered.
A notarization event (or NE) is the notarization of a document (specifically, a hash value) by the notarization service.
As with validation, notarization can be scheduled (is periodic) or can be ad hoc.
Each NE has an associated notarization time (tn ), which is a time instant.
If notarizations are periodic, the time interval between two successive notarization events is termed the notarization interval, or IN .
The validation interval should be equal to or longer than the notarization interval, should be an integer multiple of the notarization interval, and should also be aligned with it, that is, validation should occur immediately after notariza-  tc  Transaction Processing  DBMS state (Legal)  Tampering  Figure 2.  tFVF  DBMS state (Illegal)  Validation  Tamper Detection  Forensic Analysis Algorithm  Corruption Region(s)  Tampering, Detection, and Forensic Analysis.
tion.
This is because one can only validate what one has previously notarized.
Having non-aligned notarization and validation intervals can only delay tamper detection.
Thus we speak of the validation factor V such that IV = V * IN .
As long as this constraint is respected, it is possible to change V , or both IV and IN , as desired.
This, however, will affect the size of the corruption region as emphasized in Section VI.
There are several variables associated with each corruption event.
The first is the data that has been corrupted, which we term the corruption locus data (lc ).
Forensic analysis, as discussed in Section VI, involves temporal detection : the determination of the corruption time, tc .
Forensic analysis also involves spatial detection, the determination of "where," that is, the location in the database of the data altered in a CE.
(Note that the use of the adjective "spatial" does not refer to a spatial database, but rather where in the database the corruption occurred.)
Interestingly, even the corruption locus is specified in terms of time.
Recall that each transaction is hashed.
Therefore, in the absence of other information, such as a previous dump (copy) of the database, the best a forensic analysis can do is to identify the particular transaction that stored the data that was corrupted.
Instead of trying to ascertain the corruption locus data (lc ), we will instead be concerned with the locus time (tl ), the time instant the data was originally stored.
The locus time specifically refers to the time instant when the transaction storing the corruption locus data commits.
(Here we are referring to the specific version of the data that was corrupted.
This version might be the original version inserted by the transaction, or a subsequent version created through an update operation.)
A CE can have many lc 's (and hence, many tl 's) associated with it.
Such a CE is termed multi-locus: an intruder (hardware failure, etc.)
might alter many tuples.
A CE having only one lc (such as due to an intruder hoping to remain undetected by making a single, very particular change) is termed a single-locus CE.
Now we can formally define what a corruption event is.
Definition 1.
A corruption event is a two-tuple (Tl , tc ).
The set Tl = {tl1 , tl2 , .
.
.
, tln } is the set of all locus times associated with a particular corruption event.
Each (tli , tc ) [?]
T2 , where T is a time domain.
We define Rs as the finest interval chosen to express the uncertainty of the spatial bounds of a CE.
Rs is called the spatial detection resolution.
This is chosen by the database administrator (DBA).
Similarly, the finest interval chosen by  the DBA to express the uncertainty of the temporal bounds of a CE is the temporal detection resolution, or Rt .
Several others works have studied tamper detection in databases.
An example of a WORM-based, long-term highintegrity retention technique for fine granularity business records is the transaction log on WORM (TLOW) approach for supporting long-term immutability of relational tuples [12].
TLOW stores the current database instance in ordinary storage and the transaction log on Write-Once-ReadMany (WORM) storage, while dispensing with a compliance log altogether.
The audit process uses hash values representing the data rather than the data themselves.
An audit is successful if the hash from the old database snapshot plus the hash of all the new tuples introduced in the transaction log match the hash of the current database instance.
Thus within this tamper detection framework the same notions of corruption event, auditing/validation interval, and time of first validation failure can be defined.
Another time-related concept, the query verification interval, is specific to TLOW.
Guo, Jajodia, Li, and Liu formulated a fragile watermarking scheme for database tamper detection [13], [14].
Their scheme is based on a watermark that is invisible (watermark does not distort data) and can be blindly verified (original unmarked relation is not required for verification).
During verification, the extracted watermark indicates the locations of alterations.
This approach does not utilize a temporal definition of tampering.
V. T HE C ORRUPTION D IAGRAM To explain forensic analysis within the context of our approach, we introduce the Corruption Diagram, which is a graphical representation of CE(s) in terms of the temporalspatial dimensions of a database.
Figure 3 illustrates a simple corruption event.
While this figure may appear to be complex, the reader will find that it succinctly captures all the important information regarding what is stored in the database, what is notarized, and what can be determined by the Monochromatic Forensic Analysis Algorithm--the simplest of the algorithms we have proposed--about the corruption event.
This corruption diagram shares some aspects with commonly-encountered bitemporal diagrams [15].
In a bitemporal diagram, the axes are transaction time and valid time, with rectangular polygons indicating the bitemporal extent of facts.
As we will see, the corruption diagram conveys very different information, while having the surface similarity of being a two-dimensional depiction, with time as both dimensions.
First we give the definition of a corruption diagram before describing it in detail.
Definition 2.
Let T be a time domain.
A corruption diagram is a plot in T2 having its ordinate associated with wallclock time and its abscissa associated with a partition of the database according to transaction time.
This diagram  t FVF = UTB 24 tc  First Validation Failure (FVF) VE NE124  .
CE 22  NE11 NE10  LTB 18  VE3 NE 9 NE8 NE7 VE2 NE6  When NE5  IV = 6 = 3 .
IN Rt = 6  NE4 VE NE3 1 NE2 IN = 2 Rs = 2  NE1 NE0  tRVS = LSB  Where  16 USB tl  t FVF  Figure 3.
Corruption diagram for a data-only single-locus retroactive corruption event.
depicts corruption events and is annotated with hash chains and relevant notarization and validation events.
At the end of forensic analysis, this diagram can be used to visualize the regions ([?]
T2 ) where corruption has occurred.
Let us first consider the simplest case.
During validation, we have detected a corruption event.
Though we don't know it (yet), assume that this corruption event is a single-locus CE.
Furthermore, assume that the CE just altered the data of a tuple; no timestamps were changed.
The x-axis represents when the data are stored in the database.
The database was created at time 0, and is modified by transactions whose commit time is monotonically increasing along the x-axis.
(In temporal database terminology [7], the x-axis represents the transaction time of the data.)
In the corruption diagram, time moves inexorably to the right.
The x-axis is labeled "Where."
The database grows monotonically as tuples are appended (recall that the database is append-only).
As previously explained, we designate "where" a tuple or attribute is in the database by the time of the transaction that inserted that tuple or attribute.
We delimit the days by marking each midnight, or, more accurately, the time of the last transaction to commit before midnight.
A 45-degree line is shown and is termed the action line, as all the action in the database occurs on this line.
The line terminates at the point labeled "FVF," which is the validation event at which we first became aware of tampering.
The time of first validation failure (or tFVF ) is the time at which the corruption is first detected.
(Hence the name: a corruption diagram always terminates at the VE that detected the corruption event.)
Note that tFVF is an instance of a tv , in that tFVF is a specific instance of the time of a validation event.
Also note that in every corruption diagram,  tFVF coincides with the current time.
For example, in Figure 3 the VE associated with tFVF occurs on the action line, at its terminus, and turns out to be the fourth such validation event, VE4 .
The actual corruption event is shown as a point labeled "CE," which always resides above or on the action line, and below the last VE.
If we project this point onto the x-axis, we learn "where" (in terms of the corruption locus time, tl ) the corruption event occurred.
The y-axis represents the temporal dimension (actual time-line) of the database, labeled in time instants.
Any point on the action line thus indicates a transaction committing at a particular transaction time (a coordinate on the x-axis) that happened at a clock time (the same coordinate on the y-axis).
For this reason, the two times are totally correlated and the action line is always a 45-degree line.
Projecting the CE onto the y-axis tells us when in clock time the corruption occurred, that is, the corruption time, tc .
We label the y-axis with "When."
The diagram shows that the corruption occurred on day 22 and corrupted an attribute of a tuple stored by a transaction that committed on day 16.
Notarization event NE1 hashes the transactions occurring during the first two days (here, the notarization interval, IN , is two days), linking these hash values together using linked hashing [3].
This is illustrated with the upward-rightpointing arrow with the solid black arrowhead originating at NE0 (since the linking starts with the hash value notarized by NE0 ) and terminating at NE1 .
Each transaction at commit time is hashed; here the "where" (transaction time) and "when" (wall-clock time) are synchronized; hence, hashing occurs on the diagonal.
The hash value of the transaction is linked to the previous transaction, generating a linked sequence of transactions that is associated with a hash value notarized at midnight of the second day in wall-clock time and covering all the transactions up to the last one committed before midnight (hence, NE1 resides on the action line).
NE1 sends the resulting hash value to the notarization service.
Also along the action line are points denoted with "VE."
These are validation events for which a validation occurred.
During VE1 , which occurs at midnight on the sixth day (here, the validation interval, IV , is six days), rehashes all the data in the database in transaction commit order, denoted by the long right-pointing arrow with a white arrowhead, producing a linked hash value.
In fact, the diagram shows that VE1 , VE2 , and VE3 were successful (each scanning a successively larger portion of the database, the portion that existed at the time of validation).
The diagram also shows that VE4 , immediately after NE12 , failed, as it is marked as FVF; its time tFVF is shown on both axes.
In summary, we now know that at each of the VEs up to but not including FVF succeeded.
When the validator scanned the database as of that time (tv for that VE), the hash value matched that notarized by the VE.
Then, at the last VE, the FVF, the hash value didn't match.
The corruption  event, CE, occurred before midnight of the 24th day, and corrupted some data stored sometime during those twenty four days.
VI.
F ORENSIC A NALYSIS Once the corruption has been detected, a forensic analysis algorithm, like the Monochromatic Algorithm, springs into action.
The task of this algorithm as shown in Figure 2, is to ascertain, as accurately as possible, the corruption region: the bounds on "where" and "when" of the corruption.
On validation failure we know that the corruption must lie in the upper-left triangle, delimited by the When and action axes, denoting that the corruption event occurred before tFVF and altered data stored before tFVF .
The most recent VE before FVF is VE3 and it was successful.
This implies that the corruption event has occurred in this time period.
Thus tc is somewhere within the last IV , which always bounds the "when" of the CE.
To bound the "where," the Monochromatic Algorithm can validate prior portions of the database, at times that were earlier notarized.
Revisiting and revalidating the cumulative hash chains at past notarization events will yield a sequence of validation results that start out to be true and then at some point switch to false (TT.
.
.TF.
.
.FF).
This single switch from true to false is a consequence of the cumulative nature of the total hash chain.
We term the time of the last NE whose revalidation yielded a true result (before the sequence of false results starts) the time of most recent validation success (tRVS ).
This tRVS helps bound the "where" of the CE because the corrupted tuple belongs to a transaction which committed between tRVS and the next time the database was notarized (whose validation now evaluates to false).
tRVS is marked on the Where axis of the corruption diagram in Figure 3.
Definition 3.
In light of the above observations, we define the four bounds of a CE.
* * * *  the lower temporal bound: LTB := max(tFVF -IV , tRVS ), the upper temporal bound: UTB := tFVF , the lower spatial bound: LSB := tRVS , and the upper spatial bound: USB := tRVS + IN .
These bounds define a corruption region, indicated in Figure 3 as a narrow rectangle, within which the CE must lie.
This example shows that, when utilizing the Monochromatic Algorithm, the notarization interval, here IN = 2 days, bounds the "where," and the validation interval, here IV = 6 days, bounds the "when."
Hence for this algorithm, Rs = IN and Rt = IV .
(More precisely, Rt = UTB - LTB = min(IV , tFVF - tRVS ) due to the fact that Rt can be smaller than IV for late-breaking corruption events, such as that illustrated in Figure 5.)
First Validation Failure (FVF) VE NE124  t FVF = UTB 24  When  .
.
CE postdating  tc 22  IV  NE11  t FVF = UTB 24  When  backdating  NE12 VE4 (FVF)  .
tc 22  CE IV  LTB  NE10  NE10 LTB 18  V =3 N=1 RS = 2  VE NE9 3 IN  Where  Figure 4.
18 IN NE8  22 USB t FVF tl  Postdating and backdating corruption events.
Other forensic analysis algorithms we have proposed make use of partial hash chains in addition to the total chain.
These partial chains are computed and notarized during the re-hashing and validation of the total chain.
The partial chains hash only parts of the data in the database and in certain cases are not cumulative.
Their "placement," i.e., the parts of the database they collectively cover, creates a structure over the database that allows the forensic algorithm to prune the search space efficiently and thus correctly locate multiple CEs very quickly.
It also allows the decoupling of the spatial detection resolution (Rs ) and IN .
In fact, the value of Rs can be set by the DBA to be much smaller that the value of IN .
VII.
C HARACTERIZATION OF C ORRUPTION T YPES The CE shown in Figure 3 is termed a retroactive corruption event: a CE with locus time tl appearing before the next to last validation event.
As we will see in this section, this is but one of several corruption types, characterized by various temporal relationships.
A. Data-Only Corruptions Figure 5 illustrates an introactive corruption event: a CE with a locus time tl appearing after the next to last validation event.
In this figure, the corruption event occurred on day 22, as before, but altered data on day 22 (rather than day 16 as in the diagram of Figure 3).
NE10 is the most recent validation success.
Here the corruption region is a trapezoid rather than a rectangle.
This shape is implied by the definition of LTB.
Both retroactive and introactive corruptions are types of data-only corruption events.
B. Timestamp Corruptions Data-only corruption events do not change any timestamps in the tuples.
However, there are two other kinds of corruption events that arise from timestamp corruption.
In a backdating corruption event, a timestamp is changed to indicate a previous time/date with respect to the original time in the tuple.
We term the time a timestamp was backdated to the backdating time, or tb .
It is always the case that tb < tl .
Similarly, a postdating corruption event changes a timestamp to indicate a future time/date with respect to the original commit time in the tuple, with the postdating  V =3 N=1 RS = 2  VE NE9 3  NE8 tRVS = LSB  Imax_tran NE11  tRVS = LSB  Where  22 USB t FVF tl  Figure 5.
Corruption diagram with introactive data-only CE and envelope.
time (tp ) being the time a timestamp was postdated to.
It is always the case that tl < tp .
Both types of timestamp corruption are illustrated in Figure 4.
Observe that timestamp corruption produces two corruption regions since changing a timestamp effectively changes the order in which the tuple is hashed into the total chain.
Combined with the previously introduced distinction of retroactive and introactive, these considerations induce six specific corruption event types.
(  Retroactive Introactive  )    Data-only       Backdating x     Postdating    For backdating corruption events, we ask that the forensic analysis determine, to the extent possible, "when" (tc ), "where" (tl ), and "to where" (tb ).
Similarly, for postdating corruption events, we want to determine tc , tl , and tp .
This is quite challenging given the only information we have, which is a single bit for each query on the notarization service.
We have proposed a taxonomy of many other corruption types along with a forensic analysis protocol on how to identify each type (vid.
http://www.cs.arizona.edu/projects/ tau/dragoon/taxonomy protocol.pdf).
Please note that the monitored database need not support valid time for forensic analysis to work but if it is a bitemporal database then more complex corruptions involving valid-time timestamps can arise, not yet considered in the taxonomy.
VIII.
V ERY R ECENT C ORRUPTIONS Corruption events that occur very recently present a challenge to forensic analysis.
The problem arises from the assertion that a CE cannot occur below the 45-degree line.
The argument is that it is impossible for tc < tl to occur, because that would imply that the data are corrupted before they are added to the database.
This argument holds generally, but there does exist an exception, where the CE can be below the action axis: when the CE corrupts data of a currently executing transaction.
Since a single transaction takes a finite non-zero amount of time, there is a window of opportunity between when the transaction starts and when it commits during which a corruption can occur.
In such a case we will have tc < tl and the CE will be below the 45-degree line.
Fortunately, the existence of such corruptions does not invalidate any of our previous analysis.
Only the "at-thetime-current" transactions in the most recent validation interval are susceptible to this threat.
Hence, the first change to be made is to draw a straight-line "envelope" parallel to the 45-degree action axis, whose horizontal distance from the action axis represents the maximum duration of any single transaction, denoted by Imax tran .
In this way the corruption region is augmented with a narrow slice, as shown in Figure 5, to account for this possibility.
This window of opportunity for each transaction varies since it depends on the duration of the transactions and that is the reason Imax tran was chosen as the width of the "envelope."
The only case where this will affect the result of the forensic analysis is when the CE is an introactive CE: only then can it approach and move past the 45-degree line.
Thus, in such a case the upper bound on tl will be increased by Imax tran .
Note also that this weakness has a tradeoff: an introactive CE puts a tighter lower bound on tc , meaning it is easier to find the actual time of corruption.
Observe that in Figure 5 the LTB does not coincide with VE3 but is instead raised from day 18 to day 21.
A different approach to solving the above problem is to introduce the notion of a regret interval [16].
This is a minimal time interval, IR , before any adversary can reverse the change they have made.
For example, in current legal interpretations of email compliance according to SarbanesOxley [17], this time interval is zero.
However, when monitoring bioscience lab results, we may be able to assume that after a new record is added, a week will pass--given that certain protocols require several days to complete--before any adversary is likely to "regret" its existence.
The true size of the regret interval is intrinsic to the semantics and social use of the application.
Note that the DBA has no control over it.
Furthermore, the DBA may not be able to determine its size with absolute certainty.
However, the DBA can estimate it with a (possibly) tight lower bound.
We call this the regret interval estimate and * * denote it by IR .
Observe that IR <= IR .
The existence of a nonzero regret interval estimate can be leveraged to increase throughput.
However, in order not to compromise the correctness of tamper detection and subsequent forensic analysis the DBA must ensure that notarization of hash values happens at time intervals which are smaller than the estimated regret interval.
This forces all tamperings to transpire after a notarization, something that * ensures tamper detection.
Thus we have IN < IR <= IR .
Moreover, validation events have to occur after notarizations (one cannot validate a hash value that has not already been notarized).
If we set the validation interval to be smaller than the estimated regret interval then we have * IN <= IV < IR <= IR and this enforces the absence of introactive corruption events.
IX.
S HREDDING AND L ITIGATION H OLDS Transaction-time semantics allow us to keep the history of the entire database.
This in turn enables the constant monitoring of the database state in order to detect any deviation.
Keeping the totality of data that were ever stored in the database causes complications.
First it has an adverse effect on performance since all the data have to be rehashed during validation.
The ever-increasing cost of notarizing and validating the data will at some point become prohibitive.
Moreover, companies are not wont to keep legacy data for long periods of time since such a practice poses a privacy and liability threat.
In general, old data are periodically deleted while newer data must be kept for a specific retention period according to regulations and company policy.
Therefore, a sliding time frame, the length IRP of the retention period, exists whereby records continuously become old enough to fall outside that window as time progresses.
Such records are deemed safe for physical deletion (shredding).
Shredding itself occurs at time ts , at any time after the record exits the time frame now - IRP .
This is a serious issue because shredding breaks transaction-time semantics that requires that the monitored database is append-only.
To complicate the situation even further litigation holds can be issued on the data for a duration of time, ILH , specified by courts of law.
Such a hold overrides any retention period regulations and so none of the data can be subject to shredding until the hold is lifted.
Thus it can be said that litigation holds restore transaction-time semantics.
Similar concepts have been described extensively elsewhere [18].
X. E NTERPRISE C ONSIDERATIONS Companies typically have many databases, a number of which are susceptible to tampering and thus fall under the purview of database information accountability.
It is useful for the company's Chief Security Officer (CSO) to set general corporate policies on acceptable values for those parameters in Table II.
So for example the CSO could dictate that the validation interval IV be no longer than 2 days and that the spatial detection resolution Rs be no longer than one hour, applicable to all databases being monitored.
The database administrator could then indicate, for a particular database or perhaps even particular tables, the specific values for the spatial detection resolution Rs and the regret interval * estimate IR .
These values would subsequently dictate other values, such as IN and IV .
As the values are related in ways summarized in previous sections, the CSO and the DBA both have flexibility in what to specify.
Note that it is important to record these various enterprisewide and database-specific settings.
These settings have a profound influence on the quality of the forensic analysis, and a cost model has been developed which incorporates these settings, in order to assess the forensic cost associated with each algorithm.
The effect of the settings on the forensic cost has been experimentally studied and verified [5].
Because of their importance, all settings are stored in a separate enterprise security database, itself a transactiontime database (with some bitemporal portions), located in the trusted computing base.
We need to know when each setting was specified.
Time again makes its presence known.
XI.
S UMMARY AND F UTURE W ORK As demonstrated throughout this paper, time arises in many guises: in the definition of tampering, the data that is tampered, the kinds of corruptions that can occur, the detection of tampering, the forensic analysis of tampering, and the "when" and even the "where" of the tampering determined by that analysis.
Table II lists a full two dozen of the time instants and intervals involved throughout the definition and mechanism of database information accountability.
It would be interesting to see how defining tampering in terms of pattern recognition of complex events [19] can affect detection.
Our intuition tells us that it would allow detection of tampering at a semantic level wherein modifications to the database issued through the DBMS can be identified as illegal.
In general, there is something truly fundamental going on, of which we are now seeing just the surface structure.
Determining that deep structure is our challenge to this community.
ACKNOWLEDGEMENT We gratefully acknowledge support from NSF grants IIS-0415101, IIS-0803229, IIS-0639106, and EIA-0080123.
Grants from Microsoft Corporation and from Surety, LLC also provided partial support for this work.
R EFERENCES [1] D. J. Weitzner, H. Abelson, T. Berners-Lee, J. Feigenbaum, J. Hendler, and G. J. Sussman, "Information Accountability," Communications of the ACM (CACM), vol.
51, no.
6, pp.
82-87, June 2008.
[2] M. Alles, A. Kogan, and M. Vasarhelyi, "Black Box Logging and Tertiary Monitoring of Continuous Assurance Systems," Information Systems Control Journal, vol.
1, 2003.
[3] R. T. Snodgrass, S. S. Yao, and C. Collberg, "Tamper Detection in Audit Logs," in Proceedings of the International Conference on Very Large Databases, September 2004, pp.
504-515.
[4] K. E. Pavlou and R. T. Snodgrass, "Forensic Analysis of Database Tampering," in Proceedings of the ACM SIGMOD International Conference on Management of Data, June 2006, pp.
109-120.
[5] ----, "Forensic Analysis of Database Tampering," ACM Transactions on Database Systems, vol.
33, no.
4, pp.
30:1- 30:47, November 2008.
[6] ----, "The Tiled Bitmap Forensic Analysis Algorithm," IEEE Transactions on Knowledge and Data Engineering, vol.
22, no.
4, pp.
590-601, April 2010.
[7] C. S. Jensen and C. E. Dyreson (eds), "A consensus glossary of temporal database concepts--February 1998 Version," in Temporal Databases: Research and Practice, O. Etzion, S. Jajodia, and S. Sripada, Eds.
Springer-Verlag, 1998, pp.
367- 405.
[8] Oracle Corp. (2008, Aug.) Workspace Manager Developer's Guide 11g Release 1 (11.1).
[Online].
Available: http://www.oracle.com/pls/db111/to pdf?
pathname=appdev.111/b28396.pdf [9] Teradata Corp. (2010, Oct.) Teradata Temporal.
[Online].
Available: http://www.teradata.com/database/ teradata-temporal/ [10] IBM Corp. (2010, Dec.) A Matter of Time: Temporal Data Management in DB2 for z/OS.
[Online].
Available: http://www14.software.ibm.com/webapp/iwm/ web/signup.do?lang=en US&source=sw-infomgt&S PKG= db2z-temporal-tables-wp [11] J. Bair, M. Bohlen, C. S. Jensen, and R. T. Snodgrass, "Notions of upward compatibility of temporal query languages," Business Informatics (Wirtschafts Informatik), vol.
39, no.
1, pp.
25-34, 1997.
[12] R. Hasan and M. Winslett, "Efficient Audit-based Compliance for Relational Data Retention," in Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security, ser.
ASIACCS '11.
New York, NY, USA: ACM, 2011, pp.
238-248.
[13] H. Guo, Y. Li, A. Liu, and S. Jajodia, "A fragile watermarking scheme for detecting malicious modifications of database relations," Inf.
Sci., vol.
176, no.
10, pp.
1350-1378, 2006.
[14] Y. Li, H. Guo, and S. Jajodia, "Tamper Detection and Localization for Categorical Data Using Fragile Watermarks," in Proceedings of the 4th ACM Workshop on Digital Rights Management, 2004, pp.
73-82.
[15] C. S. Jensen, M. D. Soo, and R. T. Snodgrass, "Unification of Temporal Data Models," in International Conference on Data Engineering, April 1993, pp.
262-271.
[16] S. Mitra, W. W. Hsu, and M. Winslett, "Trustworthy Keyword Search for Regulatory-Compliant Record Retention," in Proceedings of the International Conference on Very Large Databases, 2006, pp.
1001-1012.
[17] Sarbanes-Oxley Act, U.S. Public Law No.
107-204, 116 Stat.
745., "The Public Company Accounting Reform and Investor Protection Act," 2002.
[18] R. Hasan and M. Winslett, "Trustworthy Vacuuming and Litigation Holds in Long-term High-integrity Records Retention," in Proceedings of the 13th International Conference on Extending Database Technology, 2010, pp.
621-632.
[19] D. C. Luckham, The Power of Events: An Introduction to Complex Event Processing in Distributed Enterprise Systems.
Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc., 2001.
A language to express time intervals and repetition Diana Cukierman and James Delgrande School of Computing Science Simon Fraser University Burnaby, BC, Canada V5A 1S6 fdiana,jimg@cs.sfu.ca  Abstract  We are investigating a formal representation of time units, calendars, and time unit instances as restricted temporal entities for reasoning about repeated activities.
We examine characteristics of time units, and provide a categorization of the hierarchical relations among them.
Hence we dene an abstract hierarchical unit structure (a calendar structure) that expresses specic relations and properties among the units that compose it.
Specic time objects in the time line are represented based on this formalism, including non-convex intervals corresponding to repeated activities.
A goal of this research is to be able to represent and reason eciently about repeated activities.
1 Introduction  The motivation for this work is to ultimately be able to reason about schedulable, repeated activities, specied using calendars.
Examples of such activities include going to a specic class every Tuesday and Thursday during a semester, attending a seminar every rst day of a month, and going to tness classes every other day.
Dening a precise representation and developing or adapting known ecient algorithms to this domain would provide a valuable framework for scheduling systems, nancial systems, process control systems and in general date-based systems.
We search for a more general, and formalized representation of the temporal entities than in previous work.
We explore further the date concept, building a structure that formalizes dates in calendars.
Schedulable activities are based on conventional systems called calendars.
We use as a departure point \calendar" in the usual sense of the word.
Examples of calendars include the traditional Gregorian calendar, university calendars, and business calendars, the last two groups being dened in terms of the Gregorian.
The framework we dene concerns a generic calendar abstract structure, which subsumes the mentioned calendars, and arguably any system of measures based on discrete units.
Calendars can be considered as repetitive, cyclic temporal objects.
We dene an abstract structure that formalizes calendars as being composed of time units, which are related by a  decomposition relation.
The decomposition relation is  a containment relation involving repetition and other specic characteristics.
Time units decompose into contiguous sequences of other time units in various ways.
A calendar structure is a hierarchical structure based on the decomposition of time units.
This structure expresses relationships that hold between time units in several calendars.
We refer to the concept of time unit instances, and distinguish dierent levels of instantiation.
Whereas \month" refers to a time unit class, \June" is referred to as a named time unit.
June is one of the 12 occurrences of the notion of month with respect to year, and viewed extensionally it represents the set of all possible occurrences of June.
Finally, \June 1994" is one specic instance of a month.
2 Related work  Our formalism deals with time units, which are a special kind of time interval with inherent durations.
Therefore we base our work on time intervals as the basic temporal objects 1].
In 21], the time point algebra is developed, based on the notion of time point in place of interval.
Computation of the closure of pairwise time-interval relations in the full interval algebra is NP-complete, whereas the time point algebra has a polynomial closure algorithm.
However the time point algebra is less expressive than the interval algebra: certain disjunctive combinations of relations are not expressible with the time point algebra.
Nonetheless, some applications do not require the full expressive power of the interval algebra, and can benet from ecient (albeit less expressive) representations.
Hence it is of interest to study restrictions of the interval algebra.
The present framework deals with restricted kinds of intervals within a hierarchical structure.
The intent is that the hierarchy provide a basis for obtaining ecient algorithms for certain operations.
(This may be contrasted with 11] which considers a hierarchical structure in the general interval algebra.)
Nonconvex intervals (intervals with \gaps") are employed in 12, 13] when using time units in a repetitive way or when referring to recurring periods.
The time unit hierarchy proposed in our work generalizes 13], in that temporal objects can be represented by any se-  quence of composed time units, as opposed to xed in Ladkin's approach.
Moreover, we are able to combine systems of measurement, and so talk about the third month of a company's business year as corresponding with June in the Gregorian calendar.
13] also does not take into account the varying duration of specic time instances, a matter addressed and formalized in our work.
In addition we address the varying duration of specic time instances.
18] also elaborate on the notions of non-convex interval relations dened in 12, 13] while 16] proposes a generalization of nonconvex intervals.
Leban et.
al.
15] deals with repetition and time units.
This work relies on sequences of consecutive intervals combined into \collections".
The collection representation makes use of \primitive collections" (essentially circular lists of integers), and two basic operators, slicing and dicing, which subdivide an interval and select a subinterval respectively.
Poessio and Brachman 19] are mainly concerned with the implementation of algorithms to detect overlapping repeated activities.
This work relies on temporal constraint satisfaction results and algorithms 8].
19] also introduces the concept of using dates as reference intervals to make constraint propagation further ecient.
We envision our proposed formalism provides a useful framework to follow this idea.
5] exposes a set theoretic structure for the time domain with a calendar perspective.
It formalizes the temporal domain with sets of \constructed intervallic partitions" which have a certain parallel to our decomposition into contiguous sequences of intervals.
However, this formalization is more restricted than ours and can not handle the Gregorian nor general calendars.
3] and 4] propose formalizations that deal with calendars and time units.
These two papers are interestingly related to our research, even though they have evolved independently.
These works are analyzed and compared with our research in the Section 5.
3 Time units and time unit instances  The central element of our formalism is that of a time unit.
Time units represent classes of time intervals, each with certain commonalties and which interact in a limited number of ways.
For example, year and month are time units.
Something common to every year is that it decomposes into a constant number of months.
A characteristic of month is that it decomposes into a non-constant number of days, which vary according to the instance of the month.
Properties that are common to time units determine the time unit class attributes.
In 6, 7], the identier of a time unit class and the (general) duration are presented.
Relative and general durations are compared and the concept of an atomic time unit is introduced.
Time unit instances and their numbering and naming is described as well.
All attributes are formally dened in a functional way.
We here  present a summary of these concepts with examples from the Gregorian calendar.
Identier of a time unit The rst attribute of the time unit class is a unique identier, a time unit name, for example year or month.
We distinguish time unit names when the time units have the same duration but dier in their origin.
For example, years in the Gregorian calendar start in January, but academic years, in university calendars in the northern hemisphere, start in September.
Year and academic year are two dierent time units, which have several properties in common.
Duration Time units inherently involve durations a time unit expressly represents a standard adopted to measure periods of time.
Dierent time unit instances of the same time unit class can have dierent durations.
For example dierent months have different number of days, from 28 to 31.
Accordingly, the attribute representing a duration of a class is a range of possible values.
We represent this range by a pair of integers, the extremes of the range of possible lengths any time unit instance can have.
Thus, month as a class has a duration of (28 31).
A duration referred to as general will be expressed in a basic unit, common to all the time units in one calendar.
For example, using day as a common or basic unit, month has a (general) duration of (28 31) days.
A specic month, for example, February 1994, has a duration of 28 days.
We also dene another kind of duration a duration relative to another time unit.
An important reason why (general) durations of all time units in a calendar are dened based on the same basic measure unit is to be able to compare them.
This notion plays a fundamental role in the partial order among time units in the same calendar or variants of a calendar.
Time units decompose into smaller units up to a nite level at which a time unit is atomic | a non-divisible interval.
When the time interval is non-decomposable it is called a time moment, following 2].
Time units therefore model time in a discrete fashion.
Time units may be considered atomic in one application and decomposable into smaller time units in other applications, depending on the intended granularity for the application 10].
Instance names and numbers The name or number of a time unit instance can be expressed in several ways.
Similar to durations, the name is relative to another time unit, a reference time unit.
For example, a day instance can be named from Sunday to Saturday or numbered 1 to 7 if week is the reference time unit of day.
(Names can be thought of as synonyms for the numbers).
Instances of time units which do not have any reference time unit are numbered relative to a conventional reference point or zero point of the calendar, for example the Christian Era for the Gregorian calendar.
The ordered set of all the possible names the instances of a time unit can take within a reference can be expressed extensionally, by a sequence of names (if there are names associated to the time unit class), or a pair of numbers representing the range of maximum possible instance numbers of a class.
This sequence (or pair of numbers) is an attribute of the time unit class.
A particular instance name or number of a time unit within a reference reects the relative position of the instance within the reference, given a certain origin where counting of instance values starts.
For example, months are counted from 1 to 12, in a year in the Gregorian calendar, starting from 1.
But, in the case of months counted within an academic year, the origin of numbering is not month number 1, but rather the 9th (or September), so the 3rd month of a academic year is the 11th month of all the possible months name sequence (or November).
Circular counting is assumed.
More detail appears in 6].
3.1 Decomposition of time units  The primary relation among time units is that of decomposition.
When A decomposes into B, A will be referred to as the composed time unit, and B will be referred to as the component unit.
For example, a year decomposes into months and a month into days.
Also a month decomposes into weeks, a week into days, etc.
Clearly there are dierent kinds of decompositions: a year decomposes exactly into 12 months, whereas a month decomposes in a non-exact way into weeks, since the extreme weeks of the month may be complete or incomplete weeks.
We propose that all these variations in the decomposition relation can be captured with two dierent aspects of the relation: alignment and constancy.
A time unit may decompose into another in an aligned or non-aligned fashion.
The decomposition is aligned just when the composed time unit starts exactly with the rst component and nishes exactly with the last component.
Consequently, a certain number of complete components t exactly into the composed time unit.
Examples of aligned decompositions include year into months, month into days, and week into day.
Examples of non-aligned decompositions include year into weeks and month into weeks.
Figure 1 shows a graphical picture of aligned and non-aligned decomposition.
A (a) Bx  By A  A  A (b)  Bx  By  Bx  By  Bx  By  Figure 1: Graphical representation of Alignment A time unit may decompose into another in a constant or non-constant fashion.
The decomposition is constant when the component time unit is repeated  a constant number of times for every time unit instance.
Examples of constant decompositions include year into months and week into days.
Examples of non-constant decompositions include month into days and year into days.
There are four possible combinations resulting from these two aspects of alignment and constancy.
These combinations cover examples from the various calendars analyzed.
(Arguably) all the relationships of interest in such systems are covered by the variants resulting from combining alignment and constancy of decomposition.
We analyze the composition (or product), intersection (or sum) and inverse of decomposition relations.
For example, if two aligned decomposition relations are multiplied, the resulting decomposition relation is also aligned.
For example year decomposes into month, month decomposes into day.
These two (aligned) decomposition relations can be composed (or multiplied) to obtain the (aligned) decomposition relation of year into day.
It should be noticed that these three operations (composition, intersection and inverse) are dened among decomposition between time unit classes.
This is to be contrasted to the relational algebras dened in the literature and constraint propagation algorithms, which deal with relations between time intervals in the time line, i.e., at the instance level (for example 1, 18, 14].)
A detailed study of these operations appears in 6].
3.2 Calendar Structures: time unit hierarchies  A calendar structure is a pair: a set of time units and a decomposition relation.
We obtained the following result:  Theorem 1 (Decomposition) The decomposition  relation is a particular case of containment, and constitutes a partial order on the set of time units in a calendar.
Therefore, a calendar structure is dened as a containment time unit hierarchy.
The structure is dened so that variants of a specic calendar can be dened in terms of a basic one.
Such would be the case of a university or business calendar, based on the Gregorian calendar.
Such calendars have the same time units as the basic one, with possible new time units or a dierent conventional beginning point.
For example, many university calendars would have a semester time unit, where the academic year begins in September.
Since calendar structures are partial orders, they can be represented by a directed acyclic graph.
The set of nodes in a calendar structure represents the set of time units.
Edges represent the decomposition relation.
The intended application of use of the calendar structure determines which level of time units is included.
Chains We develop a categorization based on the  subrelations of decomposition, i.e.
considering only constant/aligned decompositions, or aligned only, or constant only.
Calendar substructures, composed of chains result from these subrelations.
The term \chains" appears in 17], however there chains are dened on time intervals on the time line.
In our case we are referring to chains of time unit classes.
Nonetheless, chains of time unit classes are directly related to expressions that represent time unit instances, and inuence greatly in eciency matters.
To give an example, the operation of converting time unit instances from one time unit to another will be more ecient when the time units intervening in the time unit instance expression decompose in a constant/aligned way divisions and multiplications can be done, whereas it is necessary to have some iterative process of additions or subtractions when the decomposition is not exact.
A chain is a consecutive linear sequence of time units, such that each one decomposes into any other in the chain in the same way.
Hence all time units in an aligned chain decompose in an aligned way, etc.
A calendar structure can be organized according to these chains.
There is a dierent subgraph associated to each type of decomposition.
For example, Figure 2 shows the Gregorian calendar structure characterized by two aligned chains: <28-centuries, 4-centuries, century, year, month, day, hour> and <28-centuries, week, day, hour>.
In this gure we can observe there are three common nodes to both chains: 28-centuries,day and hour.
28-Centuries 4-Centuries  Century  Year  Month  Week  Day  Hour  Figure 2: Aligned Gregorian calendar substructure We refer to the subgraph that results from organizing the calendar structures according to a certain type of chain as a calendar substructures of that particular type of decomposition (constant, aligned or constant/aligned).
Therefore a chain of a certain type is composed by all those time units in the hierarchy that form a path in the corresponding calendar substructure.
3.3 A language of the set of time units  We dene a language of time units based on the fact that calendar structures can be organized in constant/aligned, constant or aligned chains.
Together with the organization of calendar structures in chains, we distinguish special time units as primitive.
The set of primitive time units includes one time unit per chain in a minimal way.
Hence, in case that all chains have at least one common node, the primitive set is a singleton.
It was proved 6] that any calendar structure can be extended (i.e.
added time units) so that there is such unique common time unit to all chains, for any type of chain.
For example, if the Gregorian calendar is organized as in Figure 2, there are three minimal sets of primitive time units: fhourg, fdayg or f28-centuriesg.
The main idea of this language is that all time units in the structure can be recursively constructed starting from a set of primitive time units, decomposing or composing them, with decomposition limited to an aspect (for example only aligned).
The symbols that are used in this language are: A set of primitive time units, PRIM = fP P1 P2 : : :g, a set of special symbols, f = ( )g a set of (possibly innitely many) constants, CONS = fsecond minute hour :::g and a language to express durations, DUR = fd j d 2 N + g fi f(d1 d2) j + d1 d2 2 N and d1 < d2g.
The language is dened: 1.
If P 2 PRIM, then P 2 TUS.
2.
If C 2 CONS, then C 2 TUS.
3.
If T 2 TUS and D 2 DUR then (T  D) 2 TUS.
4.
If T 2 TUS and D 2 DUR then (T=D) 2 TUS.
5.
Those are all the possible elements of TUS.
Briey, T = (S  D) when T is composed of a contiguous sequence of D S's and T = (S=D) when D contiguous T's compose S. For example, if we organize the Gregorian calendar with aligned chains, the following is a possible interpretation of the language: PRIM = fdayg month = day  (28 31) year = day  (365 366) = month  12 hour = day=24 twoday = day  2 trimester = month  3: Generally we consider only one time unit as primitive.
It is convenient to include constants into the language.
We abuse notation in that we name constants, which are part of the alphabet of symbols, by the name of the domain elements.
Thus if  is an interpretation function,  : TUS  Calendar ;!
Time units in the calendar.
For example (month Gregorian) = \month", (month  3 University) = \trimester".
As long as it does not lead to ambiguities, we will not make an explicit use of this interpretation function in this paper.
Using the same strings for constants and domain elements appears elsewhere, for example 20].
3.3.1 Named time units  As discussed in previous sections, there is more than one level of time unit instantiation.
For exam-  ple, a subclass of month in the Gregorian calendar could be the fourth month (synonym of April).
This does not represent a specic month yet.
We call April a named-month, and viewed extensionally, it represents the set of all specic instances of the month \April".
A specic instance would be \April 1995".
To be able to express specic instances we dene calendar expressions in the next section.
Named time units are dependent on the time unit, a reference time unit and a position within the reference.
Names and numbers are functions dened on the sets of time units, and some involving instances as well.
We write name(T R X) to represent the Xth \named-T" within the reference time unit R, such that R decomposes into T .
If X is outside permissible values, or if the time unit has no associated names with that reference name(T R X) represents an inconsistent value (?).
Examples of this function include name(month year 3) = \March" name(month academic year 3) = \November" name(day week 8) = ?.
Numbered-time units are dened in an analogous way.
For example number(month year 3) = \3".
A function related to named and numbered time units is the last possible value.
Some cases, as already explained, will not provide a unique value, but a range of last values.
In those cases there exists a unique last value only at the instance level (and not at the class level).
For example, last name(month year) = \December" last number(day month) = (28 31) last number instance(day F ebruary 1994) = 28.
4 Calendar expressions  A goal of our research is to represent and reason with time unit instances, that is, the temporal counterpart of single or repeated activities occurring in the time line.
We want to express these time entities in terms of days, weeks, hours, etc, relative to certain conventional calendars.
Calendar structures above dened provide a formal apparatus of units on which to represent a date-based temporal counterpart of activities.
Intervals, time points and moments in the time line will be represented in terms of these units.
Specic time objects are expressed based on the time units in a calendar structure, via calendar expressions.
A basic calendar expression is dened by a conventional beginning reference point or zero point associated to the calendar, and a nite sequence of pairs: Z 	 (t1 x1) : : : (tn xn)].
Each pair (ti xi) contains a time unit ti from the calendar structure and a numeric expression xi.
Numeric expressions include numbers and variables ranging over the set of integers.
The pairs in the sequence are ordered so that any time unit in a pair decomposes into the time unit in the following pair in the sequence.
We also dene duration expressions.
These are similar to calendar expressions in that they consist of a list of pairs (time unit,value), but have no beginning refer-  ence point nor included variables.
The operation of adding a duration expression to a calendar expression denes a new calendar expression.
4.1 A language for simple and repetitive time unit instances: calendar expressions  The formal denition of the language of calendar expressions is presented next.
The language of duration expressions is not introduced here for space reasons, it follows a similar style as the calendar expressions language.
The decomposition relation is used in the denitions.
The same kind of decomposition used to dene the time units in the calendar structure (and therefore the time units language, TUS) is used in these languages.
The language of calendar expressions CALXS, uses the following: A conventional zero point, Z, a set of special symbols f	 ( )  ] \ fi = Lastg, a set of time units (TUS), a set of variables (VAR), which will be ranging in the set of positive naturals, a set of duration expressions(DURXS), and can be dened as: 1.
If T 2 TUS X 2 N + fi VAR then (Z 	 (T X)]) 2 CALXS.
2.
If T1 T2 2 TUS, such that T1 decomposes into T2 , X2 2 N + fi VAR fi fLastg and Z 	 CX (T1 X1)] 2 CALXS, then (Z 	 CX (T1 X1 ) (T2 X2 )]) 2 CALXS.
3.
If CX(*v ) 2 CALXS, where *v are the variables * * in CX, then (CX( v ) where Exp( v )) 2 CALXS Exp(*v ) is an expression constraining *v .
4.
If CX1 and CX2 2 CALXS then (CX1 fi CX2 ) (CX1 \ CX2 ) (CX1 =CX2) 2 CALXS.
5.
If CX 2 CALXS and DX 2 DURXS then (CX + DX) 2 CALXS.
6.
These are all the possible elements of CALXS.
4.2 Examples of calendar expressions  The following examples express calendar expressions in the Gregorian calendar.
The zero point is the beginning of the Christian Era (CE).
1.
CE 	 (year X) (month 4)].
The fourth month within any year.
(Viewed extensionally, it represents the set of all specic instances of the month \April").
X is a non-quantied variable.
2.
CE 	 (year 1994) (week 17) (day 5)].
The 5th day within the 17th week of the year 1994.
The last time unit in the sequence provides the precision of the time unit instance.
Thus, in Example 1 above, the precision is month.
It can also be observed that a calendar expression with no variables is a single convex interval a time unit instance of the last time unit in the calendar expression.
Consequently, Z 	(t1 x1) : : : (tn xn)] is a (single) tn-instance.
Example 2 above is a (single) day-instance.
A calendar expression with variables represents a  set of time unit instances.
These sets of intervals are  the temporal counterpart of a date-based repeated activity, a specic case of a non-convex interval, as dened in 12] .
Thus, CE 	 (year X) (day 175)] represents a non-convex interval, and the subintervals are the days numbered 175th.
As well, when there are variables in the calendar expression, these can be constrained with logic/mathematical expressions.
This example can be extended to: 3.
CE 	 (year Y ) (day 175)] where (Y > 1992 and Y < 1996).
The 175th day from the beginning of each year after 1992 and before 1996.
Hence starting and ending times of non-convex intervals can be expressed straightforwardly.
Another extension to the language of calendar expressions consists of applying set operations (union, intersection and dierence) to combine non-convex intervals, viewing non-convex intervals as sets of subintervals.
(limit cases could produce an empty set of intervals, which we consider a limit case of calendar expression).
The following illustrate this possibility: 4.
CE 	 (year 1994) (month 11) (day X)] \ CE 	 (year 1994) (week W) (day Tuesday)].
Tuesdays of November 1994.
5.
CE 	 (year 1994) (month 11) (day X)] = (CE 	 (year 1994) (month W) (day Y )] where (Y = 7 or Y = 1) ).
Days of November 1994 which are not Saturdays nor Sundays, i.e., weekdays of November 1994.
Saturday and Sunday are abbreviations of certain days numbers as numbered within week.
= represents set dierence.
Finally we also allow calendar expressions to be moved (or displaced) by adding a certain (convex) interval.
For example, October 1994 plus one month is November 1994.
We use duration expressions to express moved expressions.
For example: 6.
CE 	 (year 1994) (month 11) (day 5)] + (day 5)].
The 5th day of November is moved 5 days, resulting in the 10th day of November 1994.
7.
CE 	 (year 1994) (month X) (day 5)] + (day 5)] The 10th day of every month in 1994.
It is worth noticing that (month 1)] is a duration expression representing one month.
On the contrary, CE 	 (year Y ) (month 1)], stands for the non-convex interval of all January's.
Named time units are precluded as a valid duration.
The following examples show how to represent slightly more elaborated periodicity patterns.
8.
CE 	 (year 1994) (week  2 W ) (day 1)].
Every other Monday of 1994.
9.
CE 	 (year 1994) (month M) (day Last)].
Last day of every month.
\Last" is based on the last number function above presented.
Examples 1, 2 and 8 above are accounted by rules 1 and 2 of the language.
Rule 3 allows to have calendars with variables that are constrained, as in example 3.
Examples 4 and 5 are covered by rule 4.
Finally examples 6 and 7 correspond to rule 5.
4.3 Semantics of calendar expressions  A set-based semantics is proposed for these languages.
Interpretation of duration expressions and calendar expressions is based on an interpreted calendar structure.
Recall that we conventionally name constants in the language of the time units (TUS) as the elements in the domain, i.e.
as the time units in the calendar.
Therefore, for the sake of a more clear presentation we will omit the application of an interpretation function when referring to interpreted time units whenever this does not lead to ambiguities.
Examples will be made within the Gregorian calendar.
Hence the zero point Z will be interpreted as year zero of the Christian Era (CE).
A duration expression is interpreted as a convex interval in the time line.
Comparison, addition and subtraction of duration expressions are dened.
Addition and subtraction can be viewed as translations or displacements in the time line.
Limit cases, circular counting, dierence in precision, etc, are taken into account.
This is not presented in this paper.
Calendar expressions are interpreted as sets of intervals in the time line.
Let !
be a function interpreting calendar expressions.
(We omit here the specication of the calendar to simplify this presentation, and again will provide examples from the Gregorian Calendar), then !
: CALXS ;!
2time intervals.
1.
!
(Z 	 (T X)]) = a.
If X 2 N + , the singleton with the X th occurrence of the interval T starting from !(Z).
For example, !
(Z 	 (year 1995)]) = fyear 1995g.
b.
If X is a variable, Sthe set of time intervals T starting from !
(Z), i.e.
1 X =1 !
(Z 	 (T X)]).
For example, !
(Z +	 (year Y )]) = set with every year since CE = N .
2.
!
(Z 	 CX (T1 X1 ) (T2 X2 )]) = a.
If X2 2 N + , the set of X2th subintervals T2 within each interval in the set !
(Z 	 CX (T1 X1)]).
For example, !
(Z 	 (year Y ) (month April)]) = fApril 1, April 2, : : : g. b.
If X2 = Last, the set of Lth subintervals T2 within each interval in the set !
(Z 	 CX (T1 X1 )]), where L = last number(T2 T1) as dened in Section 3.3.1 above.
For example !
(Z 	 (year Y ) (month Last)]) = f December 1, December 2, : : : g. In case T1 decomposes into T2 in a non-constant way, L depends on X1 and possibly on CX.
For example !
(Z 	 (year 95) (month M) (day Last)]) = fJanuary 31 1995, February 28 1995, : : : g. c. If X is a variable, the set of all time intervals T2 within eachS interval in the set !
(Z 	 CX (T1 X1 )]), i.e.
LX =1 !
(Z 	 CX (T1 X1)]), where L = last number(T2 T1).
For example, !
(Z 	  (year 1995) (month M)]) = fJanuary 1995, February 1995, : : : , December 1995 g. 3.
!
(CX(*v ) where Exp(*v )) = S* * !
(CX(*v )).
v j Exp( v ) For example, !
(Z 	 (year 95) (month M)] where (M > 3 and M < 6) ) = fApril 1995, May 1995g.
4.
!
(CX1 fi CX2 ) = !
(CX1 ) fi !
(CX2 ) !
(CX1 \ CX2 ) = !
(CX1 ) \ !
(CX2 ) !
(CX1 =CX2 ) = !
(CX1 )=!
(CX2 ) See examples in Section 4.2 above.
5.
!
(CX = S T + DX) (DX ) (Interval) 8 Interval 2 !
(CX) Addition of a duration expression is interpreted as a translation (T) or displacement of all the subintervals denoted by the calendar expression, eventually a single one (!
(CX)), by a distance dened by the duration expression (!(DX)).
See examples in Section 4.2 above.
5 Alternative proposals dealing with calendars  3] by Chandra et.al.
present a language of \calendar expressions" to dene, manipulate and query what they call \calendars".
In terms of terminology used, their and our proposals coincidentally refer to \calendars" and \calendar expressions".
The notions however are of a dierent nature the two researches have evolved completely independently.
We refer to \calendar" in the usual sense, where the Gregorian calendar or a university calendar are possible examples.
On the other hand, their \calendars" are structured collections of intervals, as dened in 15].
The dierence between both \calendar expressions" is more subtle.
Both calendar expressions dene, in dierent ways, lists of points and intervals in the time line.
However, our expressions are of a more declarative nature, whereas their expressions are closer to a procedure to obtain such intervals.
For example, we express the collection of Fridays as: CE 	 (year Y ) (week W ) (day 5)].
The calendar expressions in 3] are meant as a way of creating and manipulating their \calendars" (i.e., collections of intervals).
5]/DAYS:during:WEEKS expresses the Fridays collection in their language.
There are two operations involved here: selection and the strict foreach operation (or dicing, as dened in 15]) with the operator during.
We have continued further a formal denition of the domain and languages.
On the other hand, Chandra et al.
's work includes a description of an algorithm to parse their expressions and generate a procedural plan to produce an evaluation plan, implemented in Postgress.
As well, they outline how to incorporate calendar expressions to temporal rules in a temporal data base.
We have not dealt with temporal  databases however it is perceived as an area in which to apply our framework.
Ciapessoni et al.
4] dene a many sorted rst order logic language, augmented with temporal operators and a metric of time.
The language is an extension of a specication language TRIO 9].
We will focus the present discussion on the semantics of their system, specially in the extension they provide to embed time granularities in the language.
At this stage of our research, this is where we see the two works as being comparable.
The semantics of the language in 4] includes a temporal universe which consists of a nite set of disjoint and dierently grained \temporal domains".
Each temporal domain contains temporal instants expressed in the corresponding granularity.
Time domains relate with a granularity (or coarseness) relation and a disjointedness relation.
Very briey, our \time units classes" are related to their \time domains" our \decomposition relation" to their \granularity relation" our \repetition factor" to their \conversion factor", our \aligned decomposition" to their \disjointedness" relation.
Another similar characteristic in both proposals is the distinction between time moments and durations (or displacements in their terminology).
We deal with a more general concept of repetition factor.
In fact we extensively address non-constant decomposition.
We emphasize how to express temporal entities based on dates with the conventions of the Gregorian and other calendars.
At the present stage we specially address the formal representation and reasoning about repetitive temporal terms.
As well, we believe that our abstraction of decomposition with only two characteristics (constancy and alignment) denes the relations of interest between the time unit classes in a more general way, as compared to the distinction of dierent relations in 4].
6 Discussion  The goal of this work is to be able to represent and reason eciently about repeated activities using the formalism.
We have dened a hierarchical structure of time units, emphasizing on decomposition among the time units.
We take into consideration the distinction between time unit classes, named time units and specic time unit instances, (for example \month", \August", and \August 1994").
A characterization of the hierarchical structure considers subrelations of decomposition, according to the dierent aspects of decomposition: aligned, constant, and constant/aligned.
A path in such a substructure is referred to as a chain, where all time units decompose in the same way.
Chains constitute the basis we use to dene a formal language to characterize time units.
We also introduce a language to represent time unit instances, called calendar expressions.
These ex-  pressions provide for a straightforward way of representing the temporal counterpart of repeated activities.
We envision that reasoning with calendar expressions based on time units in one chain will produce very ecient operations.
Constant/aligned chains are expected to be particularly ecient.
Currently we are working on further formalizing useful operations between calendar expressions.
A set based semantics has been provided for such expressions.
We are investigating alternative semantic characterizations.
We are also considering adding more expressive power to the language to consider for example expressions that add uncertainty, as for example \twice a week".
Important future research includes studying algorithms that would best t with this formalism, so that we may obtain ecient inferences when reasoning about repeated activities.
Algorithms developed for qualitative and/or quantitative temporal constraint satisfaction problems, or variations, could be considered in this matter.
A language which allows one to dene time units of a variant calendar, such as a university calendar, in terms of a basic calendar, such as the Gregorian, is under study also.
Finally, we believe that the formalism dened represents a generic approach, appropriate to ultimately reason eciently with repeated events within any measurement system based on discrete units that relate with a repetitive containment relation, such as the Metric or Imperial systems.
References  1] J. F. Allen.
Maintaining knowledge about temporal intervals.
Communications of the ACM, 26(11):832{843, 1983.
2] J. F. Allen and P. J. Hayes.
Moments and points in an interval-based temporal logic.
Computational Intelligence, 5:225{238, 1989.
3] R. Chandra, A. Segev, and M. Stonebraker.
Implementing calendars and temporal rules in next generation databases.
In Proc.
of the International Conference on Data Engineering, ICDE94, pages 264{273, 1994.
4] E. Ciapessoni, E.Corsetti, A. Montanari, and P. San Pietro.
Embedding time granularity in a logical specication language for synchronous real-time systems.
Science of Computer Programming, 20:141{171, 1993.
5] J. Cliord and A. Rao.
A simple, general structure for temporal domains.
In C. Rolland, F. Bodart, and M. Leonard, editors, Temporal aspects of information systems, pages 17{28.
Elsevier Science Publishers B.V. (North-Holland), 1988.
6] D. Cukierman.
Formalizing the temporal domain with hierarchical structures of time units.
M.Sc.
Thesis.
Simon Fraser University, Vancouver, Canada, 1994.
7] D. Cukierman and J. Delgrande.
Hierarchical decomposition of time units.
In Workshop of Temporal and Spatial reasoning, in conjunction with AAAI-94, pages 11{17, Seattle, USA, 1994.
8] R. Dechter, I. Meiri, and J. Pearl.
Temporal constraint networks.
Articial Intelligence, 49:61{ 95, 1991.
9] C Ghezzi, D. Mandrioli, and A. Morzenti.
Trio, a logic language for executable specications of real-time systems.
Journal of Systems and Software, 12(2), 1990.
10] J. Hobbs.
Granularity.
In Proc.
of the Ninth IJCAI-85, pages 1{2, 1985.
11] J.
A. G. M. Koomen.
Localizing temporal constraint propagation.
In Proc.
of the First Inter-  national Conference on Principles of Knowledge Representation and Reasoning, pages 198{202,  12] 13] 14] 15] 16] 17] 18] 19] 20]  21]  Toronto, 1989.
P. Ladkin.
Time representation: A taxonomy of interval relations.
In Proc.
of the AAAI-86, pages 360{366, 1986.
P. B. Ladkin.
Primitives and units for time specication.
In Proc.
of the AAAI-86, pages 354{359, 1986.
P. B. Ladkin and R. D. Maddux.
On binary constraint problems.
Journal of the ACM, 41(3):435{469, 1994.
B. Leban, D. D. McDonald, and D. R. Forster.
A representation for collections of temporal intervals.
In Proc.
of the AAAI-86, pages 367{371, 1986.
G. Ligozat.
On generalized interval calculi.
In Proc.
of the AAAI-91, pages 234{240, 1991.
S. A. Miller and L. K. Schubert.
Time revisited.
Computational Intelligence, 6(2):108{118, 1990.
R. A. Morris, W. D. Shoa, and L. Khatib.
Path consistency in a network of non-convex intervals.
In Proc.
of the IJCAI-93, pages 655{660, 1993.
M. Poesio and R. J. Brachman.
Metric constraints for maintaining appointments: Dates and repeated activities.
In Proc.
of the AAAI-91, pages 253{259, 1991.
R. Reiter.
Towards a logical reconstruction of relational database theory.
In M. L. Brodie, J. Mylopoulos, and J. W. Schmidt, editors, On Conceptual Modeling, pages 191{238.
SpringerVerlag, 1984.
M. Vilain and H. Kautz.
Constraint propagation algorithms for temporal reasoning.
In Proc.
of the AAAI-86, pages 377{382, 1986.
Automata-based Verification of Linear Temporal Logic Models with Bounded Variability Carlo A. Furia ETH Zurich, Switzerland caf@inf.ethz.ch  Abstract--A model has variability bounded by v/k when the state changes at most v times over any linear interval containing k time instants.
When interpreted over models with bounded variability, specification formulae that contain redundant metric information--through the usage of next operators--can be simplified without affecting their validity.
This paper shows how to harness this simplification in practice: we present a translation of LTL into Buchi automata that removes redundant metric information, hence makes for more efficient verification over models with bounded variability.
To show the feasibility of the approach, we also implement a proofof-concept translation in ProMeLa and verify it using the Spin off-the-shelf model checker.
I. I NTRODUCTION AND OVERVIEW Linear temporal logic (LTL) formulae model linear sequences of discrete states that evolve "one step at a time".
The state may change between some pairs of adjacent steps and not change between others; we say that a linear model has variability bounded by v/k (read "v over k") when the state changes at most v times over any interval containing exactly k steps.
Bounded variability limits the amount of information necessary to define a model: characterizing the state over v time instants is sufficient to completely describe the temporal behavior over a window of length k. Consider now an LTL formula ph that describes distances among states by means of the next operator X : for example, X X X p says that p holds in the future, at a distance of 3 steps.
If ph describes distances as large as k (i.e., k nested occurrences of X ) but we are interested only in its models with variability bounded by v/k for v < k, ph contains metric information that is redundant, as all the "action" occurs only over up to v steps.
In previous work [1], we showed how to remove the redundant information and produce a smaller formula ph' whose validity is equivalent to ph's validity over models with variability bounded by v/k; the size of ph' depends on v but not on k, hence the size of ph' is significantly smaller than the size of ph when v [?]
k. Unfortunately, this result turns out to have mostly theoretical interest: the transformation from ph to ph' reduces the size due to k but also introduces a polynomial blow-up that, while it does not affect the worstcase complexity of the validity problem, is too conspicuous  Paola Spoletini Universita degli Studi dell'Insubria, Italy paola.spoletini@uninsubria.it  in practice: ph' is often still too large to be verified with standard tools for LTL.
The present papers shows how to get around this practical shortcoming.
The solution has two elements.
First, Section III presents a different transformation of ph into a formula Ph that is equivalent for models with variability bounded by v/k.
The size of Ph also does not depend on k but, surprisingly, is otherwise exponential in another of ph's size parameters!
This exponential blow-up is, however, completely immaterial: Section IV describes a direct translation of Ph into equivalent Buchi automata that can be analyzed efficiently in practice.
More precisely, some components of the translation use alternating Buchi automata extended with finite-domain counters; these make for a direct implementation of them into the ProMeLa language input to the Spin model checker.
Section V presents a few details of the ProMeLa implementation and describes experiments where we used the technique presented in the rest of the paper to check for satisfiability--over models with bounded variability--an LTL example specification of a simple "elections" scenario.
The large distances used in the specification, required to describe time units at different levels of granularity, make its verification unfeasible for standard LTL techniques that do not exploit the bounded variability assumption.
Related work: One of the original motivations to study models with bounded variability comes from the desire to reason about systems with heterogeneous time granularities [2], where large and small distances coexist.
A few authors have discussed the modeling challenges brought by such systems [3], [4], [5], [6], [7], [8], and have demonstrated their relevance in some application domains such as medical data.
Model checking and verification using LTL and automata is a subject extensively studied for over three decades.
The complexity of checking the validity of LTL formulae [9], [10] and the relations between LTL and Buchi automata [11], [12] are well-known; Section II recalls some of the main results, which are used in the rest of the paper.
The automata-theoretic approach [11], [12] to LTL has produced not only a comprehensive theoretical framework, but also practical scalable implementations such as the Spin model  checker [13], which we used in the experiments discussed in Section V. The characterization of repeated "stuttering" steps in LTL models has been studied by Lamport [14] and others [15], [16], [17].
In spite of the extensive work on LTL, to our knowledge the present paper and our previous work [1] are the first approaches that target LTL verification for models with bounded variability.
Some of the ideas used in our work are inspired--and named after--similar notions introduced for dense time models; in particular, Pnueli operators [18] and bounded variability itself [19], [20].
As we explain in Section III, our previous work [1] represents a theoretical counterpart to the present paper; in particular, we re-use some techniques of [1] to establish the correctness of a similar transformation.
While the presentation of the present paper is entirely self-contained, we warn readers already familiar with [1] that we have occasionally changed the notation and the details of some definitions to better focus the presentation on the novel contributions.
B.
Linear Temporal Logic LTL syntax: LTL formulae are defined by: LTL [?]
ph ::= [?]
| p | !ph | ph1 [?]
ph2 | ph1 U ph2 | X ph where p ranges over a set P of propositional letters; we use the standard abbreviation for [?]
(false), [?]
(or), = (implies), = (iff); and for the derived temporal operators Fph (eventually: [?
]U ph), Gph (always: !F!ph), and X k ph (distance: * * * X} ph), where k >= 0.
The size |ph| of an LTL formula |X X {z k  ph is the size of its encoding as a string.
Qualitative and propositional LTL: L(U) denotes the qualitative subset of LTL, which does not use the X operator.
P(P) denotes the purely propositional subset of LTL over P, which does not use any temporal operator.
A formula p [?]
P(P) unambiguously identifies a subset of 2P ; for example, !p corresponds to all subsets X of P such that p 6[?]
X.
Based on this correspondence, we will use the two notations equivalently when convenient.
P+ (P) denotes the positive subset of P(P) which only uses [?]
and [?].
LTL semantics: The satisfaction relation |= defines the semantics of a generic LTL formula ph, interpreted at position i [?]
N over a word w. w, i |= [?]
w, i |= p iff p [?]
w(i) w, i |= !ph iff w, i 6|= ph w, i |= ph1 [?]
ph2 iff w, i |= ph1 and w, i |= ph2 w, i |= ph1 U ph2 iff for some j >= i, w, j |= ph2 and for all i <= k < j, w, k |= ph1 w, i |= X ph iff w, i + 1 |= ph w |= ph iff w, 0 |= ph [[ph]] denotes the set {w [?]
W(P) | w |= ph} of all models of ph.
ph is satisfiable if [[ph]] 6= [?]
and is valid if [[ph]] = W(P).
Two formulae ph1 , ph2 are equivalent if [[ph1 ]] = [[ph2 ]]; they are equi-satisfiable if they are either both satisfiable or both unsatisfiable.
II.
P RELIMINARIES A.
Words and Variability Words and trees: An o-word (or simply word) w over a set S of propositional letters is a mapping w : N - 2S that associates to every discrete instant i (also called step) the subset w(i) [?]
S of propositions that hold at i. W(S) denotes the set of all words over S. A tree is a set T [?]
N* of sequences of natural numbers that is prefix-closed, that is, if x*c [?]
T --for x [?]
N* and c [?]
N--then x [?]
T as well.
The elements of T are called nodes; the empty sequence o denotes T 's root; and if x * c [?]
T we say that x * c is a successor of x.
A node without successors is called leaf.
A path of T is a sequence p0 , p1 , .
.
.
of nodes of T such that p0 = o and, for every j >= 0, either pj is a leaf or pj+1 is a successor of pj .
A S-labeled tree is a pair hT, li where T is a tree and l : T - S assigns an element of S to each node of T .
Stuttering: A step i [?]
N is stuttering in a word w if w(i + 1) = w(i) and there exists a later step j > i such that w(j) 6= w(i).
Conversely, a non-stuttering step (nss for short) i is such that either w(i + 1) 6= w(i) or, for all j > i, w(j) = w(i).
Intuitively, a stuttering step is redundant: it records information that is repeated identically in the next step, hence it only carries information about distance between states.
A word is stutter-free if it has no stuttering steps.
Two words are stutter-equivalent if removing all their stuttering steps reduces both to the same stutter-free word.
Bounded variability: Given two positive integers v, k, a word w has variability bounded by v/k (or simply is v/k bounded) if, for all i [?]
N, at most v steps among i, i + 1, .
.
.
, i + k - 1 are non-stuttering in w. A set W of words has variability bounded by v/k if every word w [?]
W is v/k bounded.
W(S, v/k) denotes the set of all words over S with variability bounded by v/k.
Proposition 1.
* [9] The satisfiability problems for LTL and for L(U) are PSPACE-complete.
* [14] The set [[ps]] of all models of any qualitative formula ps [?]
L(U) is closed under stutter-equivalence.
Pnueli operators: The qualitative extended Pnueli operators (or simply Pnueli operators) are defined by: n;hn1 ,...,nk i  Pk  (ps1 , .
.
.
, psk )  for k, n [?]
N, n1 , .
.
.
, nk [?]
N [?]
{[?
]}, and ps1 , .
.
.
, psk [?]
L(U).
L(U, Pn) denotes LTL extended with the Pnueli operators.
The size |ph| of a L(U, Pn) formula ph is the size of its encoding as a string, assuming a unary encoding for k, n, n1 , .
.
.
, nk .
The satisfaction relation for Pnueli operators n;hn1 ,...,nk i  w, i |= Pk 2  (ps1 , .
.
.
, psk )  holds if there exist k positions i = i0 <= i1 <= * * * <= ik such that, for all 1 <= j <= k, the following hold: (1) w, ij + 1 |= psj ; (2) if nj 6= [?]
then there are no more than nj nss in [ij-1 , ij - 1]; (3) there are no more than n nss in [i, ik ].
[0, C1 ]x* * *x[0, Cn ] is the Cartesian product of the counters' domains.
We define the semantics of an alternating automaton A with counters as a regular alternating automaton A with: states Q = Q x C; initial state q0 = hq0 , 0, .
.
.
, 0i; and transition function d such that d(hq, c1 , .
.
.
, cn i, s) = th if and only if d(q, s, c1 , .
.
.
, cn ) = th.
The size of A also defines the size of A.
Proposition 2 ([1]).
The satisfiability problem for L(U, Pn) is PSPACE-complete.
Example 3.
Consider the word w: 1 a b  2 a b  3 a b  4 a b  5 a b  6 a b  7 a b  8 a b  Example 5.
The following alternating automaton with one counter c over [0, 2] accepts the language [[G(X b [?]
X 2 b)]].
9 a b  [?]
where nss are in bold and underlined, and x denotes !x.
For 5;h3,2,[?
],3i the positions 1, 2, 6, 6, w, 1 |= P4 (a, !b, a [?]
b, b) 3;h3,2,2,1i holds.
On the contrary, w, 1 6|= P4 (a, !b, a [?]
b, b): if i1 , .
.
.
, i4 are the positions that match the semantics of the operator, it must be i3 >= 6, but there are 4 > 3 nss in the interval [1, 6].
b, c < 2/c - 0 !b, c < 2/c - c + 1  [?
], c = 0/c - 0  q1  * q0  [?
], c = 2/c - 0 [?]
In the figure, a bullet marks pair of edges corresponding to conjunctive transitions, and the outgoing edges to the symbols [?]
and [?]
denote transitions equal to the logic values [?]
and [?].
The automaton spawns a separate parallel computation at every step (corresponding to the G); the computation counts up to two time steps and terminates successfully only if a b is encountered before the counter reaches 2.
C. Alternating Buchi Automata An alternating (Buchi) automaton A is a tuple hS, Q, q0 , d, F i, where S is the finite input alphabet, Q is the finite set of states, q0 [?]
Q is the initial state, d : Q x S - P+ (Q) is the transition function, and F [?]
Q is the set of final states.
If d(q, s) is purely disjunctive when it is defined, A is an ordinary nondeterministic (Buchi) automaton.
The size |A| of an alternating automaton A is |Q| + |d|, where |d| is the sum of the formula sizes |d(q, s)| for all q, s where d is defined.
A run r of an alternating automaton over a word w over S is a Q-labeled tree hTr , lr i such that: (1) the root o [?]
Tr has label lr (o) = q0 ; (2) if x [?]
Tr is a node in the tree with label lr (x) = q and the transition function defines d(q, w(|x|)) = th, then there is a set P = {q1 , .
.
.
, qk } [?]
Q such that p |= th--where we define p(0) = P--and, for all 1 <= j <= k, x * j [?]
Tr is a node of Tr with lr (x * j) = qj .
A path p of a run r is any path in Tr , hence an infinite sequence q0 , q1 , .
.
.
of states; it is accepting if qi [?]
F for infinitely many i's.
A run r is accepting if all its infinite paths are accepting.
A word w is accepted if there exists an accepting run on it.
[[A]] denotes the set of all words accepted by A (also called the language of A).
III.
F ROM LTL TO L(U, Pn) Consider a generic LTL formula ph; without loss of generality, we can write ph in separated-next form with the occurrences of X separated from the rest of the formula as   ^ ph [?]
psU [?]
G  (xi = X di pi ) , 1<=i<=M  where: psU [?]
L(U) is the purely qualitative part of the formula; for i = 1, .
.
.
, M , xi [?]
P is a propositional letter and pi [?]
P(P) is a propositional formula; and 0 < d1 <= * * * <= dM are nonnegative distances.
Also, m <= M denotes the number of distinct distances d1 = D1 < * * * < Dm = dM among d1 , .
.
.
, dM .
Our ultimate goal is to determine if ph is satisfiable over words in W(P, v/V ) where v is any positive integer and V = dM is the maximum distance appearing in ph.
When V is large, |ph| is large as well; however, if v [?]
V , ph encodes information that is redundant to decide its satisfiability over words with variability bounded by v/V .
In [1], we described a polynomial-time transformation of ph into an equi-satisfiable formula ph' [?]
L(U, Pn) whose size is O(|P|2 +vM 2 +v 2 M ).
Since the size of ph' does not depend on V , if v is significantly smaller than V --in particular, exponentially smaller--then checking the satisfiability of ph' is much easier than checking the original formula ph.
The transformation from ph to ph' stands as a theoretical result but is impractical because of the quadratic increase in size it introduces, which even becomes O(v 4 ) when we express  Proposition 4 ([12]).
* The emptiness problem for languages defined by nondeterministic Buchi automata is NLOGSPACE-complete.
* For any alternating automaton of size n there exists an equivalent nondeterministic automaton of size 2O(n) .
* For any LTL formula ph there exists an equivalent alternating automaton of size O(|ph|).
Automata with counters: Consider n integer counters, each with finite domain [0, Ci ] for i = 1, .
.
.
, n. An alternating automaton A with n counters has the same components as a regular alternating automaton, but its transition function has signature d : Q x S x C - P+ (Q x C) where C = 3  Theorem 6. ph is satisfiable over words in W(P, v/V ) if and only if Ph is satisfiable over words in W(P [?]
{s}).
the Pnueli operators in plain L(U); this blow-up is normally too conspicuous to handle with standard LTL tools.
To overcome these practical shortcomings, we follow the same principles used for ph' in [1] to build Ph  [?]
Section IV shows how to exploit automata-theoretic techniques to check efficiently the satisfiability of Ph, hence, thanks to Theorem 6, to decide the satisfiability of ph over models with bounded variability.
Section V demonstrates that the automata-theoretic techniques are directly implementable using standard model-checking tools.
psU [?]
pss [?]
psP ,  where psU , pss are qualitative formulae in L(U), and psP [?]
L(U, Pn) uses Pnueli operators.
psU is the same in ph and Ph.
pss marks the nss of propositions in P through a fresh letter s 6[?]
P that toggles precisely when some proposition in P changes truth value.
Namely, if no proposition ever changes value then s holds, and any proposition changing triggers s to do the same (see [1, Sec.
IV] for a formal definition in L(U), which is however straightforward).
To present psP , we have to introduce some more notation.
Let B [?]
{0, 1}M denote a sequence of M Boolean values b1 , .
.
.
, bM ; then, for i = 1, .
.
.
, M , [bi g] is g if bi = 1 and !g if bi = 0. psP enumerates all possible 2M truth assignments to x1 , .
.
.
, xM :   ^ psP [?]
G  X 1 [?]
* * * [?]
X M = psB  ,  IV.
F ROM L(U, Pn) TO AUTOMATA This section describes an efficient translation of the components of Ph into automata.
Each component psk becomes an automaton Ak = hS, Qk , q0k , d k , F k i such that [[psk ]] = [[Ak ]]; whenever clear from the context, we drop the superscript k from the automaton components' names.
For simplicity of presentation, we assume that the alphabet S of all automata equals the set of all propositional letters used in any formula, and omit the straightforward details of how to handle letters appearing only in certain components.
We do not discuss the translation of psU [?]
L(U) into AU , because psU can have any structure, hence we just rely on standard translations of LTL into alternating automata.
B[?
]{0,1}M  where, using the notation just introduced, Xi = [bi xi ] for i = 1, .
.
.
, M .
For each truth assignment B, psP constrains the truth value of p1 , .
.
.
, pM over the following v nss:  A.
Marking Non-stuttering Steps The automaton As for pss has 2 * 2|P| + 1 states {q0 } [?]
| P [?]
P}: two for each subset of P, and a distinct initial state q0 ; all states other than q0 are accepting.
Computations start in the initial state q0 .
According to the initial values of the propositions in P, the automaton goes to a state in q + (if s holds) or in q - (if s doesn't):  1 ,...,dm i psB [?]
Pv;hd (Y1 , .
.
.
, Ym ) , m V where Yj = dk =Dj [bk pk ] is the conjunction of all pk 's corresponding to the same distance Dj in ph, for j = 1, .
.
.
, m; and, for j = 1, .
.
.
, m and D0 = 0, dj is ( Dj - Dj-1 if Dj - Dj-1 <= v - j + 1 , dj [?]
[?]
otherwise .
{qP+ , qP-  d(q0 , P [?]
{s}) = qP+  The intuition behind the transformation from ph to Ph is as follows.
At every step, ph constrains the future values of the pi 's over a time window of length V = dM according to the current value of the xi 's.
If the variability is bounded by v/V , however, no more than v changes of the proposition in P--which determine the value of the pi 's--are possible.
Correspondingly, psP converts the distance constraints in ph into qualitative constraints over nss: rather than saying that p1 must occur at distance d1 , p2 at distance d2 , and so on, psP only requires that p1 occurs first, followed by p2 , and so on.
Since Ph is qualitative, we can transform one of its models into a model for ph by adding stuttering steps so that the pi 's follow the original metric constraints in ph.
The additional constraints introduced by the di 's ensure that this "padding" is always possible (since we cannot remove nss, we must ensure that there are not "too many" of them between any two consecutive distances).
Using the same techniques used in [1], it is not difficult to make this intuition rigorous and prove the following.
and d(q0 , P ) = qP- ,  for P [?]
2P .
The automaton leaves states of the form qP+ only if the values of the propositions change and s turns false; otherwise, s must hold continuously: d(qP+ , P [?]
{s}) = qP+  and d(qP+ , Pb) = qP- b,  where Pb ranges over the complement set of propositions 2P \ P .
Similarly, As leaves states of the form qP- only if the values of the propositions change and s turns true; otherwise, s must not hold: d(qP- , P ) = qP-  and  d(qP- , Pb [?]
{s}) = qP+ b.
Figure 1 shows As for P = {a, b}, where every transitions that enters a state qP+ has label P [?]
{s}, every transition that enters a state qP- has label P , and the initial transitions are dotted for readability.
4  - q{a,b}  + q{a}  q[?
]-  + q{b}  - q{b}  q[?
]+  - q{a}  Figure 1.
Automaton As for pss , when P = {a, b}.
now on, we omit from the presentation all transitions from states of the form qi- that follow by duality.
- The transition from qi+ to qi+1 is also possible when the local counter equals di : when s takes a new value we are already past the nss that occurred in the previous step, and the new nss is counted in the next round starting with cL = 1: - d(qi+ , !s [?]
Yi , eG , di ) = hqi+1 , eG + 1, 1i .
B. Translating Pnueli Operators B  The automaton A for psB has 2m + 2 states {q0 , qF } [?]
{qi+ , qi- | 1 <= i <= m} and two counters cG [?]
[0, v] and cL [?]
[0, d] where d = maxi di ; cG is the "global" counter that counts the following v nss, whereas cL is the "local" counter that measures each of the di 's.
Computations start in the initial state q0 and should end in the only accepting state qF .
At any point during a computation, AB is in state qi* when it is ready to read Yi , .
.
.
, YM before cG reaches v, with * = + if s held in the latest step, and * = - otherwise.
In the following, dG ranges over [0, v], eG over [0, v - 1], diL over [0, di ] [?]
[0, v], and eiL over [0, di - 1] [?]
[0, v - 1].
The automaton stays in qi+ (resp.
qi- ) without changing the counters if s holds (resp.
does not hold) and Yi is false:  Notice that the value of eiL does not matter in transitions corresponding to di = [?
], hence we need not update the local counter (we omit the straightforward details).
Now, we define the initial and final transitions.
Initially, AB goes to q1+ or q1- according to the first value of s, e.g.
: d(q0 , s [?]
!Y1 , 0, 0) = hq1+ , 0, 0i ,  d(qi+ , s [?]
!Yi , dG , diL ) = hqi+ , dG , diL i ,  d(q0 , s [?]
Y1 , 0, 0) = hq1+ , 0, 0i [?]
hq2+ , 0, 0i .
d(qi- , !s [?]
!Yi , dG , diL ) = hqi- , dG , diL i ,  + The last successful transition from qm may lead to qF :  When s toggles but Yi is false, AB rotates between qi+ and qi- while incrementing both counters by one: d(qi+ , !s d(qi- , s  [?]
[?]
!Yi , eG , eiL ) !Yi , eG , eiL )  = =  hqi- , eG hqi+ , eG  + +  1, eiL 1, eiL  + - d(qm , !s [?]
Ym , eG , eiL ) =hqF , 0, 0i[?
]hqm , eG +1, eiL +1i,  + 1i ,  + + d(qm , s [?]
Ym , dG , diL ) =hqF , 0, 0i[?
]hqm , dG , diL i.
+ 1i ,  The transition to qF is possible also when the local counter equals dm , the global counter equals v, or both:  with i <= m. When Yi holds, if AB nondeterministically guesses that this is the "right" occurrence of Yi it goes to +- qi+1 and resets the local counter; otherwise, it remains in +- qi .
For i < m, define d(qi+ , s [?]
Yi , dG , diL ) as  + d(qm , !s [?]
Ym , v, diL ) = hqF , 0, 0i , + d(qm , !s [?]
Ym , dG , dm ) = hqF , 0, 0i .
+ hqi+1 , dG , 0i [?]
hqi+ , dG , diL i ,  and  d(qi+ , !s  [?]
Yi , eG , eiL )  - hqi+1 , eG  + q{a,b}  q0  Finally, the accepting state is absorbing:  as  d(qF , [?
], 0, 0) = [?]
.
+ 1, 1i [?]
hqi- , eG + 1, eiL + 1i .
The transitions introduced so far do not allow for some of the following steps to coincide.
To account for this case, we introduce O(m2 ) transitions that "jump" multiple states  The transitions outgoing qi- when Yi holds are obtained by duality with the substitutions - - + and !s - s. From 5  s [?]
a [?]
!b  s[?]
!s  s  !s  s  [?]
b  a[?]
[?
], 0, 0  a  s[?]
qF  s  [?]
a[?]
b  !b q3-  !s [?]
!b  s  b  s  q2+  !b  a s[?
]a  [?]
b  !s  [?]
[?]
q1-  !s  !s  s  !s  b  s  !s [?]
q4-  [?]
s  !s  !s s[?
]a  b  [?]
[?]
!s q0  !
a[?]
a  !s [?]
a [?]
b  q3+  [?]
!s [?]
a  s  s [?]
!b  q2-  !s  a  !s [?]
a  q1+  s  !s  s  !b  !b  !s [?]
a  a[?]
q4+  s[?]a[?
]b  a  !s  !b  [?]
b  s  !s [?]
a [?]
!b  Figure 2.
6;h3,2,[?
],1i  Automaton AB for psB = P4  (a, !b, a [?]
b, b).
while reading multiple Yi 's.
For 1 <= i <= m, i < k < m, we add the transitions: AB 2  - d(qi+ , !s [?]
Yi [?]
* * * [?]
Yk , eG , diL ) = hqk+1 , eG + 1, 1i ,  B2  *  q0  *  B1  AB1  + d(qi+ , s [?]
Yi [?]
* * * [?]
Yk , dG , diL ) = hqk+1 , dG , 0i ,  d(qi+ , Yi [?]
* * * [?]
Ym , dG , dL ) = hqF , 0, 0i ,  Figure 3.
Schema of automaton AP .
+ d(q0 , s [?]
Y1 [?]
* * * [?]
Yk , 0, 0) = hqk+1 , 0, 0i , - d(q0 , !s [?]
Y1 [?]
* * * [?]
Yk , 0, 0) = hqk+1 , 0, 0i ,  C. Overall Automaton  d(q0 , Y1 [?]
* * * [?]
Ym , 0, 0) = hqF , 0, 0i .
The automaton A for Ph is a nondeterministic Buchi automaton, given by the intersection of 3 components: AU is a standard encoding of LTL into nondeterministic Buchi automata, of size 2O(|psU |) ; As is a nondeterministic Buchi automaton of size  O 2|P| ;  AP is an alternating automaton of size O 2M m2 v 2 , where the v 2 factor accounts for counters.
The size of AU is fixed and reflects the fact that satisfiability of LTL is PSPACE-complete; we need not worry about it.
AP is an alternating automaton; to compose it with the others, we have to convert it into a nondeterministic automaton, but this involves an additional exponential blowup in the worst-case.
The usage of universal alternation is, however, quite restricted in AP : at every step, AP activates exactly one new component of size O(m2 v 2 ) in parallel with the others, and each of these components is active for no longer than v nss.
Therefore, the exponential size of AP is immaterial in practice: if we compute the intersection and  6;h3,2,[?
],1i  Figure 2 shows AB for P4 (a, !b, a [?]
b, b); for readability, the "jump" edges we described last are dotted, and the update of the counters are omitted.
The automaton AP for psP combines the various AB through conjunctive alternation, as illustrated in Figure 3.
First, coalesce all their initial states into a single one, also called q0 , and all their final states into another one, also called qF ; this gives an automaton with 2 + m2M +1 states.
Then, for each B [?]
{0, 1}M , replace each initial transition of the component AB of the form d B (q0B , S, 0, 0) = thB , S [?]
P(P [?]
{s}), with: d(q0 , S [?]
X1 [?]
* * * [?]
XM , 0, 0) = hq0 , 0, 0i [?]
thB ; that is, at any step, the value of the propositions x1 , .
.
.
, xM activates a uniquely determined component AB , while a parallel computation remains in q0 ready for the next step.
6  check for emptiness on the fly, we have to deal with an active nondeterministic Buchi automaton of size O(2M + m2 v 3 ).
The "actual" size of A--given by the product of the size of its components as Buchi automata--is then only singly exponential in M , v, and |P|; this matches the theoretical complexity of [1], and is manageable in practice as we demonstrate in Section V.  to the semantics of conjunctive alternation (see Figure 3) and re-uses processes that have terminated for new computations.
The process running Pnueli acts as an acceptor that filters out the models generated by PsiUOpModel that also satisfy psP .
Finally, the functionality corresponding to As , which is independent of the particular form of ph, is directly implemented in the global environment: at every new step, the previous value of the propositions is compared with the new value, and s is complemented whenever the two differ.
Experiments: We verified the ProMeLa model using the Spin model checker.
The verification consisted in checking the absence of invalid end states; if successful, this guarantees that Spin can expand the complete ProMeLa model, hence it can perform emptiness check and exhaustive checking of arbitrary LTL properties.
The experiments ran Spin 6.10 on a Ubuntu box (kernel 2.6.32) with Intel QuadCore2 CPU at 2.40 GhZ with 4 GB of RAM.
We ran verification on the model with a variability bound v/V = v/1460, for values of v between 6 and 38; for all such values, the results were the following in terms of total running time (in seconds), memory used (in MB), number of primitive states generated (in millions), and maximum expansion depth reached (in thousands).
V. E XAMPLE AND I MPLEMENTATION The example used in our experiments is repeated from [1], and it is representative of several similar examples in the literature on time granularity.
The elections example: Consider elections that occur every four years, in one of two consecutive days.
Proposition q marks the first day of every quadrennial, hence it holds initially and then precisely every 365 * 4 = 1460 days.
The elections e occur once within every quadrennial; precisely they occur 40 or 41 days before the end of the quadrennial.
Formula ph in SNF describes this behavior:     (u = !e U q) (x1 = X d1 u) [?]
(v = !q [?]
!q U q)   [?]
(x2 = X d2 v)    [?]
(q = x2 [?]
x5 ) [?
]G [?]
(x3 = X d3 q) ph [?]
q[?
]G     [?]
(q = !x1 )  [?]
(x4 = X d4 q)  [?]
(e = !q [?]
x1 )  [?]
(x5 = X d5 q) [?]
(e = x3 [?]
x4 ) {z } |  T IME ( S ) 48  psU  M EM .
(MB) 2012  # S (106 ) 41.8  D (103 ) 569  Since v is merely a global upper bound on the relative distance between events, not a distance that must be reached, the performance is insensitive to changes in the value of v as long as changing v does not change the values of the dj 's (defined in Section III); this is the case for the chosen range 6 <= v <= 38, and allows for some scalability.
Even if this is only a proof-of-concept as the example is not overly complicated, it is representative of a larger class of systems, and it demonstrates that our approach is feasible and scales.
On the contrary, verifying the original formula ph "as is" is unfeasible with state-of-the-art techniques because of the sheer size of ph due to the V = 1460 nested occurrences of X .
For example, the tool LTL2BA [21]-- that translates LTL formulae into Buchi automata encoded in ProMeLa--runs out of resources while generating the automaton, and even an ad hoc implementation in ProMeLa using features such as counters would become too large for Spin to exhaustively analyze.
Our encoding is instead significantly more concise and requires a sustainable amount of resources.
with d1 = d2 = 1, d3 = 40, d4 = 41, d5 = 1460, and P = {q, e, u, v, x1 , .
.
.
, x5 }.
A variability of 6/1460 makes such specification tight, as it allows at most 6 nss over a windows of length 1460: 2 of them accounts for q becoming true and then false again once, another 3 nss mark a similar double transition of e, and one extra nss is required by the auxiliary propositions u, v, x1 , .
.
.
, x5 .
Implementation in ProMeLa: We transformed ph into Ph for the elections example, according to Section III.
Then, we implemented the automaton A described in Section IV for such Ph in the ProMeLa language [13].
ProMeLa is an expressive process description language for the Spin explicit-state model checker, suitable to describe finite-state computations and their coordination.
Our implementation of A in ProMeLa has two main components, grouped in a global environment that handles coordination between them.
The first component PsiUOpModel corresponds to Buchi automaton ApsU and is a fairly standard encoding of the L(U) formula psU ; PsiUOpModel is a ProMeLa process that acts as a (nondeterministic) generator of all models of psU .
The other component Pnueli implements the alternating automaton AP ; the expressiveness of ProMeLa makes for a straightforward implementation of the counters, which are just process integer variables.
The code for Pnueli is partitioned in four parts, corresponding to the pairs of states qi+ , qi- for i = 1, .
.
.
, 4, plus a general coordination section that activates new components at every time step according  VI.
F UTURE W ORK In future work, we plan to build an automated translator of LTL into ProMeLa implementing the construction for bounded variability introduced in the paper.
With the translator, we will be able to perform more experiments with some of the domain-specific examples available in the literature (see the related work in Section I).
In addition, we will 7  try to construct simplifications similar to those discussed in the paper that are directly applicable to automata model (as opposed to LTL formulae), with the ultimate goal of applying the model-checking paradigm--based on the combination of automata and logic--under the bounded variability assumption.
Acknowledgements: Thanks to the anonymous reviewers for useful comments.
[9] A. P. Sistla and E. M. Clarke, "The complexity of propositional linear temporal logics," JACM, vol.
32, no.
3, pp.
733-749, 1985.
[10] E. A. Emerson, "Temporal and modal logic," in Handbook of Theoretical Computer Science, 1990, pp.
996-1072.
[11] M. Y. Vardi and P. Wolper, "An automata-theoretic approach to automatic program verification," in LICS.
IEEE, 1986, pp.
332-344.
R EFERENCES  [12] J. Esparza, O. Kupferman, and M. Vardi, "Verification," in Handbook on Automata Theory, 2012.
[1] C. A. Furia and P. Spoletini, "On relaxing metric information in linear temporal logic," in TIME.
IEEE, 2011, pp.
72-79.
[13] G. J. Holzmann, The SPIN Model Checker: Primer and Reference Manual.
Addison-Wesley, 2003.
[2] C. A. Furia, D. Mandrioli, A. Morzenti, and M. Rossi, "Modeling time in computing: a taxonomy and a comparative survey," ACM Computing Surveys, vol.
42, no.
2, pp.
1-59, 2010.
[14] L. Lamport, "What good is temporal logic?"
in IFIP Congress.
North Holland/IFIP, 1983, pp.
657-668.
[3] A. Belussi, C. Combi, and G. Pozzani, "Formal and conceptual modeling of spatio-temporal granularities," in IDEAS.
ACM, 2009, pp.
275-283.
[15] D. Peled and T. Wilke, "Stutter-invariant temporal properties are expressible without the next-time operator," IPL, vol.
63, no.
5, pp.
243-246, 1997.
[4] C. Combi and S. Degani, "Building logical specifications of temporal granularities through algebraic operators," in TIME.
IEEE Computer Society, 2009, pp.
107-114.
[16] K. Etessami, "A note on a question of Peled and Wilke regarding stutter-invariant LTL," IPL, vol.
75, no.
6, pp.
261- 263, 2000.
[5] M. Franceschet and A. Montanari, "Temporalized logics and automata for time granularity," TPLP, vol.
4, no.
5-6, pp.
621-658, 2004.
[17] A. Kucera and J. Strejcek, "The stuttering principle revisited," Acta Informatica, vol.
41, no.
7/8, pp.
415-434, 2005.
[18] Y. Hirshfeld and A. M. Rabinovich, "Logics for real time: Decidability and complexity," Fundamenta Informaticae, vol.
62, no.
1, pp.
1-28, 2004.
[6] C. Combi, A. Montanari, and P. Sala, "A uniform framework for temporal functional dependencies with multiple granularities," in SSTD, ser.
LNCS, vol.
6849.
Springer, 2011, pp.
404-421.
[19] T. Wilke, "Specifying timed state sequences in powerful decidable logics and timed automata," in FTRTFT, ser.
LNCS, vol.
863.
Springer, 1994, pp.
694-715.
[7] A. Burns and I. J. Hayes, "A timeband framework for modelling real-time systems," Real-Time Systems, vol.
45, no.
1-2, pp.
106-142, 2010.
[20] C. A. Furia and M. Rossi, "MTL with bounded variability: Decidability and complexity," in FORMATS, ser.
LNCS, vol.
5215.
Springer, 2008, pp.
109-123.
[8] E. Corsetti, E. Crivelli, D. Mandrioli, A. Morzenti, A. Montanari, P. San Pietro, and E. Ratto, "Dealing with different time scales in formal specifications," in Int.
Workshop on Software Specification and Design, 1991, pp.
92-101.
[21] P. Gastin and D. Oddoux, "Fast LTL to Buchi automata translation," in CAV, ser.
LNCS, vol.
2102, 2001, pp.
53-65.
8
Experimental Evaluation of Search and Reasoning Algorithms, 1994.
11] Debasis Mitra, Padmini Srnivasan, Mark L. Gerard, and Adrian E. Hands.
A probabilistic interval constraint problem: fuzzy temporal reasoning.
In World Congress on Computational Intelligence (FUZZ-IEEE'94), 1994.
12] Raul E. Valdes-Perez.
The satisability of temporal constraint networks.
In Proceedings of AAAI, 1987.
13] Peter van Beek.
Ph.D. dissertation: Exact and Approximate Reasoning about Qualitative Temporal Relations.
University of Alberta, Ed-  monton, Canada, 1990.
5 Conclusion In this article we have described some advantages of having the capability to generate all possible consistent singleton models (CSM), from a given set of temporal intervals and some incomplete constraints between them.
The problem of nding all consistent singleton models is plagued with two sources of expected exponential growth with respect to the number of temporal entities in the data base.
First, the problem of nding one consistent model is itself NP-complete.
Second, intuition suggests that the number of models should increase exponentially with respect to the number of nodes.
The latter apprehension is possibly not appropriate, at least from our preliminary experimental results with randomly generated temporal networks.
Number of models actually reduces as constraining level increases with the number of nodes6].
Ladkin's experiment4] has also allayed the fear about hardness of the problem of nding one consistent model.
An algorithm is described here which systematically searches and prunes search space to achieve not only one CSM, but all CSM's.
The systematic nature of its searching (and pruning) seem to be the key to its eciency.
Signicance of this algorithm in temporal reasoning and its capability to nd all CSM's in reasonable amount of time is the focus of this article.
Theoretical implications involve the capability of studying global consistency problem empirically at much greater depth than has been done so far.
Our mechanism also makes us capable to handle non-monotonicity (of a particular type) in temporal reasoning.
Other theoretical implications are also discussed in this article.
There are quite a few implications of this algorithm from the point of view of applied research.
Some of the most important implications involve temporal data base, critical-domain application areas, prediction/explanation, generating all feasible (interval-based) plans, plan recognition, and image recognition There are many other implications which have not been discussed in this article (for example, parallelizability of the algorithm and associated speed up).
Generating all CSM's were considered to be a very hard problem.
This is the main reason why no one (as far as we know) has looked into the signicance of having all CSM's available.
Higher eciency of our algorithm makes such modeling feasible, and hence studying the signicance  of such modeling necessary.
References 1] J. F. Allen.
Maintaining knowledge about temporal intervals.
Communications of the ACM, 26(11):510{521, 1983.
2] J. F. Allen.
Towards a general theory of action and time.
Arti cial Intelligence, 26(2), 1984.
3] Peter Cheeseman, Bob Kanefsky, and William M. Taylor.
Where the really hard problems are.
In Proccedings of International Joint Conference on Arti cial Intelligence, pages 331{337, 1991.
4] Peter B. Ladkin and Alexander Reineeld.
Eective solution of qualitative interval constraint problems.
Art cial Intelligence, 57:105{124, 1992.
5] David Mitchell, Bart Seleman, and Hector Levesque.
Hard and easy distributions of sat problems.
In Proceedings of the Tenth National Conference of Am.
Asso.
of Arti cial Intelligence, 1992.
6] Debasis Mitra.
Ph.D. dissertation: Eciency issues in temporal reasoning.
University of  Southwestern Louisiana, Lafayette, 1994.
7] Debasis Mitra and Rasiah Loganantharaj.
All feasible plans using temporal reasoning.
In Proceedings of AIAA/NASA conference on intelligent robotics in  eld, factory, services and space, '94, 1994.
8] Debasis Mitra and Rasiah Loganantharaj.
Efcent exact algorithm for nding all consistent singleton labelled models.
In Proceedings of IEEE Robotics and Automation conference, Nice, France, 1991.
9] Debasis Mitra and Rasiah Loganantharaj.
Weak-consistency algorithms for intervalbased temporal constraint propagation.
In AAAI'94 workshop note on Spatial and Temporal reasoning, 1994.
10] Debasis Mitra, Nabendu Pal, and Rasiah Logananthatraj.
Complexity studies of a temporal constraint propagation algorithm: a statistical analysis.
AAAI'94 workshop note on  example, we may study how such models grow in planning domain with respect to the structural parameters mentioned above.
(c) Studying real-life problems: Instead of studying average number of models (or average-case complexity) for randomly generated networks, as suggested in previous paragraphs, one can study networks from classes of real life of temporal consistency-problems, e.g., planning, scheduling and diagnosis.
(d) Topological distance between local consistency problems and global-consistency problem: Local consistency problems and global-consistency problem form a hieararchy9].
An ecient globalconsistent algorithm makes it feasible to empirically study the topological distance6] between global-consistency problem and any other localconsistency problem (e.g.
3-consistency), for which ecient polynomial algorithm already exists.
Such study will expose a quantitative measure of the usefulness of these local consistency algorithms.
(e) Predictability of complexity: In a recent set of experimental studies we are trying to have the capability of predicting run-time of an algorithm based on the structure of a problem instance10].
In addition to predicting time-complexity, now we could predict the number of CSM's a problem instance can have, which is more related to the problem-structure.
In order to gain such statistical prediction power, we need to experiment with our algorithm, in line with such experiments for empirically studying time-complexity.
(f) Non-monotonic temporal reasoning: The algorithm requires maintenance of all CSM's at each stage of updating the network.
This enables one to go back and redo the reasoning from any stage, in case some information on any old arc gets changed in future.
This non-monotonicity is not feasible unless all CSM's are preserved at each stage.
4 Practical implications of the algorithm Practical implication of being able to incrementally developing models, and having all such models available in a data base are immense.
Some of them are discussed in this section.
(a) Temporal data base: A temporal data base will grow incrementally as and when a new temporal assertion comes to the knowledge of the user.
So far temporal reasoning community has not paid much attention to this fact.
The present algorithm is particularly tuned to such application for ecient incremental growth, making it a very strong candidate for utilization in temporal data bases.
(b) Critical applications: In any critical application temporal queries on multiple arcs have to be answered in real-time.
Most of the temporal reasoning scheme of present day are not suitable for handling query involving multiple temporal relations in real time.
Having all CSM's available in data base makes this feasible.
(c) Prediction of possible scenarios: Having all CSM's available again makes one capable of nding out a suitable model for the purpose of prediction, such that the chosen model is consistent with the currently supplied partial model.
(d) Explanation: Similar to prediction, developing scenarios involving past temporal assertions can act as explanations for some phenomena which are occurring at present or which have occurred in the past.
(e) All feasible plans: A special case of predictive capability of temporal reasoning system is that of generating all feasible plans7].
(f) Plan recognition: A special advantage of having a data base of all feasible plans available, is to recognize a plan based on executed operations up to a `present' time.
(g) Image recognition: If images are represented in terms of spatial relations (a two dimensional extension of temporal relations) between objects in the image (as number of possible models derived from incomplete information), then image recognition problem becomes a problem of search within models.
(h) Incorporating uncertainty in temporal reasoning: Some work has been done recently in studying propagation of fuzzy plausibility values of temporal constraints while running 3-consistency algorithm11].
In the temporal reasoning system for nding all CSM's, presented in this article, such uncertainty propagation will result in an ordering on all possible models, and possibly eliminating some weak models, thus gaining further pruning power for the sake of eciency, paying for the overhead incurred in uncertainty propagation.
2 Consistent Singleton Modeling Algorithm The algorithm described here for nding all consistent temporal models is based on forward pruning technique which we have developed sometime back8].
The formalism used is based on constraint propagation technique, which was rst developed for interval based-temporal reasoning by Allen1].
In this formalism propositional temporal entities (on time-intervals) are represented as nodes in a graph, and relations between them are represented as directed arcs between them.
Labels on each arc express possible temporal relations between two end nodes.
There are 13 primitive temporal relations feasible between time intervals1].
Disjunction of them forms an incomplete information between two temporal entities.
Three types of such labels are of special interest.
(1) Disjunction of all 13 primitive relations signies lack of any information (or constraint) between two nodes.
(2) A null relation as any label in the network signies contradiction of constraints, or an inconsistent network.
(3) Single primitive relation on each of the labels signify a singleton model of the temporal data base.
Our algorithm adds each node one by one to the data base of temporal intervals.
Thus the n-th node is added to the database of (n -1) nodes.
The data base of (n -1) nodes consists of a set of consistent singleton models (CSM).
New constraints from nth node to all other previously added nodes are used to nd n-node consistent singleton models.
This is done for all CSM's available in the old data base.
New data base consists of n-node CSM's.
At each stage an approximate algorithm is run rst as preprocessor to prune primitive relations from labels which do not have any possibility of forming a CSM.
After running the preprocessor, the forward pruning (FP) algorithm is run.
FPalgorithm systematically picks up singletons (primitive relations) from the next new arc from an ordered set of new arcs, and updates labels on all remaining new arcs by standard temporal interval{ constraint updating technique2].
If in any updating stage a null relation is generated it is considered to be a contradiction, and the algorithm backtracks over, rst the primitive relations on current arc (we call it sidetrack), and if it is exhausted, then over the previous arc in the ordered set (of new arcs).
If backtracking exhausts all primitive relations from label on the rst picked up arc, then the present  old-CSM can not nd a progeny.
A new n-node CSM is found when a primitive relation is picked up nal updated label of on the last arc of the set.
A new CSM is added for each primitive relation on the last arc to the new data base.
This process is repeated for all old CSM's.
If no model is found for all old CSM's then the new given constraints on n-th node is not consistent with respect to old data base.
Using this dynamic programming technique, the algorithm improves upon the unsystematic approach of backtracking which have been used for complete interval-based reasoning algorithms developed before.
The cost of this improved time eciency is in the additional space requirement of storing list of singletons at each stage.
The data structure design for the implementation becomes quite important in achieving space and time eciency.
The algorithm is already implemented in its preliminary form.
3 Theoretical implications of the algorithm In this section some theoretical signicance of having this algorithm for completely solving the problem of interval-based temporal constraint propagation is discussed.
(a) Empirical studies of temporal constraint satisfaction problem (TCSP): Recently a new approach of empirically studying NP-complete problems3, 5] is taking shape.
Apart from gaining insight into the structure of the problem, such empirical studies also help in developing more efcient algorithms.
Our algorithm should provide an ecient means to empirically study the temporal constraint propagation problem, which also happened to be NP-complete problem.
This algorithm, being more ecient and powerful (in providing all models), should yield better insight into the problem, with respect to some identied problem structures like average number of constrained arcs, average number of primitive relations on those arcs, or higher moments of their distributions10].
(b) Average number of models: Since our algorithm is particularly suitable for generating all CSM's, it gives an opportunity to study average number of models with respect to dierent problem structures.
Such studies could be very valuable in acquiring domain-specic information.
For  Theoretical and practical implications of an algorithm for nding all consistent temporal models Debasis Mitra dmitra@ccaix.jsums.edu Department of Computer Science 1400 Lynch St, P.O.
Box 18839 Jackson State University, Jackson MS 39217  Abstract In this article we have discussed an algorithm for nding all consistent temporal models (with interval-based representation) in an incremental fashion, and signicance of having this algorithm.
Reasoning with time in interval-based representation is NP-complete problem.
This has deterred researchers from studying the signicance of having a data base of all consistent models.
Advantage of having such models is multi-fold, as we have tried to show here.
Our algorithm is ecient enough so that obtaining all consistent models become practicable.
This makes such study necessary.
Signicance elaborated here spreads over both theoretical as well as practical aspects.
1 Introduction Reasoning with time is an important part of most cognitive activities.
Detecting consistency for a given set of temporal constraints is an NP-complete problem, when temporal entities are considered as intervals in time.
So far there exist only four algorithms for completely detecting temporal consistency.
First one, based on dependency-directed backtracking was proposed by Valdes-Perez12].
It was not complete, and there is no reported implementation of it.
Second one, forwarded by Peter van Beek13] is based on rst isolating a polynomially solvable (pointizable) subset of the problem, next solving it using polynomial algorithm, then converting the result back to original domain, and on failure, backtracking to nd dierent subset of the original problem.
Third algorithm, based on an unsystematic approach of backtrack, was developed and implemented by Ladkin et al4].
Experimentation with their algorithm has shown that, on an average, the problem is not a very hard one.
Almost at the same time, we have developed another algorithm which not only detects consistency, but also nds all possible consistent (temporal) models.
Ladkin et al's algorithm nds one consistent model as a side eect.
Although, if sucient time is given, their depthrst search algorithm also can be extended to nd all consistent models, our dynamic programmingbased algorithm is particularly geared towards efciently nding all consistent models.
Its forwardpruning heuristic prunes the search space in each stage, thus gaining eciency on average case.
Another aspect of our algorithm is that it adds each temporal entity individually, thus developing the data base of the temporal entities incrementally.
Other algorithms are not particularly geared towards such incremental development of data base.
Formal Modeling and Analysis of a Distributed Transaction Protocol in UPPAAL Omar Al-Bataineh  Tim French  Abstract We present a formal analysis of the well-known two phase atomic commitment protocol.
The protocol is modeled as networks of timed automata using the model checker UPPAAL.
The protocol has been verified in two different crash models, the crash-stop model, and the crash-recovery model.
The analysis allows us to discover several interesting conclusions about the protocol.
The paper also describes how dense-timed model checking technology may be applied to discover the worst-case execution time and the corresponding worst-case scenario of the protocol.
The analysis also allows us to illustrate various features of the UPPAAL tool, which shows that the specification language of the tool lacks the expressiveness to capture some desired properties of the protocol.
1.
Introduction Distributed systems have proven to be hard to understand, design, and reason about due to their complexity and non-deterministic nature.
They usually involve subtle interactions of a number of components that have high level of parallelism.
This is why the correctness of these systems is difficult to ensure.
Several systems and protocols have been proven not to succeed in satisfying their intended goals after they have been published [19, 15].
One of the promising solutions to this problem is the use of formal verification techniques such as model checking technique [13].
Model checking is one of the well-known formal verification techniques that is used in checking critical systems such as hardware designs, communication protocols, and distributed systems.
Model checking is an automated method for verifying finite state systems.
It uses a variety of sophisticated heuristics and symbolic implementation techniques to check that a logical formula holds in the given system design.
Typically, formulas are expressed using logics such as temporal logic, belief logic, or epistemic logic, while the system will be expressed as a set of states (finite number of states) and a set of transitions.
When the system fails to meet a desired property, the model checker produces  Terry Wooding  a counterexample that helps to identify the source of the error in the system design.
Typically modelers use untimed models (i.e.
models that do not capture timing details in the systems) to describe distributed systems.
This has several advantages.
First, untimed models are simpler to represent, describe, and to reason about.
Second, ignoring the timing details in these protocols helps to reduce significantly the size of the state space of the system under consideration, since in real-time systems the state space grows exponentially not only with the number of the concurrent components, but also with the number of clocks in the system under consideration.
There are many interesting systems and protocols where timing assumptions can be essential to their correctness, and therefore can not be accurately described using untimed models.
This applies to a large class of synchronous distributed systems.
Examples include, sliding windows protocol for reliable transmission of data over unreliable channels [10], a protocol to monitor the presence of network nodes [8], atomic commitment protocols [7, 16], the ZeroConfig protocol [9, 22], and the agreement algorithm described in [5].
The correct behaviour of these protocols typically depends on determining the minimum length of timeout intervals; if transmission delays are not properly taken into account, data may be lost if timeouts occur too soon.
Modeling such protocols are in general non-trivial and their correctness is not obvious.
In order to specify and model check this class of protocols finite state automata and linear temporal logic are not sufficient.
They especially lack the ability to trace and analyse real-time system properties.
However, the timed automata framework is an appropriate choice for describing and modeling this class of protocols.
Timed automata [3] is an extension of the classical finite state automata with clock variables to model timing aspects.
Timed automata has been shown to provide a useful formalism for describing systems in which timing constraints plays a critical factor for their correctness.
The range of problems to which timed automata has been applied successfully includes distributed systems, secure authentication protocols, embedded systems, and much more.
These applications have motivated the development of verification tools based on timed automata and temporal logic such as the UPPAAL model checker tool [6].
UPPAAL is a tool  designed for modeling real-time systems using timed automata extended with features for concurrency, communication, data variables, and priority.
The atomic commitment protocols (ACPs) are one of the interesting examples of synchronous distributed protocols that are difficult to analyse from the perspective of model checking.
The ACP protocol example is based on the description given in [7].
The protocol coordinates all the processes that participate in a distributed atomic transaction on whether to commit or abort (roll back) the transaction, while preserving data consistency.
The protocol has received great attention from the research community since it has a large number of applications in transaction processing, databases and computer networking.
The analysis of this protocol with the UPPAAL model checker tool is the subject of this paper.
We consider the protocol in two different crash models, the crash-stop model, in which processes that crashed never recovered, and the crash-recovery model, in which processes might crash and recover several times during the execution of the protocol.
The models capture realistic temporal properties of the protocol (i.e.
the coordinator times out if it does not receive a vote from the participant soon enough).
One of the main difficulties in these models is that, one can not predict the future behaviour of the agents since they might remain correct and follow the rules of the original protocol or they might fail and follow a modified protocol according to the type of the fault.
During our analysis, we have been able to discover some interesting conclusions about the protocol.
In particular in the crash-recovery model, we find that the central property of the protocol, the data consistency property, might be temporarily broken during the execution of the protocol.
However, when the protocol does terminate, we find that the consistency is preserved.
We describe a methodology for the use of dense-timed model checking to determine the longest execution time of an algorithm and then to discover the corresponding worst-case scenario.
The methodology is partially automated.
We illustrate the methodology using our case study.
As UPPAAL does not allow nested modalities, some properties of the protocol can not be verified directly.
We therefore strengthened the models and weakened the properties until UPPAAL could verify them  2 Preliminaries 2.1  Timed Automata and UPPAAL  Timed automata is an extension of the classical finite state automata with clock variables to model timing aspects [3].
Let X be a set of clock variables, then the set of Ph(X) of clock constraint ph is defined by the following grammar ph ::= t ~ c | ph1 [?]
ph2  where t [?]
X, c [?]
N, and ~[?]
{<, <=, =, >, >=}.
A clock interpretation v for a set X is a mapping from X to R+ where R+ denotes the set of nonnegative real numbers.
A timed automata is formally defined as a tuple (L, l0 , S, X, I, E), where L is a finite set of locations, l0 is the initial location, S is a finite set of labels, X is a finite set of clocks, I is a mapping that maps each location l [?]
L with some clock constraint in Ph(X), and E [?]
L x S x Ph(X) x 2X x L is a set of edges.
An edge 0 (l, a, ph, s, l ) represents a transition from location l to loca0 tion l after performing the action a.
The clock constraint ph determines when the edge is enabled and the set s [?]
X gives the clocks to be reset with this edge.
The semantics of a timed automaton (L, l0 , S, X, I, E) is defined by associating a transition systems with it.
A state (l, v) or configuration consists of the current location and the current values of clocks.
The initial state is (l0 , v0 ) where v0 = 0 for all x [?]
X.
A timed action is a pair (t, a) where a [?]
S is an action performed by an Automata A after t [?]
R+ time units since A has been started.
An execution of a timed automata A = (L, l0 , S, X, I, E) with an initial state (l0 , v0 ) over a timed trace z = (t1 , a1 ), (t2 , a2 ), (t3 , a3 ), .. is a sequence of transitions: d  a  d  a  d  a  3 3 2 2 1 1 -- hl3 , v3 i... -- hl2 , v2 i -- -- hl1 , v1 i -- hl0 , v0 i --  satisfying the condition ti = ti-1 + di for all i >= 1.
Recall that in timed automata models there are two types of transitions: delay transition di and action transition ai .
The transition system in timed automata is infinite as clocks are real-valued, therefore timed automata models can not be directly model checked.
Several techniques have been proposed to make the model checking problem decidable.
The region [2] and zone [1] approaches, however, are finite abstractions that preserve Timed Computation Tree Logic (TCTL) formulas.
The zone approach has been implemented in UPPAAL to make the model checking problem traceable.
UPPAAL [6] is a model checker for real-time systems developed in conjunction by Uppsala University, Sweden, and Aalborg University, Denmark.
It extends the basic timed automata with features for concurrency, communication, data variables, and priority.
UPPAAL uses a densetime model to describe systems, where each clock variable evaluates to a real number.
UPPAAL model is a parallel composition of all of its timed automata.
All automata start at its initial state (location) and run independently of each other unless synchronization with other automata is required.
A transition is enabled when all enabling conditions are evaluated to true and all the synchronization statements are executed.
If more than one transitions are enabled, one of them is chosen non-deterministically.
There are two types of transitions in UPPAAL: (a) delay transitions that model the elapse of time, and (b) action transitions  that execute an edge of the automata.
Note that each transition consumes a finite amount of time that can be bounded by the use of invariants.
UPPAAL uses a client-server architecture which splits the tool into a graphical user interface (client) and a model checking engine (server).
The user interface consists of three main sections: system editor, simulator, and verifier.
The editor allows the user to model the system as a network of timed automata.
The simulator gives the user the capability to interactively run the system to check if there some trivial errors in the system design.
The verifier allows the user to enter the properties to be verified in a restricted language of CTL.
UPPAAL can verify safety, bounded liveness, and reachability properties.
The syntax of the fragment of the UPPAAL's specification language relevant for this paper is given by the following grammar: P rop ::= AGph | AF ph | EGph | EF ph | ph1 - ph2 where ps can be a clock constraint, a boolean combination of equalities or inequalities over local variables, or an expression of the form process.location.
Intuitively, AGps means that every reachable state in the model satisfies ps , AF ps means in all possible paths in the model there is a state satisfies ps, EGps means there is a path where ps is always true, EF ps indicates that there is a path where eventually ps is true, and ps1 - ps2 means whenever ps1 holds eventually ps2 will hold as well.
2.2  The Two Phase commit Protocol  This section presents an informal description of a protocol that solves the problem of processing a distributed transaction in a synchronous setting.
The algorithm description here is adapted from [7] and following [16].
A set of processes {p1 , .., pn } prepare to involve in a distributed transaction.
Each process has been given its own subtransaction.
One of the processes will act as a coordinator and all other processes are participants.
The protocol proceeds into two phases.
In the first phase (voting phase), the coordinator broadcasts a start message to all the participants, and then waits to receive vote messages from the participants.
The participant will vote to commit the transaction if all its local computations regarding the transaction have been completed successfully; otherwise, it will vote to abort.
In the second phase (commit phase), if the coordinator received the votes of all the participants, it decides and broadcasts the decision.
If all the votes are 'yes' then the coordinator will decide to commit the result of the transaction.
However, if one vote said 'no', then the coordinator will decide to abort the transaction.
After sending the decision, the coordinator waits to receive a COMPLETION messages from all the participants.
The protocol terminates  whenever the coordinator receives all COMPLETION messages successfully.
The basic idea in the design of the protocol is to preserve data consistency in distributed systems in case of failure or delay in message transmission, assuming the systems are able to recover after failure.
The above version of the 2PC protocol has frequently been the focus of studies of verification of distributed computing, but it is just one of several variants discussed in the paper.
We focus here on one particular variant of the protocol in which the coordinator and the participants use a set of timers in order to detect and handle node failures.
Note that the basic 2PC protocol (without node failures) has been proved correct, but what about the situations in which some participants can crash permanently at any point of time or crash and recover several times during the execution of the protocol?
It is not immediately clear that there are no scenarios where atomicity and consistency can be violated.
One of the benefits of verification by model checking is that it permits different scenarios of a protocol to be investigated efficiently without requiring reconstruction of possibly complex proofs.
2.3  Related Work  Some work has already been done on the verification of commitment protocols using formal techniques.
The work in [17] has model checked the 2PC protocol using the LTSA tool, but they do not model explicitly the timing details of the protocol.
Also they consider the protocol only in a crashed-stop model so they did not analyse it in a crash-recovery failure model as we have done in this paper.
The protocol has been also analysed using process algebra mCRL2 [4].
The author considers a setting with two nodes, one of them is designed as a coordinator, and the other as participant.
He claims that the protocol violates consistency property in case a single participant fails, but he has not given a clear scenario where the protocol violates data consistency.
However, we believe that in order to study the protocol correctly, it should be considered in a setting with a larger number of participants not just with a single participant, so one can verify properties about participant i when for example participant j fails.
Also, he considers the protocol only in a crash-stop model, so he does not consider it in a crash-recovery model.
Simplified versions of the 2PC protocol (without timing, node failures, and recovery) have been also analysed in [12] using algebraic techniques.
However, their analysis has not led them to discover any subtleties in the protocol.
Closet to our work is the work of Olveczky [20] who have taken the approach of explicitly including time in verifying the 2PC, using the Maude tool.
He analysed the protocol under the assumption that some processes can crash and recover.
However, he does not consider the questions we have studied concern-  ing strong and weak termination, nor he does try to find the upper bound for termination in the crash-recovery model.
3 Modeling The 2-phase Commit Protocol in UPPAAL In this section, we model the protocol as networks of timed automata using the UPPAAL model checker tool.
We consider a setting with four processes, one as a coordinator and the other three as participants.
We investigate the correctness of the protocol in two different crash models, the crash-stop model, and the crash-recovery model  3.1  The Coordinator  The coordinator process in the crash-recovery model is given in Figure 1.
For space limitation we omit the crash-stop model since it is similar to the crash-recovery model except that processes do not execute a recovery protocol when they crash.
The coordinator initially chooses non-deterministically its vote using the select statement vote:votes[abort,commit].
This is modelled by the initial transition from m0 to begin.
We assume here that agents do not change their held votes.
Then it will either start the protocol or it may fail.
The coordinator (master) starts the protocol by broadcasting a commit request message to all the participants in the network.
The broadcast channel commit-request is used for this purpose.
It then activates a timer via sending a message in the channel set to a timeout automaton (see Figure 2).
The coordinator uses the timeout automaton to measure the time units that are spent in waiting the participants' votes.
Now the master will either receive all votes or it will time-out, if at least one of the participants has not sent his vote within a certain time limit.
In case a time-out occurs, the coordinator will decide to abort the transaction and enforce (instruct) all the participants to abort.
This is modeled in the transition from location m6 to location incompleteTrans.
Intuitively, if the coordinator receives all the votes before the timeout expires, it will reset the timer and jump to location m5.
Note that the channels in UPPAAL are not communicating channels but synchronising channels, in the sense they can not carry information.
To model data transfer through channels we need to use global variables.
The global array variable vote[i] is used to represent the announcement (vote) made by participant i.
The isVoted[i] variable is used to indicate whether participant i has sent his vote to the coordinator.
If the coordinator received all the votes successfully, he can then decide whether to commit or to abort the transaction.
A function decision(votes) returns the result of the transaction based on the values of the received votes.
The coordinator broadcasts this result using the broadcast channel fin_result and the global  variable outcome.
These actions are modelled in the transition from m5 to m7.
The coordinator then waits c time units in location m8 in order to receive acknowledgement from the participants.
The protocol ends successfully at location finished if the coordinator receives these signals within the time bound c. Note that the coordinator repeatedly sends the commit or abort command to all the participants that have not been responded, and wait for their acknowledgements.
The location crashed indicates that the process has crashed due to a failure.
The failure can be either temporary (soft) failure or permanent failure.
In case a soft failure occurs, a restart action will be taken to recover the process, as modeled in the transition from crashed to recovered.
When the process fails it stops all its activities, including sending messages to other processes, until it recovers.
The local variable status shows the current status of the process, which could be one of the following values {correct, crash, term}, where term stands for termination.
At the beginning of the protocol all processes will be in a correct status but it can be changed to any other status during the execution of the protocol.
The local variable rcd is used to restart the 2PC protocol after soft crashes of the coordinator.
The value of the rcd variable determines the most recent state prior to a failure.
Clearly, if the coordinator fails in the initial state, it simply restarts the protocol in the initial state.
Failures in the final state do not require any action from the coordinator.
For the remaining states, restart protocol will return the coordinator process to the state where the process was before the failure occurs.
The variable k is used to record the number of times the process has crashed and recovered during the execution of the protocol.
The local clock time_to_recover represents the time that the process can spend in the recovered location which is bounded by the constant c1.
3.2  The Participants  The template of the participants is depicted in Figure 3.
All three participants i, j, k use the same template, but with different environment variables bound to the local variable of the template.
The template is parametrised with the following variables: vote, isVoted, ack, and outcome.
The use of these variables is already explained in the description of the coordinator template.
Similar to the model of the coordinator, each participant initially chooses its vote non-deterministically and then waits for a request commit signal from the coordinator.
If they do not receive that signal within the timeout limit, they will decide to abort the transaction and terminate.
On the other hand, if they received the signal successfully, they will send their votes to the coordinator and then set the boolean variable isVoted to true.
The participants then wait to receive either a signal to collect the final outcome of the transaction or a signal to  set?
t[id] :=0  m0  rcd == initial_state  t0  vote: votes [abort, commit]  t1  timeout!
k++, status := correct rcd := initial_state,  t[id] == TIMEOUT  begin  reset?
commit_request!
rcd == commit_query_sent  rcd:= commit_query_sent  k++, status := correct  Figure 2.
The timer template  m2 set[pid]!
rcd := first_timer  rcd == first_timer  status := crashed recoverd  r0  m6 m3  k++, status := correct  crashed time_to_recover == c1  timeout[pid]?
t[pid]:=0  vote: votes [abort, commit]  votes_received ()  all_abort!
rcd := votes_received  outcome:= abort  rcd := initial_state  reset[pid]!
m4  rcd == votes_received k++, status := correct  rcd == initial_state IncompleteTrans  begin  status:= correct, k++  rcd := timer1_reset  set[pid]!
timeout[pid]?
t[pid] :=0  m5 rcd == timer1_reset  fin_result!
outcome := decision (votes), rcd :=decision_sent m7  k++, status := correct  rcd== com_req_received  r1 r2 timeoutErr commit_request?
reset[pid]!
rcd:= com_req_received,  status:= correct, k++  rcd ==decision_sent fin_result!
k++, status := correct  rcd:= second_timer  set[pid]!
m8  time_to_recover == c1 recovered  crashed  r3  status := crashed  all_abort?
dec := abort, terminate := true  rcd := vote_sent rcd == second_timer k++, status := correct  timeout[pid]?
ack_received ()  t[pid]:=0  dec := abort, terminate :=true  retransmit  rcd == vote_sent  r4  status:= correct, k++  IncompleteTrans fin_result?
dec:= outcome, rcd := dec_received, ack:= true  finished  Figure 1.
The coordinator template in the crash-recovery model  rcd == dec_received status:= correct, k++  r5 rcd:= ack_sent, terminate := true  finished  abort the transaction due to a timeout failure at the coordinator side.
Once they receive the signal to collect the final result they will set their ack variable to true and then terminate.
Note that the recovery protocol implemented at the participants' crash-recovery template is identical to the one discussed at the coordinator crash-recovery template.
4 Verification of the Protocol In this section, we explain the properties that any distributed transaction protocol must satisfy which are: validity, atomicity, consistency, and termination.
4.1  Correctness Conditions  Before we discuss the correctness conditions of the protocol let us first formalise the behaviour of the processes in the crash models that we consider.
The behaviour of the processes in the crash-stop (CS) model can be described by  Figure 3.
The participant template in the crash-recovery model  the following temporal formula.
V  i=1..n ((t = 0 = i.status = correct) [?]
(i.status = crash = AG (i.status = crash)) [?]
(i.status = term = AG (i.status = term)))  CS =  where t is a local clock to process i.
The processes initially start with a correct status which might be changed to the crash status at any point of time.
In case they remain correct they follow the rules of the original protocol until they terminate, however, if they crashed they stop all their activities and never recovered.
On the other hand, we can describe the behaviour of the processes in the crash-recovery (CR) model as follows.
CR =  V  i=1..n  ((t = 0 = i.status = correct ) [?]
AF (i.status = term))  The formula states that processes in the crash-recovery model start the protocol with a correct status but they might crash and recover several times during the execution of the protocol, however, there is a time after which processes will be up until they decide and then terminate.
For both models, we assume initially that no agent has received a message, no agent has decided, and all of them have a correct status, which can be formalized as follows.
I=  ^  (mi =[?]
[?]
dec i =[?]
[?]
statusi = correct )  i=1..n  Now we turn to discuss the correctness conditions of the protocol.
The first formula of interest is global atomicity (i.e.
all processes must abort or all must commit.)
As remarked above, it has been claimed that the 2-phase commit protocol is guaranteed the global atomicity even when a failure occurs during the execution of the protocol.
Specification 1a: (Safety property) Any two processes that have decided never decide differently.
^ AG ( !
(i.dec = abort [?]
j.dec = commit )) i6=j  We can also formalise atomicity property as follows.
V AG ((coord.dec = commit ) = i=1..n !
(i.dec = abort )) Intuitively the above formula states that if the coordinator decided to commit the transaction then none of the participants will decide to abort it.
An important property of the protocol is that a decision made during its execution must be taken by all the participants.
We can formalise this property as follows.
Specification 1b: (Liveness property) Every correct process eventually decides.
^ (i.dec = commit [?]
i.dec = abort )) AF ( i=1..n  Note that the variable dec can take one of the following values {undecided, abort , commit }.
All agents are initially undecided.
By verifying atomicity property we verify implicitly consistency property since ensuring atomicity guarantees data consistency on all distributed database systems.
Note that through the execution of the distributed transaction, some of the involving processes might fail while executing, however, the effects of the transaction on the distributed databases must be all-or-nothing.
This is very important when we consider the protocol in practical applications, where the processes that failed might recover later.
In the crash-stop model, we want to verify that if the coordinator crashed before announcing its knowledge of the outcome of the votes, then no-one commits the transaction.
Specification 1c: If the coordinator crashed then no-one  commits unless the decision has already been made before the crash.
(C.status =V crash [?]
outcome = undecided ) = i (i.dec 6= commit ) Next, we want to verify whether the protocol guarantees validity property (i.e.
if process i votes 'no' then 'no' is the only possible decision value, also if all processes vote 'yes' then 'yes' is the only decision value).
Specification 2: Abort-validity condition in the crash models.
_ (i.vote = no)) = AF (outcome = abort ) ( i=1..n  Specification 3: Commit-validity is guaranteed in the crash models.
^ (i.vote = yes)) = AF (outcome = commit ) ( i=1..n  Next assuming some nodes can fail during the execution of the protocol, we want to verify that correct nodes still can terminate successfully.
Specification 4b: (Strong termination condition for the crash-stop model): Every nonfaulty process eventually decides and then terminates.
AG (i.status 6= crash) = AF (i.status = term) Specification 4c: (Strong termination condition for the crash-recovery model) If all failures are repaired, then every participant eventually reaches a decision and terminate.
V AF ( i=1..n (i.status = term))  4.2  Verification Results  In Table 1 we report the verification results of the protocol for both crash models.
We report 'NA' in the table when the specification is not applicable for the given failure model and 'X' when UPPAAL is unable to verify the given specification.
UPPAAL successfully verifies Specification 1a in both failure models which proves that the protocol guarantees atomicity property in all possible scenarios including failure scenarios.
When model checking Specification 1b in the crash-stop model we found the specification fails where UPPAAL produced a counterexample.
The generated counterexample represents a typical scenario where the 2PC protocol blocks.
This happens when the coordinator crashes at the beginning of the second phase before announcing his knowledge of the outcome of the votes.
In this case all processes that voted to commit in the first phase can not decide.
On the other hand, all processes that voted to abort will know that the only possible decision is to abort  and therefore they do not need to wait for the decision of the coordinator.
Note that in the crash-recovery model it might not be possible for the coordinator to deliver its decision to all the participants at the same time, since some of the participants might be crashed at the time at which the coordinator transmits its decision.
So we might have situations in the protocol where participant i commits its subtransaction at real time t, while j commits at t + 4, k commits at t + 10, and C commits at t + 20.
The protocol allows such situations to occur, in particular when some processes fail during the execution of the protocol.
Our analysis shows that atomicity and consistency properties in the crash-recovery model might be temporarily broken if some processes crash for a period of time, while some other processes commit the results of their transactions during that period of time.
So temporal failures might lead to temporal inconsistency.
However, when all failures are eventually repaired we found the model satisfies atomicity and consistency properties.
Next we discuss the question whether the protocol can succeed to terminate.
Note that UPPAAL specification language does not allow nested modalities, we therefore could not verify specification 4a.
We alternatively considered a weaker termination condition for the crash-stop model via using the same termination condition we use for the crashrecovery model (specification 4b).
We found the specification fails where UPPAAL discovered a counter-example where the protocol can not terminate.
This happens when the coordinator fails after receiving the votes of the participants.
In this case the transaction remains unterminated for indeterminate period of time, since all processes are waiting the decision of the coordinator.
Note that the participants can not solve the transaction even if they cooperate with each other since they do not know the vote of the coordinator.
On the other hand, UPPAAL successfully verifies termination condition in the crash-recovery model.
Specification 1a 1b 1c 2 3 4a 4b  Crash-stop model holds fails holds holds holds X fails  Crash-recovery model holds holds NA holds holds NA holds  Table 1.
The verification Results of the 2PC protocol in UPPAAL  5 A Methodology for Finding Longest Execution Path of Timed Systems Using Model Checking When analysing real-time systems, we are often interested in studying questions related to the Worst-Case Execution Time (WCET) and the scenarios that lead to the WCET.
Since determining upper bounds on execution times is a necessary step in the development and verification process for real-time systems.
In general, it is difficult to determine the exact worstcase scenario for a given system.
Typically, researchers use static timing analysis techniques to compute the worst-case execution time for the given system.
These techniques have been shown to be potentially inaccurate, since they rely on observing the worst-case scenarios during testing or simulation or even via code inspection.
Moreover, processes in the system can have many timers (clocks) whose timing values can vary with each event processes perform, therefore, the timing analysis can be very complicated and time consuming.
Thus a need to automate the timing analysis is highly desirable.
Since model checking comprehensively explores all possible traces of the system, it can be used to answer such questions efficiently.
It is claimed in [21] that model checking is inadequate for WCET analysis.
However, Metzner in [18] has shown that model checking can be used efficiently for WCET analysis.
He used model checking to improve WCET analyses for hardware with caching.
In fact there are few worked examples on using model checking for WCET analysis.
The work in [11] has used model checking to measure WCET of real-world, modern processors with good performance.
A combination of static methods and model checking has been used in [14] to analyse WCET in programs whose loops are allowed to change dynamically.
We describe here a partially automated approach, using timed model checking, that can be followed to find the longest execution path of a given timed-based system (provide this terminates in a bounded time).
In order to verify the maximum time that the system takes to terminate, we use the timed model checker to verify formulas of the following form: AF ((system.f inished) [?]
t1 <= x) where system is a process that describes the behavioral model of the analysed system, the location f inished represents the location at which the process terminates, and t1 is a timer that is used to measure the execution time of the system.
The timer should be set initially to 0.
Intuitively, the formula states that the system can always reach the location f inished within the time bound x.
Now in order to verify the correctness of the above formula, the user needs first to guess a value for x.
The model  checker can then be used to verify the correctness of the guess.
In general, the guess concerning the value of the timer may be incorrect, and the model checker will report the error.
In this case, the model checker can be used to generate an error trace.
The next step of the process requires to analyse this error trace.
Recall that in dense-time models all the clocks progress synchronously.
This may make the analysis a bit harder.
However, the error trace will help to estimate the amount of time that the process needs in order to reach the required location.
As a result of this analysis, a new guess for the clock value will be introduced.
The model checker is then invoked again to check the new guess.
This process is iterated until a guess is produced for which the formula holds.
By the end of this process the user may be able also to discover the scenarios that lead to the WCET via analysing the generated counterexamples that he obtains while discovering the WCET.
We describe now a confirmation process by which the user can verify the correctness of his WCET calculations and then discover the corresponding worst-case scenario.
Note that the user can skip the confirmation process if he can discover worst case scenarios during his analysis of the WCET.
However, the process boosts the confidence of the user about the correctness of his analysis.
Once we know the longest execution time of the system, we can investigate the path(s) that lead to the worst-case scenario using also a process based on timed model checking technology.
In fact the process of finding the worst-case scenario is much harder than the above one since it might require some ingenuity on the part of the user.
Also it requires some manual effort of the user.
The first step of the process requires the user to guess a scenario that is supposed to be the worst-case scenario of the system (by inspection and human reasoning).
The next step is then to formalise the supposed scenario using the language of the given model checker via building what we call a test automaton that captures the intended scenario.
The third step is to model check the actual model of the system with the constructed test automaton, and then to verify formulas of the following form: EF ((test.f inished) [?]
t2 = y) where test is a process that models the proposed worst-case scenario, and t2 is a timer that is used to measure the execution time of that scenario.
The formula simply verifies whether there exists a path where process test can reach location f inished with the time bound y.
Now the user needs to follow the first described process in order to verify the above formula and to find the value of y that makes the formula hold.
Intuitively, if the value of y matches the value of x, then we found the worst-case scenario that we seek.
On the other hand, if the two values do not match then the proposed scenario is not the worst-case scenario and the user needs to guess a new scenario and then to repeat the  second process again.
5.1  Finding Longest Execution Path of The 2PC Protocol  Since UPPAAL successfully verifies all termination properties in the crash-recovery model, it is then interesting to study the upper bound for termination in that model.
Note that processes may either terminate in the first phase of the protocol if some processes crash early, or they may terminate after successfully completing the protocol.
The repeated run of the simulation of UPPAAL and the manual inspection lead us to guess that the following scenario is the worst-case scenario of the model.
We expect that the worst case scenario results when at least one of the participants let say i crashed r of times during the first phase of the protocol such that r <= k, but it recovered before the timeout of the coordinator expires (r x c1 < C.timeout), this guarantees that the coordinator will receive the votes of all participants successfully and then go to the second phase of the protocol.
Recall that k represents the maximum number of times processes can crash during the protocol execution, and that c1 represents the upper bound for crash recovery.
Now assume that the coordinator crashed k times before sending the decision and recovered after kxc1 time units, and that when it recovered some other participant j 6= i crashed also k times before it receives the decision of the coordinator.
Recall that in the second phase of the protocol the coordinator every T = C.timeout will retransmit its decision if some of the participants have not received it successfully.
From the structure of the protocol, we note that if all participants went successfully to the second phase, then all of them will be able to receive the decision of the coordinator within (2 x k x c1 + timeout).
This represents the maximum length of time processes can spend in the second phase of the protocol, which includes the time delay results if the coordinator and any of the participants crash k of times.
It is then clear that within (r x c1+ 2 x kx c1+ timeout) time units the coordinator will be able to finish the protocol and terminate.
Recall that we assume here that processes communicate with each other using perfect communication links so there is no time delay.
This assumption is made only to simplify the computations.
Note that the maximum time for termination in the crash-recovery model does not depend directly on the number of processes that crash during the protocol execution.
For example, failure of n participants k of times during the second phase will delay termination exactly k x c1 time units which equal to the time delay results if a single node fails k of times!
This is because of the time interleaving between the processes running in the protocol.
Following the above described methodology we will show how we can measure the longest execution time of the  protocol and then prove that the above described scenario is indeed the worst-case scenario.
In order to verify the maximum time that the protocol takes to terminate, we use the UPPAAL model checker to verify the following formula:  WCES :=0  part_crashed[2]?
AF ((C.finished [?]
C.IncompleteTrans) [?
]t <= x) Intuitively, the above formula states that the coordinator C can always reach the finished location or the IncompleteTrans location within the time bound x.
Recall that the protocol can either terminate at location finished if the transaction completed successfully, or at location IncompleteTrans if some failures occurred and caused the timeout of the coordinator or the participants to expire during the first phase of the protocol.
We verify the formula for the following parameter values: *  c1 = 2, k = 2, timeout = 4,  *  c1 = 2, k = 4, timeout = 4,  *  c1 = 3, k = 2, timeout = 4,  *  c1 = 2, k = 2, timeout = 6  part_crashed[1]?
coord_crashed-MAX?
coord_crashed-MAX?
part_crashed_M[2]?
coord_crashed-MAX?
part_crashed_M[0]?
part_crashed_M[1]?
trans_terminated?
trans_terminated?
The selection of the parameter values in this way helps to show how each parameter influences the execution time of the protocol.
We discover by repeated verification attempts that for the above parameter values respectively with t less than or equal to 14, 22, 19, and 18 will ensure that the protocol can always terminate.
Since we obtained the longest execution times of the model under different settings, the next step is then to prove that the above described scenario indeed represents the longest execution path of the model.
To do so we need to enforce the protocol to go through certain selected paths and then to measure the execution time of these paths.
If the measured values matched the above worst-case execution times then the scenario indeed represents the worstcase scenario of the model.
We add a special automaton (called the test automaton) which models the supposed scenario via interacting with the actual model of the protocol, as shown in Figure 4.
The test automaton is forced to only take the paths leading to the supposed scenario.
The automaton first waits to receive a signal from any of the three participants in case they crashed and recovered r times during the first phase of the protocol.
It then waits to receive a signal from the coordinator if it crashed and recovered k times at the beginning of the second phase.
Now according to the supposed worst-case scenario, the test automaton needs again to wait for a signal from any of the participants if they crashed and recovered k times in the second phase.
The test automaton terminates whenever the coordinator send it a termination signal.
part_crashed[0]?
trans_terminated?
Figure 4.
The test automaton of the worstcase scenario  We then verify the following formula: EF (test.finished [?]
WCES = y) We discover by repeated verification attempts that for the same above parameter values respectively with WCES less than or equal to 14, 22, 19, and 18 there exists a path where test automaton can reach the location finished.
These values match exactly the longest execution time of the model when we verified it under the same parameter values.
We therefore conclude that the scenario modeled by the test automaton is indeed the worst-case scenario.
6 Conclusion and Future Work We have modeled and analysed the 2-phase commit protocol in different failure settings using the UPPAAL model checker tool.
The consideration of time in the analysis allows us to specify the protocol in detail, with timeouts, retransmissions, and recovery mechanisms, which is closer to an implementation.
We have chosen UPPAAL among all available real-time model checkers because it is the most well-known and mature tool in the literature.
However, we found that UPPAAL does not support a full TCTL language and therefore we were unable to consider all interesting properties of the protocol.
We described also a partially automated methodology based on dense-timed model checking that can be followed to discover the longest execution  paths of timed systems.
An interesting research challenge is then to fully automate the methodology.
We plan to address this in future work.
References [1] R. Alur.
Timed automata.
In NATO ASI Summer School on Verification of Digital and Hybrid Systems.
1998.
[2] R. Alur, C. Courcoubetis, and D. L. Dill.
Model-checking for real-time systems.
In Proceeding of the 5th Annual Sympoisum on Logic in Computer Science, pages 414-425.
IEEE Computer Society Press, 1990.
[3] R. Alur and D. Dill.
A theory of timed automata.
In TCS, pages 183-235.
1994.
[4] M. Atif.
Analysis and verification of two-phase commit and three-phase commit protocols.
In Emerging Technologies ICET'09, pages 326-331, 2009.
[5] H. Attiya, C. Dwork, N. Lynch, , and L. Stockmeyer.
Bounds on the time to reach agreement in the presence of timing uncertainty.
Journal of the ACM, 41(1):, pages 122-15, 1994.
[6] G. Behrmann, A. David, and K. Larsen.
A tutorial on Uppaal.
In Formal Methods for the Design of Real-time Systems (SFM-RT 2004), pages 200-236.
Springer, 2004.
[7] A. P. Bernstein, V. Hadzilacos, and N. Goodman.
Concurrency control and recovery in database systems.
AddisonWesley, 1987.
[8] M. Bodlaender, J. Guidi, and L. Heerink.
Enhancing discovery with liveness.
In CCNC'04, IEEE Computer Society Press, 2004.
[9] S. Cheshire, B. Aboba, and E. Guttman.
Dynamic configuration of IPv4 linklocal addresses (2004).
2004.
[10] D. Chkliaev, J. Hooman, and E. de Vink.
Verification and improvement of the sliding window protocol.
In TACAS'03.
Number 2619.
LNCS, Springer-Verlag, 2003.
[11] A. E. Dalsgaard, M. C. Olesen, M. Toft, R. R. Hansen, and K. G. Larsen.
METAMOC: Modular Execution Time Analysis using Model Checking.
In 10th International Workshop on Worst-Case Execution Time Analysis (WCET 2010), pages 113-123, 2010.
[12] W. Janssen and J. Zwiers.
Protocol design by layered decomposition.
In Proc.
FTRTFTS 2nd International Symposium, pages 307-326.
LNCS, 1992.
[13] E. M. C. Jr., O. Grumberg, and D. A. Peled.
Model Checking.
The MIT Press, 1999.
[14] S. Kim, H. D. Patel, and S. A. Edwards.
Using a Model Checker to Determine Worst-case Execution Time.
2009.
[15] G. Lowe.
Breaking and fixing the Needham-Schroeder public-key protocol using FDR.
In Proceedings of TACAS, volume 1055 of Lecture Notes in Computer Science, pages 147-166.
Springer Verlag, 1996.
[16] N. A. Lynch.
Distributed Algorithms.
Morgan Kaufmann Publishers, 1996.
[17] J. Magee.
Analyzing synchronous distributed algorithms.
2003.
[18] A. Metzner.
Why model checking can improve WCET analysis.
In Proceeding of the International Conference on Computer-Aided Verification (CAV), pages 334-347, 2004.
[19] R. Needham and M. Schroeder.
Using encryption for authentication in large networks of computers.
In Communications of the ACM, pages 993-999.
1978.
[20] Olveczky Peter Csaba.
Formal Modeling and Analysis of a Distributed Database Protocol in Maude.
In Proceedings of the 2008 11th IEEE International Conference on Computational Science and Engineering - Workshops, pages 37-44, 2008.
[21] R. Wilhelm.
Why AI + ILP is good for WCET, but MC is not, nor ILP alone.
In Bernhard Steffen and Giorgio Levi, editiors, VMCAI, pages 309-322, 2004.
[22] M. Zhang and F. Vaandrager.
Analysis of a protocol for dynamic configuration of IPv4 link local addresses using Uppaal.
Technical report, NIII, Radboud University Nijmegen (2005), 2005.
Using Temporal Logic to Control Search in a Forward Chaining Planner Fahiem Bacchus Dept.
Of Computer Science University Of Waterloo Waterloo, Ontario Canada, N2L 3G1 fbacchus@logo.uwaterloo.ca Abstract: Over the years increasingly sophisticated planning algorithms have been developed.
These have made for more efficient planners, but unfortunately these planners still suffer from combinatorial explosion.
Indeed, recent theoretical results demonstrate that such an explosion is inevitable.
It has long been acknowledged that domain independent planners need domain dependent information to help them plan effectively.
In this work we describe how natural domain information, of a "strategic" nature, can be expressed in a temporal logic, and then utilized to effectively control a forwardchaining planner.
There are numerous advantages to our approach, including a declarative semantics for the search control knowledge; a high degree of modularity (the more search control knowledge utilized the more efficient search becomes); and an independence of this knowledge from the details of the planning algorithm.
We have implemented our ideas in the TLP LAN system, and have been able to demonstrate its remarkable effectiveness in a wide range of planning domains.
1  Introduction  Planners generally employ search to find plans, and planning research has identified a number of different spaces in which search can be performed.
Of these, three of the most common are (1) the forward-chaining search space, (2) the backwardchaining search space, and (3) the space of partially ordered plans.
The forward-chaining space is generated by applying all applicable actions to every state starting with the initial state; the backward-chaining space by regressing the goal conditions back through actions that achieve at least one of the subgoals; and the space of partially ordered plans by applying a collection of plan modification operators to an initial "dummy" plan.
Planners that explore the backward-chaining space or the space of partially ordered plans have an advantage over those that explore the forward-chaining space in that the latter spaces are generated in a "goal directed" manner.
Hence, such This research was supported by the Canadian Government through their IRIS project and NSERC programs.
Fahiem Bacchus is currently on sabbatical leave from the University of Waterloo, Canada.
Froduald Kabanza Dept.
De Math Et Informatique Universite De Sherbrooke Sherbrooke, Quebec Canada, J1K 2R1 kabanza@dmi.usherb.ca planners are intrinsically goal directed: they need never consider actions that are not syntactically relevant to the goal because the spaces they explore do not include such actions.
Partial-order planners have an additional advantage over simple backward chaining planners in that the objects in their search space are partially ordered plans.
This allows these planners to delay ordering actions until they detect an interaction between them.
Linear backward or forward-chaining planners, on the other hand, might be forced into backtracking because they have prematurely committed to an ordering between the actions.
However, both backward-chaining and partial-order planners search in spaces in which knowledge of the state of the world is far less complete than in the forward-chaining space.
For example, even if a backward-chaining planner starts with a completely described initial world and actions that preserve the completeness of this description, it will still have only incomplete knowledge of the world state at the various points of its search space.
Partial order planners also suffer from this problem.
The points of their search space are incomplete partially ordered plans, and at the various stages of an incomplete plan we have only limited knowledge of the state of the world.
On the other hand, the points in the forward-chaining space are world descriptions.
Such descriptions provide a lot of information about the world state, even if the description is incomplete.
As we will demonstrate in this paper, such knowledge can be effectively utilized to control search in this space.
The choice between the various search spaces has been the subject of much recent inquiry [BW94; MDBP92], with current consensus seemingly converging on the space of partially ordered plans,1 mainly because of its goal-directness and least commitment attitude towards action ordering.
However, these studies have only investigated simple heuristic search over these spaces, where domain independent heuristics, like counting the number of unsatisfied sub-goals, are utilized.
Domain independent heuristics cannot take advantage of structural features that might be present in a particular domain.
Theoretical work [ENS92; Sel94] indicates that for the traditional S TRIPS actions used by almost all current planners, 1  Although, see [VB94] for an refreshing counterpoint.
finding a plan is, in general, intractable.
This means that no domain independent planning algorithm can succeed except in very simple (and probably artificial) domains.
More importantly, however, is that there may be many domains where it is feasible to find plans, but where domain structure must be exploited to do so.
This can be verified empirically; e.g., the partial order planner implemented by Soderland et al.
[SBW90] cannot effectively generate plans for reconfiguring more than 5 blocks in the blocks world using domain independent heuristic search.
Nevertheless, the blocks world does have sufficient structure to make it easy to generate good plans in this domain [GN92].
One way of exploiting domain structure during planning is to use domain information to control search.
Hence, a more practical evaluation of the relative merit of various planning algorithms and search spaces would also take into account how easy it is to exploit domain knowledge to control search in that space.
The idea of search control is not new, e.g., it is a prominent part of the P RODIGY planing system [CBE+ 92].
Our work, however, makes a number of new contributions to the notion of search control.
In particular, we demonstrate how search control information can be expressed in a first-order temporal logic, and we develop a method for utilizing this information to control search during planning.
By using a logic we gain the advantage of providing a formal semantics for the search control information.
Furthermore, we would claim that this semantics is quite natural and intuitive.
This differentiates our mechanism for search control from classical state-based heuristics and from the control rules employed by the P RODIGY system.
P RODIGY control rules are implemented as a rule-based system.
Various rules are activated dependent on the properties of the node in the search space that is currently being expanded.
These rules are activated in a particular order and have various effects.
This means that any attempt to give a semantics to these rules would require an operational semantics that makes reference to way in which the rules are utilized.
By using the forward-chaining search space we end up searching in the space of world descriptions.
This allows us to utilize search control knowledge that only makes reference to the properties of these worlds, i.e., to properties of the domain.
Thus the search control knowledge used can be considered to be no different from the description of the domain actions: it is part of our knowledge of the dynamics of the domain.
In contrast, P RODIGY control rules include things like binding selection rules that guide the planner in deciding how to instantiate actions.
Such rules have to do with particular operations of the P RODIGY planning algorithm, and to compose such rules the user must not only possess domain knowledge but also knowledge of the planning algorithm.
Finally, the language in which we express search control knowledge is richer than previous approaches.
Hence, it can capture much more complex control knowledge.
In particular, the control strategies are not restricted to considering only the current state, as are P RODIGY control rules and statebased heuristics.
They can, e.g., consider past states and pass  information forward into future states.
All of these features make the control information employed by our system not only easier to express and understand, but also more effective, sometimes amazingly effective, as we will demonstrate in Section 4.
Using the forward-chaining search space is not, of course, a panacea.
It does, however, seem to better support effective search control.
We have already mentioned two reasons for this: we have access to more information about the world state in this space, and it allows us to express search control information that is independent of the planning algorithm.
We have also found a third advantage during our experiments.
In many domains, humans seem to possess strategies for achieving various kinds of goals.
Such strategies seem to be most often expressed in a "forward-direction".
This makes their use in controlling forward-chaining search straightforward, but exploiting them in the other search spaces not always so.
Due to its support of effective search control, we have found that forward-chaining can in many domains yield planners that are more effective than those based on partial order planning or backwards-chaining regression.
The forward-chaining search space still suffers from the problem that it is not goal directed, and in many of our test domains we have found that some of the search control information we added was designed to recapture goal-directedness.
Much of this kind of search control knowledge can be automatically inferred from the operator descriptions, using ideas like those of [Etz93].
Inferring and learning search control in the form we utilize is an area of research we are currently pursuing.
One of the key advantages of using a logic to express search control knowledge is that it opens the door to reasoning with this knowledge to, e.g., generate further control knowledge or to verify and prove properties of the search control knowledge.
But again this avenue is a topic for future research.
In the rest of the paper we will first describe the temporal logic we use to express domain strategies.
We then describe how knowledge expressed in this language can be used to control forward chaining search.
We have implemented our approach in a system we call TLP LAN, and we describe some of our empirical results with this system next.
We close with a summary of our contributions and a description of some of the extensions to our approach we are currently working on.
2 First-order Linear Temporal Logic We use as our language for expressing strategic knowledge a first-order version of linear temporal logic (LTL) [Eme90].
The language starts with a standard first-order language, L, containing some collection of constant, function, and predicate symbols.
LTL adds to L the following temporal modalities: U (until), 2 (always), 3 (eventually), and (next).
The standard formula formation rules for first-order logic are augmented by the following rules: if f 1 and f2 are formulas then so are f1 U f2 , 2f1 , 3f1 , and f1 .
Note that the first-order and temporal formula formation rules can be applied in any order, so, e.g., quantifiers can scope temporal modalities al-  lowing quantifying into modal contexts.
Our planner works with standard S TRIPS operators and world descriptions, and it takes advantage of the fact that these world descriptions support the efficient testing of various conditions.
In particular, worlds described as lists of positive literals support the efficient evaluation of complex first-order formulas via model-checking [HV91].
Hence, we can express complex conditions as first-order formulas and evaluate their truth in the worlds generated by forward-chaining.
Part of our TLP LAN implementation is a first-order formula evaluator, and TLP LAN allows the user to define predicates by firstorder formulas.
These predicates can in turn be used in temporal control formulas, where they act to detect various conditions in the sequence of worlds explored by the planner.
To ensure that it is computationally effective to evaluate these first-order formulas and at the same time not limit ourselves to finite domains (e.g., we may want to use the integers in our domain axiomatization), we use bounded instead of standard quantification.
In particular, instead of the quantifiers 8x or 9x, we have 8 x: ] and 9 x: ] , where  is an atomic formula2 whose free variables include x.
It is easiest to think about bounded quantifiers semantically: 8 x: ]  for some formula  holds iff  is true for all x such that  (x) holds, and 9 x: ]  holds iff  is true for some x such that  (x) holds.
Computational effectiveness is attained by requiring that in any world the set of satisfying instances of  be finite.
3 The formulas of LTL are interpreted over models of the form M = hs0 fi s1 fi : : :i, i.e., a sequence of states.
Every state si is a model (a first-order interpretation) for the base language L. In addition to the standard rules for the first-order connectives and quantifiers, we have that for a state si in a model M and formulas f1 and f2 :  fi hMfi sii j= f1 U f2 iff there exists j  i such that hMfi sj i j= f2 and for all k, i  k < j we have hMfi sk i j= f1 : f1 is true until f 2 is achieved.
fi hMfi sii j= state.
f1 iff hMfi si+1 i j f1 : f1 is true in the next =  fi hMfi sii j= 3f1 iff there exists j  i such that hMfi sj i j= f1 : f1 is eventually true.
fi hMfi sii j= 2f1 iff for all j  i we have hMfi sj i j= f1 : f1 is always true.
Finally, we say that the model M satisfies a formula f if hMfi s0i j= f .
First-order LTL allows us to express various claims about the sequence of states M. For example, on(Afi B ) asserts that in state s2 we have that A is on B .
Similarly, 2  We also allow to be an atomic formula within the scope of a (described below).
That is, instead of allowing x to range over the entire domain, we only allow it to range over the elements satisfying .
Thus, the underlying domain may be infinite, but any particular quantification over it is finite.
Also we allow formulas of the form 9 x: ] where  is implicitly taken to be TRUE.
GOAL modality 3  2:holding C asserts that we are never in a state where we are holding C , and 2 on Bfi C ) on Bfi C U on Afi B asserts that whenever we enter a state in which B is on C it remains on C until A is on B , i.e., on Bfi C is preserved until we achieve on Afi B .
Quantification allows even greater expressiveness, e.g., 8 x clear x clear x asserts that ev(  )  (  (  )  (  (  (  (  )  (  )))  )  )  :  (  )]  ( )  ery object that is clear in the current state remains clear in the next state.
We are going to use LTL formulas to express search control information (domain strategies).
Search control generally needs to take into account properties of the goal, and we have found a need to make reference to requirements of the goal in our LTL formulas.
To accomplish this we augment the base language L with a goal modality.
In particular, to the base language L we add the following formula formation rule: if f is a formula of L then so is GOAL(f ).
If the agent's goal is expressed by the first order formula , then semantically this modality is a modality of entailment from  and any state constraints.
That is, GOAL (f ) is true iff  ^  j= f , where  are the set of conditions true in every state, i.e., the set of state constraints.
However, testing if GOAL (f ) is true given an arbitrary goal formula  is intractable (in general, it requires theorem proving).
Our implemented planning system TLP LAN allows the goal modality to be used only when goals are sets of positive literals, and it computes goal formulas by assuming that these literals describe a "goal world" using a closed world assumption.
For example, if the goal is the set of literals fon(Afi B ), on(Bfi C )g then these are assumed to be the only positive literals that are true in the goal world, every other atomic formula is false by the closed world assumption.
For example clear(A) is false in the goal world.
Intuitively, it is not a necessary requirement of the goal.
TLP LAN can then use its firstorder formula evaluator over this goal world, so the formula GOAL (9 y:on(Afi y )] ) will also evaluate to true.
If, however, we had as our goal fP (A)g and the state constraint that in all states P (A) ) Q(A), then, in its current implementation, TLP LAN will incorrectly (according to the above semantics) conclude that GOAL (Q(A)) is false.
That is, TLP LAN cannot currently handle state constraints over the goal world.
3 Expressing Search Control Information Any LTL formula specifies a property of a sequence of states: it is satisfied by some sequences and falsified by others.
In planning we are dealing with sequences of executable actions, but to each such sequence there corresponds a sequence of worlds: the worlds we pass through as we execute the actions.
These worlds act as models for the language L. Hence, we can check the truth of an LTL formula given a plan, by checking its truth in the sequence of world visited by that plan using standard model checking techniques developed in the program verification area (see, e.g., [CG87]).4 Hence, if 4 LTL formulas  actually require an infinite sequence of worlds as their model.
In the context of standard planning languages, where a plan consists of a finite sequence of actions, we can terminate every finite sequence of actions with an infinitely replicated "do nothing"  we have a domain strategy for the goal fon(Bfi A)fi on(Cfi B )g like "if we achieve on(Bfi A) then preserve it until on(Cfi B ) is achieved", we could express this information as the LTL formula 2(on(Bfi A) ) on(Bfi A) U on(Cfi B )) and check its truth against candidate plans, rejecting any plans that violate this condition.
What we need is an incremental way of checking our control strategies against the partial plans generated as we search for a correct plan.
If one of our partial plans violates our control strategy we can reject it, thus pruning all of its extensions from the search space.
We have developed a mechanism for doing incremental checking of an LTL formula.
The key to this method is the progression algorithm given in Table 1.
In the algorithm quantified formulas are progressed by progressing all of their instances.
This algorithm is characterized by the following theorem: Theorem 3.1 Let M = hs0 fi s1 fi : : :i be any LTL model.
Then, we have for any LTL formula f , hMfi si i j= f if and only if hMfi si+1i j= f + .
The progression algorithm admits the following implementation strategy, used in TLP LAN.
Every world generated during our search of the forward-chaining space is labeled with an LTL formula f , with the initial world being labeled with a user supplied LTL control formula that expresses a control strategy for this domain.
When we expand a world w we progress its formula f through w using the given algorithm, generating a new formula f + .
This new formula becomes the label of all of w's successor worlds (the worlds generated by applying all applicable actions to w).
If f progresses to FALSE , (i.e., f + is FALSE ), then Theorem 3.1 shows that none of the sequences of worlds emanating from w can satisfy our LTL formula.
Hence, we can mark w as a dead-end in the search space and prune all of its successors.
The complexity of evaluating Clause 2 of the progression algorithm depends on the form of the world descriptions.
It requires us to test an atemporal formula in the current world.
Hence, its complexity depends on two things, the complexity of the atemporal formula and the form of the world description.
If the worlds are incompletely described and represented simply as a first-order formula that characterizes some of its properties, then this clause will require theorem proving to evaluate.
If the world is described as a set of atomic formulas and a collection of horn clauses, and if the formula is quantifier free then evaluating the formula in the world might still be tractable.
The efficiency of this step is important however, as we must use this algorithm at every world expanded during plan search.
In our current implementation of TLP LAN we use worlds that are described as sets of positive literals, and we employ a closed world assumption: every positive literal not in this set is assumed to be false.
In this way we need make no restrictions on the atemporal formulas that can appear in our LTL control formula.
In particular, we can use arbitrary first-order action.
This corresponds to infinitely replicating the final world in the sequence of worlds visited by the plan.
Inputs: An LTL formula f and a world w (generated by forward-chaining).
Output: A new formula f + , also expressed as an LTL formula, representing the progression of f through the world w.  Algorithm Progress(f ,w) 1.
Case 2. f =  2 L (i.e.,  contains no temporal modalities): f + := TRUE if w j= ffi FALSE otherwise.
3 f = f1 ^ f2 : f + := Progress(f1 fi w) ^ Progress(f2 fi w) 4. f = :f1: f + := :Progress(f1 fi w) 5. f = f1 : f + := f1 6. f = f1 U f2 : f + := Progress(f2 fi w) _ (Progress(f1 fi w) ^ f ) 7. f = 3f1: f + := Progress(f1 fi w) _ f 8. f = 2f1 : f + := V Progress(f1 fi w) ^ f 9. f = 8 x: ] f1 : f + := fc:wj=(c)g Progress(f1 (x=c)fi w) W 10. f = 9 x: ] f1 : f + := fc:wj=(c)g Progress(f1 (x=c)fi w) Table 1: The progression algorithm.
formulas in our LTL control.
With worlds described by (assumed to be) complete sets of positive literals, we can employ model-checking instead of theorem proving to determine the truth of these formulas in any world, and thus evaluate clause 2 efficiently.
4 Empirical Results Blocks World.
Our first empirical results come from the blocks world, which we describe using the four operators given in table 2.
If we run our planner with the vacuous search control formula 2TRUE 5 , and exploring candidate plans in a depth-first manner, rejecting plans with state cycles, we obtain the performance given in Figure 1.
Each data point represents the average time required to solve 5 randomly generated blocks world problems (in CPU seconds on a SUN1000), where the initial state and the goal state were independently randomly generated.
The same problems were also run using S NLP, a partial order planner [MR91; SBW90], using domain independent heuristic search.
The graph demonstrates that both of these planners hit a computational wall at or before 6 blocks.6 S NLP failed to solve 4 of the six block problems posed; the times shown on the graph include the time taken by the runs that failed.7 5 This formula is satisfied by every sequence, and hence it provides no pruning of the search space.
6 We can note that with 5 blocks and a holding predicate there are only 866 different configurations of the blocks world.
This number jumps to 7057 when we have 6 blocks, and to 65990 when we have 7 blocks.
7 That is, S NLP exceeded the resource bounds we set (on the number of nodes in the search tree).
Note that by including these times in the data we are making S NLP's performance seem better than it really is: S NLP would have taken strictly more time to solve these problems than the numbers indicate.
The same comment applies to the tests described below.
Operator pickup (x) putdown (x) stack (xfi y) unstack (xfi y)  Preconditions and Deletes ontable(x), clear(x), handempty.
holding(x).
holding(x), clear(y).
on(xfi y), clear(x), handempty.
Adds holding(x).
ontable(x), clear(x), handempty.
on(xfi y), clear(x), handempty.
holding(x), clear(y).
Table 2: Blocks World operators.
400 SNLP TLPlan  Time (CPU sec.)
350 300 250 200 150 100 50 0 0  1  2  3  4  5  6  Number of Blocks  Figure 1: Performance of blind search in the blocks world This shows that domain independent heuristic search does not work well in this domain, even for the sophisticated S NLP algorithm.
Domain independent heuristics have difficult exploiting the special structure of blocks world.
Nevertheless, the blocks world does have a special structure that makes planning in this domain easy [GN92], and it is easy to come up with effective control strategies.
A basic one is that towers in the blocks world can be build from the bottom up.
That is, if we have built a good base we need never disassemble that base to achieve the goal.
We can write a firstorder formula that defines when a block x is a good tower, i.e., a good base that need not be disassembled.
4  goodtower(x) = clear(x) ^ goodtowerbelow(x)  4  goodtowerbelow(x) = (ontable(x) ^ : GOAL (9 y :on(xfi y )] _ holding(x))) _ 9 y:on(xfi y)] :GOAL(ontable(x) _ holding(x)) ^ :GOAL(clear(y)) ^ 8 z :GOAL(on(xfi z ))] z = y ^ 8 z :GOAL(on(zfi y))] z = x ^ goodtowerbelow(y) A block x satisfies the predicate goodtower(x) if it is on top of a tower, i.e., it is clear, and the tower below it does not violate any goal conditions.
The various tests for the violation of a goal condition are given in the definition of goodtowerbelow.
If x is on the table, the goal cannot require that it be on another block y nor can it require that the robot be holding x.
On the other hand, if x is on another block y, then x should not be required to be on the table, nor should the robot be required to hold it, nor should y be required to be clear, any block that is  required to be below x should be y, any block that is required to be on y should be x, and finally the tower below y cannot violate any goal conditions.
Our planner can take this first-order definition of a predicate (rewritten in Lisp syntax) as input.
And we can then use this predicate in an LTL control formula where during the operation of the progression algorithm (Table 1) its first-order definition will be evaluated in the current world for various instantiations of its "parameter" x.
Hence, we can use a strategy of preserving good towers by setting our LTL control formula to  2 8 x clear x (  :  (  )]  goodtower(x) )  goodtowerabove(x))fi  (1)  where the predicate goodtowerabove is defined in a manner that is symmetric to goodtowerbelow.
In any world the formula will prune all successor worlds in which a good tower x is destroyed, either by picking up x or by stacking a new block y on x that results in a violation of a goal condition.
Note also that by our definition of goodtower, a tower will be a good tower if none of its blocks are mentioned in the goal: such a tower of irrelevant blocks cannot violate any goal conditions.
Hence, this control rule also stops the planner from considering actions that unstack towers of irrelevant blocks.
What about towers that are not good towers?
Clearly they violate some goal condition.
Hence, there is no point in stacking more blocks on top of them as eventually we must disassemble these towers.
We can define: badtower(x)  4 clear x  =  (  )  ^ :goodtower(x)  And we can augment our control strategy to prevent growing  bad towers, by using the formula:    2 8 x clear x :  ( )]  goodtower(x) ) goodtowerabove(x) ^ badtower(x) ) (:9 y:on(yfi x)] )  (2)  This control formula stops the placement of additional blocks onto a bad tower.
With this control formula only blocks on top of bad towers can be picked up.
This is what we want, as bad towers must be disassembled.
However, a single block on the table that is not intended to be on the table is also a bad tower, and there is no point in picking up such a block unless its final position is ready.
Adding this insight we arrive at our final control strategy for the blocks world:    2 8 x clear x :  ( )]  goodtower(x) ) goodtowerabove(x) ^ ;badtower(x) ) (:9 y:on(yfi x)] ) ^ ontable(x)  ^ 9 y:GOAL(on(xfi y))]:goodtower(y) ) (:holding(x))  (3)  The performance of our planner with these three different control formulas is shown in Figure 2.
As in Figure 1 each data point represents the average time taken to solve 5 randomly generated blocks world problems.
This figure also shows the performance of the P RODIGY planner on these problems.
This planner, like TLP LAN, was run with a collection of hand written search control rules.
In this domain our method proved to be more effective than that of P RODIGY.
In fact, it is not difficult to show that the final control rule yields an O(n2) blocks world planner (where n is the number of blocks in the world).
In particular, the planner can find a near optimal plan (at most twice the length of the optimal) using depth-first search without ever having to backtrack.
Furthermore, there is always an optimal plan admitted by this control formula.
Hence, if we employ breadth-first search our planner will find an optimal plan.
However, finding an optimal plan is known to be NP-hard [GN92].
P RODIGY employed 11 different control rules some of which have similar intuitive content to our control formulas, but with others that required an understanding the P RODIGY planning algorithm.
We would claim that our final control formula is easily understood by anyone familiar with the blocks world.
P RODIGY does end-means analysis, so at every node in its search space it has available a world description.
It would be possible to use our control formulas on this world description.
However, most of the search performed by P RODIGY is a goal regressive search to find an action applicable to the current world.
It is this part of the search that seems to be hard to control.
Bounded Blocks World.
We have also implemented a bounded blocks world in which the table has a limited amount of space.
Dealing with resource constraints of this kind is  fairly easy for a forward-chaining planner, but much more difficult for partial order planners.8 A strategy capable of generating good plans in polynomial time can be written for this domain also, but it is more complex than our strategy for the unconstrained blocks world.
But even very simple strategies can be amazingly effective.
With no search control at all TLP LAN took an average of 470 CPU seconds to solve 10 different randomly generated six block problems when the table had space for 3 blocks.
When we changed the strategy to a simple "trigger" rule (trigger rules are rules that take advantage of fortuitous situations but do not attempt to achieve these situations) the average dropped to 0.48 seconds!
The particular rule we added was: whenever a block is clear and its final position is ready, move it there immediately.
This rule is easily expressed as an LTL formula.
Figure 3 plots the average time taken by TLP LAN to solve 10 random n block reconfiguration problems in the bounded blocks world where the table has space for 3 blocks.
The graph shows TLP LAN's performance using no control knowledge, the simple trigger rule given above, and a complete backtrack-free strategy.
Schedule World.
Another domain we have tested is the P RODIGY scheduling domain.
This domain has a large number of actions and the branching factor of the forward chaining space is large.
Nevertheless, we were able to write a conjunction of natural control formulas that allowed TLP LAN to generate good schedules without backtracking.
In this domain the task is to schedule a collection of objects on various machines to achieve various machining effects.
One example of the control formulas we used is, 8 x:object(x)] 2(polish(x) ^ :polish(x)) ) 2:polish(x), where polish is true of an object x if x is being polished in the current world.
This formula prohibits action sequences where an object is polished twice (basically the transition from being polished to when polishing stops prohibits future polishing).
Another use of the control formulas was to detect impossible goals.
For example, 8 x:object(x)] 8 s:GOAL(shape(xfi s))] s = cylindrical _ 2shape(xfi s).
In the domain the only shape we can create are cylinders.
This formula, when progressed through the initial state, checks every object for which the goal mentions a desired shape to ensure that the desired shape is cylindrical.
If it is not then the object must have that shape in the current state (i.e., in the initial state) and in all subsequent states.
Hence, when we pose a goal such as shape(Afi cone), the planner will immediately detect the impossibility of achieving this goal unless A starts off being cone shaped.
The performance of TLP LAN and S NLP (using domain independent heuristics) is shown in Figure 4.9 The data points in the figure show the average time taken to solve 10 random problems.
The x-axis plots the number of new features the goal requires (i.e., the 8  Resource constraints are beyond the capabilities of S NLP, but see [YC94] for a partial order planner with some ability to deal with resource constraints.
9 We were unable to obtain the P RODIGY control rules for this domain; hence, we omitted P RODIGY from this comparison.
400  Time (CPU sec.)
350 300 250 200 150 Prodigy 4.0 Control Formula 1 Control Formula 2 Control Formula 3  100 50 0 0  5  10  15  20  25  30  35  40  45  50  Number of Blocks  Figure 2: Performance of search control in the blocks world 400  Time (CPU sec.)
350 300 250 200 150 100  No Control Tigger Rule Complete Strategy  50 0 0  5  10  15  20  25  30  35  40  Number of Blocks  Figure 3: Performance of TLP LAN in the bounded blocks World number of machining operations that must be scheduled).10 In the experiments the number of objects are just sufficient to allow goals involving that number of new features (in this domain we can only add a limited number of new features to each object).
TLP LAN was able to solve all of the problems at each data point.
However, S NLP failed to solve 4 of the 3 new feature problems.
It is important to note that we are not using our experiments to claim that TLP LAN is a superior planner to S NLP (or P RODIGY).
After all, in the experiments described above, TLP LAN is being run with extensive control knowledge while S NLP was not.
Hence, it should be expected to outperform S NLP.
What we are claiming is that (1) domain independent heuristic search in real domains is totally inadequate, (2) planning can be effective in these domains with the addition of natural domain dependent search control knowledge, and (3) the TLP LAN approach to search control knowledge in particular is an effective way to utilize such knowledge.
These points are borne out by the data we have presented.
We have only incomplete evidence, given from the blocks world, that our approach to specifying search control knowledge is superior to 10 In this test we did not pose any impossible goals; so did not take advantage of the TLP LAN control formulas designed to detect impyossible goals.
P RODIGY's.
However, we are currently engaging in a more systematic comparison.
What is very clear at this point however, is that our LTL control formulas are much easier to understand, and their behavior easier to predict, than P RODIGY control rules.
In conclusion, we have demonstrated that search control knowledge for forward chaining planners can be expressed in a logical formalism and utilized effectively to produce efficient planners for a number of domains.
We are currently working on extending our planner so that it can plan for temporally extended goals (e.g., maintenance goals) and quantified goals.
TLP LAN is not yet capable of generating plans that satisfy all such goals.
This is due to its handling of eventuality goals like 3p.
If we pose the goal q, then our current implementation will search for a plan whose final state satisfies q.
The temporal formula 3p will be used only as a search control formula, and since it involves only an eventuality that can be postponed indefinitely, this will have no pruning effect.
Hence, our implementation could return a plan that achieves q in the final state but never passes through a state satisfying p. A more sophisticated implementation is required to ensure that eventualities are eventually satisfied and not postponed indefinitely.
In addition, we are working on applying our planner to some practical problem domains.
Finally,  400  Time (CPU sec.)
350 300 250 200 150 100  SNLP  50  TLPlan  0 0  5  10  15  20  25  30  Number of new features  Figure 4: Performance in the Schedule world.
as mentioned above, we are working on automatically generating search control knowledge from operator descriptions along the lines of [Etz93], and on a more systematic comparison with the P RODIGY system.
Acknowledgments: thanks to Adam Grove for extensive discussions; David McAllister for insights into inductive definitions; John McCarthy for the idea of trigger rules; Manuela Veloso and Jim Blythe for help with P RODIGY; and Hector Levesque, Nir Friedman and Jeff Siskind, David Etherington, Oren Ertzioni, and Dan Weld for various useful insights and comments on previous versions.
References [BW94]  A. Barrett and D.S.
Weld.
Partial-order planning: evaluating possible efficiency gains.
Artificial Intelligence, 67(1):71-112, 1994.
[CBE+ 92] J.G.
Carbonell, J. Blythe, O. Etzioni, Y. Gill, R. Joseph, D. Khan, C. Knoblock, S. Minton, A. Perez, S. Reilly, M. Veloso, and X. Wang.
Prodigy 4.0: The manual and turorial.
Technical Report CMU-CS-92-150, School of Computer Science, Carnegie Mellon University, 1992.
[CG87]  E. M. Clarke and O. Grumberg.
Research on automatic verification of finite-state concurrent systems.
In Joe F. Traub, Nils J. Nilsson, and Barbara J. Grozf, editors, Annual Review of Computing Science.
Annual Reviews Inc., 1987.
[Eme90]  E. A. Emerson.
Temporal and modal logic.
In J. van Leeuwen, editor, Handbook of Theoretical Computer Science, Volume B, chapter 16, pages 997-1072.
MIT, 1990.
[ENS92]  K. Erol, D.S.
Nau, and V.S.
Subrahmanian.
On the complexity of domain-independent planning.
In Proceedings of the AAAI National Conference, pages 381-386, 1992.
[Etz93]  Oren Etzioni.
Acquiring search-control knowledge via static analysis.
Artificial Intelligence, 62(2):255-302, 1993.
[GN92]  N. Gupta and D.S.
Nau.
On the complexity of blocksworld planning.
Artificial Intelligence, 56:223-254, 1992.
[HV91]  J. Y. Halpern and M. Y. Vardi.
Model checking vs. theorem proving: a manifesto.
In Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, pages 325-334, 1991.
[MDBP92] S. Minton, M. Drummond, J. Bresina, and A. Phillips.
Total order vs. partial order planning: Factors influencing performance.
In Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, pages 83-82, 1992.
[MR91]  D. McAllester and D. Rosenblitt.
Systematic nonlinear planning.
In Proceedings of the AAAI National Conference, pages 634-639, 1991.
[SBW90]  S. Soderland, T. Barrett, and D. Weld.
The SNLP planner implementation.
Contact bug-snlp@cs.washington.edu, 1990.
[Sel94]  B. Selman.
Near-optimal plans, tractability and reactivity.
In Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, pages 521-529, 1994.
[VB94]  M. Veloso and J. Blythe.
Linkability: Examining causal link commitments in partial-order planning.
In Proceedings of the Second International Conference on AI Planning Systems, 1994.
[YC94]  Q. Yang and A. Chan.
Delaying variable binding committments in planning.
In Proceedings of the Second International Conference on AI Planning Systems, 1994.
Efficient Regular Linear Temporal Logic using Dualization and Stratification CeEsar SaEnchez IMDEA Software Institute, Madrid, Spain Institute for Applied Physics, CSIC, Spain Email: Cesar.Sanchez@imdea.org  AbstractaWe study efficient translations of Regular Linear Temporal Logic (RLTL) into automata on infinite words.
RLTL is a temporal logic that fuses Linear Temporal Logic (LTL) with regular expressions, extending its expressive power to all D-regular languages.
The first contribution of this paper is a novel bottom up translation from RLTL into alternating parity automata of linear size that requires only colors 0, 1 and 2.
Moreover, the resulting automata enjoy the stratified internal structure of hesitant automata.
Our translation is defined inductively for every operator, and does not require an upfront transformation of the expression into a normal form.
Our construction builds at every step two automata: one equivalent to the formula and another to its complement.
Inspired by this construction, our second contribution is to extend RLTL with new operators, including universal sequential composition, that enrich the logic with duality laws and negation normal forms.
The third contribution is a ranking translation of the resulting alternating automata into non-deterministic BuEchi automata.
To provide this efficient translation we introduce the notion of stratified rankings, and show how the translation is optimal for the LTL fragment of the logic.
Keywords-temporal logic; formal verification; formal methods;  I. I NTRODUCTION We study the problem of formal temporal verification of reactive systems, which starts from a specification of the intended behavior in some temporal logic.
In this paper we study the logic RLTL [1], [2] that extends LTL [3], [4] with regular expressions.
The automata-theoretic approach to model checking reduces this verification problem to automata constructions and automata decision problems.
The verification process begins by translating the negation of the formula into an equivalent automaton on infinite words.
This automaton accepts all the traces that violate the specification.
Then, the automaton is composed synchronously with the system description.
Finally, a non-emptiness check reveals whether the system admits some counterexample trace.
Modernly, specifications are translated into alternating automata because their richer structure enables a direct This work was funded in part by the EU project FET IST-231620 HATS, MICINN project TIN-2008-05624 DOVES, CAM project S2009TIC-1465 PROMETIDOS, and by the COST Action IC0901 Rich ModelToolkit-An Infrastructure for Reliable Computer Systems.
JuliaEn Samborski-Forlese IMDEA Software Institute, Madrid, Spain Email: Julian.SF@imdea.org  translation from temporal logics, postponing a potentially exponential blow-up.
Another advantage of alternation is the easy dualization (see Muller and Schupp [5]) provided by the availability of both conjunctive and disjunctive transition relations.
However, to obtain an automaton accepting the complement language of a given automaton, one also needs to complement the acceptance condition (see for example [6]).
For LTL one can first translate a formula (e.g., the negation of the specification) into negation normal form (NNF) by pushing negation to the propositional level, and then use automata with weak acceptance conditions [7], [8], in which the structured of the automaton consists of strongly connected components (SCC) all of which are either accepting or rejecting.
Extensions of LTL with regular expression, like RLTL, do not have negation normal forms.
Hence, a translation of the logical negation operator must be given, precluding the use of weak acceptance conditions.
In this paper we show how to translate RLTL into strong parity automata on words (APW) with a particular internal structure, and study the complementation construction for the resulting APW.
The classical complementation for the parity condition increments in one unit the color assigned to every state, turning an arbitrary sequence of states from accepting into rejecting (and viceversa).
However, if this construction is used to translate the logical negation operator, the total number of colors in the resulting automaton can grow linearly in the size of the formula.
The best known algorithm [9] for translating an APW with n states and k colors into a non-deterministic BuEchi automaton requires 2O(nk log nk) .
In this work, we use a faster complementation construction based on the following intuition.
Traces of runs of the automaton get trapped in an SCC, meaning that all states in a suffix of a given trace belong to some SCC of the automaton.
Hence, it is sufficient for a complementation construction to consider SCCs independently.
This idea enables a translation of RLTL (including the negation operator) into APW using only colors 0, 1 and 2.
These automata are equivalent to alternating Streett automata on words (ASW) with one accepting pair (denoted ASW{1}).
The translation proceeds inductively, building at each step a pair of complement automata.
Then, inspired by this translation we enrich RLTL with new constructs, including universal sequential composition.
The enriched logic admits  a negation normal form.
Finally, we study the translation into non-deterministic BuEchi automata (NBW).
Streett{1} rankings (see [10]) directly allow to translate an ASW{1} into an NBW of size 2O(n log n) .
Here, we use again the particular stratified structure of the ASW{1} automata obtained from RLTL expressions.
Each stratum in the generated ASW{1} is either BuEchi (only colors 1 and 2) or coBuEchi (colors 0 and 1), making these automata equivalent to hesitant automata AHW (see [11]).
We introduce a notion of stratified ranking and show that for all RLTL operators (except one), the ranking of each state can be statically predetermined.
This result produces NBW with size 2O(n log m) where m is the size of the largest stratum that cannot be predetermined.
In particular, all LTL operators generate strata of size 1, which result into NBW of size 2O(n) when using our method to translate LTL into NBW.
The rest of the of paper is structured as follows.
Section II presents the preliminaries, and Section III introduces RLTL.
Section IV shows the translation from RLTL into stratified ASW{1}, and Section V the translation into NBW, including stratified rankings.
Section VI shows our empirical study.
Finally, Section VII concludes.
II.
P RELIMINARIES +  We use B (X ) for the positive Boolean formulas over a set of propositions X .
These formulas are built from true, false and elements of X , using aSS and a".
A minimal model M of a positive Boolean formula I, is a subset of X such that M satisfies I, but no strict subset of M satisfies I,.
For example, given the set Q = {q0 , q1 , q2 , q3 }, the formula I,1 = (q1 aSS q2 ) a" q3 is a B + (Q) formula.
The minimal models of I,1 are {q1 , q2 } and {q3 }.
Given a positive Boolean formula I, there is a dual formula I,e obtained by switching aSS and a", and switching true and false.
For example, the dual of I,1 above is I,e1 = (q1 a" q2 ) aSS q3 , or equivalently in disjunctive normal form I,e1 = (q1 aSS q3 ) a" (q2 aSS q3 ).
The minimal models of I,e1 are {q1 , q3 } and {q2 , q3 }.
An alternating automaton is a tuple A : hIL, Q, I', I, F i where IL is a propositional alphabet, Q is a finite set of states, I' : Q A IL a B + (Q) is the transition function, I a B + (Q) is the initial condition, and F is the acceptance condition.
A frame of an automaton A is the tuple hIL, Q, I', Ii.
A frame is called non-deterministic whenever I, and I'(q, a) for all states q and symbols a, have singleton sets as minimal models.
In other words, I and I'(q, a) are equivalent to disjunctive formulas.
A frame is called universal if I, and I'(q, a) for all states q and symbols a, have a unique minimal model.
In other words, I and I'(q, a) are equivalent to conjunctive formulas.
A frame is deterministic if it is both non-deterministic and universal, that is if both the initial condition and transition functions correspond to true, false or a single successor state.
In general a frame is neither universal nor non-deterministic, but fully alternating.
A transition function I' can be extended to positive Boolean formulas I' : B + (Q)AIL a B + (Q) in the standard way, taking I'(q, a) as the base case and letting I'(true, a) = true, I'(false, a) = false, I'(A a" B, a) = I'(A, a) a" I'(B, a) and I'(A aSS B, a) = I'(A, a) aSS I'(B, a).
Given a word w a ILD , a run of w on a frame F : hIL, Q, I', Ii is a DAG (V, E) with nodes V a Q A N, s.t.
: 1) The set {m | (m, 0) a V } is a minimal model for I.
2) a(q, k) a V , {q 0 | (q 0 , k + 1) a V aSS ((q, k), (q 0 , k + 1)) a E} is a minimal model for I'(q, w[k]).
A trace of a run is an infinite path in the run, or a finite path finishing in an state with no successor in the run.
A non-deterministic frame may admit multiple different runs for a given word, but each run contains a unique trace.
A universal frame admits just one run for each word, but this run may contain multiple traces.
In general a frame admits multiple runs each with multiple traces.
Given a frame F : hIL, Q, I', Ii, the specular frame is e Ii, e where Ie is the dual of I and I'e is the dual Fe : hIL, Q, I', e a) is the dual formula of I'(q, a) for transition function: I'(q, all states q and symbols a.
The graph of a frame has Q as a set of nodes and contains an edge p a q whenever q is in some minimal model of I'(p, a) for some symbol a.
The graphs of a frame and its specular frame are identical, because if q is in some minimal model of I'(p, a) then q is e a).
Therefore, a frame also in some minimal model of I'(p, admits a trace iff its specular frame also admits the trace.
An automaton equips a frame with an acceptance condition, which determines whether an infinite sequence of states is accepting.
A finite trace finishing in a state (q, i) with no successor is accepting.
Given an infinite sequence of states D : q0 , q1 , q2 .
.
.
we let inf(D) be those states from Q that occur infinitely many times in D. In this paper we consider the following acceptance conditions: aV BuEchi: F a Q.
D is accepting when inf(D) aS F 6= a. aV coBuEchi: F a Q.
D is accepting when inf(D) aS F = a. aV parity: F : Q a {0 .
.
.
d}.
D is accepting when max{F (q) | q a inf(D)} is even.
The elements of {0 .
.
.
d} are called colors.
aV Streett: F = {hB1 , G1 i, hB2 , G2 i, .
.
.
, hBk , Gk i}.
D is accepting when for all 1 a$?
i a$?
k, if inf(D) aS Bi 6= a then inf(D) aS Gi 6= a. aV Streett{1}: F = (B, G).
D is accepting when if inf(D)aS B 6= a then inf(D) aS G 6= a. aV hesitant: F a Q, and H = h(S0 .
.
.
, Sk ), <, Iai is a partition of Q induced by the SCCs, ordered by < according to reachability in the automaton graph, and Ia marks each partition as either BuEchi or coBuEchi.
A trace D is accepting when a inf(D) a Si , Si is BuEchi and inf(D) aS F 6= a, or a inf(D) a Sj , Sj is coBuEchi and inf(D) aS F = a.
Observation: A parity acceptance condition with colors {0, 1, 2} corresponds to the Streett condition (B, G) with B = {q | F (q) = 1} and G = {q | F (q) = 2}.
The Streett  pair (B, G) forces (for a trace to be accepting) that if some state marked 1 is visited infinitely often, then some state marked 2 is also visited infinitely often.
The other possible case is that only states that are not marked either B or G states are visited infinitely often.
In this case, the trace is also good for the parity automaton.
We use stratum to refer to an SCC of an automaton graph.
The stratification of hesitant automata given by the partition implies that every infinite trace gets trapped in a stratum Si .
Then, the BuEchi or coBuEchi condition on the stratum determines whether the trace is accepting.
We use ABW (resp.
AcBW, APW, ASW and AHW) to represent BuEchi (resp.
coBuEchi, parity, Streett and hesitant) alternating automata on words.
We use APW{0, 1, 2} for APW that only use colors 0, 1 and 2 and ASW{1} for ASW with only one pair.
When a trace D is accepted according to an acceptance condition F , we write D a acc(F ).
A run of an alternating automaton is called accepting whenever all its traces are accepting.
We say that a word w is in the language of automaton A, and we write w a L(A), whenever there is an accepting run for w on A.
The following definition and theorem relate the notions of specular pairs and complement languages.
Definition 1 Two automata A and B over the same alphabet are a specular pair whenever their frames are specular and for all paths D in the frame graph D a acc(FA ) if and only if D a / acc(FB ).
Theorem 2 (Specular Automata and Complement) Let A and B be a specular pair of automata.
Then L(A) = ILD \ L(B).
Theorem 2 reduces the proof that two automata with dual frames are complements to checking that the traces that can happen have opposite acceptance.
In the next section, we use this result to build an incremental translation, in which we only need to check the new traces added at each step.
III.
T HE L OGIC RLTL Regular Linear Temporal Logic [1], [2] is a formalism for specifying w-regular languages.
The logic is defined in two stages, similarly to PSL [12] or ForSpec [13].
In the first stage we build regular expressions that define finite non-empty segments of infinite words.
In the second stage, we build RLTL expressions to define sets of infinite words.
The syntax of each of these two formalisms contain only a finite collection of constructor symbols.
In particular, the language of RLTL contains no fix-point binders or automata constructors.
Regular Expressions: The basic elements of regular expressions are basic expressions, which are Boolean combinations of a finite set of atomic propositions, whose truth  value is interpreted in a single state.
The syntax of regular expressions is given by the following grammar:    Ia ::= Ia + Ia  Ia ; Ia  Ia a Ia  p where p ranges over basic expressions.
The intended interpretation of the operators +, ; and a are the standard union, concatenation and binary Kleene-star.
Our version of regular expressions describe segments of infinite words.
Given an infinite word w a ILD , a position is a natural number.
We use w[i] for the symbol at position i in word w. Given an infinite word w and two positions i and j, the tuple (w, i, j) is called the segment of the word w between positions i and j.
Note that a segment consists of the whole word w with two tags, not just the sequence of symbols that occur between two positions.
This allows the extension of regular expressions to past expressions [2], but in this paper we only study future expressions.
A pointed word is a pair (w, i) formed by a word w and a position i.
The formal semantics of regular expressions is defined as a binary relation RE between segments and regular expressions, as follows.
Given a basic expression p, regular expressions r and s, and a word w: aV (w, i, j) RE p, whenever w[i] satisfies p and j = i + 1. aV (w, i, j) RE r + s whenever either (w, i, j) RE r or (w, i, j) RE s, or both.
aV (w, i, j) RE r ; s whenever for some k, (w, i, k) RE r and (w, k, j) RE s. aV (w, i, j) RE r a s whenever either (w, i, j) RE s, or for some sequence (i0 = i, i1 , .
.
.
im ) and all k a {0, .., m a 1}, (w, ik , ik+1 ) RE r and (w, im , j) RE s. RLTL: Expressions in Regular Linear Temporal Logic define languages over infinite words.
The key elements of RLTL are the power operators that generalize many constructs from different linear-time logics and calculi.
The syntax of RLTL expressions is defined by the grammar:      D ::= a  D a" D  AZD  Ia ; D  D|IaiiD  D|IaiD where Ia ranges over regular expressions.
The symbol a" stands for union of languages (logical disjunction), and AZ represents language complement (logical negation).
The symbol ; stands for the concatenation of an expression over finite words followed by an expression over infinite words.
The operator a defines the empty language (logical false).
The operators D|IaiiD and its weak version D|IaiD are called the power operators.
The expressions x|riiy and x|riy (read x at r until y, and, respectively, x at r weak-until y) are built from three elements: y (the attempt), x (the obligation) and r (the delay).
For x|riiy to hold, either the attempt holds, or the obligation is met and the whole expression evaluates successfully after the delay.
For x|riiy to hold, the obligation must be met after a finite number of delays.
On the contrary, x|ziy does not require the attempt to be met after a finite  number of delays, allowing the obligation and delay to be repeated ad infinitum.
These two simple operators allow the definition of many other temporal operators.
For example, the strong until operator x U y of LTL can be seen as an attempt for y to hold, or otherwise an obligation for x to be met and a delay of a single step.
Similarly, the D-regular expression xD can be interpreted as a weak power operator having no possible escape and a trivially fulfilled obligation, with a delay indicated by x.
Then, conventional D-regular expressions can describe sophisticated delays with trivial attempts and obligations, while conventional LTL constructs allow complex attempts and obligations but trivial one-step delays.
Power operators generalize both types of constructs.
The completeness of RLTL with respect to D-regular languages follows immediately from the expressibility of D-regular expressions.
In particular, Wolperas example [14] of an Dregular language not definable in LTL (p happening at every even state) can be defined as p|true ; trueia.
The size of an RLTL formula is defined as the total number of its symbols.
The semantics of RLTL relates expressions and pointed words.
Given two RLTL expressions x and y, a regular expression r, and a word w: aV (w, i)  a never holds.
aV (w, i)  x a" y iff either (w, i)  x or (w, i)  y. aV (w, i)  AZx iff (w, i) 6 x. aV (w, i)  r ;y iff for some k, (w, i, k) REr and (w,k)  y. aV (w, i)  x|riiy iff (w, i)  y or for some sequence (i0 = i, i1 , .
.
.
im ), for all k < m: (w, ik , ik+1 ) RE r and (w, ik )  x, and (w, im )  y. aV (w, i)  x|riy whenever either x|riiy or for some infinite seq (i0 = i, i1 , .
.
.
), for all k > 0, (w, ik , ik+1 ) REr and (w, ik )  x.
The semantics of x|riiy establishes that either the obligation y is satisfied at the point i of the evaluation, or there is a sequence of delaysaeach determined by raafter which y holds, and x holds before each individual delay.
The semantics of x|riy also allow the case where y never holds, but x always holds before any number of evaluations of r. Languages are associated with RLTL expressions as usual: a word w a ILD is in the language of an expression x, denoted by w a L(x), whenever (w, 0)  x.
Using [10], [9] to translate APW into NBW would produce 2 NBW with 2O(n log n) states for the old translation and 2O(n log n) states for the one presented here.
In Section V below we show how to reduce it further to 2O(n log m) (where m is the size of the largest stratum), and 2O(n) for the LTL fragment of RLTL.
The translation is described inductively.
For every operator, we show how to compute the specular automata pair, starting from the automata pairs for the sub-expressions.
In particular, assume that (Ax , Ax ) and (Ay , Ay ) are specular pairs for RLTL expressions x and y and that Nr is an NFA for regular expression r. We use q aa Fr for aq a Qr and I'(q, a) aS Fr 6= a,a and we use q 6aa Fr for aq a Qr and I'(q, a) aS Fr = a.a Empty: The pair (Aa , Aa ) has state set Q = {q0 }, and initial conditions I = q0 and I = q0 .
The acceptance conditions are F (q0 ) = 0 and F (q0 ) = 0.
The transition relations are I'(q0 , ) = false and I'(q0 , ) = true.
This choice of I' and I' allow all traces to be accepting for Aa and no trace to be accepting for Aa , so Aa accepts all words and Aa accepts no word, as desired.
Disjunction: The state space of Axa"y : hIL, Q, I', I, F i and Axa"y : hIL, Q, I', I, F i are Q = Qx aS Qy .
The initial conditions are I = Ix a" Iy and I = Ix aSS Iy .
The transition functions and acceptance condition are: if I'(q, a) I'(q, a) F (q) F (q) q a Qx I'x (q, a) I'x (q, a) Fx (q) Fx (q) q a Qy I'y (q, a) I'y (q, a) Fy (q) Fy (q) Sequential: The state space of both Ar;x : hIL, Q, I', I, F i and Ar;x : hIL, Q, I', I, F i are Qr aSQx .
The initial conditions are I = Ir and I = Ier .
The transition function is: if I'(q, a) I'(q, a) I'er (q, a) q 6aa Fr I'r (q, a) q aa Fr I'r (q, a) a" Ix I'er (q, a) aSS Ix q a Qx I'x (q, a) I'x (q, a) The acceptance condition is: for q a Qx then F (q) = Fx (q) and F (q) = Fx (q).
For q a Qr then F (q) = 1 and F (q) = 0.
Complementation: Consider now an RLTL subexpression x, with specular pair (Ax , Ax ).
Since (w, i)  Ax if and only if (w, i) 6 Ax , it follows that (Ax , Ax ) is a specular pair for AZx.
IV.
RLTL INTO APW USING S PECULAR PAIRS  Power: Let q0 be a fresh state, not present in Qx or Qy .
The state spaces of Ax|riiy : hIL, Q, I', I, F i and Ax|riiy : hIL, Q, I', I, F i are Qr aSQx aSQy aS{q0 }.
The initial conds.
are I = q0 and I = q0 .
For the transition relation: if I'(q, a) I'(q, a) q = q0 I'(Iy a" (Ix aSS Ir ), a) I'(Iy aSS (Ix a" Ir ), a) q 6aa Fr I'r (q, a) I'er (q, a) q aa Fr I'r (q, a) a" q0 I'er (q, a) aSS q0 q a Qx I'x (q, a) I'x (q, a) q a Qy I'y (q, a) I'y (q, a)  We present here a translation of RLTL expressions into APW{0, 1, 2} based on Theorem 2.
The main idea is to generate, at each step, a specular automata pair with the first automaton accepting the same language as the expression.
By duality, the specular automaton accepts the complement language.
Handling logical negation becomes trivial: one simply needs to switch the elements of the pair.
A previous translation of RLTL presented in [2] needed n colors (n being the size of the formula) instead of 3.
For the acceptance condition: if F (q) F (q) q a Qx Fx (q) Fx (q) Fy (q) Fy (q) q a Qy 0 q a Qr or q = q0 1 Even though the frame of these automata could have been defined without introducing q0 (by cleverly choosing I and I'), the introduction of q0 is justified by the necessity to distinguish in the acceptance condition traces that visit q0 infinitely often versus traces that get trapped in Qr .
Weak Power: Again, the state spaces of both Ax|riy : hIL, Q, I', I, F i and Ax|riy : hIL, Q, I', I, F i is Qr aSQx aSQy aS {q0 } for a fresh state q0 .
For the initial condition I = q0 and I = q0 .
The transition relation and acceptance condition are exactly the same as for the Power operator except for the following cases: ( ( 1 if q = q0 2 if q = q0 F (q) = F (q) = 0 if q a Qr 1 if q a Qr Theorem 3 Let D be an RLTL expression and AD be the automaton obtained using the construction described in this section.
Then, L(D) = L(AD ).
The proof of Theorem 3 is greatly simplified by Theorem 2 because at every stage the construction builds automata with specular frame, so one only needs to reason about the acceptance of traces that get trapped in SCCs formed by the freshly added states.
The construction also satisfies two important properties: 1) each stage introduces a new stratum (SCC) that cannot be reached from strata added in previous stages.
That is, traces that move to the automaton of a sub-expression do not visit the stratum added for the containing expression.
2) The stratum at each stage is decorated only with color 0 (an accepting stratum), only with color 1 (a rejecting stratum), only with colors 0 and 1 (a coBuEchi stratum) or only with colors 1 and 2 (a BuEchi stratum).
These two observations imply that the automaton has the particular structure of a stratified ASW{1} or equivalently of hesitant automaton AHW.
We show in Section V how to efficiently translate these automata into NBW using a refined version of Streett rankings.
A Universal Sequential Operator: In the previous construction, we observe that the specular automaton for the sequential operator r ; x describes the set of traces in which aall occurrences of r (if any) are followed by failing occurrences of xa.
This observation inspires the introduction of the universal sequential operator r AV x, whose semantics is: aV (w, i)  r AV x iff forall k s.t.
(w, i, k) RE r, (w, k)  x.
The translation of r AV x is precisely Ar;AZx above, and the specular automaton is exactly Ar;AZx .
Note that the stratum  corresponding to r in ArAVx has a universal frame, obtained by dualizing the non-deterministic transition relation of Nr .
The duality laws AZ(r ; x) aA r AV AZx and AZ(r AV x) aA r ; AZx hold immediately.
Universal Power Operators: Similarly, we define new operators xkriiy and xkriy, duals of x|riy and x|riiy, respectively.
These new operators force repetitions to hold at all possible delays, instead of at some possible delay.
The semantics are: aV (w, i)  xkriiy iff (w, i)  y and for all seq (i = i0 , .
.
.
, im ) with (w, ik , ik+1 ) RE r, either (w, ij )  x for some j a$?
k or (w, ik+1 )  y, and for all infinite seq (i = i0 , i1 .
.
.)
with (w, ik , ik+1 ) RE r and (w, ik )  y, there is an m with (w, im )  x. aV (w, i)  xkriy iff (w, i)  xkriiy, or (w, i)  y and for all k and j with (w, i, j) RE rk then (w, j)  y.
The translation of xkriiy is Ax|riy (the dual being Axkriiy = Ax|riy ), and the translation of xkriy is the pair (Ax|riiy , Ax|riiy ).
The following duality laws hold: AZ(x|riiy) aA AZxkriAZy  AZ(x|riy) aA AZxkriiAZy  AZ(xkriy) aA AZx|riiAZy  AZ(xkriiy) aA AZx|riAZy  (1) (2)  Finally, x aSS y is defined with translation (Axa"y , Axa"y ).
The deMorgan laws hold: (AZAZx aA x), (AZ(x a" y) aAAZx aSSAZy) and (AZ(x aSS y) aAAZx a"AZy).
Orienting these duality laws from left to right allows to push logical negation AZ to the propositional level, so RLTL extended with these operators admits a negation normal form.
Note that this negation normal form is obtained after the translation by specular pairs.
It does not follow immediately that the existence of such a normal form enables a translation into automata with weak acceptance condition, because one has to show translations for the new operators, including essentially all elements of pairs in the translation of RLTL presented above.
V. F ROM S TRATIFIED ASW{1} INTO NBW This section shows how to translate the alternating automata obtained in Section IV into NBW.
We first revisit the notion of Streett ranking from [10], which in turn is based on the notion of coBuEchi ranking [15].
Then, we refine rankings to exploit the stratification of the automata obtained as a result of the translation from RLTL.
We first show a general translation of ASW{1} into NBW.
Rankings for ASW{1}: We use [k] an abbreviation for the set {0 .
.
.
k}.
The following definitions assume a given ASW{1} automaton A with n states, acceptance condition (B, G), a word w a ILD and a run G : (V, E) of A on w. Definition 4 An S{1}-ranking is a function f : V A N a [2n] that satisfies: (i) if q a B then f (hq, li) is even, (ii) for all hq, li a hq 0 , l0 i in E, either q a G or f (hq, li) aL f (hq 0 , l0 i).
It follows that for every path D on a run DAG G, either D visits infinitely often G states or, after some prefix, condition (ii) applies continuously.
Hence, since the image of f is bounded, the value of f converges to a value: there is a number l, such that, for every l0 > l, f (D(l0 )) = f (D(l)).
The following definition of odd S{1}-ranking relates the convergence to an odd value with the fact that B states are visited only finitely often.
Then, the construction of the NBW below is justified by Lemma 6.
Definition 5 (odd S{1}-ranking) An S{1}-ranking is odd whenever, for every path D of G, either (i) D visits infinitely often G states, or (ii) f converges to an odd value on D. Lemma 6 G is an accepting run iff there is an odd S{1}-ranking for G. An equivalent NBW: We describe here the translation from ASW{1} into NBW.
The main idea is to encode in the states of the NBW cuts of a run DAG of the ASW{1}, decorated with enough information to check whether an oddranking exists.
In particular, each state of the alternating automaton present in a given state of the NBW is labeled with a ranking value.
This annotation must respect the definition of ranking (Def.
4).
Additionally, the set of states of the ASW{1} that form a state of the NBW are partitioned into those that owe an improvement in the ranking (either a visit to a G state or a decrease in the ranking), and those that already showed improvement.
Membership to the owe set is propagated, so an accepting state is one in which all constituent states have seen some progress since the last accepting state.
After an accepting state, the owe set is reset.
Formally, we start from an ASW{1} automaton A : hIL, QA , IA , I'A , {(B, G)}i and we build an NBW N : hIL, QN , IN , I'N , FN i as follows: aV QN contains elements of the form (S, O, f ) where S a QA is a subset of states of A, O a S, and f : S a [2n] is a function that satisfies: Q1.
if q a B then f (q) is even.
aV IN contains all those (M, O, f ) a QN where I1.
M is a minimal model of IA and O = {q a M |qa / G and f (q) is even}.
aV FN = {(S, O, f ) a QN | O = a}.
Q 0 0 0 aV I'N : QN A IL a 2 N , such that (S , O , f ) a I'N ((S, O, f ), a) whenever there is one minimal model Mq of I'A (q, a) for each q a S satisfying: D1.
S 0 = aSqaS Mq , D2.
For all p a S 0 , the rank annotation f 0 (p) a$?
min{f (q) | q a pred(p) \ G} where pred(p) = {q a S | p a Mq } denotes the set of predecessors of p. D3.
O0 is given as follows.
Let p a S 0 \ G, we have aV If O = a then p a O0 iff f 0 (p) is even.
aV If O 6= a then p a O0 iff f 0 (p) = f (q) for some q a (pred(p) aS O).
The states of N consist of a set S representing elements of a cut of a run DAG of A.
The function f represents an S{1}-ranking, where Q1 guarantees that no B node receives an odd value, and D2 guarantees the non-increasing condition of rankings.
Condition D1 ensures that successor states of N correspond to legal successor cuts of a run of A.
Finally, condition D3 ensures that O contains those vertices of the run DAG that have not seen progress for some path leading to them, where progress is defined as visiting a G state, or experiencing a decrease in f .
A reset of this check is represented by a final state, which can happen only when all paths to all states contain some progress, as captured by FN .
Finally, I1 captures that the initial states of N correspond to initial cuts of runs of A.
All these facts imply that a successful run DAG of A is matched by a successful run of N. Theorem 7 Let A be an ASW{1} and N the corresponding NBW.
Then w a L(A) if and only if w a L(N ).
The automaton obtained can be easily pruned with one simple observation: if there is an odd S{1}-ranking, then there is an odd S{1}-ranking where all decreases (according to D2) only drop to the highest legal value.
That is: ( M or M a 1 if p a /B 0 f (p) = M or M a 2 if p a B where M = min{f (q) | q a pred(p) \ G}.
This observation reduces the guessing in f to only two possibilities, providing a more efficient translation.
The next paragraphs exploit the internal structure of stratified ASW{1} automata to introduce a faster solution, specific for the particular case of AHW.
Rankings for Stratified ASW{1}: Consider a stratified ASW{1}.
This is an automaton for which Q is divided into strata (S1 , .
.
.
, Sk ) ordered according to <, and each stratum is labeled by a function Ia as either BuEchi (all states are either B or G) or coBuEchi (no state is G).
The stratification structure implies that for every q a Si and successor p with p a Sj , either Sj = Si or Sj < Si .
Remark: This automaton is equivalent to an AHW with H = h(S1 , .
.
.
, Sk ), <, Iai and F =  [ i  {Si aS G | if Si is BuEchi} aS  [ {Si aS B | if Si is coBuEchi} i  We use mj = |Sj | to refer to the number of states in stratum Sj .
We first define the notion of stratified S{1}-ranking: Definition 8 A stratified S{1}-ranking is a family of functions fj : Sj A N a [2mj ] that satisfies: (i) if q a Sj aS B then fj (hq, li) is even, (ii) for every hq, li a hq 0 , l0 i in E with q, q 0 a Sj , then fj (hq, li) aL fj (hq 0 , l0 i), unless q a G. Intuitively, a stratified ASW{1} ranking is like an ASW{1} ranking except values need not decrease when  moving across strata.
Due to the stratification, every trace of a run gets trapped in a stratum of the automaton.
Once the trace converges to a stratum, either the trace visits infinitely many good nodes, or the ranking converges to a single value.
Again, the notion of odd ranking captures whether the suffix traces are accepting.
Definition 9 A stratified S{1}-ranking is odd whenever, for every infinite path D of G, either (i) D visits infinitely often G states, or (ii) D gets trapped in stratum Sj and fj converges to an odd value on D. The following lemma justifies the construction of NBW using stratified rankings.
Lemma 10 G is an accepting run iff there is a stratified odd S{1}-ranking for G. Stratified rankings drastically limit the guessing that is necessary in the construction of the states of the NBW, because each ranking is local to the stratum under consideration.
The following choices produce a good ranking for stratum Sj , if there is one such a good ranking G1.
If Sj is an accepting stratum and qj a Sj , fj (qj ) = 1.
G2.
If Sj is a rejecting stratum and qj a Sj , fj (qj ) = 2.
G3.
If Sj is BuEchi, then assign fj (qj ) = 2 to qj a B, and fj (qj ) = 1 to qj a G. G4.
If Sj is coBuEchi then fj (qj ) a [2mj ].
Note that this restriction eliminates the guessing except for coBuEchi strata, and consequently ranking guessing only happens to the states of Nr in expressions xkriiy.
In terms of the LTL fragment, all delays are one step so the size of |Nr | = 1 and hence the maximum size of the coBuEchi strata is 1.
In fact, for LTL sub-expressions of the form xkriiy, Nr consists of a single B state, which can be assigned value 2.
Consequently, following the steps in this paper LTL expressions get translated into NBW of size 2O(n) .
An equivalent NBW using Stratified Rankings: We refine the construction for general ASW{1} rankings, limiting the guesses using G1-G4.
Also, only predecessors within the same stratum are considered when computing f : Q1s.
if q a Sj aS B then fj (q) is even.
D2s.
fj0 (p) a$?
min{fj (q) | q a pred(p) \ G} where pred(p) = {q a Sj | p a Mq } now only considers predecessors from the same stratum.
D3s.
O0 is given as follows.
Let p a Sj0 \ G, we have aV If O = a then p a O0 iff fj0 (p) is even.
aV If O 6= a then p a O0 iff fj0 (p) = fj (q) for some q a (pred(p) aS O aS Sj ).
Theorem 11 Let A be a stratified ASW{1} and N the corresponding NBW using stratified rankings.
Then w a L(A) if and only if w a L(N ).
VI.
E MPIRICAL E VALUATION This section reports the result of an empirical evaluation of the translation algorithms presented above.
The evaluation was performed using a sequential implementation written in OCaml, available online at [16].
The running times reported in Fig.
1 were obtained using an Intel Core2 @ 2.83GHz with 8GB of RAM running a 64 bit Linux kernel.
Fig.
1 compares the number of states and the running time used to compute explicit NBW representations of two families of formulas (and their negation), for i = 8, 11, 17, 20.
These choices are inspired by [8]:  aV Ai = p1 U (p2 U (.
.
.
U pi ) .
.
.
.
The expression Ai is equivalent to the RLTL expression  p1 |trueii p2 |trueii.
.
.
.
 5 5 5 aV Bi = p1 |true ii p2 |true ii.
.
.
, where true stands for a five instant delay true ; true ; true ; true ; true.
These are not expressible in LTL.
The table illustrates that the general ASW{1} ranking is only practical for the smallest cases.
Limiting the guessing to the highest ranks allows to handle slightly larger formulas.
The stratified ranking translation results in a dramatic improvement, comparable to state of the art LTL translators, particularly considering that our prototype does not use simulations or handle propositional alphabets (only discrete alphabets).
Simulation reductions have been reported [8] to be a very effective method to reduce the size of the NBW generated, but this optimization is currently ongoing work.
VII.
C ONCLUSIONS AND F UTURE W ORK This paper has presented a novel translation from the logic RLTL into alternating parity automata using only colors 0, 1 and 2, based on a bottom-up construction of specular pairs accepting complement languages.
Inspired by the duality in the translation we introduce universal sequential operators that enrich the logic with negation normal forms.
We also show that the resulting automata enjoy some stratified structure in their transition relation that makes all their strata purely BuEchi or coBuEchi.
These automata are equivalent to hesitant automata.
Then, we study translations of the resulting automata into NBW.
The main result is the specialization of Street rankings to stratified automata to obtain a more efficient ranking translation.
Unlike [11] our construction preserves the alphabet between the alternating automaton an the NBW.
We are currently investigating alternative algorithms for model-checking RLTL specifications based on bounded model checking [17], antichains [18] and IC3 [19].
R EFERENCES [1] M. Leucker and C. SaEnchez, aRegular linear temporal logic,a in Proc.
of ICTACa07, ser.
LNCS, vol.
4711.
Springer, 2007, pp.
291a305.
[2] C. SaEnchez and M. Leucker, aRegular linear temporal logic with past,a in Proc.
of VMCAIa10, ser.
LNCS, vol.
5944.
Springer, 2010, pp.
295a311.
size A8 A11 A17 A20 AZA8 AZA11 AZA17 AZA20 B8 B11 B17 B20 AZB8 AZB11 AZB17 AZB20  APW time(s) 7 0.048 10 0.172 16 0.936 19 1.796 7 0.048 10 0.172 16 0.940 19 1.792 35 0.268 50 1.084 80 5.064 95 10.041 35 0.268 50 0.908 80 5.072 95 9.753  Figure 1.
NBW (direct) size time(s) 93 0.128 192 0.504 498 3.680 705 8.149 142 0.252 292 1.140 754 10.545 1066 25.718 2417 50.103 4952 360.571 12722 1h56m 17957 8h32m 3642 209.157 7452 26m56s 19122 18h15m 26982 58h8m  NBW (max2) size time(s) 93 0.100 192 0.336 498 1.700 705 3.184 100 0.100 202 0.336 514 1.688 724 3.160 2417 5.936 4952 26.846 12722 217.698 17957 598.129 2452 5.704 5002 25.106 12802 220.762 18052 674.070  NBW (strat) size time(s) 9 0.052 12 0.176 18 0.952 21 1.816 9 0.052 12 0.172 18 0.948 21 1.884 37 0.296 52 0.952 82 5.200 97 9.897 37 0.300 52 0.956 82 5.192 97 9.905  Number of states and running time to compute an APW{0, 1, 2} and an NBW.
[3] A. Pnueli, aThe temporal logic of programs,a in Proc.
of FOCSa77.
IEEE CS Press, 1977, pp.
46a67.
[4] Z.
Manna and A. Pnueli, Temporal Verification of Reactive Systems.
Springer-Verlag, 1995.
[5] D. E. Muller and P. E. Schupp, aAltenating automata on infinite trees,a Theoretical Computer Science, vol.
54, pp.
267a276, 1987.
[6] W. Thomas, aComplementation of BuEchi automata revisited,a in Jewels are Forever, Contributions on TCS in Honor of Arto Salomaa.
Springer, 1999, pp.
109a120.
[7] O. Kupferman and M. Y. Vardi, aWeak alternating automata are not that weak,a ACM Transactions on Computational Logic, vol.
2, no.
3, pp.
408a429, 2001.
[8] P. Gastin and D. Oddoux, aFast LTL to BuEchi automata translation,a in Proc.
of CAVa01, ser.
LNCS, vol.
2102.
Springer, 2001, pp.
53a65.
[9] C. Dax and F. Klaedtke, aAlternation elimination by complementation,a in Proc.
of LPARa08, ser.
LNCS, vol.
5530.
Springer, 2008, pp.
214a229.
[10] O. Kupferman and M. Y. Vardi, aComplementation constructions for nondeterministic automata on infinite words,a in Proc.
of TACASa05, ser.
LNCS, vol.
3440.
Springer, 2005, pp.
206a221.
[11] O. Kupferman, N. Piterman, and M. Y. Vardi, aExtended temporal logic revisited,a in Proc.
of CONCURa01, ser.
LNCS, vol.
2154.
Springer, 2001, pp.
519a535.
[12] D. Fisman, C. Eisner, and J. Havlicek, Formal syntax and Semantics of PSL: App.
B of Accellera Property Language Ref.
Manual, Ver.
1.1, March 2004.
[13] A. Armando, S. Ranise, and M. Rusinowitch, aA rewriting approach to satisfiability procedures,a Information and Computation, vol.
183, no.
2, pp.
140a164, 2003.
[14] P. Wolper, aTemporal logic can be more expressive,a Information and Control, vol.
56, pp.
72a99, 1983.
[15] O. Kupferman and M. Y. Vardi, aFrom complementation to certification,a in Proc.
of TACASa04, ser.
LNCS, vol.
2988.
Springer, 2004, pp.
591a606.
[16] http://software.imdea.org/rounded/.
[17] A. Biere, A. Cimatti, E. M. Clarke, and Y. Zhu, aSymbolic model checking without BDDs,a in Proc.
of TACASa99, ser.
LNCS.
Springer, 1999, pp.
193a207.
[18] M. D. Wulf, L. Doyen, N. Maquet, and J.-F. Raskin, aAntichains: Alternative algorithms for LTL satisfiability and model-checking,a in Proc.
of TACASa08, ser.
LNCS, vol.
4693.
Springer, 2008, pp.
63a77.
[19] A. R. Bradley, aSAT-based model checking without unrolling,a in Proc.
of VMCAIa11, ser.
LNCS, vol.
6538.
Springer, 2011, pp.
70a87.
A PPENDIX This section shows a self-contained proof of Theorem 2.
Positive Boolean Formulas:: Every positive boolean formula can be expressed in disjunctive normal form, as disjunction of conjunctions of propositions.
Given a positive boolean formula I, there is a dual formula I,e obtained by switching aSS and a", and switching true and false.
Some easy properties of dual formulas are: e and for every Proposition 12 (Duals) For every I, and I,, M a Mod (I,): e M aS M 0 6= a.
1) For every M 0 a Mod (I,), e with q a M 0 .
2) Let q a M .
There is an M 0 in Mod (I,) For example, the dual of I,1 above is I,e1 = (q1 a" q2 ) aSS q3 , or equivalently in disjunctive normal form I,e1 = (q1 aSS q3 ) a" (q2 aSS q3 ).
The minimal models of I,e1 are {q1 , q3 } and {q2 , q3 }.
A choice function is a map f that chooses, for a model M of I, an element of M , i.e., f : Mod (I,) a X such f (M ) a M .
Some interesting properties of choice functions follow: Proposition 13 (Choice Functions) Let I, be a formula and I,e its dual.
Then e 1) If f is a choice function for I,, then Img f a Mod (I,).
2) If M a mod (I,) then there is a choice function f of I,e such that Img f = M .
Proof: We prove 13.1 first.
Consider I, in disjunctive normal form.
Each child subexpression of the root expression corresponds to a conjunction of states that form a model.
The choice function f chooses one state from each model of I,.
Expressing I,e dualy, each child subexpression of I, is a disjunction of the corresponding set of states.
Hence, the element that f chooses in each child  S satisfies the corresponding disjunction, and Img f = M aMod(I,) f (M ) is e a model of I,.
We now show 13.2.
Let M be a minimal model of I,.
Consider an arbitrary choice function f for I,e with: f (M 0 ) = q for some q a M aS M 0 .
By Prop.
12.1 for any M 0 there is one such q, so f is well defined, and by construction Img f a M .
By Prop.
13.1 Img f is a model of I,, and since M is a minimal model it has no proper sub-model, so Img f = M .
 Automata and Games: We show now that specular automata accept complement languages, using game theory.
From a given automaton A and a word w, we create a parity game called a word game as a tuple G(A, w) :  hVA , VP , EA , EP , f i where: VA = Q A D  VP = {(M, q, i) | M a Mod (I'(q, w[i]))} aS {(M, AV, 0) | M a Mod (I)}  EA = (q, i) a (M, q, i) for each M a Mod (I'(q, w[i]))  EP = (M, q, i) a (q 0 , i + 1) for q 0 a M  The game is played by two players: Automaton (A) and Pathfinder (P ).
The set of positions V = VA aS VP is partitioned into positions in which A plays and those in which P plays.
The game begins by A choosing a model of I, which determines the initial position (M, AV, 0) (here AV represent an irrelevant state).
The legal moves of the game are captured by the relation E = EA aSEP which correspond to A choosing a model from a VA position, and P choosing the next successor from a given model from a VP position.
A play is an infinite sequence of positions D : V0 v0 V1 v1 .
.
.
with V0 being an initial position, vi obtained from Vi by a P move, and Vi+1 obtained from vi by an A move.
The map f : V a {0 .
.
.
d} determines the outcome of a play.
We define the trace of a play D : V0 v0 V1 v1 .
.
.
as the sequence of states trace(D) : p0 p1 .
.
.
obtained by projecting the first component of the VP positions of the play (i.e., vi = (pi , i)).
The following follows directly from the definition: Proposition 14 Every trace of a play of G(A, w) is also a trace of some run of A on w. As for parity automata the outcome of a play is determined by the highest color that is seen infinitely often in the play.
Player A wins play D whenever: max{f (q) | q a inf(trace(D))} is even Otherwise, P wins play D. A strategy for player A is a map DA : (V a VA aS ) a V , that maps histories of positions into moves.
Here,  denotes the empty sequence of positions, to let player A choose an initial state in the game.
A memoryless strategy simply takes into account the last position: DA : VA aS  a V .
Since parity games are memoryless determined it is enough to consider memoryless strategies.
Similarly, a strategy for player P is a map DP : VP a V .
A play D : V0 v0 V1 v1 .
.
.
is played according to strategy DA whenever the initial position is V0 = DA () and all moves of A are played according to it Vi = DA (vi ).
A strategy DA is winning for player A whenever all plays played according to DA are winning for A. Memoryless determinacy of parity games guarantees that either player A has a memoryless winning strategy or player P has a memoryless winning strategy.
We say that D is a G AV DA play whenever D is played in G according to DA .
We restrict our attention to strategies for A that choose minimal models, and strategies for P that are proper choice functions.
This is not a drastic restriction.
Clearly, if there  is a winning strategy for A that does not choose a minimal model, then any strategy that chooses a smaller minimal model is also winning.
This is because the set of plays is reduced, and all plays in the unrestricted set are winning for A.
Similarly, if DP is a winning strategy for P , then restricting its moves to be a proper choice functions (by restricting the image) also gives a winning strategy.
In both cases, the set of successor moves is restricted but still confined within winning regions.
This lemma is essentially Prop.
2 from [6], where complementation of weak alternation automata by dualization is studied.
of the form (q, i) a (q 0 , i + 1) for all q 0 a M .
We have to show that D is successful run.
We show by induction that all traces of D correspond to plays in G(A, w) played according to DA .
For the base case (q, 0) is the initial state of the trace.
By construction (q, 0) a DA () so (q, 0) is a possible choice of player P , and consequently a play prefix.
For the inductive case, assume that trace prefix (q0 , 0) .
.
.
(qi , i) is a play prefix, and let (qi , i) a (qi+1 , i + 1) be in ED .
By construction DA (qi , i) contains position (qi+1 , i + 1) so player P can again move to it.
This shows that the arbitrary trace of D correspond to a play played according to DA .
  Lemma 15 w a L(A) if and only if A has a winning strategy in G(A, w).
Specular Pairs and Complementation: We show now that specular automata accept complement languages.
In the rest of the section we let A and Ae be a specular automata e : G(A, e w) be the pair, w be a word and G : G(A, w) and G corresponding word games.
First we need some preliminary definitions.
Proof: Assume w a L(A) and let D : (VD , ED ) be a successful run of w on A.
We first build a strategy DA for A on G(A, w) and then show that DA is winning: DA () = (M0 , AV, 0)  with M0 = {q | (q, 0) a VD }  DA (q, i) = (M, q, i + 1)  with M = {q 0 | (q, i) a (q 0 , i + 1) a ED } The set M in (M, q, i + 1) is a model of I'(q, i) because D is a run.
For positions (q, i) that do not appear in the run D, the strategy DA (q, i) = (M, q, i + 1) can assign any model M in Mod (I'(q, w[i])).
This model is not relevant because no play played according to DA will visit these states.
Consider now an arbitrary play D : V0 v0 V1 v1 .
.
.
of G(A, w) played according to DA .
We show by induction that trace(D) : p0 p1 .
.
.
is a trace of D. aV base: By construction M0 is the set of initial positions of D. Since p0 , chosen by player P , is v0 a M0 , then v0 is a prefix of a trace of run D. aV induction step: assume p0 .
.
.
pi is a prefix of some trace in D, so (pi , i) is in VD .
Hence, DA (pi , i) = (M, pi , i + 1) for M being the set of successors of (pi , i) in ED .
Consequently pi+1 = (q, i + 1) for some (pi , i) a (pi+1 , i + 1) in ED , so v0 .
.
.
vi vi+1 is a longer prefix of a trace of run in D. This shows that trace(D) is a trace of the run D. Now, since D is a successful run all its traces must be accepting, and then: max{F (q) | q a inf(trace(D)} is even, which shows that DA is a winning strategy for G(A, w).
We now show the other direction: we start from a winning strategy DA for A in G(A, w) and show that there is a successful run D of w on A.
Let (M, AV, 0) = DA ().
Then we let VD contain (q, 0) for all q a M .
Note that M is a minimal model of I.
Now, consider an arbitrary position (q, i) and let (M, q, i+1) be DA (q, i).
We add to ED all pairs  Definition 16 We say that strategies DA (for A in G) and e are duals whenever both: DeP (for P in G) e AV DP play D aV for every G AV DA play D there is a G e s.t.
trace(e D ) = trace(D).
e AV DP play D aV for every G e there is a G AV DA play D s.t.
trace(e D ) = trace(D).
Theorem 17 (Dual Strategies) The following holds: (1) For every strategy DA for A in G, there is a dual strategy e DeP for P in G. (2) For every DP for P in G, there is a dual strategy DeA e for A in G. Proof: We prove the two statements separately: (1): Let DA be a strategy for A in G. This strategy DA is characterized by DA () = (M0 , AV, 0) where M0 a mod (I) DA ((q, i)) = (M, q, i + 1) where M a mod (I'(q, w[i])) By Prop.
13.1 there are choice functions satisfying e aQ fM0 : Mod (I) e a)) a Q fhM,q,ai : Mod (I'(q,  Img fM0 = M0 Img fhM,q,ai = M  Moreover, these functions are proper choice functions.
We e as follows: now define the dual strategy DeP for P in G DeP ((N0 , AV, 0)) = (fM0 (N0 ), 0) DeP ((N, q, i + 1)) = (fhM,q,ai (N ), q, i + 1) where M is the move of A in G from (q, i): DA (q, i) = (M, q, i + 1), and a = w[i].
Our choice of choice functions fhM,q,ai guarantees that for every move of player P from e that, when followed M , there is a move for player A in G by fhM,q,ai results in the same state.
The properties of fM0 and fhM,q,ai ensure that the strategy DeP is proper.
We are ready to show that for every G AV DA play there is e AV DP play with the same trace, and vice-versa.
aG  aaa Consider an arbitrary GAVDA play D : V0 v0 V1 v1 .
.
., and let DA () = (M0 , AV, 0) and DA (vi ) = (Mi+1 , qi , i + 1).
We use qi for vi = (qi , i).
Note that qi+1 a Mi+1 because all moves of player P in D are legal moves.
We e AV DP play D f0 , ve0 , V f1 , ve1 .
.
.
as follows: create the G e:V f a V0 = (N0 , AV, 0) where N0 is such that fM0 (N0 ) = q0 .
One such N0 exists since Img fM0 = M0 and q0 a M0 (recall that (q0 , 0) is the result of a move of P in G from (M0 , AV, 0)).
e the position a From (qi , i), player A chooses in G (Ni+1 , qi , i + 1), where Ni+1 is chosen such that fhMi+1 ,q,w[i]i = qi+1 .
By induction, we show that vi = vei .
First, ve0 = DeP ((N0 , AV, 0)) = (fM0 (N0 ), 0) = (q0 , 0) = v0 .
Now, assume that for some i, vi = vei .
Then, Vei = (Ni+1 , qi , i+1), and Vi = DA (qi , i) = (Mi+1 , qi , i+1).
Now, vei+1 = DeP (Vei ) = DeP ((Ni+1 , qi , i + 1)) = = (fhMi+1 ,qi ,w[i]i (Ni+1 ), i + 1) = = (qi+1 , i + 1) = = vi+1 .
Hence, trace(D) = trace(e D ).
e AV DP play D aaa Consider an arbitrary G e : Ve0 ve0 Ve1 ve1 .
.
., and let qi and Ni be such that: vei = (qi , i) Ve0 = (N0 , AV, 0) Vei+1 = (Ni+1 , qi , i + 1) e AV DP play, it satisfies that Since D e is a G vei+1 = DeP (Vei+1 ) = (fhMi+1 ,qi ,w[i]i (Ni+1 ), i + 1) where Mi is obtained from DA (qi , i) = (Mi+1 , i + 1).
Now, we define the play D : V0 v0 V1 v1 .
.
.
as follows.
First the move for A is played according to DA : V0 = DA () = (M0 , AV, 0)  Vi+1 = DA (vi )  with g0 : Mod (I) a Q e Img g0 a mod (I)  gq,i : Mod (I'(q, w[i])) a Q e w[i])) Img gq,i a mod (I'(q,  (3)  e as follows: We define the strategy DeA for A in G DeA () = Img g0  DeA ((q, i)) = Img gq,i  By (3), DeA is well defined.
We show now that DeA and DP are dual strategies.
First, consider (q, i) an arbitrary state and (M, q, i) a legal move for player A in G. Player P will move to (q 0 , i + 1) = DP ((M, q, i)) with e player A will move from q 0 = gq,i ((M, q, i)).
In G, e to (q, i) into (Img gq,i , q, i).
We let player P move in G 0 0 (q , i + 1), which is legal, since q a Img gq,i .
Consider e now an arbitrary state (p, i) and the move of A in G: DeA ((p, i)) = (Img gp,i , p, i), and consider an arbitrary legal move for P , (p0 , i + 1), hence p0 a Img gp,i .
Consequently, there is an M a Mod (I'(p, w[i])) such that gp,i ((M, p, i)) = p0 .
Let A choose (M, p, i) as the move from (p, i), which is a legal move.
Then, playing from (M, p, i) in G according to DP , the resulting state is (p0 , i + 1).
This shows that DA and DeP are dual strategies.
It is important to note that the moves of the players playing against the strategies are not restricted to follow proper strategies (give minimal models or be proper choice functions).
Still, DA is winning precisely whenever DP is.
 The following theorem follows directly from Lemma 15 and Theorem 17.
This theorem allows to reason about complementation simply by reasoning about traces of two automata with dual frames.
Then, we let the moves of P to be: v0 = (q0 , 0)  vi+1 = (qi+1 , i + 1)  We only need to show that these moves for P are legal.
First, q0 = fM0 (N0 ), and since Img fM0 = M0 it follows that q0 a M0 , so moving from V0 into v0 is a legal move.
Moreover, (qi+1 = fhMi+1 ,qi ,w[i]i (Ni )).
Since Img fhMi+1 ,qi ,w[i]i = Mi+1 it follows that qi+1 a Mi+1 , so again moving from Vi+1 into vi+1 is a legal move.
By construction, trace(D) = trace(e D ) again.
(2): Assume now that DP is a (proper) strategy for P in G. The strategy DP is characterized by DP ((M0 , AV, 0)) = (q0 , 0)  DP ((M, q, i)) = (qi , i)  Since the strategy is proper there are proper choice functions: g0 : Mod (I) a Q  gq,i : Mod (I'(q, w[i])) a Q  Theorem 18 Let A and Ae be specular automata.
Then e L(A) = ILD \ L(A).
We show the correctness of Streett ranking algorithm.
Lemma 19 Let G be an accepting run, and let G 0 be a nonempty sub-graph of G with no G vertices and only infinite paths.
Then, there is some node in G 0 that cannot access any B node.
Proof: Consider, by contradiction that there is no one such a node in G 0 = (V 0 , E 0 ), or equivalently, that all vertices in G 0 can access a B node: for all hq, li a V 0 , there is some hq 0 , l0 i a V 0 with q 0 a B and hq, li aaE 0 hq 0 , l0 i.
Then, every node can be associated with a B node by a map next(hq, li) that returns one path to a B reachable  node (for example, the shortest non-empty path to a B state, and picking the smallest according to some lexicographic order among the shortest ones.)
Then using induction define, starting from an arbitrary node hq, li a V 0 , an infinite path in G 0 that visits infinitely B nodes infinitely often by concatenating the paths returned by next.
Let us call D one such path.
Since D(0) = hq, li is a node of G 0 , and consequently a node of G, D(0) is reachable from some initial node by point 3 in the definition of a run.
Let Dpre be a finite path in G from a node hq0 , 0i a V .
The path Dpre D is a trace in G that visits G nodes finitely often (only nodes in Dpre can possibly be G nodes) and B nodes infinitely often in D. This trace contradicts that G is an accepting run.
 We will use the following notation, for a given sub-graph G 0 of a run: def  access(G 0 , hq, li) = {hq 0 , l0 i | hq, li aa hq 0 , l0 i} 0  def  0  finite(G ) = {hq, li | access(G , hq, li) is finite} def  nobad(G 0 ) = {hq, li | access(G 0 , hq, li) aS B = a} def  width(G 0 , l) = |{hq, li a G 0 }|  Lemma 6 G is an accepting run iff there is an odd S{1}-ranking for G. Proof: We prove the two directions separately: aaa Assume there is an odd S{1}-ranking f for G and let D be an arbitrary trace of G. Since, f is odd, either D visits infinitely many G states, in which case D is accepting, or f (D) converges to an odd value.
In this second case, there is l such that for all l0 > l, f (D(l0 )) = f (D(l)) and f (D(l)) is odd.
By definition of S{1}-ranking (point (i)), D(l0 ) cannot be a B state, and consequently D visits only finitely many B states.
Hence, D is an accepting trace.
aaa Assume G is an accepting run for A. a Initial Stage The construction of f starts by removing from G all G vertices.
Let VG be {hq, li | q a G}, then f (hq, li) = 0 for all hq, li a VG .
Also, let V0 = finite(G \ VG ), we let f (hq, li = 0 for all hq, li a V0 .
Also G0 = G \ (VG aS V0 ), which contains the original graph except the G nodes, and every node that reach G nodes in all its outgoing paths.
a Incremental Stage The algorithm proceeds in at most n rounds, performing the following two operations in each round k. The round begins with subgraph G2k of G. a Phase I: Let V2k+1 = nobad(G2k ).
Then, f (hq, li) = 2k + 1 for all hq, li a V2k+1 .
G2k+1 = G2k \ V2k+1 .
a Phase II: Let V2k+2 = finite(G2k+1 ).
Then, f (hq, li) = 2k + 2 for all hq, li a V2k+2 .
G2k+2 = G2k \ V2k+2 .
The graphs G0 as well all graphs G2k+2 are either empty, or guaranteed to have only infinite paths, since all nodes that can only access finitely many nodes are removed.
(a finite path ends in a node with no successor).
Hence, if V2k is non-empty Lemma 19 guarantees that V2k+1 is non-empty as well: there is a node in V2k+1 that accesses infinitely many vertices, but no B node.
In particular there is an infinite path that is removed in Phase I.
Hence, for some level l, all l0 > l satisfy that width(G2k+1 , l0 ) + 1 a$?
width(G2k , l0 ) Phase II only removes nodes, so width(G2k+2 , l0 ) a$?
width(G2k+1 , l0 ) Since, initially width(G, l) a$?
n for all levels l, it follows that, at the end of round k, for a sufficiently large l0 : width(G2k+1 , l0 ) a$?
n a (k + 1) Consequently, at the end of Phase II of round n a 1: width(G2na1 , l0 ) a$?
0.
All remaining vertices in G2na1 can access only finitely many vertices.
Hence G2n = a, and the algorithm terminates.
Note that it is possible that G2k = a in an earlier round, but guaranteed that after round n, G2n = a.
It remains to be seen that f is indeed an odd S{1}-ranking.
The function f is a S{1}-ranking:: By construction, all B vertices are marked in Phase II of some round because B aS nobad(Gi ) = a, and hence receive an even value.
Therefore, all B nodes satisfy condition (i) of the definition of S{1}-ranking.
Now consider an arbitrary node hq, li.
We consider three cases: 1) If hq, li is removed in the Initial Stage then q is either a G node, in which case (ii) holds trivially, or it is in V0 .
In the latter case, all its outgoing paths hit a G node in a finite number of steps, and all the intermediate nodes are mapped to 0.
Hence, if hq, li a hq 0 , l0 i, then f (hq 0 , l0 i) = 0 = f (hq 0 , l0 i) and f (hq, li) aL f (hq 0 , l0 i), and condition (ii) holds.
2) If hq, li is removed in Phase I of round k, so hq, li a V2k+1 .
Then all its outgoing paths either hit a node removed in a previous round or are in V2k+1 .
In both cases hq, li a hq 0 , l0 i implies f (hq, li) aL f (hq 0 , l0 i).
3) If hq, li is removed in Phase II of round k, so hq, li a V2k+2 .
Then all its outgoing paths either hit a node removed in a previous round, or are in V2k+1  or in V2k+2 .
In all cases hq, li a hq 0 , l0 i implies f (hq, li) aL f (hq 0 , l0 i).
The function f is an odd S{1}-ranking:: Consider an arbitrary path D. If D visits infinitely many G nodes, then the condition for f being odd on D holds.
If D does not visit infinitely many G nodes, then f converges on D to some value.
This value cannot be even, because that would imply that all these infinitely many vertices are in some V2k+2 , but there are not infinite paths containing these kind of node: by construction all nodes label in Phase II have finite outgoing paths before changing ranking.
This finishes the proof.
 Theorem 7 Let A be an ASW{1} and N the corresponding NBW.
Then w a L(A) if and only of w a L(N ).
Proof: We prove the two directions separately: aaa We assume w a L(A) and show that w a L(N ).
Let G be a run dag for w on A, and f an odd S{1}-ranking.
Consider the sequence Q0 Q1 .
.
.
of states of N induced by G and f as Qi = (Si , Oi , fi ) with the set of states in Si : Si  = {q | hq, ii a G}  and the pending states Oi : O0 = {p | hp, 0i a G with p a /G  and f (hp, 0i) is even}  Oi+1 = {p | hp, i + 1i a G with p a /G and f (hp, i + 1i) even}  Oi+1 = {p | hp, i + 1i a G  if Oi = a  and p a / G, and for some q a Oi , f (hp, i + 1i) = f (hq, ii)  and hq, ii a hp, i + 1i}  if Oi 6= a  and fi (q)  =  f (hq, ii)  It is routine to check that Q0 Q1 .
.
.
is a run.
We show that this run is accepting for N .
By contradiction, if Q0 Q1 .
.
.
is non accepting, there exists i such that, for all j aL i, Qj a / FN , hence Oj 6= a.
By D3 every qj+1 a Oj+1 has a predecessor qj a Oj with fj (qj ) = fj+1 (qj+1 ) being an even value by definition of Oi above.
Since, as shown above, every Oj 6= a, it follows that there is an infinite sub-dag of nodes in G of the form hqj , ji with f (hqj , ji) being even, and with infinitely many nodes having an incident edge.
By KoEnigas lemma, since this dag is finitely branching, it has an infinite path, all whose nodes are assigned the same even value by f .
This is a contradiction with f being an odd S{1}-ranking for G. Hence we find  that Q0 Q1 .
.
.
is a run that accepts w which shows w a L(N ).
aaa We assume now w a L(N ) and show that w a L(A).
Let Q0 Q1 Q2 .
.
.
be an accepting run for w on N and let G = (V, E) and f be an induced run and function V a [2n].
We conclude from Q1 and D2, respectively, that properties (i) and (ii) of S{1}-ranking holds on f .
Therefore f is a S{1}-ranking.
Now let us show that f is an odd S{1}-ranking.
To this end, consider an arbitrary path D in G for which we will show that either condition (i) or (ii) of the definition of odd S{1}-ranking holds.
If D visits G nodes infinitely often, then condition (i) holds.
Otherwise, there is an i after which no more G nodes are visited in D. Hence, since every node D(i0 ) with i0 > i + 1 has a predecessor not in G, D2 shows that f converges on D to some value.
Let j aL i0 be such that f has converged already (i.e., f (D(j 0 )) = f (D(j)) for all j 0 aL j).
Let Qk , Ql a FN with j a$?
k < l be two accepting states in the run Q0 Q1 of w on N .
It must be the case that D(k + 1) a / Ok+1 .
Assume the contrary (i.e.
D(k + 1) a Ok+1 ), since D visits no G node after k and f has converged, then we conclude by D3 that D(k 0 ) a Ok0 for all k 0 > k, hence that Ol 6= a, and finally that Ql a / FN by definition of FN which is a contradiction.
Also since D(k + 1) a / Ok+1 and Qk a FN , D3 shows that f (D(k + 1)) is odd.
Hence f converges on D to an odd value showing that condition (ii) of the definition of S{1}-ranking holds.
This concludes that f is an odd S{1}-ranking for G. Finally Lem.
6 shows that G is an accepting run, hence that w a L(A).
 Lemma 20 G is an accepting run iff there is a stratified odd S{1}-ranking for G. Proof: We prove the two directions separately: aaa Assume there is a stratified odd S{1}-ranking {fj } for G and let D be an arbitrary trace of G. Since, {fj } is odd, either D visits infinitely many G states, in which case D is accepting, or D converges to a stratum Sj and fj (D) converges to an odd value.
In this second case, there is l such that for all l0 > l, fj (D(l0 )) = fj (D(l)) and fj (D(l)) is odd.
By definition of stratified S{1}-ranking (point (i)), D(l0 ) cannot be a B state, and consequently D visits only finitely many B states.
Hence, D is an accepting trace.
aaa Assume now that G is an accepting run for A.
The construction of each fj works at each stratum independently.
Fix Sj .
First, one removes all G vertices and all those vertices not in Sj .
The algorithm works exactly as with the proof of Lemma 6 by stages, at each stage first removing those states that cannot access B nodes,  and then remove those states that only access finitely many nodes.
Since at each stage one removes at least one element from all cuts at a sufficiently large l, at the width of elements from Sj is at most |Sj |, the algorithm is guaranteed to finish in |Sj | rounds, generating an odd S{1}-ranking for stratum Sj .
It is routine to check that {fj } is indeed a stratified S{1}-ranking.
 Theorem 11 Let A be a stratified ASW{1} and N the corresponding NBW using stratified rankings.
Then w a L(A) if and only of w a L(N ).
Proof: The proof is analogous to Theorem 11.
Fig.
2 depicts the translation of RLTL into APW.
q0 false  q0 true  Automaton Aa for a.  Specular automaton Aa .
=  =  =  Ay  Ax  =  Ay  Ax  Automaton Axa"y for x a" y.  Specular automaton Axa"y .
=  =  Ax  Ax  Automaton AAZx for AZx.
1  Specular automaton AAZx .
0  =  Nr  Ax  Nr  Automaton Ar;x for r ; x. q0  Ay  q0  Ay  Automaton Ax|riiy for x|riiy.
Ay  Ax  q0  =  =  Ax  1  Nr  Automaton Ax|riy for x|riy.
Figure 2.
0  Nr  Specular automaton Ax|riiy .
2  =  =  1  Nr  Ax  0  =  =  q0  Ax  Specular automaton Ar;x .
1  =  =  Ay  1  =  Ax  0  Nr  Specular automaton Ax|riy .
Specular automata pairs for a, x a" y, AZx, x ; y, x|riiy and x|riy.
Speeding up temporal reasoning by exploiting the notion of kernel of an ordering relation Luca Chittaro, Angelo Montanari Dipartimento di Matematica e Informatica Universita di Udine, Via delle Scienze, 206 33100 Udine - ITALY {chittaro|montana}@dimi.uniud.it  Iliano Cervesato Dipartimento di Informatica Universita di Torino, Corso Svizzera, 185 10149 Torino - ITALY iliano@di.unito.it  1 Introduction In this paper, we consider the problem of expediting temporal reasoning about partially ordered events in Kowalski and Sergot's Event Calculus (EC).
EC is a formalism for representing and reasoning about events and their effects in a logic programming framework [7].
Given a set of events occurring in the real world, EC is able to infer the set of maximal validity intervals (MVIs, hereinafter) over which the properties initiated and/or terminated by the events maximally hold.
Event occurrences can be provided with different temporal qualifications [1].
In this paper, we suppose that for each event we either specify its relative position with respect to some other events (e.g., event e 1 occurs before event e2) or leave it temporally unqualified (the only thing we know is that it occurred).
Database updates in EC provide information about the occurrences of events and their times [6] and are of additive nature only.
We assume here that the set of events is fixed, and the input process consists in the addition of ordering information.
We will show how the introduction of partial ordering heavily increases the computational complexity of deriving MVIs.
Then, we will provide a precise characterization of what EC actually does to compute MVIs, and propose a solution to do it efficiently when only incomplete information about event ordering is available.
The paper is organized as follows.
In Section 2, we introduce the basic features of EC with relative times and partial ordering.
In Section 3, we analyze its computational complexity, that turns out to be exponential.
Moreover, we show how complexity can be reduced to polynomial (O(n5)) by adopting a graph marking technique that speeds up search.
In Section 4, we provide a deeper analysis of how EC derives MVIs, and we formally introduce the notion of kernel of an ordering relation.
Then, we show how the notion of kernel can be usefully applied to further reduce the complexity of computing MVIs.
Section 5 discusses an example, also contrasting the set of MVIs with the sets of necessarily and possibly true MVIs.
Section 6 concludes the paper.
2 The Event Calculus with relative times and partial ordering EC takes the notions of event, property, time-point and time-interval as primitives and defines a model of change in which events happen at time-points and initiate and/or terminate time-intervals over which some property holds.
Time-points are unique points in time at which events take place instantaneously.
Time-intervals are represented as pairs  of time-points.
EC embodies a notion of default persistence according to which properties are assumed to persist until an event occurs which terminates them.
In this paper, we focus our attention on situations where precise temporal information for event occurrences is not available.
We represent the occurrence of an event e of type tye by means of the clause: happens(e,tye).
The relation between types of events and properties is defined by means of initiates and terminates clauses: initiates(tye, p1).
terminates(tye, p2).
The initiates (terminates ) clause relates each type of event tye to the property p it initiates (terminates).
The plain EC model of time and change is defined by means of the axioms: holds(period(Ei,P,Et)):happens(Ei,TyEi), initiates(TyEi,P), happens(Et,TyEt), terminates(TyEt,P), before(Ei,Et), not broken(Ei,P,Et).
(1.1)  broken(Ei,P,Et):(1.2) happens(E,TyE), before(Ei,E), before(E,Et), (initiates(TyE,Q);terminates(TyE,Q)), (exclusive(P,Q);P=Q).
The holds axiom states that a property P maximally holds between events Ei and Et if Ei initiates P and occurs before Et that terminates P, provided there is no known interruption in between.
The negation involving the predicate broken is interpreted using negation-as-failure.
The broken axiom states that a given property P ceases to hold if there is an event E that happens between Ei and Et and initiates or terminates a property Q that is exclusive with P .
The exclusive( P , Q ) predicate is a constraint to force the derivation of P to fail when it is possible to conclude that Q holds at the same time.
Finally, the condition P = Q constrains interferences due to incomplete sequences of events relating to the same property.
It indeed guarantees that broken succeeds also when an initiating or terminating event for property P is found between the pair of events Ei and Et starting and ending P respectively.
The exclusive facts have obviously to be defined for each specific application (e.g.
exclusive(p,q).
).
Finally, knowledge about the relative ordering of events is expressed by means of facts of the form beforeFact( e 1 , e 2 ) .
The predicate b e f o r e used in h o l d s and b r o k e n is defined as the transitive closure of beforeFact :  before(E1,E2):beforeFact(E1,E2).
(1.3)  before(E1,E2):beforeFact(E1,E3),before(E3,E2).
(1.4)  The ordering information is entered through the predicate updateOrder( e 1 , e 2 ) : updateOrder(E1, E2) :assert(beforeFact(E1, E2)).
(1.5)  We assume that the set of ordered pairs is always consistent as it grows.
This means that before is supposed to represent a relation that is irreflexive, anti-symmetric and transitive.
The axioms of EC, shown as clauses (1.1-5), will be referred as program 1 in the following.
3  A complexity analysis  In the case of EC with absolute times and total ordering, the worst case complexity of deriving all the MVIs for a given property has been proven to be O(n3), where n is the number of recorded events [3].
In this section, a worst case complexity analysis will be carried out for EC with relative times and partial ordering.
We consider an EC database consisting of a set of events E={e1,...,en} and a set w of elements (ei,ej) whose transitive closure w + is a strict ordering relation on ExE.
The cost is measured as the number of accesses to the database to unify facts during the computation.
Some hashing mechanism is assumed so that fully-instantiated atomic goals are matched in one single access to a sequence of variable-free facts in case of success, and do not need any access in case of failure.
The complexity is given as a function of the number n of recorded events.
3.1  The complexity of EC with relative times and partial ordering  Queries have the form h o l d s ( p e r i o d ( E i , p , E t ) ) , where Ei and Et are variables and p can be either a variable or a constant.
The update predicate is always called with ground arguments.
For each predicate, we now analyze the cost of finding all its solutions.
u p d a t e O r d e r ( e 1 , e 2 ) : a call to this predicate has unitary cost since it only results in asserting a new fact in the database.
happens(Ei,TyEi) and happens(Et,TyEt) : each of this goal succeeds n times, since n events are recorded in the database.
So, the cost of each is O(n).
i n i t i a t e s ( T y E i , P ) and t e r m i n a t e s ( T y E t , P ) : the cost of these predicates is constant for a ground TyEi (or TyEt) even when they are called with P uninstantiated (as in clause 1.2).
exclusive(P,Q) : this predicate is always called ground and it thus can be matched against at most one fact in the database.
The cost is therefore constant.
beforeFact(E1,E2) : When called ground, as in clause (1.3), the query cost is constant.
In clause (1.4) instead, the call results in instantiating a variable.
The complexity is given as the maximum number of matching facts in the  database.
Having n nodes, at most n-1 edges can start from a given node.
Thus, when called with one variable argument, this predicate has cost O(n).
before(Ei,Et) : we will show that the standard twoclauses definition of before (clauses 1.3-4) has a worst case complexity that is at least exponential.
Consider n>=4 events arranged as shown in figure 1: all the n events but two (en-1 and en) participate in a total order between e1 and en2 .
All the transitive pairs, but the pair ( e 1 , e n ) are explicitly specified by means of beforeFact .
We assume that beforeFact(e 1 ,e n-1 ) textually follows any other fact of the form beforeFact(e 1 ,e i ) , for i = 2 ..n-2 .
en-2  Due to the operational behavior of PROLOG, EC thus tries to prove before(e1,en)  m = n-3  looking for a path that passes through e n - 2 e 1 e n-1 before attempting the en (only possible) path Figure 1 that includes e n - 1 .
Backtracking due to the failure in proving before(e n-2 ,e n ) causes every path from e 1 to e n-2 to be unsuccessfully attempted.
The resulting cost is computed as follows.
Let m=n-3 be the length of the longest path between e 1 and e n-2 .
We have the following recursive relation, where Cbf(m) represents the cost of finding all the solutions to the goal before(e',e") in case a total order of length m exists between e' and e" (the value of m highlighted in Figure 1 concerns the pair (e1,en-2)): Cbf (1) = 1;  m= 1 m -1  Cbf ( m ) = m + [?]
Cbf (i )  m >1  i =1  Indeed, there are m edges (represented by beforeFact ) starting from e' , which we can traverse to go towards e" .
One of these edges directly reaches e" (clause 1.3).
If m>1, each of the remaining m-1 edges leads to a node e (clause 1.4), reducing the problem to size i, where i is the length of the longest path between e and e".
In order to give an analytical form for Cbf(m), let us unfold the expression for Cbf(m): Cbf(m)=m+Cbf(m-1)+ Cbf(m-2) + Cbf(m-3) +...  +Cbf(1)=  =m +  (m-1)+2Cbf(m-2) +2Cbf(m-3) +... +2Cbf(1)=  =m+  (m-1) +  =m+ 20(m-1)+  2(m-2) +4Cbf(m-3) +... +4Cbf(1)= 21(m-2) +  22(m-3) +... +2m-2(1)  We can summarize this formula as: m- 1  Cbf (m ) = m +  m- 1  m -2  [?]
2i-1 ( m - i ) >= [?]
2i -1 = [?]
2 j = 2 m-1 - 1  i =1  i =1  j =0  Therefore the cost is at least O(2 m ).
Since we set m=n-3, before with both arguments instantiated turns out to be at least exponential in the worst case.
broken(ei,p,et) : since the definition of this predicate contains calls to before , this goal has an exponential  complexity.
holds(period(Ei,p,Et)) : reasoning as for broken , we obtain an exponential cost too.
The major results of the preceding analysis are the constant cost of updating ordering information (updateOrder ) and the exponential query complexity (holds).
3.2  The addition of marking The exponential cost resulting from the previous analysis makes EC with relative times not appealing for practical computations.
It is interesting to note that this very high cost origins from the calls to b e f o r e .
Can this predicate be re-implemented with a lower cost?
We use before to check whether a pair of nodes belongs to the transitive closure of a cycle-free relation.
Well-known algorithms for this kind of operations have polynomial complexity in the number of nodes.
Unfortunately, these algorithms are more suited to be implemented using traditional programming languages rather than logic programming.
We will now present a PROLOG program implementing a marking algorithm.
We foresee that it is written using extra-logical features of PROLOG.
Therefore, it will hardly be classified as a logic program.
Nevertheless, this program can be considered acceptable: once we have proven that the two versions of before behave coherently, we can see the non-declarative procedure as an actual implementation of the logical one.
before(E1, E2) :markingBefore(E1, E2), !, unmarkAll.
before(E1, E2) :unmarkAll, fail.
markingBefore(E1, E2) :beforeFact(E1, E2), !.
markingBefore(E1, E2) :beforeFact(E1, E3), happens(E3, _, unmarked), mark(E3), markingBefore(E3, E2).
(2.1)  unmarkAll :happens(E, _, marked), !, unmark(E), unmarkAll.
unmarkAll.
unmark(E) :retract(happens(E, TyE, marked)), assert(happens(E, TyE, unmarked)).
mark(E) :retract(happens(E, TyE, unmarked)), assert(happens(E, TyE, marked)).
happens(E,TyE):happens(E,TyE,_).
(2.5)  (2.2) (2.3) (2.4)  (2.6) (2.7) (2.8) (2.9)  Program 2 The idea is very simple: during the search, nodes are marked as they are visited, and only edges leading to not yet marked nodes are analyzed.
We need to change the arity of the predicate happens to support marking: the third argument contains either marked or unmarked with the obvious meaning.
Initially all the nodes are unmarked.
The purpose  of clause (2.9) is to maintain the one parameter interface to happens.
Let us now prove that the two versions of before compute the same relation, given the same factual database.
The declarative program consisting of clauses (1.3-4) yields before(e',e") if and only if the database contains a path leading from e' to e" , where the edges are represented by beforeFact (a simple inductive proof can be found in [2]).
We will now prove that the database contains that path if and only if program 2 derives m a r k i n g B e f o r e ( e ' , e " ) , and consequently before(e',e").
First suppose that the database contains at least a path p=( e' ,e 1 ),(e 1 ,e 2 ),...,(e k-1 ,e k ), (e k ,e" ) of length k+1 that links nodes e' and e" passing through k intermediate nodes and that all nodes are initially unmarked (the validity of this condition after each execution of before is guaranteed by the execution of the unmarkAll predicate occuring in clauses (2.1) and (2.2)).
If there is more than one path from e' to e" , let p be that path whose first edge comes first in the listing of beforeFact (if there is more than one path from e' to e" with this edge as its first edge, then let p be the path whose second edge comes first in the listing of beforeFact ; and so on).
In other words, this selected path is the first path from e' to e" considered by the PROLOG control strategy.
Let us prove that markingBefore(e',e") is derivable from program 2, and only nodes e 1,e 2,..,e k of the selected path are marked during this process.
The proof is inductive in the length of the selected path.
The case where the length of the path is 1, i.e.
there are 0 intermediate nodes and p=(e',e"), is caught by clause (2.3).
We assume, as inductive hypothesis, that the statement holds for length k (i.e.
k-1 intermediate nodes), and we prove that it holds for length k+1 (i.e.
k intermediate nodes).
Let us consider an instance of clause (2.4) where E 1 = e ' and E 2 = e " .
The first subgoal matches beforeFact(e',e 1 ) in the database, instantiating E3 to e 1 .
By hypothesis, all nodes are initially unmarked and e 1 can not have been marked up to now: if e1 were marked, then it would have been already reached by traversing another path, but this would contradict the hypothesis that p (to which e1 belongs) is the first path from e' to e" considered by the PROLOG control strategy.
Therefore, the second subgoal, happens(e 1 ,_,unmarked) , is immediately provable.
Moreover, the presence of this fact in the database causes the subgoal mark(e1) to mark e1 by clause (2.8).
By inductive hypothesis, markingBefore(e 1 ,e") is derivable and nodes e2,..,ek of the selected path are marked as a by-product of the process.
Thus, the overall clause succeeds and proves the goal markingBefore(e',e") .
Conversely, suppose that m a r k i n g B e f o r e ( e ' , e") is derivable from program 2.
We proceed by induction on the height h of the resolution tree for markingBefore(e',e") .
If h=1, then clause (2.3) has been applied, and the database contains the fact  beforeFact(e',e").
Otherwise, we assume, as inductive hypothesis, that the statement holds for every tree of height lower than h and prove its validity for trees of height h. Since h>1, clause (2.4) must have been selected at the first step.
Thus, b e f o r e F a c t ( e ' , e 1 ) a n d markingBefore(e 1 ,e") have successful derivations for some node e1.
By inductive hypothesis, the derivability of the former goal implies that there is a path p'=(e1,e2),...,(ek,e") between nodes e1 and e".
Considering (e',e1) together with p', we obtain the desired path.
We will now evaluate the cost of b e f o r e as implemented by program 2, and show the impact on EC of substituting clauses (1.3-4) of program 1 with program 2.
Let us first compute the cost of m a r k i n g B e f o r e and unmarkAll .
It is easy to show that the latter is always called.
Thus, the complexity of before is equal to the sum of the costs of the two.
The predicate m a r k i n g B e f o r e is designed to be called with both arguments instantiated.
Since clause (2.4) marks a node before the recursive call and since the number of nodes (initially all unmarked) is n, this predicate is called at most n times.
Moreover, each execution of m a r k i n g B e f o r e involves at most n -1 accesses to a b e f o r e F a c t fact.
Therefore, the overall cost for this predicate is O(n2).
Since at most n nodes have been marked by m a r k i n g B e f o r e , u n m a r k A l l has cost O ( n ) .
Therefore, before costs at most O(n2).
This upper bound is reached in the situation of Figure 1.
After integrating this version of before into EC, the cost of holds becomes polynomial, dropping from O(2n) to O(n5).
Indeed, if there are k events initiating p and h events terminating p in the database, the call to h a p p e n s ( E i , T y E i ) in the body of h o l d s , with E i unbound, can succeed n times but initiates(TyEi,P) will succeed only for k of the identified events.
Analogously, h a p p e n s ( E t , T y E t ) succeeds n times but terminates(TyEt,P) retains only h events.
As a result, k*h pairs of events are allowed to reach before(Ei,Et) .
Since k+h <= n, the product k*h is maximum for k=h=n/2, resulting in a quadratic number of pairs.
For each pair, both b e f o r e ( E i , E t ) and not broken(Ei,P,Et) will be considered in the worst case.
The cost of the former has been proved to be O(n 2 ) above, while the cost of the latter is evaluated as follows: the first goal in broken is called with an uninstantiated argument and can succeed n times; for each success, at worst two calls to before (2*O(n 2 )) and three constant cost calls (initiates and terminates with the first argument bound, and exclusive ) are performed.
Therefore, the cost of b r o k e n turns out to be cubic (O(n)*O(n2)).
Returning to holds, we obtain a cost equal to O(n2)*O(n3)=O(n5).
4 What the Event Calculus actually does and how to do it efficiently In this section, we aim at getting a better understanding  of what EC actually does when computing MVIs.
This insight allows to design more efficient versions of EC.
The representation of the ordering of events is of primary importance.
Let E = { e 1 ,...,e n } be the set of events, represented in EC by the predicate happens .
The ordered pairs beforeFact( e i , e j ) contained into the database constitute a set w[?
]ExE .
Notice however that the main axioms of EC never access w (i.e.
beforeFact facts) directly.
Instead, they rely heavily on the predicate before that models the transitive closure of w. Let us denote as w+ the transitive closure of w. w + is a strict order on E, i.e.
a relation that is irreflexive, asymmetric and transitive.
w is a subset of w+ and can indeed be viewed as a specification of it.
It is easy to prove that w+ can contain a quadratic number of edges; indeed the maximum number of edges n*(n-1)/2 is reached when w + is a total order.
From a graph-theoretic point of view, w corresponds to a directed acyclic graph G on E , whose nodes are event occurrences and such that there exists an edge from node ei to ej if and only if the pair (ei,ej) belongs to w., while w+ corresponds to its completion G+.
In order to compute the set of MVIs for a property p, the predicate holds in program 1 considers every pair of events e i , e j such that e i initiates p and e j terminates p, checks whether (ei,ej) belongs to w +, i.e.
if G + contains an edge from ei to ej, and ascertains that no interrupting event e occurs in between, i.e.
that G + does not contain any node e associated to a property q exclusive with p (or associated to the property p itself) such that (ei,e)[?
]G+ and (e,ej)[?]G+.
This approach presents two drawbacks.
First, EC blindly picks up every pair consisting of an event initiating p and an event terminating p, and only later looks for possible interruptions.
We would like instead to include the determination of possibly interrupting events within the search of candidate MVIs for p (i.e.
pairs (ei,ej) such that ei initiates p and ej terminates it).
Second, since G+ is implicit in G, we showed in the previous section that the cost of checking whether an edge belongs to G + by means of the marking version of before is proportional to the number of edges in G, i.e.
to the number of beforeFact in the database.
Both problems can be solved by shifting the emphasis from the transitive closure w + of w to its antitransitive closure, or kernel, w -.
w - is the least subset of w such that (w-)+=w+ and it can be obtained by removing every pair (e i,e j) from w such that (e i,e)[?
]w + and (e,e j)[?
]w + for some event e. The notion of kernel induces a subgraph G- of G that does not contain any transitive edge.
The number of edges in G - is strictly lower than n*(n-1)/2 and is indeed linear in most cases (as in the example reported in Section 5).
The results of Section 3 call for optimization in those cases (we expect them to be the most frequent) where the critical operation is querying for the validity of a certain property.
In these circumstances, the upper bound that comes out from the previous analysis is still not acceptable.
The solution we propose in the following operates on the representation of ordering information in the database.
We  will first introduce the proposed technique in the case where a single property is involved.
Then, the solution will be generalized in order to account for multiple properties.
4.1  Storing and updating the kernel In order to store and update the kernel of the ordering relation, clause (1.5) of program 1 must be replaced with the following program: updateOrder(E1, E2) :(3.1) not before(E1, E2), assertOP(E1,E2).
assertOP(E1, E2) :beforeFact(EA, EB), retractInBetween(E1,EA,EB,E2).
(3.2)  assertOP(E1, E2) :assert(beforeFact(E1, E2)), !.
(3.3)  retractInBetween(E1,EA,EB,E2) :(E1=EA; before(EA, E1)), !, (EB=E2; before(E2, EB)), !, retract(beforeFact(EA, EB)), fail.
(3.4)  Program 3 When the edge (e1,e2) is already entailed by the current ordering relation, it is not added to the representation, in order to maintain minimality.
This case is caught by clause (3.1) through the negative call to before.
Co-operating clauses (3.2-4) deal with the complementary case, i.e.
edge (e1,e2) is not subsumed by the current ordering.
Edge (e1,e2) is added to the representation by clause (3.3).
Before doing this, edges becoming redundant because of transitivity must be located and retracted from the database.
As shown by figure 2 (where the thin lines represent sequences of zero or more chained instances of beforeFact ), adding the edge (e1,e2) can close a transitive relation between nodes eA (possibly e1 ) and eB (possibly e2).
This is problematic when there exists already a direct link between these two nodes: this previously e1 e2 inserted link has now become redundant and eB eA must be removed.
This is done by Figure 2 clauses (3.2) and (3.4).
Notice that there may exist several pairs of the above kind, and all of the corresponding edges must be retracted.
This is achieved through backtracking by forcing the failure of clause (3.4).
When every possibility has been examined, the execution finally backtracks to clause (3.3) that succeeds asserting (only once) the added edge.
The cost of these operations is the following: retractInBetween(E1,EA,EB,E2) : this predicate is called ground and its cost thus corresponds to the cost of two ground calls to before - 2O(n2) - plus the constant cost of performing the retraction.
Notice that no backtracking is allowed within this clause.
The resulting cost is therefore quadratic.
assertOP(E1,E2): this predicate calls retractInBetween for each element of the kernel of the ordering relation (clause 3.2) and then asserts the ordered pair of interest (clause 3.3).
We showed that an upper bound for  the number of edges of the kernel is at most O (n 2 ) .
Therefore, a call to this predicate can cost at most O(n4).
updateOrder(E1,E2) : this predicate is called ground and its cost is given by the cost of one negative call to b e f o r e , and one to a s s e r t O P , resulting in O (n 4 ) complexity.
4.2  Single property In the case of a single property p, once only the kernel of the ordering relation is retained in the database, clause (1.1) can be simplified as follows: holds(period(Ei, p, Et)) :happens(Ei,TyEi), initiates(TyEi, p), happens(Et,TyEt), terminates(TyEt, p), beforeFact(Ei, Et).
Indeed, whenever p is the only property represented in the database, an event e interrupting a candidate MVI (e i,e j), where ei initiates p and ej terminates it, must either initiate or terminate p. Therefore (ei,ej) is an MVI for p if and only if ei is an immediate predecessor of ej in the current ordering, in the sense that no other event is recorded between the two.
It is worth noting that the predicate broken is not needed in this case.
Computing the complexity of this restricted version of EC is trivial.
In fact, the cost of holds(period(Ei,p,Et)) consists in the two calls to happens .
Since there are n events in the database, a call to h o l d s costs O (n 2 ).
Finally, notice that a further improvement in efficiency (at least in the average case) can be obtained by eliminating the calls to happens and by rearranging the atomic goals in its body as follows: holds(period(Ei, p, Et)) :beforeFact(Ei, Et), happens(Ei,TyEi), initiates(TyEi, p), happens(Et,TyEt), terminates(TyEt, p).
The complexity becomes equal to the number of beforeFact in the database, i.e.
the cardinality of the kernel.
4.3  Multiple properties We now generalize the technique to the case of multiple properties.
We maintain the minimality of the ordering information, as in the single property case, and implement a graph search algorithm for the query predicate holds.
This algorithm is implemented by the program given in the Appendix, where holds is clause (4.1).
The search is started from a specific initiating event.
Let ei be this event and p the corresponding property.
If ei is not instantiated in the query, all events in the graph will be processed.
The idea is to examine all the successors of e i searching for events terminating p. The search starts from its immediate successors, and proceeds breadth-first.
Exhausting a layer before examining nodes in the next is indeed crucial for the soundness of the algorithm.
As depicted in Figure 3, the nodes in the first layer after ei, are partitioned in three categories: terminating events for p, events interfering with p (i.e.
other initiating events for p, or  for properties incompatible with p) and independent events.
The nodes in the first category are terminating events in the MVIs returned to the user, and their successors are marked since there is no need to keep them into consideration during further processing.
<p] Nodes in the second termP category are simply marked as well as their successors since [p> initP [p> they cannot be ei contained in a successful path for Others otherP the user query.
The nodes in the third category are used to determine the next Figure 3 layer to explore, which is obtained by collecting all of their unmarked immediate successors.
The procedure repeats recursively until the most distant layer from ei is examined.
With reference to the code in the Appendix, findTerm (clause 4.2) finds the elements in the first layer after a given node, f i n d T e r m i n a n t s (clause 4.3) is the predicate which processes a layer and partitions the nodes, termP (clauses 4.4-6) is used to identify the events in the first category, nodes in the second category are processed by means of the predicates initP together with the auxiliary predicate initPorEx (clauses 4.7-11), and the remaining nodes are processed by the predicate otherP (clauses 4.12-13).  }
} }  5  Analyzing example  the  beverage  dispenser  We will now introduce an example, comment on the results of executing the basic and enhanced versions of EC on it, and further characterize the set of MVIs computed on this example by contrasting it with the set of possibly true and the set of necessarily true MVIs, respectively.
Consider the functioning of the simple beverage dispenser depicted in Figure 4: by setting the selector to the apple or to the orange position, apple juice or orange juice is obtained, respectively.
Choosing the stop position terminates the output of juice.
We model this knowledge as follows: initiates(selectApple,supplyApple).
initiates(selectOrange,supplyOrange).
terminates(selectStop, supplyApple).
terminates(selectStop, supplyOrange).
exclusive(supplyApple,supplyOrange).
exclusive(supplyOrange,supplyApple).
We consider an actual situation where six events happened: e1, e2, e3, e4, e5, and e6.
The following PROLOG factual knowledge associates events to their types: happens(e1,selectApple,unmarked).
happens(e2,selectStop,unmarked).
happens(e3,selectOrange,unmarked).
happens(e4,selectStop,unmarked).
happens(e5,selectApple,unmarked).
happens(e6,selectStop,unmarked).
These facts are intended for the marking implementation of EC, as it can be seen from the arity of the predicate happens .
The PROLOG code for the standard case is analogous and differs only for the absence of the third argument.
In the intended final ordering, events are ordered according to their indices.
Therefore, the final situation is represented in figure 5.
In our example, we will consider the following sequence of ordered pairs, which arrive one at a time: (e 1 ,e 4 ) - (e 1 ,e 6 ) - (e 2 ,e 4 ) - (e 1 ,e 2 ) - (e 3 ,e 4 ) - (e 4 ,e 5 ) (e2,e3) - (e2,e6) - (e5,e6).
e  1  supplyApple  e  2  e  e  3  supplyOrange  4  e  e  5  6  supplyApple  Figure 5 This sequence has been devised so that the complete situation shown in Figure 5 can be fully derived only after the last update.
The 9 ordered pairs are entered into the PROLOG database by running the following goals, in sequence.
????
?-  updateOrder(e1,e4).
updateOrder(e1,e6).
updateOrder(e2,e4).
updateOrder(e1,e2).
updateOrder(e3,e4).
???
?-  updateOrder(e4,e5).
updateOrder(e2,e3).
updateOrder(e2,e6).
updateOrder(e5,e6).
Table 1 shows the evolution of the Apple STOP Orange computation: each row corresponds to the addition of one of these ordered pairs to the database.
The first column shows which update is being performed.
The second column gives a visual account of the content of the database.
In particular, the kernel is represented in solid lines while deleted edges are drawn as dotted lines.
The third column contains the list of the MVIs derived by EC, i.e.
the result of running a generic query of the form ?h o l d s ( X ) .
For conciseness, we represented p e r i o d ( e i , s u p p l y A p p l e , e t ) as Figure 4 the more compact a ( e i , e t ) and period(ei,supplyOrange,et) as the more compact o(ei,et).
The experimental data (number of nodes visited in the resolution tree) obtained with this example show a more efficient behavior for the enhanced version of EC in the query phase.
This fact becomes more and more evident as the number of ordered pairs into the knowledge base grows: if the enhanced EC is only slightly faster (40 nodes analyzed versus 47) when there is no ordering information, after adding the last ordered pair the first answer is retrieved 4.2 times faster (86 nodes examined instead of 363) and the basic implementation explores 5 times more nodes (889 versus 178) to find all the MVIs.
Of course, the update operation is more expensive in the enhanced case, since just one node is explored in the basic implementation.
Anyway, this extracost is acceptable considering the benefits produced in the query phase and the fact that the overall cost (update and query) of the enhanced version is lower.
w  w visually  X:  w  w visually  X:  holds(X)  e1  e5  e3  e2  holds(X)  e4  e3  + (e 3 ,e 4 )  e6  a(e 1 ,e 2 ) a(e 1 ,e 6 ) o(e 3 ,e 4 )  e4  e2 e1 e6  + (e 1 ,e 4 )  e1  e4  e3  e5  e2  e6  e5  e3  + (e 4 ,e 5 )  e5  e4  e2  a(e 1 ,e 2 ) a(e 1 ,e 6 ) o(e 3 ,e 4 )  e1 e6  + (e 1 ,e 6 )  e4 e1  e3  e6  e5  e5  e2  a(e 1 ,e 6 )  + (e 2 ,e 3 )  e4  e3  a(e 1 ,e 2 ) a(e 1 ,e 6 ) o(e 3 ,e 4 )  e2 e1 e6  e2  + (e 2 ,e 4 )  e4  e3  e1 e6  a(e 1 ,e 6 )  e5  + (e 2 ,e 6 )  e3  e4 e2  e3  e6  e5  e1  a(e 1 ,e 2 ) a(e 1 ,e 6 )  + (e 5 ,e 6 )  a(e 1 ,e 2 ) o(e 3 ,e 4 )  e2 e1  + (e 1 ,e 2 )  e5  e4  e1  e6  e2  e3  e4  e5  e 6 a(e 1 ,e 2 ) o(e 3 ,e 4 ) a(e 5 ,e 6 )  Table 1 MVIs derived by EC  Necessary MVIs  Possible  MVIs  [?]
[?]
a(e1,e2),a(e1,e6),o(e3,e4),a(e5,e2),a(e5,e6)  ?- updateOrder(e1,e4).
[?]
[?]
a(e1,e2),a(e1,e6),o(e3,e4),a(e5,e2),a(e5,e6)  ?- updateOrder(e1,e6).
a(e1,e6)  [?]
a(e1,e2),a(e1,e6),o(e3,e4),a(e5,e2),a(e5,e6)  ...  ...  ...  ...  ?- updateOrder(e2,e3).
a(e1,e2),a(e1,e6),o(e3,e4)  [?]
a(e1,e2),a(e1,e6),o(e3,e4),a(e5,e6)  ?- updateOrder(e2,e6).
a(e1,e2),o(e3,e4)  a(e1,e2)  a(e1,e2),o(e3,e4),a(e5,e6)  ?- updateOrder(e5,e6).
a(e1,e2),o(e3,e4),a(e5,e6)  a(e1,e2),o(e3,e4),a(e5,e6)  a(e1,e2),o(e3,e4),a(e5,e6)  Table 2 Further insights on the behavior of EC with partially ordered events can be obtained by comparing it with the behavior of the Skeptical EC and Credulous EC, two variants of EC we proposed [4] to compute the MVIs which are derivable in all the total orders consistent with the given partial order (Skeptical EC), and those derivable in at least one of the total orders (Credulous EC).
As an example, Table 2 considers  again the beverage dispenser example and provides a comparison of the MVIs computed by the calculus presented in this paper, contrasted with those computed by the Skeptical and the Credulous calculus.
Dean and Boddy [5] studied the task of deriving which facts must be or can possibly be true over certain intervals of time in presence of partially ordered events (in our context, which MVIs must  necessarily hold and which possibly hold), focusing on the computational complexity of the task and showing that it is intractable in the general case.
In [2,4], we focused on providing the task with a modal logic formulation.
While [5] develop polynomial algorithms to compute supersets of the set of possible facts and subsets of the set of necessary facts, the calculus presented in this paper polynomially computes a set in between, mimicking some behaviors of human reasoners.
6 Conclusions The paper analyzed in detail the process of computing MVIs for properties in EC, and proposed a revision of the calculus that strongly increases its efficiency when dealing with partial ordering information.
The resulting calculus models events and their ordering relations in terms of a directed acyclic graph, and incorporates a marking technique to speed up the visit of the graph during the computation of validity intervals.
Moreover, it provides an alternative solution to the problem of supporting default persistence that further improves its performance.
Instead of the expensive generateand-test approach of the original calculus, it restricts a priori the search space by exploiting the kernel of an ordering relation.
Since we did not determine a lower bound for the complexity of the problem of deriving MVIs with partially information about event ordering, the possibility of further improving the achieved results can not be excluded.
References [1] I. Cervesato, A. Montanari, A. Provetti 1993.
"On the Non-monotonic Behavior of Event Calculus for Deriving Maximal Time Intervals", I n t e r v a l Computations 2, 83-119.
[2] I. Cervesato, L. Chittaro, A. Montanari 1995.
"A Modal Calculus of Partially Ordered Events in a Logic Programming Framework".
Proc.
ICLP '95, Tokyo, Japan, MIT Press.
[3] L. Chittaro, A. Montanari 1996.
"Efficient temporal reasoning in the Cached Event Calculus", to appear in Computational Intelligence Journal.
[4] L. Chittaro, A. Montanari, A. Provetti 1994.
"Skeptical and Credulous Event Calculi for Supporting Modal Queries", in Proc.
ECAI '94, Amsterdam, The Netherlands, Wiley and Sons Publishers, 361-365.
[5] T. Dean, M. Boddy 1988.
"Reasoning about Partially Ordered Events", Artificial Intelligence 36, 375-399.
[6] R. Kowalski 1992.
"Database Updates in the Event Calculus", in Journal of Logic Programming 12, 121146.
[7] R. Kowalski, M. Sergot 1986.
"A Logic-based Calculus of Events", in New Generation Computing,  4, Ohmsha Ltd and Springer-Verlag, 67-95.
Appendix holds(period(Ei, P, Et)) :(4.1) happens(Ei, TyEi, unmarked), initiates(TyEi, P), findTerm(Ei, P, Et).
findTerm(Ei, P, Et) :(4.2) findSucc(Ei, Es), findTerminants(Es, P, Res),unmarkAll,!, member(Et, Res).
findTerminants(Es, P, Res) :termP(P, Es, LessEs, ResTerm), initP(P, LessEs, FewerEs), otherP(P, FewerEs, ResOther), append(ResTerm, ResOther,Res).
(4.3)  termP(P,[E|Tail], NonTerm,[E|Term]) :(4.4) happens(E,TyE),terminates(TyE, P), markAll(E),termP(P, Tail, NonTerm, Term).
termP(P,[E|Tail],[E|NonTerm],Term) :(4.5) happens(E,TyE), not terminates(TyE, P), termP(P, Tail, NonTerm, Term).
termP(P, [], [], []).
(4.6) initP(P, [E|Tail], NonP) :initPorEx(E, P), markAll(E), initP(P, Tail, NonP).
initP(P, [E|Tail], [E|NonP]) :not initPorEx(E, P), initP(P, Tail, NonP).
initP(P, [], []).
(4.7)  (4.8) (4.9)  initPorEx(E, P) :(4.10) happens(E,TyE), initiates(TyE, P).
initPorEx(E, P) :(4.11) happens(E,TyE), (initiates(TyE,Q);terminates(TyE,Q)), exclusive(P, Q).
otherP(P, [E|Es], Res) :listSucc([E|Es], SuccEs), findTerminants(SuccEs, P, Res).
otherP(P, [], []).
(4.12)  findSucc(E, Es) :setof(NextE,(beforeFact(E, NextE), happens(NextE, _, unmarked)),Es), !.
findSucc(E, []).
(4.14)  listSucc([E|Es], SuccEEs) :findSucc(E, SuccE), listSucc(Es, SuccEs), listUnion(SuccE, SuccEs, SuccEEs).
listSucc([], []).
(4.13)  (4.15) (4.16)  (4.17)  markAll(E) :mark(E), findSucc(E, SuccE), markAllIn(SuccE).
(4.18)  markAllIn([E|Es]) :markAll(E), markAllIn(Es).
markAllIn([]).
(4.19)  listUnion([E|L1], L2, L3) :member(E, L2), !, listUnion(L1, L2, L3).
listUnion([E|L1], L2, [E|L3]) :listUnion(L1, L2, L3).
listUnion([], L, L).
(4.20) (4.21) (4.22) (4.23)
Data Currency Model More on CERTAINTY(q)  Towards a Foundation of Data Currency Jef Wijsen University of Mons Joint work with Wenfei Fan and Floris Geerts, University of Edinburgh  TIME Symposium, 2011  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Background/Motivation  "The problem with data is that its quality quickly degenerates over time.
Experts say 2 percent of records in a customer file become obsolete in one month because customers die, divorce, marry, and move."
[Eck02] Often no reliable timestamps.
How can we decide the "current truth" of a Boolean query?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Caveat  Simplified version of the currency model proposed at PODS 2011 [FGW11].
But the simplification maintains lower and upper complexity bounds of the problems presented.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Ordered Relation Ordered relation (I , [?])
Relation I equipped with a currency order [?]
such that: distinct tuples that agree on the primary key are comparable under [?
]; and tuples that disagree on the primary key are incomparable.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  Jef Wijsen  Data Currency  t1 [?]
t3 [?]
t2 t4 [?]
t5  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Ordered Relation Ordered relation (I , [?])
Relation I equipped with a currency order [?]
such that: distinct tuples that agree on the primary key are comparable under [?
]; and tuples that disagree on the primary key are incomparable.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  Jef Wijsen  Data Currency  t1 [?]
t3 [?]
t2 t4 [?]
t5  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Ordered Relation Ordered relation (I , [?])
Relation I equipped with a currency order [?]
such that: distinct tuples that agree on the primary key are comparable under [?
]; and tuples that disagree on the primary key are incomparable.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  Jef Wijsen  Data Currency  t1 [?]
t3 [?]
t2 t4 [?]
t5  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Ordered Relation Ordered relation (I , [?])
Relation I equipped with a currency order [?]
such that: distinct tuples that agree on the primary key are comparable under [?
]; and tuples that disagree on the primary key are incomparable.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  There is a unique present.
Jef Wijsen  Data Currency  t1 [?]
t3 [?]
t2 t4 [?]
t5  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Present  Present [relation] Relation obtained by selecting all greatest tuples.
Example EMP  FN Mary Bob  LN Smith Luth  Addr 10 Elm Ave 8 Drum St  Jef Wijsen  Sal 80k 80k  Stat married married  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Unordered Relation Unordered relation A relation in which primary keys need not be satisfied.
No currency order.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Unordered Relation Unordered relation A relation in which primary keys need not be satisfied.
No currency order.
Example EMP t1 : t2 : t3 :  FN Mary Mary Mary  LN Smith Smith Smith  Addr 2 Small St 10 Elm Ave 6 Main St  Sal 50k 80k 50k  Stat single married married  t4 : t5 :  Bob Bob  Luth Luth  8 Cowan St 8 Drum St  55k 80k  married married  This leaves six possible presents.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  [Currently] Certain Completion (of an unordered relation) Ordered relation obtained by adding a currency order [?]
to an unordered relation.
Every completion gives a possible present.
Definition A Boolean query is [currently] certain if it is true in each possible present.
Certainty It is certain that "Bob is married."
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Certainty The problem of certainty For any fixed Boolean first-order query q, CERTAINTY(q) is the following problem: Input An unordered relation Question Is q [currently] certain?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Certainty The problem of certainty For any fixed Boolean first-order query q, CERTAINTY(q) is the following problem: Input An unordered relation Question Is q [currently] certain?
Data complexity CERTAINTY(q) is in coNP.
There exists a Boolean conjunctive query q such that CERTAINTY(q) is coNP-complete.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Currency Constraints Definition Currency constraints are denial constraints that restrict the set of legal completions (and hence restrict the set of possible presents).
Currency constraints Salaries don't decrease.
![?]s[?
]t s.FN = t.FN [?]
s.LN = t.LN[?]
s.Sal < t.Sal [?]
t [?]
s Mary never divorced.
![?]s[?
]t s.FN = t.FN = Mary [?]
s.LN = t.LN = Smith[?]
 s.Stat = single [?]
t.Stat = married [?]
t [?]
s Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Consistent Consistency w.r.t.
a set S of denials We call an unordered relation I consistent if it has a consistent completion (i.e., if (I , [?])
|= S for some currency order [?]
on I ).
Inconsistency EMP s1 : s2 :  FN Mary Mary  LN Smith Smith  Addr 2 Small St 10 Elm Ave  Sal 80k 50k  Stat single married  ![?]s[?
]t s.FN = t.FN [?]
s.LN = t.LN[?]
s.Sal < t.Sal [?]
t [?]
s ![?]s[?
]t s.FN = t.FN = Mary [?]
s.LN = t.LN = Smith[?]
 s.Stat = single [?]
t.Stat = married [?]
t [?]
s Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Consistency The problem of consistency For any fixed set S of currency constraints, CONSISTENCY(S) is the following problem: Input An unordered relation I Question Is I consistent?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Consistency The problem of consistency For any fixed set S of currency constraints, CONSISTENCY(S) is the following problem: Input An unordered relation I Question Is I consistent?
Data complexity CONSISTENCY(S) is in NP.
There exists a set S of currency constraints such that CONSISTENCY(S) is NP-complete.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Background/Motivation  Deciding the "current truth" (of a Boolean query) in: Data integration: Conflicting facts are provided by a large number of sources [DBES09].
Data replication: Applications use out-of-date replicas to improve scalability, availability, and performance [GLR05].
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Copying Example CACHE s1 : s2 : EMP t1 : t2 :  FN Mary Mary FN Mary Mary  LN Smith Smith LN Smith Smith  Addr 2 Small St 10 Elm Ave  Sal 50k 70k  Stat single married  Addr 2 Small St 6 Main St  Sal 60k 60k  Stat single married  The cache is a finite set of unordered tuples.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Copying Example CACHE s1 : s2 : EMP t1 : t2 :  FN Mary Mary FN Mary Mary  LN Smith Smith LN Smith Smith  Addr 2 Small St 10 Elm Ave  Sal 50k 70k  Stat single married  Addr 2 Small St 6 Main St  Sal 60k 60k  Stat single married  The cache is a finite set of unordered tuples.
Should we extend EMP with extra tuples from the cache in order to get the "current truth" of a Boolean query?
Compare:  "Is Mary married?"
"Does Mary earn 60k?"
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Copying Problems Caveat Extending with all "cache" tuples may result in inconsistency.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Copying Problems Caveat Extending with all "cache" tuples may result in inconsistency.
Consistent extension w.r.t.
a set S of denials An unordered relation can be extended with "cache" tuples.
We call such extension maximal consistent if it is consistent; and any further proper extension is inconsistent.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Copying Problems Caveat Extending with all "cache" tuples may result in inconsistency.
Consistent extension w.r.t.
a set S of denials An unordered relation can be extended with "cache" tuples.
We call such extension maximal consistent if it is consistent; and any further proper extension is inconsistent.
Don't confuse: Completion Extension  adding currency order [?]
importing "cache" tuples Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Certainty Preservation The problem of certainty preservation For any fixed Boolean first-order query q and set S of currency constraints, CPP(q, S) is the following problem: Input  a consistent unordered relation in which q is [currently] certain a "cache"  Question Is q [currently] certain in at least one maximal consistent extension?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Certainty Preservation The problem of certainty preservation For any fixed Boolean first-order query q and set S of currency constraints, CPP(q, S) is the following problem: Input  a consistent unordered relation in which q is [currently] certain a "cache"  Question Is q [currently] certain in at least one maximal consistent extension?
Data complexity CPP(q, S) is in Sp2 .
There exists a Boolean conjunctive query q and set S such that CPP(q, S) is Sp2 -complete.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Basic Model Extension: Currency Constraints Extension: Copying  Sp2 Algorithm  Outline 1 Guess an ordered relation (I , [?]).
2  Verify I is an extension and (I , [?])
|= S (in P).
3  Verify maximality, i.e., adding an extra cache tuple to I results in inconsistency (at most linearly many queries of coNP oracle).
4  Verify q is [currently] certain in I (one query of coNP oracle).
Hardness is by reduction from the complement of [?][?
]3CNF .
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Back to the Basic Model/Motivation  No currency constraints.
No copying.
What you get if you strip off timestamps from a temporal relation.
We have seen that even in this basic model, there exists a Boolean conjunctive query q such that CERTAINTY(q) is coNP-hard.
Can we identify queries q for which CERTAINTY(q) is tractable (or, even better, first-order definable)?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Unordered Database Again Unordered database A database in which primary keys need not be satisfied.
Possible present In the absence of currency constraints, a possible present is any maximal subset of tuples that satisfy primary keys.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Unordered Database Again Unordered database A database in which primary keys need not be satisfied.
Possible present In the absence of currency constraints, a possible present is any maximal subset of tuples that satisfy primary keys.
Every tuple was once true T R  FN Mary Mary  LN Smith Smith  Dname R&D MIS  Dname R&D MIS Toys Toys  2 x 2 possible presents Jef Wijsen  Data Currency  Budget 60K 60K 60K 70K  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Certainty Definition A Boolean query is certain if it is true in each possible present.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Certainty Definition A Boolean query is certain if it is true in each possible present.
Example T R  FN Mary Mary  LN Smith Smith  Dname R&D MIS  Dname R&D MIS Toys Toys  Budget 60K 60K 60K 70K  q1 = [?
]x(R(Mary, x, R&D)) q2 = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , 60K)) q1 is not certain, q2 is certain Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Problem Statement CERTAINTY(q) For fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, is q certain?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Problem Statement CERTAINTY(q) For fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, is q certain?
Complexity for conjunctive queries For q3 = [?]x[?
]y [?
]z(S(x, z) [?]
T (y , z)), CERTAINTY(q3 ) is coNP-hard.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Problem Statement CERTAINTY(q) For fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, is q certain?
Complexity for conjunctive queries For q3 = [?]x[?
]y [?
]z(S(x, z) [?]
T (y , z)), CERTAINTY(q3 ) is coNP-hard.
CERTAINTY(q1 ) is first-order expressible (see later).
That is, "Is q1 certain?"
can be encoded in FO.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Problem Statement CERTAINTY(q) For fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, is q certain?
Complexity for conjunctive queries For q3 = [?]x[?
]y [?
]z(S(x, z) [?]
T (y , z)), CERTAINTY(q3 ) is coNP-hard.
CERTAINTY(q1 ) is first-order expressible (see later).
That is, "Is q1 certain?"
can be encoded in FO.
Research problem Find algorithm for the following decision problem: Given Boolean conjunctive query q, is CERTAINTY(q) first-order expressible (and hence in AC0 )?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  State of the art [Wij10a] An algorithm for the following decision problem: Given Boolean acyclic conjunctive query q without self-join, is CERTAINTY(q) first-order expressible?
If answer is "yes," we can construct the first-order expression.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  State of the art [Wij10a] An algorithm for the following decision problem: Given Boolean acyclic conjunctive query q without self-join, is CERTAINTY(q) first-order expressible?
If answer is "yes," we can construct the first-order expression.
Remaining restrictions q without self-join == no duplicate relation names in q q acyclic == q has a join tree  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Join Tree Definition A join tree for conjunctive query q is an undirected tree whose vertices are the atoms of q, such that: Connectedness Cond.
if the same variable x occurs in two distinct atoms F and G , then x occurs in each vertex on the (unique) path linking F and G .
Jef Wijsen  Example R0 (x, y ) {x, y }  {x}  R1 (y , x) {x, y } R2 (x, y ) R3 (x, z)  {x, z} R4 (x, z)  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  First-order Expressibility  CERTAINTY(q1 ) is first-order expressible q1 = [?
]x(R(Mary, x, R&D))  ph1 = [?
]x R(Mary, x, R&D)[?]
 [?
]z R(Mary, x, z) - z = R&D For every unordered database, q1 certain == ph1 true.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  First-order Expressibility CERTAINTY(q2 ) is first-order expressible q2 = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , 60K)) h ph2 = [?]x[?
]y R(Mary, x, y )[?]
  [?
]y R(Mary, x, y ) - T (y , 60K)[?]
i [?
]z T (y , z) - z = 60K  For every unordered database, q2 certain == ph2 true.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Order is Important Changing the order q2 = [?]x[?
]y (T (y , 60K) [?]
R(Mary, x, y )) h ' ph2 = [?
]y T (y , 60K)[?]
 [?
]z T (y , z) - z = 60K[?]
 [?
]x R(Mary, x, y )[?]
[?
]w R(Mary, x, w ) - w = y  i  For every unordered database, ph'2 true == q2 certain; but the converse does not hold:  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Order is Important Changing the order q2 = [?]x[?
]y (T (y , 60K) [?]
R(Mary, x, y )) h ' ph2 = [?
]y T (y , 60K)[?]
 [?
]z T (y , z) - z = 60K[?]
 [?
]x R(Mary, x, y )[?]
[?
]w R(Mary, x, w ) - w = y  i  For every unordered database, ph'2 true == q2 certain; but the converse does not hold: T  Dname R&D MIS  Budget 60K 60K  R  FN Mary Mary  Jef Wijsen  LN Smith Smith Data Currency  Dname R&D MIS  q2 certain ph'2 false  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Determining the Order  Attack graph For each Boolean acyclic conjunctive query q, without self-join, we compute a directed graph, called attack graph: The vertices are the atoms of q.
The directed edges, to be defined later on, are such that a first-order expression for CERTAINTY(q) can be obtained by applying our "[?][?
]-rewrite function" on any topological sort of the attack graph.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Getting the Idea  Attack graph  Join tree R(Mary, x, y )  R(Mary, x, y )  y T (y , 60K)  T (y , 60K)  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Functional Dependencies Implied by Primary Keys Definition We write vars(~x ) for the set of variables occurring in ~x .
For single atom F = R(~x , ~y ): K(F ) := vars(~x ) - vars(~x ~y ) Extension to conjunctive query q: K(q) := {K(F ) | F atom of q} Example q2 = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , 60K)) K(q2 ) = {x - xy , y - y }  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Attack Graph of a Join Tree  Attack graph The attack graph of join tree t contains a directed edge from R(~x , ~y ) to another atom F if for each label L on the path that links R(~x , ~y ) and F in t : K(q \ {R(~x , ~y )}) 6|= vars(~x ) - L  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Attack Graph of a Join Tree Example Attack graph The attack graph of join tree t contains a directed edge from R(~x , ~y ) to another atom F if for each label L on the path that links R(~x , ~y ) and F in t : K(q \ {R(~x , ~y )}) 6|= vars(~x ) - L  Jef Wijsen  R0 (x, y ) {x, y }  {x} R3 (x, z) {x, z} R4 (x, z)  Data Currency  R1 (y , x) {x, y } R2 (x, y )  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Attack Graph of a Join Tree Example Attack graph The attack graph of join tree t contains a directed edge from R(~x , ~y ) to another atom F if for each label L on the path that links R(~x , ~y ) and F in t : K(q \ {R(~x , ~y )}) 6|= vars(~x ) - L  R0 (x, y ) {x, y }  {x}  R1 (y , x) {x, y } R2 (x, y )  R3 (x, z) {x, z} R4 (x, z)  K(q \ {R0 (x, y )}) [?]
{y - x, x - z} |= x - xz  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Attack Graph of a Join Tree Example Attack graph The attack graph of join tree t contains a directed edge from R(~x , ~y ) to another atom F if for each label L on the path that links R(~x , ~y ) and F in t : K(q \ {R(~x , ~y )}) 6|= vars(~x ) - L  R0 (x, y ) {x, y }  {x}  R1 (y , x) {x, y } R2 (x, y )  R3 (x, z) {x, z} R4 (x, z)  K(q \ {R1 (y , x)}) [?]
{x - y , x - z} |= y - y  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Attack Graph of a Join Tree Example Attack graph The attack graph of join tree t contains a directed edge from R(~x , ~y ) to another atom F if for each label L on the path that links R(~x , ~y ) and F in t : K(q \ {R(~x , ~y )}) 6|= vars(~x ) - L  R0 (x, y ) {x, y }  {x}  R1 (y , x) {x, y } R2 (x, y )  R3 (x, z) {x, z} R4 (x, z)  K(q \ {R3 (x, z)}) [?]
{x - y , y - x, x - z} |= x - xyz Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Main Result Acyclicity of attack graph is both sufficient and necessary for first-order expressibility.
Theorem Let q be a Boolean conjunctive query, without self join.
Let t be a join tree for q.  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Main Result Acyclicity of attack graph is both sufficient and necessary for first-order expressibility.
Theorem Let q be a Boolean conjunctive query, without self join.
Let t be a join tree for q.
Sufficient If the attack graph of t is acyclic, then CERTAINTY(q) is first-order expressible (and its first-order definition can be obtained by applying our "[?][?
]-rewrite function" on any topological sort of the attack graph).
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Main Result Acyclicity of attack graph is both sufficient and necessary for first-order expressibility.
Theorem Let q be a Boolean conjunctive query, without self join.
Let t be a join tree for q.
Sufficient If the attack graph of t is acyclic, then CERTAINTY(q) is first-order expressible (and its first-order definition can be obtained by applying our "[?][?
]-rewrite function" on any topological sort of the attack graph).
Necessary If the attack graph of t is cyclic, then CERTAINTY(q) is not first-order expressible.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Proof of Inexpressibility Result  Lemma Let q be a Boolean conjunctive query, without self join.
Let t be a join tree for q.
If the attack graph of t is cyclic, then it has a cycle of size 2.
Then we can assume two distinct atoms, say F and G , such that the attack graph contains a directed edge from F to G , and a directed edge from G to F .
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Two Databases that Locally Look the Same th1 (F )  th1 (G )  th1 (F )  th1 (G )  th2 (F )  th2 (G )  th2 (F )  th2 (G )  th3 (F )  th3 (G )  th3 (F )  th3 (G )  th4 (F )  th4 (G )  th4 (F )  th4 (G )  th5 (F )  th5 (G )  th5 (F )  u1 (G )  dbyes  u1 (G )  u2 (F )  u2 (G )  u2 (F )  u2 (G )  u3 (F )  u3 (G )  u3 (F )  u3 (G )  u4 (F )  u4 (G )  u4 (F )  u4 (G )  u5 (F )  u5 (G )  u5 (F )  dbno Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Outline  1  Data Currency Model Basic Model Extension: Currency Constraints Extension: Copying  2  More on CERTAINTY(q) Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  NonBoolean Queries NonBoolean queries Our results apply to nonBoolean queries: treat free variables as new constants.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  NonBoolean Queries NonBoolean queries Our results apply to nonBoolean queries: treat free variables as new constants.
NonBoolean query q2 (v ) = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , v )) h ph2 (v ) = [?]x[?
]y R(Mary, x, y )[?]
  [?
]y R(Mary, x, y ) - T (y , v )[?]
[?
]z T (y , z) - z = v  i  For every unordered database, for every constant a, q2 (a) certain == ph2 (a) true.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Self-join Acyclic conjunctive queries with self-join q4 = [?]x[?
]y [?
]z(T (x, y ) [?]
T (y , z)) q5 = [?]x[?
]y (T (x, y ) [?]
T (y , c)) We know from earlier work [Wij09]: CERTAINTY(q4 ) is first-order expressible; CERTAINTY(q5 ) is not first-order expressible.
Attack graphs cannot distinguish q4 and q5 .
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Cyclic Queries  Cyclic conjunctive query without self-join Deciding first-order expressibility of CERTAINTY(q) for cyclic q remains open.
For example, q6 = [?]x[?
]y [?
]z(R0 (x, y ), R1 (y , z), R2 (z, x)) It is not known whether CERTAINTY(q6 ) is tractable.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Tractability of CERTAINTY(q) For q ranging over the class of Boolean acyclic conjunctive queries without self-join: we can decide whether CERTAINTY(q) is first-order expressible (and hence in AC0 ); but can we decide whether CERTAINTY(q) is in P?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Tractability of CERTAINTY(q) For q ranging over the class of Boolean acyclic conjunctive queries without self-join: we can decide whether CERTAINTY(q) is first-order expressible (and hence in AC0 ); but can we decide whether CERTAINTY(q) is in P?
Boundaries do not coincide There exists q such that CERTAINTY(q) is in P but not first-order expressible [Wij10b].
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Tractability of CERTAINTY(q) For q ranging over the class of Boolean acyclic conjunctive queries without self-join: we can decide whether CERTAINTY(q) is first-order expressible (and hence in AC0 ); but can we decide whether CERTAINTY(q) is in P?
Boundaries do not coincide There exists q such that CERTAINTY(q) is in P but not first-order expressible [Wij10b].
Dichotomy conjecture CERTAINTY(q) is in P or is coNP-complete.
For queries with exactly 2 atoms, this dichotomy has recently been proved by Kolaitis and Pena.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  The Counting Problem CERTAINTY(q) Definition For a fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, how many possible presents satisfy q?
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  The Counting Problem CERTAINTY(q) Definition For a fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, how many possible presents satisfy q?
Example R  FN Mary Mary Mary  LN Smith Smith Smith  Dname R&D MIS Toys  T  Dname R&D MIS Toys Toys  Budget 60K 60K 60K 70K  q2 = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , 60K)) q2 is true in 5 possible presents (out of 6) Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  The Counting Problem CERTAINTY(q) Definition For a fixed Boolean query q, the problem CERTAINTY(q) is: Given an unordered database, how many possible presents satisfy q?
Example R  FN  LN  Dname  Mary  Smith  Toys  T  Dname R&D MIS  Budget 60K 60K  Toys  70K  q2 = [?]x[?
]y (R(Mary, x, y ) [?]
T (y , 60K)) q2 is true in 5 possible presents (out of 6) Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Complexity Dichotomy for CERTAINTY(q)  Dichotomy [MW11] For every Boolean conjunctive query q without self-join, at least one of the following holds: CERTAINTY(q) is in P; or CERTAINTY(q) is P-complete under polynomial-time Turing reductions.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Complexity Dichotomy for CERTAINTY(q)  Dichotomy [MW11] For every Boolean conjunctive query q without self-join, at least one of the following holds: CERTAINTY(q) is in P; or CERTAINTY(q) is P-complete under polynomial-time Turing reductions.
Other dichotomy A similar dichotomy holds in probabilistic databases [DRS11].
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  Summary of Main Results Uncertainty about currency leads to high data complexity.
There exist conjunctive queries q, q ' and sets S, S' of denials such that: CERTAINTY(q) is coNP-hard CONSISTENCY(S) is NP-hard CPP(q ' , S' ), certainty preservation under copying, is Sp2 -hard  But: For acyclic conjunctive queries q without self-join, we can decide whether CERTAINTY(q) is first-order definable (and hence in AC0 ).
For conjunctive queries q without self-join, we can decide whether CERTAINTY(q) is in P.  Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  References I Xin Luna Dong, Laure Berti-Equille, and Divesh Srivastava.
Truth discovery and copying detection in a dynamic world.
PVLDB, 2(1):562-573, 2009.
Nilesh N. Dalvi, Christopher Re, and Dan Suciu.
Queries and materialized views on probabilistic databases.
J. Comput.
Syst.
Sci., 77(3):473-490, 2011.
Wayne W. Eckerson.
Data quality and the bottom line: Achieving business success through a commitment to high quality data.
The Data Warehousing Institute, 2002.
Wenfei Fan, Floris Geerts, and Jef Wijsen.
Determining the currency of data.
In Maurizio Lenzerini and Thomas Schwentick, editors, PODS, pages 71-82.
ACM, 2011.
Hongfei Guo, Per-Ake Larson, and Raghu Ramakrishnan.
Caching with 'good enough' currency, consistency, and completeness.
In Klemens Bohm, Christian S. Jensen, Laura M. Haas, Martin L. Kersten, Per-Ake Larson, and Beng Chin Ooi, editors, VLDB, pages 457-468.
ACM, 2005.
Dany Maslowski and Jef Wijsen.
On counting database repairs.
In Proceedings of the 4th International Workshop on Logic in Databases, LID '11, pages 15-22, New York, NY, USA, 2011.
ACM.
Jef Wijsen  Data Currency  Data Currency Model More on CERTAINTY(q)  Deciding FO Definability of CERTAINTY(q) Technical Development Discussion and Extensions  References II  Jef Wijsen.
On the consistent rewriting of conjunctive queries under primary key constraints.
Inf.
Syst., 34(7):578-601, 2009.
Jef Wijsen.
On the first-order expressibility of computing certain answers to conjunctive queries over uncertain databases.
In Jan Paredaens and Dirk Van Gucht, editors, PODS, pages 179-190.
ACM, 2010.
Jef Wijsen.
A remark on the complexity of consistent conjunctive query answering under primary key violations.
Information Processing Letters, 110(21):950 - 955, 2010.
Jef Wijsen  Data Currency

2011 Eighteenth International Symposium on Temporal Representation and Reasoning  MulTiSEX - A Multilanguage Timex Sequential Extractor Stefan Rigo+ ++ and Alberto Lavelli ++ ++  Human Language Technology Research Unit, Fondazione Bruno Kessler + DISI, University of Trento Trento, Italy {rigo,lavelli}@fbk.eu  Abstract--In this paper we present a light-weighted Machine Learning based approach to the recognition and semantic classification of temporal expressions in different languages.
We applied the proposed approach to English, Italian and Spanish with limited porting efforts.
The experimental results show that our system produces state-of-the-art performance on all the corpora used and in some cases outperforms available systems.
Journal, is scheduled to expire at the end of November.
Montedison currently owns about 72% of Erbamont 's common shares outstanding.
The hermeneutic effort that humans produce in order to understand the temporal information in Example 1 is fairly small.
On the other hand, a computer can hardly process questions like "When was Montedison's tender offer published?
", "When does Montedison's offer expire?"
or "How much of Erbamont's shares does Montedison actually own?"
without accessing information about the temporal structure of a text, which, in turn, can not be produced without the recognition, classification and normalization of temporal expressions.
This paper addresses the recognition and semantic classification of temporal expressions, i.e.
the identification and interpretation of phrases that convey temporal expressions in sentences.
A light-weighted Machine Learning (ML) based system built using off-the-shelf components is presented.
The intuition we are following is that the performance of ML-driven approaches for timex recognition can be improved by taking into account lexical peculiarities of timexes and of the context they are occurring in.
Our system produces state-of-the-art results employing a small set of generic morpho-syntactic and surface features, augmented by a database of time-related lexical items.
Conditional Random Fields [11] are employed as underlying learning paradigm.
We address a cross-linguistic setting as test case for our system, using the English, Spanish and Italian datasets delivered for the TempEval-2 challenge [27].
In order to be able to compare our results on a multilingual basis, and to the most recent state-of-the-art systems, we chose the TempEval-2 scorer as reference benchmark.
Nevertheless, we will also evaluate our system using a stricter metric, namely the CoNLL chunking-task scorer [25].
The experiments show that our system can be ported to different languages with little effort while maintaining high accuracy both on the recognition and the classification of timexes.
Our system performs better than the first ranking systems in the English and Spanish timex-recognition tasks at TempEval-2 (task A).
For Italian we obtain high performance as well (comparison for Italian is not possible since there were no participants to TempEval-2 Italian task A).
Moreover, we extend the evaluation to the English TimeBank [19] and the Italian ICAB corpus [13].
Keywords-Natural Language Processing; Temporal Processing; Temporal Expressions; Machine Learning  I.
INTRODUCTION  Time is a critical dimension of our information space.
Hence, it is not surprising that the Natural Language Processing (NLP) community is highly interested in exploiting the time dimension in text/discourse.
The automatic recognition of temporal information has become an area of intense research both in Computational Linguistics (CL) and Artificial Intelligence (AI).
NLP-related systems could substantially benefit from temporal processing capabilities.
Applications for Information Retrieval (IR), Information Extraction (IE), Question Answering (QA), summarization, and, last but not least, the actual development of the Semantic Web, all exploit temporal related information.
Advanced content processing systems start integrating temporal reasoning in their operational architecture.
For instance, a complex QA system needs to be able to operate on more information than can be extracted from temporal markers.
To produce a timeline, a text summarization system needs to extract and chronologically order temporal entities.
The recognition of temporal expressions is an essential task to achieve such processing skills.
Temporal expressions (henceforth, timexes) are the basic, time-related constituents in a temporal-information space, and they are needed to anchor events on a timeline, or to temporally structure a text.
In general, the recognition and classification of events and temporal expressions, and the temporal ordering over these entities, are gaining momentum in the NLP community.
Take the following example: Example 1: 17-10-1997: Italian chemical giant Montedison S.p.A., through its Montedison Acquisition N.V. indirect unit, began its $37-a-share tender offer for all the common shares outstanding of Erbamont N.V., a maker of pharmaceuticals incorporated in the Netherlands.
The offer, advertised in today's editions of The Wall Street 1530-1311/11 $26.00 (c) 2011 IEEE DOI 10.1109/TIME.2011.13  163  value.
TERN 2004 was the first challenge where timex recognition and normalization were tackled as a task distinct from NER.
Moreover, TERN 2004 was important for the fact that the TIDES TIMEX2 annotation guidelines [6] were established.
More recent efforts produced the specification language TimeML [20], an annotation scheme for events, temporal expressions and temporal relations in text/discourse.
In this paper we refer to the TIMEX3 guidelines, which are defined in the TimeML specifications.
TIMEX3 entities are classified as DATE, TIME, DURATION and SET.
The development of TimeML led to the creation of TimeBank [19], a temporally annotated corpus of English documents.
The latest release is TimeBank 1.2.1, containing 186 articles with approximately 68,000 tokens.
The content is taken from a variety of different sources, including newswire and transcribed broadcast news.
The relevant corpus for our purposes is the TempEval-2 [27] multilingual training and test data, which we will use for our cross-linguistic experiments.
TempEval-2 data was annotated with a simplified version of TimeML.
The type and value attributes of timexes are annotated.
The English data sets are derived from TimeBank.
While the TempEval-2 corpora and scoring script are our primary benchmarking reference, we evaluate our system also on TimeBank and on the Italian ICAB corpus [13] annotated according to the It-TimeML [4] specifications.
The remainder of this paper is structured as follows.
In Section II we give a short survey about what timexes are.
Section III provides an overview on temporal annotation standards and corpora.
In Section IV relevant works are discussed.
Section V presents our system architecture.
In Section VI we illustrate and discuss evaluation and results.
Finally, we draw some conclusion and outline future work in Section VII.
II.
WHAT IS A TIMEX?
Temporal expressions are natural language phrases that refer to time points or intervals.
They convey temporal information on their own, but operate also as anchors for temporally locating events referred to in a text.
The semantics of timexes can express duration, points in time, sets, direction in time (future, past).
We define a timex as a chunk of text denoting an explicit or implicit (i.e.
inferable) temporal information.
Timexes can occur in the following forms:          Fully specified timexes, like dates or times: November 27th, 2006, the eight century,11/27/2006 at 12:00 Anaphoric timexes anchored to an expression in the local context: three days after the meeting, the previous month, two weeks since the exam Deictic timexes (indexical), anchored to the time an expression was written (e.g.
the document creation time, DCT): today, this day, currently, now, last five weeks, tomorrow Durations or intervals: a week, five days, three semesters Frequencies: weekly, every other day, once a month, every first day of the week Culturally dependent timexes: Christmas, Easter, World AIDS Day Fuzzy (quantified) timexes: the past, some day  IV.
The recognition of a timex consists firstly in bracketing the extension of the chunk representing it, and successively in assigning it a type-value.
Finally, timexes have to be normalized, i.e.
an ISO-8601 value has to be assigned to each recognized timex.
The value is constrained by the type of the temporal expression.
The normalization step is not discussed in this paper.
III.
RELEVANT WORK  The best performing system at TERN 2004 English Full Task, the rule-based CHRONOS [16] achieved F1 results of 87% for bracketing and normalization.
After the TERN challenge, [1], [8] and [18] used sequential approaches for the classification of temporal expressions and used the TERN dataset as test bed.
F1 results for bracketing range from 77% [18] to 88% [8].
The system described in [2], while being mainly a ML approach, uses a small set of rules to compute first an underspecified representation for recognized timexes and subsequently to assign a ISOconform value.
They report an F1 measure of 90% for the recognition and bracketing of timex-chunks.
Using TimeBank as dataset, [3] built a timex-classifier based on a cascaded finite-state grammar.
They report an F1 measure around 82% for bracketing and around 68% for simultaneous bracketing and typing.
[10] used a Maximum Entropy classifier and TimeBank for training and test, reporting an F1 measure of around 82% for bracketing.
One of the best performing TempEval-2 systems [12] uses a sequential ML approach together with semantic roles.
Results are F1 of 85% for bracketing, and accuracy of 92% for the classification (cf.
Table V for all TempEval-2 English results).
As for Italian, to the best of our knowledge, the only TIMEX3-compliant system is the rule-based TETI [5].
TETI was evaluated on a manually annotated subset of the Italian syntactic-semantic Treebank [14] and is limited to the bracketing of timexes, i.e.
they are neither type-classified nor normalized.
Results are around 86% (F1) for the recognition of temporal expressions.
Another rule-based  BACKGROUND  Work on temporal annotation of English content started in the middle of the nineties (Message Understanding Conference - MUC-6, 1995), gradually evolving in annotation schemes of increasing expressive power.
In MUC-6 the recognition of temporal expressions was part of the Named Entity Recognition (NER) task, in which tokens had to be classified with labels from a given set.
In 2004 the Automated Content Extraction (ACE) conference proposed a competition for Temporal Expression Recognition and Normalization (TERN 2004), which extended the complexity of the task: temporal expressions had to be recognized in free text and normalized using an ISO-based  164  properties of the words in their context.
Furthermore, timexes are often expressed by sequences of words.
We argue that Conditional Random Fields (CRF) [11] are well suited to tackle timex recognition and classification in a sequential chunking task.
CRFs ground on exponential models where probabilities are computed from the values of a set of features derived from both the observation and the label sequences.
For sequence labeling problems linear chain CRFs are widely used.
They are expressed in the following form:  system (adhering to the TIMEX2 specifications and evaluated on a TIMEX2-compliant version of ICAB), ITA-Chronos [15], has an F1 performance of 92% for the recognition (i.e.
bracketing), and of 67% for the recognition and normalization of temporal expressions (i.e.
bracketing and assigning a value).
The first Spanish TIMEX2-compliant system was TERSEO [22], a knowledge-based architecture, which performs with an F1 of 77% on a manually annotated corpus of Spanish news.
The same system was automatically adapted to English and Italian [21], and evaluated on the English TERN 2004 corpus and on a TIMEX2-adhering version of the Italian ICAB corpus.
Results for English are comparable to other systems, while for Italian performance is considerably lower compared to ITA-Chronos.
The rule-based system that participated to the ACE 2007 TERN pilot-task for Spanish [28] was evaluated on a TIMEX2-annotated corpus of Spanish news.
Results range around F1 = 62% for recognition and bracketing, and accuracy over 95% for the classification of recognized timexes.
The best performing system at TempEval-2 task A for Spanish is also one of the best for English [12].
The ML-based architecture performs with F1 of 91% for recognition and bracketing, and with an accuracy of 91% for classification.
The other participating system was UC3M [29], a rule-based architecture that performed with comparable results (cf.
Table VI for all TempEval-2 Spanish results).
V.  (1) where Z(x) is the normalization factor, X={x1,...,xn} represents the observation sequence, Y= {y1,...,yt} represents the label sequence, and fk and k represent the feature functions and their respective weights.
CRFs have been employed for PoS tagging, shallow parsing, and named entity recognition.
We use the CRF++ toolkit for our experiments.1 B.
Feature engineering We use a small set of features, based on morphosyntactic and surface properties.
Timexes exhibit various textual properties, ranging from patterns that can be recognized using simple regular expressions to complex linguistic forms (phrases).
While timexes are realized in different phrase types, the lexical items expressing timexes, and their modifiers, quantifiers, adverbs, adjectives etc, form a restricted set.
Grounding on this consideration, two vectors that generalize the occurrence of different classes of temporally related items in a given context-window are assembled.
To be able to do this, we classify lexical items using a set of 22 categories.
These are:  SYSTEM ARCHITECTURE  Most state-of-the-art systems for the classification of temporal expressions recognize and label timexes in two steps, i.e.
first bracketing the extension of the TIMEX3-chunk and then classifying it.
On the contrary, we tackle the recognition of timexes as a classification problem in a wordchunking paradigm, i.e.
as a sequential labeling task where chunk information is encoded into token tags.
For the classification of timexes, we use an I-O-B tagging convention, i.e.
the tokens are labeled either as (B)eginning, (I)nside or (O)utside a TIMEX3 chunk.
The timex-phrase is classified with one of the four values for the type-attribute of the TIMEX3 tag (or with the OTHER label).
Example 2 shows an annotated fragment: Example 2:  Several years ago it was hot as this year .
1.
2.
3.
4.
5.
6.
B-DATE I-DATE I-DATE O O O O B-DATE I-DATE O  7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
A.
Conditional Random Fields Timexes are connected with the structural properties of sentences.
They are related to the syntactic structure of phrases and with morphological, semantic and syntactic  1  165  Items matching duration patterns (e.g.
20", eightminute) Items matching year-patterns (e.g.
2011, '45) Items matching time-patterns (e.g.
11:19, 01.30) Items matching ordinals (e.g.
first [of July]) Items matching digits Items matching numbers expressed through strings (e.g.
five [weeks]) Weekdays Months Part of day (e.g.
morning, noon) Seasons Festivities Items referring to the past (e.g.
earlier, last) Items referring to the present (e.g.
current, now) Items referring to the future (e.g.
next, coming) Fuzzy quantifiers (e.g.
few, some) Modifiers (e.g.
long, short) Temporal adverbs (e.g.
daily, earlier)  http://crfpp.sourceforge.net/  18.
19.
20.
21.
22.
VI.
Temporal adjectives (e.g.
early) Temporal conjunctives (e.g.
when, meanwhile) Temporal prepositions (e.g.
during, for) Time units (e.g.
seconds, minutes) Temporal co-references (e.g.
time, period)  While the English and Spanish training sets delivered for TempEval-2 have approximately the same size (around 67,000 tokens), the Italian data set is smaller (approximately 28,000 tokens).
Nevertheless, results for all languages reach state-of-the-art performance, showing that our system is easily portable among languages.
Moreover, we discuss results obtained using 10-fold cross validation over the Italian ICAB corpus (approx.
200,000 tokens) and the English TimeBank (approx.
68,000 tokens).
The first vector (p1) summarizes both the category of the processed token, and the categories of the surrounding items together with their relative position in an eight token context window.
We do this by assigning a letter to each category (and to the case the item does not match any of the defined categories) and assembling a string where the rightmost character expresses the category of the forth token after the parsed one, the leftmost the category of the first token in the context window (-3 to 4).
Lexical items that belong to different categories (e.g.
early can be an adverb or an adjective) are currently not disambiguated with regard to the PoS tag.
The second vector is a simple sequence of binary flags (p2) expressing the properties of the processed token, i.e.
we are encoding all categories a given token belongs to.
The feature set was developed over the ICAB corpus applying 10-fold cross-validation, and is listed in Table I.
We first built our system for Italian and successively adapted it to English and Spanish.
All we needed were a POS-Tagger and a stemmer for these languages, and a database of language-specific temporally related items.
TreeTagger [23] was used for PoS tagging and the Porter Stemmer for stemming.2 TABLE I.
Feature token PoS p1 p2 3pos 3stm abs 3-gr  EVALUATION  A. Metrics As previously stated, we use the TempEval-2 data sets and scoring script as reference benchmark.
This allows us to compare our architecture to the most recent state-of-the-art systems for the processing of temporal expressions.
However, since the TempEval-2 scorer is "relaxed" (i.e.
it computes the score on a token-basis and not on a phrasebasis) we will also evaluate our system using a stricter scoring method (i.e.
based on exact matches between the recognized and the gold-standard chunks), namely the CoNLL chunking task scoring script.
The TempEval-2 scorer computes precision, recall and F1-measure of recognized and bracketed timex-extents on a token-basis, using the following formulas: Precision = tp/(tp + fp) Recall = tp/(tp + fn) F1 = 2 *(Precision * Recall)/(Precision + Recall)  (2) (3) (4)  FEATURE SET  where tp is the number of tokens that are part of both the recognized and the gold-extent, fp is the number of tokens that are part of a recognized extent but not of the goldstandard, and fn is the number of tokens that are part of the gold-extent but not in the recognized extent.
The semantic class of a time expression is computed on the recognized timexes, using a simple metric: the number of correct answers divided by the number of answers (last column in Table II).
On the other hand, the CoNLL chunking task scorer computes performance on a phrase-basis.
The performance is measured with three figures: i) the percentage of detected phrases that are correct (precision), ii) the percentage of phrases in the test-data that were correctly recognized (recall), and iii) the F1 rate, which is computed with the same formula as in the TempEval-2 scoring script.
Moreover, the CoNLL scoring script gives an F1 measure of the combined recognition and classification task.
Hence, while we use the TempEval-2 scorer as reference benchmark, we will also use the CoNLL scorer since it provides us a more expressive measure.
We exemplify the difference between the two scripts using the fragment in Example 2.
Let us assume a system recognizes and classifies the chunk years/B-DATE ago/I-DATE (hence, missing the initial token of the gold-extent: Several), and correctly found and classified the temporal expression this/B-DATE year/IDATE.
For the first chunk, the TempEval-2 scorer would  Description Baseline system - lowercase token Part of Speech of token Context and category aware vector Vector of binary flags PoS 3-gram (previous, current, next) Stem 3-gram (previous, current, next) Surface properties abstractions Character 3-grams of token  For the purpose of this paper the items in the lexical database have been translated manually.
However, we argue that Machine Translation (MT) could be employed with limited effort, since we are handling single tokens.
The choice to manually translate the database was motivated by the fact that we wanted to i) empirically investigate differences in temporal semantics among languages, and ii) create a gold standard to evaluate the automatic translation (which we plan to implement in the near future).
2  We used the Python implementation of the Snowball project, http://snowball.tartarus.org.
166  Values in %  compute a precision of 2/(2+0) = 1, recall of 2/(2+1) = 0.66, and F1 = 2*(1*0.66)/(1+0.66) = 0.79.
For the second chunk we get precision = recall = F1 = 1.
The final TempeEval-2 figures on the fragment in example 2 are precision = 1, recall = 0.83, and F1 = 0.89.
On the contrary, the CoNLL scorer would yield precision = recall = F1 = 0.50.
B.
Results We trained and evaluated our TIMEX3-classifier on the TempEval-2 multilingual data sets using the features in Table I.
Figures 1 and 2 show the results obtained by subsequently adding the listed features.
We observed differences related to the employed PoS tagger.
While the choice of TreeTagger was motivated also by the fact that it was available for all languages used in our experiments, it did not seem to be the best choice for every language.
For instance in the case of English, if we use the PoS tagger that is part of the TextPro suite [17], we gain 2% for the F1 measure on both scoring methods, while for Italian results remain the same (TextPro does not provide a PoS tagger for Spanish).
Figures 3, 4 and 5 show the incremental results for precision, recall, and F1 for the combined recognition and classification of timexes for the languages in our test case.
We used TreeTagger and the CoNLL scorer on the TempEval-2 data sets.
Concerning PoS tagging, differences in accuracy emerged also on the Italian ICAB corpus.
Performing a 10fold cross-validation, we gain 3% in F1 results on exact match and 1% on token-based match when using TextPro instead of TreeTagger.
As can be seen in Figure 4, the PoS-3-gram feature seems to penalize the performance on the Spanish data.
Training a model without this feature would yield a 2% F1 gain on exact match, while differences for the token-based scoring are negligible.
Similar performance penalties can be  English  Spanish  +p1  +p2  Values in %  Values in %  +3-gr  Values in %  Italian  +p2 +3pos +3stm +Abs  Precision  +PoS  Recall  +p1 +p2 +3pos +3stm Subsequently added features  F1  +abs  +3.gr  100 Precision Recall 95 90 85 80 75 70 65 60 55 50 token +PoS +p1 +p2 +3pos +3stm Subsequently added features  F1  +abs  +3.gr  observed also for Italian (surface abstraction) and English (p1 and stem-3-gram).
However, in both cases subtracting these features from the set did lower the overall performance.
We argue that the performance gain observed on the Spanish test data is peculiar to this corpus and that it cannot be generalized over other corpora and/or languages.
The low recall seen on the Italian TempEval-2 corpus is clearly an indication of its reduced size.
Table II resumes the results obtained with the TempEval-2 scoring script, Table III those obtained using the CoNLL scorer.
Finally, Table IV shows the results obtained for the sole bracketing of timexes (using the CoNLL scorer).
Figures 6 and 7 show the results obtained respectively on the English TimeBank (TB) and the Italian ICAB.
TextPro was used on ICAB, and on the English TempEval-2 (TE-2) corpus, TreeTagger for all other corpora.
The experiments showed that we could gain additional accuracy using different PoS taggers (as for English).
For the purpose of comparing our system to others, on the TempEval-2 data sets we used TreeTagger for PoS-tagging on the Spanish and Italian corpora, and TextPro for English.
This is the only adaption we made.
We used the feature set in Table I for all languages.
Figure 1.
F1 - TempEval-2 scorer (TempEval-2, TreeTagger)  Spanish  100 95 90 85 80 75 70 65 60 55 50 token  Figure 5.
Italian F1 exact match (TempEval-2, TreeTagger)  Subsequently added features  100 English 95 90 85 80 75 70 65 60 token +PoS +p1  +3-gr  Figure 4.
Spanish F1 exact match (TempEval-2, TreeTagger)  Italian  +3pos +3stm +Abs  F1  Figure 3.
English F1 exact match (TempEval-2, TreeTagger)  Values in %  100 95 90 85 80 75 70 token +PoS  100 95 Precision Recall 90 85 80 75 70 65 60 55 50 token +PoS +p1 +p2 +3pos +3stm +abs Subsequently added features  +3-gr  Subsequently added features  Figure 2.
F1 - CoNLL scorer (TempEval-2, TreeTagger)  167  Values in %  90 85  TABLE II.
Precision  Recall  Dataset TE-2 ENG TE-2 SPA TE-2 ITA TB (ENG) ICAB (ITA)  80 75 70 65 token +PoS  +p1 +p2 +3pos +3stm Subsequently added features  +abs  +3-gr  TABLE III.
Values in %  Figure 6.
TimeBank F1 exact match (TreeTagger)  100 Precision Recall 95 90 85 80 75 70 token +PoS +p1 +p2 +3pos +3stm Subsequently added features  RECOGNITION & CLASSIFICATION - TEMPEVAL-2 SCORER  F1  Precision 0.89 0.94 0.95 0.92 0.96  Precision 0.82 0.87 0.91 0.81 0.87  TABLE IV.
+abs  Figure 7.
ICAB F1 exact match (TextPro)  For the subtasks of recognizing the extent and type-value of a TIMEX3, our classifier outperforms all systems (English and Spanish) submitted for task A at TempEval-2 [27].
Tables 5 and 6 show our results compared to the English and Spanish systems that participated to TempEval-2 task A.
As for Italian, we obtain a precision of 95%, recall of 79% and F1 of 87%, and our system correctly classified 96% of the recognized TIMEX3 chunks.
Although this result is satisfactory, it reflects the fact that the used training corpus has half the size of the other corpora.
There is no system we can use for direct comparison of the results obtained using the timex-classifier on the Italian TempEval-2 data sets.
Precision 0.84 0.87 0.93 0.86 0.90  TABLE V.  We have presented a state-of-the-art ML-classifier for temporal expressions and have shown that it can be adapted to different languages without major efforts.
A small set of generic, morpho-syntactic features is employed.
The feature representation is augmented using a lexical database of time-related items.
We evaluated our architecture across different languages and corpora.
Our classifier outperforms all systems that participated to the English and Spanish task A of TempEval-2, and reaches similar high performance on the Italian TempEval-2 data set.
State-of-the-art performance is obtained also on the TimeBank and ICAB corpora.
While we are getting satisfactory results, we argue there is still room for improvement, particularly with regard to feature engineering.
We are currently working on a normalization module for both English and Italian, and on PoS-based disambiguation of items that belong to different categories of our database of time-related lexical items.
Finally, we will explore the use  Recall 0.78 0.88 0.70 0.77 0.83  F1 rec+class 0.80 0.88 0.79 0.79 0.85  Recall 0.81 0.88 0.73 0.83 0.88  F1 bracketing 0.82 0.88 0.82 0.85 0.89  TEMPEVAL-2 TASK A ENGLISH RESULTS  TempEval-2 English  VII.
CONCLUSION AND FUTURE WORK  Class-acc.
0.93 1 0.96 0.92 0.95  BRACKETING RESULTS - CONLL SCORER  Dataset TE-2 ENG TE-2 SPA TE-2 ITA TB (ENG) ICAB (ITA)  +3-gr  F1 0.87 0.94 0.87 0.90 0.93  RECOGNITION & CLASSIFICATION - CONLL SCORER  Dataset TE-2 ENG TE-2 SPA TE-2 ITA TB (ENG) ICAB (ITA)  F1  Recall 0.85 0.93 0.79 0.87 0.90  Precision  Recall  F1  type  HEIDELTIME1 [24]  0.90  0.82  0.86  0.96  HEIDELTIME2 [24]  0.82  0.91  0.86  0.92  TIPSEM [12]  0.92  0.80  0.85  0.92  TRIOS & TRIPS [26]  0.85  0.85  0.85  0.94  EDINBURGH [7]  0.85  0.82  0.84  0.84  KUL-3 [9]  0.85  0.84  0.84  0.91  MULTISEX ENGLISH  0.89  0.85  0.87  0.93  TABLE VI.
TEMPEVAL-2 TASK A SPANISH RESULTS  TempEval-2 Spanish  Precision  Recall  F1  type  TIPSEM [12]  0.95  0.87  0.91  0.91  TIPSEM -B  0.97  0.81  0.88  0.99  0.90  0.87  0.88  0.91  0.94  0.93  0.94  1  UC3M  [12]  [29]  MULTISEX SPANISH  of Machine Translation to translate database of temporally related items.
ACKNOWLEDGMENTS This work has been partially supported by the LiveMemories project (Active Digital Memories of Collective Life - http://www.livememories.org) funded by the Autonomous Province of Trento under the call "Major Project 2006".
We would like to thank Matteo Negri and Emanuele Pianta for support and insights.
168  REFERENCES [1] Ahn, D., Adafre, S.F., Rijke, M.D.
Towards Task-Based Temporal Extraction and Recognition.
In Proceedings of the Dagstuhl Workshop on Annotating, Extracting, and Reasoning about Time and Events, Dagstuhl, Germany, 2005.
[2] Ahn, D., van Rantwijk, J., de Rijke, M. A Cascaded Machine Learning Approach to Interpreting Temporal Expressions.
In Proceedings of the Annual Conference of the North American Chapter of the ACL NAACL-HLT 2007, 2007, 420-427.
[3] Boguraev, B., Ando, R.K. TimeBank-Driven TimeML Analysis.
In Proceedings of the Dagstuhl Workshop on Annotating, Extracting, and Reasoning about Time and Events, Dagstuhl, Germany, 2005.
[4] Caselli, T. It-TimeML Annotation Scheme for Italian.
Linee guida per l'applicazione di uno schema di annotazione.
Version 1.3.1, ILC-PISA, Pisa (Italy), 2010.
[5] Caselli, T. Time, Events and Temporal Relations: an Empirical Model for Temporal Processing of Italian Texts.
University of Pisa, PhD Thesis, 2009.
[6] Ferro, L., Gerber, L., Mani, I., Sundheim, B., Wilson, G. TIDES.
2003 Standard for the Annotation of Temporal Expressions, 2004.
[7] Grover, C., Tobin, R., Alex, B., Byrne, K. Edinburgh-LTG: TempEval-2 system description.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010, 333-336.
[8] Hacioglu, K., Chen, Y., Douglas, B.
Automatic Time Expression Labeling for English and Chinese Text.
In Proceedings of the 6th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing'05), 2005, 548-559.
[9] Kolomiyets, O., Moens, M.-F. KUL: Recognition and normalization of temporal expressions.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010, 325-328.
[10] Kolomiyets, O., Moens, M.-F. Meeting TempEval-2: Shallow Approach for Temporal Tagger.
In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions, Boulder, Colorado, 2009, 52-57.
[11] Lafferty, J.D., McCallum, A., Pereira, F.C.N.
"Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data".
In Proceedings of the ICML '01, 2001, 282-289.
[12] Llorens, H., Saquete, E., Navarro, B. TIPSem (English and Spanish): Evaluating CRFs and semantic roles in TempEval2.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010, 284-291.
[13] Magnini, B., Pianta, E., Girardi, C., Negri, M., Romano, L., Speranza, M., Bartalesi Lenzi, V., Sprugnoli, R. I-CAB: the Italian Content Annotation Bank.
In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC'06 ), Genova, Italy, 2006.
[14] Montemagni, S., Barsotti, F., Battista, M., Calzolari, N., Corazzar, O., Lenci, A., Pirelli, V., Zampolli, A., Fanciulli, F., Massetani, M., Raffaelli, R., Basili, R., Pazienza, M.T.,  [15]  [16]  [17]  [18]  [19]  [20]  [21]  [22]  [23]  [24]  [25]  [26]  [27]  [28]  169  Saracino, D., Zanzotto, F., Mana, N., Pianesi, F., Delmonte, R. "The syntactic-semantic treebank of Italian.
An overview".
Linguistica Computazionale, Computational Linguistics in Pisa, special Issue, vol.
XVIII-XIX, 2003, 461-493.
Negri, M. Dealing with Italian temporal expressions: The ITA-Chronos system.
In Proceedings of EVALITA 2007.
Workshop held in conjunction with AI*IA, 2007.
Negri, M., Marseglia, L. Recognition and normalization of time expressions: Itc-irst at TERN 2004.
Technical Report, ITC-irst, Trento, 2004.
Pianta, E., Girardi, C., Zanoli, R. The TextPro tool suite.
In Proceedings of the 6th Conference on Language Resources and Evaluation (LREC'08), Marrakech (Morocco), 2008.
Poveda, J., Surdeanu, M., Turmo, J.
A Comparison of Statistical and Rule-Induction Learners for Automatic Tagging of Time Expressions in English.
In Proceedings of the 14th International Symposium on Temporal Representation and Reasoning (TIME'07), 2007, 141-149.
Pustejovsky, J., Hanks, P., Sauri, R., See, A., Gaizauskas, R., Setzer, A., Radev, D., Sundheim, B., Day, D., Ferro, L., Lazo, M. The TIMEBANK Corpus.
In Proceedings of the Corpus Linguistics, 2003, 647-656.
Pustejovsky, J., Ingria, R., Sauri, R., Littman, J., Gaizauskas, R., Setzer, A., Katz, G. The Specification Language TimeML.
The Language of Time: A Reader.
Oxford University Press (2004).
Saquete, E., Martinez-Barco, P., Munoz, R., Negri, M., Speranza, M., Sprugnoli, R. Multilingual extension of a temporal expression normalizer using annotated corpora.
In Proceedings of the International Workshop on CrossLanguage Knowledge Induction, Trento, Italy, 2006, 1-8.
Saquete, E., Munoz, R., Martinez, P. "Event ordering using TERSEO system".
Data & Knowledge Engineering - Special issue: Application of Natural Language to Information Systems (NLDB'04), vol.
58-1, 2006, 70-89.
Schmid, H. Probabilistic part-of-speech tagging using decision trees.
In Proceedings of the First International Conference on New Methods in Language Processing, Manchester, England, 1994, 44-49.
Strotgen, J., Gertz, M. HeidelTime: High quality rule-based extraction and normalization of temporal expressions.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10) , Uppsala, Sweden, 2010, 321-324.
Tjong Kim Sang, E.F., Buchholz, S. Introduction to the CoNLL-2000 Shared Task: Chunking.
In Proceedings of the CoNLL-2000, Lisbon, Portugal, 2000, 127-132.
UzZaman, N., Allen, J.
TRIPS and TRIOS System for TempEval-2: Extracting Temporal Information from Text.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010, 276-283.
Verhagen, M., Sauri, R., Caselli, T., Pustejovsky, J. SemEval-2010 task 13: TempEval-2.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010.
Vicente-Diez, M.T., de Pablo-Sanchez, C., Martinez, P. "Evaluacion de un sistema de reconocimiento y  normalizacion de expresiones temporales en espanol".
Procesamiento del Lenguaje Natural, vol.
39-2007, 113-120.
[29] Vicente-Diez, M.T., Schneider, J.M., Martinez, P. UC3M system: Determining the Extent, Type and Value of Time Expressions in TempEval-2.
In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval'10), Uppsala, Sweden, 2010, 329-332.
170
Formalizing Actions in Branching Time: Model-Theoretic Considerations Munindar P. Singh  Microelectronics and Computer Technology Corporation 3500 W. Balcones Center Drive Austin, TX 78759-5398 USA msingh@mcc.com  Abstract  The formalization of actions is essential to AI.
Several approaches have been proposed over the years.
However, most approaches concentrate on the causes and effects of actions, but do not give general characterizations of actions themselves.
A useful formalization of actions would be based on a general, possibly nondiscrete, model of time that allows branching (to capture agents' choices).
A good formalization would also allow actions to be of arbitrary duration and would permit multiple agents to act concurrently.
We develop a branching-time framework that allows great exibility in how time and action are modeled.
We motivate and formalize several coherence constraints on our models, which capture some nice intuitions and validate some useful inferences relating actions with time.
1 Introduction  Actions and time have drawn much attention in arti	cial intelligence (AI).
Whereas much progress has been made in modeling time, corresponding progress has not been made in modeling actions.
Temporal approaches run the gamut from discrete to continuous, point-based to interval-based, and linear to branching.
By contrast, approaches to formalizing actions tend to be restricted to discrete models, typically linear and with additional assumptions such as that exactly one action happens at a time, and all actions have the same duration.
Reasoning about actions focuses on the possible causes and e ects of the actions, but not on their structure.
This work is undoubtedly of value.
However, we submit that its full potential can be realized only if actions themselves are formalized in a general framework.
What are the properties that intuitively acceptable and technically feasible models of actions and time should support?
We  address this question here.
A general model of actions would provide the underpinnings for work on concepts|such as intentions, ability, and know-how|that supervene on actions.
When actions are modeled restrictively, the technical results obtained on the above concepts end up with potentially superuous or even pernicious restrictions.
It is easy to obtain spurious results on the above concepts that rely on some irrelevant aspect of the underlying model of actions Singh, 1992].
Our main interest is in formalizing the above concepts, but we must model actions properly to succeed Singh, 1994].
We introduce this formalization to the temporal representation community here.
Our framework allows (a) time to branch to model agents' choices, (b) multiple agents to act simultaneously, (c) actions to be of varying durations relative to one another, and (d) time to be nondiscrete.
Thus choice and control can be properly captured in this framework.
Our approach is nonrei	ed Bacchus et al., 1989], as is common in the non-AI literature Emerson, 1990].
Time can variously be modeled as linear or branching.
Allen presents an interval-based linear-time theory of actions in 1984].
Turner (p. 88) and Shoham 1988, ch.
2] show that Allen's theory is not conceptually clear, especially with regard to intervals.
Shoham too restricts his models to be linear.
Allen (p. 131) and Shoham (p. 36) argue that branching time is unnecessary since the agents' ignorance can be modeled in other ways.
However, branching into the future is not a matter of ignorance, but of choice.
That is why, ignorance apart, the past can be linear but the future must branch.
(Sometimes, eciency may be gained by treating even the past as branching: we allow this.)
Galton 1990] improves over Allen's approach in some respects but does not address constraints on actions per se.
McDermott's approach, like ours, is point-based and involves branching-time 1982].
But, McDermott requires his models to be dense also, clock values are essential to his semantics.
McDermott notes, correctly, that an action cannot hap-  pen over overlapping intervals: we capture this differently.
But a lot more must be said that his and other approaches do not say.
Related research includes Thomason & Gupta, 1981 van Frassen, 1981 Haddawy, 1990 Dean & Boddy, 1988], but it does not model actions as motivated here.
We present our formal language and model next and discuss our key operators informally.
Then we motivate and formalize a number of coherence constraints on our models that are required for various useful properties.
We use these to prove some important results relating actions and time.
We close with a discussion of some open problems.
2 Technical Framework  The proposed formal model is based on a set of moments with a strict partial order, which denotes temporal precedence.
Each moment is associated with a possible state of the world, which is identi	ed by the atomic conditions or propositions that hold at that moment.
A scenario at a moment is any maximal set of moments containing the given moment, and all moments in its future along some particular branch.
 .. .. ..     q X HX  HX  XX .
.
.
t 1 HX  H   q .
.
.
HH .
.
.
a k c  a k d t2    XHXHXXX b k c  qq .. .. ..   t0 HH XXX   HHH XXXr X HHXXXX q .
.
.
HH t3HX bkd HH q .
.
.
HHH q .
.
.
t4  does action a, then whether t1 or t2 becomes the case depends on whether the second agent does c or d. Intuitively, actions are package deals.
They correspond to the granularity at which an agent can make his choices.
In Figure 1, the 	rst agent can choose between t1 and t2, on the one hand, and between t3 and t4 , on the other hand.
However, he cannot choose between t1 and t2 , or between t3 and t4 .
Both choice and limited control are thus captured.
2.1 The Formal Language  We use a qualitative temporal language, L, based on CTL* Emerson, 1990].
This captures the essential properties of actions and time that are of interest.
Formally, L is the minimalset closed under the following rules.
Here L is the set of \scenario-formulae," which is used as an auxiliary de	nition.
is a set of atomic propositional symbols, A is a set of agent symbols, B is a set of basic action symbols, and X is a set of variables.
L1.
 2  implies that  2 L L2.
p Wq 2 L and a 2 B implies that p ^ q, :p, Pp, ( a : p) 2 L s  LL L4.
p q 2 L , x 2 A, and a 2 B implies that p ^ q, :p, pUq, xa]p, xhaip, xjhaijp 2 L L5.
p 2 L implies that Ap 2 L W L6.
p 2 (L ; L) and a 2 X implies that ( a : p) 2 L 2.2 The Formal Model A model for L is a four-tuple, M = (T < A  ] ).
Here T is a set of possible moments ordered by <.
A assigns agents to di erent moments i.e., A : T 7!
}(A).  ]
is described below.
The relation < is a L3.
s  s  s  s  s  s  strict partial order:  	 Transitivity: (8t t  t 2 T : (t < t ^ t < t )) t < t ) 	 Asymmetry: (8t t 2 T : t < t ) t 6< t) 	 Irreexivity: (8t 2 T : t 6< t) 0  00  Figure 1: The Formal Model Figure 1 shows a schematic picture of the formal model.
Time may branch into the future and, in any interesting application, does.
It may be taken as linear in the past, although nothing hinges upon this.
The agents' ignorance about the past, as about anything else, is captured by beliefs (not discussed here).
Each agent inuences the future by acting, but the outcome also depends on other events.
Figure 1 is labeled with the actions of two agents.
The 	rst agent can constrain the future to some extent by choosing to do action a or action b.
If he does a, then the world progresses along one of the top two branches out of t0  if he does b, then it progresses along one of the bottom two branches.
However, the agent cannot control what exactly transpires.
For example, if he  00  0  0  00  0  0  0  A scenario at a moment t is any single branch of the relation < that includes t and all moments in some future of t that is a linear subrelation of <.
Di erent scenarios correspond to di erent ways in which the world may develop, as a result of the actions of agents and events in the environment.
Formally, a scenario at t is a set S  T that satis	es the following.
Rootedness: t 2 S 	 Linearity: (8t  t 2 S : (t = t ) _ (t < t ) _ 0  (t < t )) 00  00  0  00  0  00  0  	 Relative Density: (8t  t 2 S t 2 T : (t < t < t )) t 2 S ) 0  000  00  000  00  000  0  	 Relative Maximality: (8t 2 S t 2 T : (t < t )) (9t 2 S : (t < t ) ^ (t 6< t ))) 0  00  000  0  00  000  000  0  00  It is possible to extend S (here to t ), then it is extended, either to t (when t = t ), or along some other branch.
By itself, this does not entail that time be eternal.
S is the set of all scenarios at moment t. Since each scenario at a moment is rooted at that moment, the sets of scenarios at di erent moments are disjoint, that is, t 6= t ) S \ S = .
If t is such that t < t , then for every scenario, S 2 S , there is a scenario, S , such that S  S and S 2 S .
Conversely, for every scenario S 2 S , for each moment t 2 S , there is a scenario S 2 S , such that S  S .
S  t t ] denotes a period on scenario S from t to t , inclusive, i.e., the subset of S from t to t .
Thus, if S0 t t ]  S1 , then S0  t t ] = S1  t t ].
However, in general, S0 t t ] 6= S1 t t ].
For notational simplicity, S  t t ] presupposes t t 2 S and t  t .
00  00  000  00  t  0  t0  t  0  0  0  t0  0  t  t  0  t0  0  0  0  0  0  0  0  0  0  0  0  0  0  2.3 Semantics For p 2 L, M j= p expresses \M satis	es p at t." For p 2 L , M j= p expresses \M satis	es p at moment t on scenario S " (we require t 2 S ).
We say p is satisable i  for some M and t, M j= p. The t  s  St  t  satisfaction conditions for the temporal operators are adapted from those in Emerson, 1990].
It is assumed that each action symbol is quanti	ed over at most once in any formula.
Below, pj is the formula resulting from the substitution of all occurrences of a in p by b.
Two useful abbreviations are false  (p ^ :p), for any p 2 , and true  :false.
Formally, we have: M1.
M j=  i  t 2  ] , where  2  M2.
M j= p ^ q i  M j= p and M j= q M3.
M j= :p i  M 6j= p M4.
M j= Ap i  (8S : S 2 S ) M j= p) M5.
M j= Pp i  (9t : t < t and M j= p) W M6.
M j= ( a : p) i  (9b : b 2 B and M j= pj ), where p 2 L W M7.
M j= ( a : p) i  (9b : b 2 B and M j= pj ), where p 2 (L ; L) q and M8.
M j= pUq i  (9t : t  t and M j= (8t : t  t  t ) M j= p)) M9.
M j= xa]p i  (8t 2 S : S  t t ] 2  a] implies that (9t : t < t  t and M j= p)) M10.
M j= xhaip i  (9t 2 S : S  t t ] 2  a] and (9t : t < t  t and M j= p)) M11.
M j= xjhaijp i  (9t 2 S : S  t t ] 2  a] and (9t : t < t  t and (8t : t < t  t implies that M j= p))) M12.
M j= p ^ q i  M j= p and M j= q M13.
M j= :p i  M 6j= p M14.
M j= p i  M j= p, where p 2 L a b  t t  t  t  t  t  t  t  0  t  St  0  t0  t  : c :  00  x  x  0  0  0  St  St  St 00  0  0  St  x  0  0  00  0  St0  St00  0  St  Figure 2: Actions: Nonsynchronized and of Varying Durations Basic actions can be of arbitrary durations.
Multiple agents may act simultaneously.
The set of actions available to an agent can be di erent at di erent moments.
For example, the actions of moving a block may take more or less time than the action of turning a knob.
This case is diagramed in Figure 2, which also shows that actions may begin and end arbitrarily.
The intension,  ] , of an atomic proposition is the set of moments at which it is true.
The intension of an action symbol a is, for each agent symbol x, the set of periods in which an instance of a is performed by x.
Thus t 2  p] means that p is true at moment t and, S  t t ] 2  a] means that agent x is performing action a from moment t to moment t .
When S  t t ] 2  a] , t corresponds to the ending of a, but t does not correspond to the initiation of a.
This is because a may already be in progress before t. Constraints C1 and C2 of section 3 pertain to this aspect.
All basic actions take time.
That is, if S  t t ] 2  a] , then t < t .
a b  s  00  b = move a block a = turn a knob  0  St  a b  b 9 : 9 9 a XXyXXXXX XyXXXXb XXXXX zXXX yXXXXXXXXXX a XXX z XXXXX XdX zX X  t  00  0  00  0  St00  0  00  x  x  0  0  St00  0  00  0  0  000  x  000  00  St000  St  St  St St  St  St  t  2.4 Temporal and Action Operators: Discussion  pUq is true at a moment t on a scenario, i  q holds at a future moment on the given scenario and p holds on all moments between t and the selected occurrence of q. Fp means that p holds sometimes in the future on the given scenario and abbreviates trueUp.
Gp means that p always holds in the future on the given scenario it abbreviates :F:p. Pp denotes p held at  some moment in the past.
The branching-time operator, A, denotes \in all scenarios at the present moment."
Here \the present moment" refers to the moment at which a given formula is evaluated.
A useful abbreviation is E, which denotes \in some scenario at the present moment."
In other words, Ep  :A:p. For example, in Figure 1, EFr and AFq hold at t0 , since r holds on some  moment on some scenario at t0 and q holds on some moment on each scenario.
L also contains operators on actions.
These are based on operators in dynamic logic, but are given a linear rather than a branching semantics.
For an action symbol a, an agent symbol x, and a formula p, xa]p holds on a given scenario S and a moment t on it, i , if x performs a on S starting at t, then p holds at some moment while a is being performed.
The formula xhaip holds on a given scenario S and a moment t on it, i , x performs a on S starting at t and p holds at some moment while a is being performed.
These de	nitions require p to hold at any moment in the (left-open and right-closed) period in which the given action is being performed.
Thus they are weaker than possible de	nitions that require p to hold at the moment at which the given action completes.
It is essential to allow the condition to hold at any moment in the period over which the action is performed.
This is because we are not assuming that time is discrete or that all actions are of equal durations and synchronized to begin and end together.
Intuitively, if we insisted that the relevant condition hold at the end of the action, then an agent could e ectively leap over a condition.
In that case, even if a condition occurs while an action is performed, we may not have xhaip.
For example, if p is \the agent is at the equator," and the agent performs the action of hopping northwards from just south of the equator, he may end up north of the equator without ever (of	cially) being at it.
That would be quite unintuitive.
For this reason, the present de	nitions are preferred although as a consequence, the operators h i and  ] are not formal duals of each other.
But this is made up for by having a more intuitive set of de	nitions, which also enable the right relationship between the action operators and F, G, and U to be captured.
Recall from above that pUq considers all moments between the given moment and the 	rst occurrence of q, not just those at which di erent actions may end.
Further, xjhaijp holds on a scenario S and moment t if x performs action a starting at t and p holds in some initial subperiod of the period over which a is performed.
This operator is necessary to relate actions with time for the following reason.
We allow actions to happen over periods which contain moments between their endpoints.
Such cases can arise even in discrete models if all actions are not unit length.
Consequently, if a is performed at t and q holds at an internal moment of a and p holds throughout, then pUq holds at t. But absent the jh ij operator, we cannot characterize pUq recursively in terms of actions.
One useful characterization is given in section 4: this helps in giving the 	xed point semantics of the temporal operators, which is essential to computing them eciently.
The above action modalities yield scenarioformulae, which can be combined with the branchingtime operators A and E. Axa]p denotes that on all  scenarios S at the present moment, if a is performed on S , then p holds at some moment on S between the present moment and the moment at which a is completed.
Similarly, Exhaip denotes that a is being performed on some scenario at the present moment and that on this scenario p holds at some moment between the present moment and the moment at which a is completed.
In other words, Axa]p corresponds to the necessitation operator and Exhaip to the possibility operator in dynamic logic.
Existential quanti	cation over basic actions is a useful feature.
Of the several basic actions that an agent may do at a given moment, we would often like to talk restrictively of the subset of actions that have some interesting property.
Indeed, we need something like this to formally express the idea of choice: an agent may be able to do several actions, but would, in fact, choose to do one, e.g., one of those that ensure success.
3 Coherence Constraints  For the above models to be coherent and useful, further technical constraints are required.
These are motivated and formalized below.
z z  t0 t1  a }|  }|a  { {  t3  t2  Figure 3: Case Disallowed by Action Uniqueness (1) z  t0  }|a  {  t1  z  a}|  t2  {  t3  Figure 4: Case Disallowed by Action Uniqueness (2) C1.
Uniqueness of Termination of Actions:  Starting at any given moment, each action can be performed in at most one way on any given scenario.
In other words, for any action a, scenario S , and moments t0  t1 t2 t3 in S , we have that S  t0 t2] 2  a] and S  t1 t3] 2  a] implies that, if t0  t1 < t2 , then t2 = t3.
This is needed to exclude ill-formed models in which an action does not have a unique moment of ending (see Figures 3 and 4).
If an agent performs an action and then repeats it, the repetition counts as a separate instance, because it has a distinct starting moment.
This constraint permits di erent actions with possibly distinct endpoints to happen simultaneously.
In discrete models with unit length actions, both endpoints are necessarily unique here only the termination point is assumed to be unique.
a }|  z  t  ...  t  00  z  }|  in Figure 6, would allow a condition to be inevitable and yet unreachable though any 	nite sequence of actions.
It is important that this not be the case for inevitability to relate properly with know-how.
This constraint always holds in discrete models.
{  a  {  t  ... S  0  Figure 5: Actions in Progress  Actions in Progress: It helps in relating moments with actions to require that S  t t ] 2  a] ) (8t : t  t < t ) S  t  t ] 2  a] ).
This allows us to talk of an agent's actions at any moment at which they are happening, not just where they begin.
However, in accordance with constraint C1, actions begun at a moment still have a unique ending moment.
As a result of this constraint, the actions operators behave properly.
For example, if an agent can achieve a condition by performing some action, then he can also achieve it while in the process of performing that action (until it happens).
This constraint holds vacuously in discrete models.
Figure 5 shows how this constraint causes the intension of an action to be 	lled out by suxes of the period over which it is performed.
The period S  t  t ] is not added to  a] , since that would lead to a violation of our assumption that S  t t ] 2  a] implies that t < t .
This would cause ambiguity between an action instance ending at t and another beginning there.
C3.
Passage of Time: Something must be done by each agent along each scenario in the model, even if it is some kind of a dummy action.
This assumption ensures that time does not just pass by itself, and is needed to make the appropriate connections between time and action.
Formally, (8t 2 T x 2 A(t) S 2 S ) ((9t 2 S )) (9t 2 S a : S  t t ] 2  a] ))).
C2.
00  0  0  00  0  0  0  0  0  0  t  x  0  t  t  0  0  t  ... S  00  Figure 6: Limit Sequences Disallowed by Reachability of Moments C4.
S0  0  00  Reachability of Moments: For any scenario and two moments on it, there is a 	nite number of actions of each agent that, if performed on that scenario starting at the 	rst moment, will lead to a moment in the future of the second moment.
Formally, (8S : (8t t 2 S : t < t ) (9t : t  t and (9a1  .
.
.
 a and S  t t ] 2  a1 .
.
.
 a ] )))).
This condition is intended to exclude models in which there are moments that would require in	nitely long action sequences to reach.
Such models, e.g., as 0  0  00  00  0  00  n  n  t  tX 0    a  X-XXXX XXXXX t1 S1  Figure 7: Actions Cannot be Partially Performed on any Scenario  Atomicity of Basic Actions: If an agent is performing an action over a part of a scenario, then he completes that action on that scenario.
This makes sense since the actions in the model are basic actions, performed with one atomic choice by their agent.
If an action in some domain can in fact be chopped into a pre	x and sux such that the sux is optional, then it should be modeled as two separate basic actions, the 	rst of which completes entirely and the second of which may not be begun at all.
Formally, let t t  t1 2 T, such that t < t < t1.
Let S0  S1 2 S , such that S1  t t ] 2 S0 .
Then S1 t t1] 2  a] implies that (9t0 2 S0 : S0 t t0] 2  a] ).
Intuitively, S1 t t1] 2  a] means that x is performing a from t to t1.
Therefore, he must be performing a in any subperiod of that, including S1 t t ], which is the same as S0  t t ].
Thus, a must be completed on S0 .
Higher-level actions do not satisfy this.
For example, Al may be crossing the street (on a scenario) even if he did not cross it successfully on that scenario, e.g., by being run over by a bus.
Our models represent physical systems, albeit nondeterministic ones.
The actions available to the agents and the conditions that hold on di erent scenarios leading from a given state are determined by that state itself.
Constraints on agent's choices, abilities, or intentions can thus be exibly modeled.
A well-known alternative characterization of models of time is by the set of all scenarios at all states.
We relate moments and states as follows.
De	ne a relation  to indicate the state-equivalence of moments and periods.
The state at a moment is precisely characterized by the atomic propositions that hold at that moment.
For moments, t and t , we de	ne t  t i  f 2 jt 2  ] g = f 2 jt 2  ] g. For sets of C5.
0  0  t  0  x  x  x  0  0  0  0  0  moments, L and L , we de	ne L  L in terms of an order-isomorphism, f .
Given two sets L and L with an order <, a map f from L to L is an orderisomorphism i  (a) f is onto, (b) (t 2 L i  f (t) 2 L ), and (c) (8t t0 2 L : t < t0 i  f (t) < f (t0 )).
We can now de	ne L  L as L  L i  (9f : f is an orderisomorphism and (8t 2 L) t  f (t))).
Observation 1  is an equivalence relation 2 Thus, t  t means that the same physical state occurs at moments t and t .
Thus, states are the equivalence classes of  on moments.
L  L means that the moments in L and L represent the same states occurring in the same temporal order.
In other words, L and L represent the same trajectory in state-space.
For a model to represent a physical system and be speci	able by a transition relation among di erent states, the corresponding set of scenarios, S, must satisfy the following closure properties Emerson, 1990].
We generalize these from discrete time.
Sux closure: If S 2 S, then all suxes of S belong to S. 	 Limit closure: If for a set of states T = ft0 .
.
.
t .
.
.g, scenarios containing t0 .
.
.
t , for n  0 are in S, then a scenario S such that T  S is also in S. 	 Fusion closure: If S0 = S0  t  S0 and S1 = S1  t  S1 in S include the same state t, then the scenarios S0  t  S1 and S1  t  S0 formed by concatenating the initial and later parts of S0 and S1 also belong to S ( indicates concatenation).
Lemma 2 By construction, S derived from our models satis	es sux and limit closures.
2 0  0  0  0  0  0  0  0  0  0  0  0  n  n  p  p  f  p  z  f  f  p  a  ...  }|  ...  f  {      t0    0  0  t  x  x  0  t0  4 Results on Time and Actions  It is helpful in intuitively understanding formal de	nitions to attempt to prove some technical results that should follow from them.
For this reason, we state and discuss some consequences of the above model and semantic de	nitions next.
We believe constraint C1 is what McDermott intends by requiring that actions do not overlap.
But, that also eliminates C2, which is essential, e.g., so that Fp can be concluded at all moments which precede p (Observation 6).
Constraints C3 and C4 are required for Observation 6 and related results about G and U.
We also use the fact that x:a]:p means that a is performed and p holds throughout a.
Observation 4 (xhaip)!
Fp 2  Observation 5 (xhaiFp)!
Fp 2 Observation 6 Fp!
p _ (W a : xhaiFp) 2 Observation 8 Gp!
(W a : x:a]:Gp) 2  XXXX  a  t  0  0  Observation 7 Gp!
p 2  XXXXX XXXX6X 6 XXXX6 XXX  t  Weak Determinism: If two moments satisfy exactly the same atomic propositions, then the fragments of the model rooted at those moments must be isomorphic with respect to the temporal precedence relation and the atomic propositions in the formal language.
Thus, we can de	ne weak determinism as the following constraint.
(8x 2 A a 2 B t t  t0 2 T S0 2 S : t  t ) (S0  t t0] 2  a] ) (9S1 2 S  t1 : S1 t  t1 ] 2  a] and S0  t t0]  S1  t  t1]))) Lemma 3 Under weak determinism, S derived from our models satis	es fusion closure.
2 C6.
?z .
.
.
}| ?
.
.
.
{ ?t1 XXXXX XXXXX XXXX XXXXX XX Figure 8: Weak Determinism  However, fusion closure is not satis	ed in general.
We show next how to satisfy it.
Observation 9 (p ^ x:a]:Gp)!
Gp 2 Observation 10 (p ^ q)!
pUq 2 Observation 11 (p ^ x:a]:(pUq))!
pUq 2 Observation 12 (p ^ xjhaij(pUq))!
pUq 2 Observation 13 pUq!
((p ^ q)_W W (p ^ ( a : x:a]:(pUq))) _ (p ^ ( a : xjhaij(pUq)))) 2  Observation 14 In discrete models with unit length actions, xhaip  x:a]:p and xhaip  xjhaijp.
Thus one action operator suces in such models.
2  5 Conclusions and Open Problems  Actions and time are crucial to several subareas of AI.
We sought to generalize the formalization of actions, so that several important properties are not excluded.
These include the actions being of di erent durations, the actions being performed concurrently by di erent agents.
the underlying notion of time being variously continuous or discrete, and the underlying notion of time allowing branching into the future.
We stated various coherence constraints that capture the intuitive properties of actions in di erent cases of interest.
Or model can thus serve as an underpinning for further research on notions such as intentions and know-how.
Previous research on these concepts has been shackled by poor models of time and action, thereby leading to spurious results Singh, 1992].
The logic CTL* was designed over a decade ago for reasoning about programs.
Usually, its models are discrete with unit length actions performed one at a time.
We extended CTL* with new operators and gave our language a more general semantics that allows time to be discrete, dense, or continuous.
One of our concerns was that our de	nitions specialize to each case properly.
This is useful since AI models must often function at multiple levels of abstraction.
We also discovered that several constraints must be stated on models to capture the AI notion of basic actions.
The sole traditional constraint of no overlap McDermott, 1982] says too little and sometimes is too strong.
Even though several decision procedures are known for CTL*, no closed-form axiomatization is still known.
This is an important open problem, as is determining an axiomatization for our language, L. Further research is required to determine the role of past time operators for AI purposes.
Such operators are known to make formulae drastically compact in some cases, but they also raise the complexity of the required decision procedures signi	cantly.
Would it help for AI to augment L with operators such as since ?
For models with exclusively unit length actions, one action operator is enough (instead of three).
Are there other interesting classes of models for which L can be simpli	ed?
We have focused here on representational issues.
We have not explored the tradeo s between expressiveness and computational complexity.
Clearly, eciency can be gained by simplifying the formal language and model.
One class of reasoning techniques that is likely to prove of much value is the one developed in the qualitative reasoning community, which routinely deals with continuous phenomena and looks for ways to express them in terms of signi	cant transitions Kuipers, 1986 Sandewall, 1989].
Model checkers (programs which check whether a given model satis	es a given formula) have drawn much attention lately Burch et al., 1990].
One such  can fairly easily be constructed for L by generalizing the ones known for CTL*.
The recursive characterizations of the temporal operators in terms of actions go a long way in designing this.
Instead of points in discrete models, we have to maintain periods in our model.
Clearly, if a model is 	nitely speci	able in terms of periods, we can compute on it in 	nite time using standard techniques.
However, ecient, specialized data structures for periods would be essential in practice.
References  Allen, 1984] Allen, James F. 1984.
Towards a general theory of action and time.
Articial Intelligence 23(2):123{154.
Bacchus et al., 1989] Bacchus, Fahiem Tenenberg, Josh and Koomen, Johannes A. 1989.
A nonrei	ed temporal logic.
In First Conference on Knowledge Representation and Reasoning.
2{10.
Burch et al., 1990] Burch, J. R. Clarke, E. C. McMillan, K. L. Dill, D. L. and Hwang, L. J. 1990.
Symbolic model checking: 1020 states and beyond.
In LICS.
Dean & Boddy, 1988] Dean, Thomas and Boddy, Mark 1988.
Reasoning about partially ordered events.
Articial Intelligence 36:375{399.
Emerson, 1990] Emerson, E. A. 1990.
Temporal and modal logic.
In Leeuwen, J.van, editor, Handbook of Theoretical Computer Science, volume B. North-Holland Publishing Company, Amsterdam, The Netherlands.
Galton, 1990] Galton, Antony 1990.
A critical examination of Allen's theory of action and time.
Articial Intelligence 42:159{188.
Haddawy, 1990] Haddawy, Peter 1990.
Time, chance, and action.
In Sixth Conference on Uncertainty in AI.
Harper et al., 1981] Harper, William L. Stalnaker, Robert and Pearce, Glenn, editors.
IFS: Conditionals, Belief, Decision, Chance, and Time.
D. Reidel, Dordrecht, Netherlands.
Kuipers, 1986] Kuipers, Benjamin J. 1986.
Qualitative simulation.
Articial Intelligence 29:289{338.
McDermott, 1982] McDermott, Drew 1982.
A temporal logic for reasoning about processes and plans.
Cognitive Science 6(2):101{155.
Sandewall, 1989] Sandewall, Erik 1989.
Combining logic and di erential equations for describing realworld systems.
In Principles of Knowledge Representation and Reasoning.
Shoham, 1988] Shoham, Yoav 1988.
Reasoning About Change: Time and Causation from the Standpoint of AI.
MIT Press, Cambridge, MA.
Singh, 1992] Singh, Munindar P. 1992.
A critical examination of the Cohen-Levesque theory of intentions.
In 10th European Conference on Articial Intelligence.
Singh, 1994] Singh, Munindar P. 1994.
Multiagent Systems: A Theoretical Framework for Intentions, Know-How, and Communications.
Springer Ver-  lag, Heidelberg, Germany.
Thomason & Gupta, 1981] Thomason, Richmond H. and Gupta, Anil 1981.
A theory of conditionals in the context of branching time.
In Harper et al., 1981].
299{322. van Frassen, 1981] van Frassen, Bas C. 1981.
A temporal framework for conditionals and chance.
In Harper et al., 1981].
323{340.
2011 Eighteenth International Symposium on Temporal Representation and Reasoning  Consistency of qualitative constraint networks from tree decompositions Jean-FranASSois Condotta and Dominique DaAlmeida UniversitAS Lille-Nord de France, Artois CRIL-CNRS, UMR 8188 Rue de launiversitAS, SP 16, F62307 Lens {condotta,dalmeida}@cril.fr  approaches can be used.
AbstractaA common way to decide the consistency problem of a qualitative constraint network (QCN) is to encode it as a boolean formula in order to benedZt from the efdZciency of SAT solvers.
In recent works, a decomposition method of QCNs have been proposed to reduce the amount of boolean formulae.
In this paper, we dZrst show that the decompositions used can be expressed by particular tree decompositions.
Furthermore, for some classes of relations, we prove that the consistency problem of a QCN can be decided by applying the method of the closure by weak composition on the clusters of a tree decomposition.
This result allows us to extend the approach recently proposed to tree decompositions of QCNs.
The dZrst, introduced by Nebel [7], consists in a synchronous backtracking algorithm by maintaining a local consistency.
This algorithm exploits certain tractable classes of relations with multi-valued assignments and the weak composition closure allowing to obtain a local consistency close to path-consistency.
At each step during search, a constraint relation is split into sub-relations belonging to the tractable class.
The constraint is iteratively replaced by each sub-relation.
This cutting allows us to decrease the branching factor during the search.
Most of the QCN solvers exploit this solving method, in particular GQRa [8] which is currently the most efdZcient solver.
Keywords-Temporal qualitative constraints ; Consistency problem ; Tree decomposition  I. I NTRODUCTION  The second approach [9], [10] consists in encoding the consistency problem of QCNs as boolean formulae in order to benedZt from the efdZciency of SAT solvers.
However, the counter-part of this approach is the large amount of the boolean formulae obtained.
Recently, in order to overcome this drawback for QCNs of the Interval Algebra, Li et al.
[11] proposed a method of decomposition allowing to discard some constraints of the QCN.
This method splits recursively the QCN considered in two equivalent subQCNs.
Each constraint of the initial QCN which is absent from one of the two QCNs is considered as useless to decide the consistency, and is not considered in the encoding.
The amount of the boolean formulae is greatly reduced compared to the full encoding, and the experimental results show an improvement in term of solving time.
Reasoning about temporal or spatial knowledge is a major task in many domains of ArtidZcial Intelligence, such as Geographic Information System (GIS), natural language processing, temporal/spatial scheduling, and so on.
Qualitative reasoning is a way to express and process the qualitative aspect of knowledge about temporal or spatial entities.
A qualitative calculus considers a domain from temporal or spatial entities and a dZnite set of base relations over these entities.
Each base relation symbolizes a relative position between the entities, and is a factoring for condZgurations given as numeric information.
These previous decades, many qualitative calculi have been studied.
The Interval Algebra [1] represents temporal entities by intervals and considers thirteen base relations describing each possible relative position between two temporal entities (see Figure 1).
Many qualitative calculi for temporal knowledge are derived from the Interval Algebra [2], [3], [4].
In spatial reasoning, the well-known qualitative calculus RCC [5], [6] is quite possibly the most studied.
RCC is based on eight base relations between entities dedZned over all regions of a topological space.
In the qualitative calculi frameworks, the set of temporal or spatial information may be represented by some specidZc constraint networks called qualitative constraint networks (QCNs).
In a QCN, each variable stands for a temporal or spatial entity and each constraint restricts the possible condZgurations between entities by using a set of base relations.
Given a QCN, the main decision problem is the consistency problem.
In the general case, this problem is NP-complete.
To solve it, we can cite two kinds of 1530-1311/11 $26.00 AS 2011 IEEE DOI 10.1109/TIME.2011.22  In this paper, we dedZne particular decompositions called RecPart decompositions.
These specidZc decompositions formalize the decompositions of QCNs used by Li et al.
in their process of SAT encoding.
Then, we show that the RecPart decompositions can be equivalently dedZned as tree decompositions [12], widely studied in the framework of dZnite CSPs.
Moreover, we study the consistency problem for the QCN through the tree decompositions.
In particular, we show that, given a tree decomposition for a QCN dedZned over a tractable class of relations, the weak composition closure applied on each cluster is sufdZcient to decide the consistency of the QCN.
Finally, by exploiting this result we propose to decide the consistency of QCNs by using a tractable class of relations and a tree decomposition in the framework of boolean formula encodings.
149   with a, b a B, r  s = aar,bas {a  b}, with r, s a 2B .
The relation r  s is also dedZned as the strongest relation in 2B which contains the usual composition r aS s = {(x, y) a DA D : ax, y, z a D with x a z, z b y and x c y}.
For some qualitative calculi, r aS s and r  s are equivalent.
A class of relations C is a subset of 2B which contains the relation I", all of the singleton relations of 2B , and which is closed under converse, intersection and weak composition.
Given r a 2B and a class C, the smallest relation of C which contains r is denoted by rC and is called the closure of r in C. In IA, let us consider the relation {p, m} a 2B between two entities X and Y .
X {p, m} Y means that a1 X precedes or meets Y .
The converse relation {p, m} = a1 a1 {p , m } = {pi, mi} expresses the relation between Y and X, so Y is preceded or is met by X.
Finally, let us introduce Y {m, s, eq} Z.
We have some information about the relations between X, Y and Y, Z, so we can deduce information about the relation between X, Z by using the weak composition.
Since {p, m}  {m, s, eq} = {p, m}, we have X {p, m} Z.  II.
P RELIMINARY NOTIONS ON QUALITATIVE CALCULI A. Qualitative calculi A qualitative calculus considers a dZnite set of relations B, called base relations, over an indZnite domain D representing the temporal or spatial entities.
In our study, we focus on binary relations (a large part of qualitative calculi considers this kind of base relations).
Each base relation of B represents a certain relative position between spatial or temporal entities.
They are Jointly Exhaustive and Pairwise Disjoint (JEPD), i.e.
each element (x, y) a D A D belongs to one and only one a a B.
The set B has some properties [13] : (1) B is a partition of D A D, (2) B contains the identity relation id and, (3) B is closed by converse, i.e.
the converse of an base relation in B is also in B.
As an illustration, the Interval Algebra (IA), also known as Allenas calculus [1], considers intervals of the line to represent the temporal entities.
The domain D is dedZned by D = {(xa , x+ ) a Q A Q | xa < x+ }.
The base relations correspond to the set B = {eq, p, pi, m, mi, o, oi, s, si, d, di, f, f i}.
Each of these base relations symbolizes a relative position between two temporal intervals, which is illustrated in Figure 1.
A complex relation, also called relation, for a qualitative calculus is an union of base relations.
It is customary to represent a relation by the set of the base relations which compose it.
Hence, in the sequel we make no distinction between the set of relations and the set 2B which will represent the set of relations of a qualitative calculus based on the set of base relations B.
In the Interval Algebra, the relation r = p aS mi aS eq will be represented by the set {p, mi, eq}.
The usual set-theoretic operations union (aS), intersection (aS) B .
For a relation r a 2B , and converse (AVa1 ) are dedZned over 2 a1 the converse is dedZned as r = {aa1 |a a r}.
Among B the relations of 2 , I" denotes the relation that contains all the base relations of B.
The set 2B is also equipped with the weak composition operation, denoted by , dedZned as: a  b = {c a B : ax, y, z a D with x a z, z b y and x c y},  B. Qualitative Constraint Networks A Qualitative Constraint Network (QCN) consists of a dZnite set of m variables V = {v1 , .
.
.
, vm } which represent the spatial or temporal entities, and a map C from V A V to 2B such that C(vi , vi ) a {Id} for each vi a V , with Id the base relation corresponding to the identity relation over D, and a1 C(vi , vj ) = C(vj , vi ) for all vi , vj a V .
In the rest of this paper, we will also denote C(vi , vj ) by N [vi , vj ].
The dZgure 2 illustrates a QCN N of the Interval Algebra.
In this dZgure, a variable is represented by a node, and a constraint by an arc labelled with the associated relation.
Note that, for simplicity, there is no arc going from vi to vj when either there is already an arc going from vj to vi or i = j.
Given a QCN N = (V, C), a partial instantiation of N on V fi a V is a map s from V fi to D. A partial solution on N on V fi a V is a partial instantiation on V fi such that (s(vi ), s(vj )) satisdZes C(vi , vj ) for all vi , vj a V fi , i.e.
there exists a base relation b a C(vi , vj ) such that (s(vi ), s(vj )) a b for all vi , vj a V fi .
A solution of N is a partial solution of N on V .
N is consistent if, and only if,  Relation Symbol Converse Illustration X  precedes  p  pi  Y X  meets  m  mi  Y  {o, mi, f i}  X  overlaps  o  oi  starts  s  si  v8  Y X  {p, pi, di}  Y  {eq, p, mi, f i}  X  during  d  di  Y X  finishes  f  equals  eq  Figure 1.  fi eq  Y  v10  X Y  {eq, m, s, si} v6 {oi, mi}  v9  {oi, m, f i} {eq, p, f i} {di, o, m}  Figure 2.
150  {o, oi, mi, f i}  {eq, p, o, f i} v1  v0  {m, f }  {o, oi, mi, f } {o, mi, f i} v2  The base relations of the Interval Algebra.
v7  {p, mi, s}  v3  v4 {pi, di, o} v5  A QCN N = (V, C) of the Interval Algebra.
there exists a solution of N .
N is trivially inconsistent when there exist two variables v, v fi a V such that N [v, v fi ] = a. N is globally consistent if, and only if, each partial solution of N can be extended to a solution of N .
The projection of the QCN N to V fi with V fi a V , denoted by NV  , is the QCN (V fi , Cproj ) with Cproj the restriction of C to the set V fi .
A sub-QCN N fi of N is a QCN (V, C fi ) such that C fi (vi , vj ) a C(vi , vj ), for all vi , vj a V .
Let N 1 and N 2 be two QCNs dedZned respectively on the sets of variables V 1 and V 2 , with for each pair of variables v, v fi a V 1 aS V 2 , N 1 [v, v fi ] = N 2 [v, v fi ].
We denote by N 1 aS N 2 the unique QCN N dedZned on V 1 aS V 2 such that N [v, v fi ] = N 1 [v, v fi ] for all v, v fi a V 1 , N [v, v fi ] = N 2 [v, v fi ] for all v, v fi a V 2 , N [v, v fi ] = I" for all v a V 2 \ V 1 and v fi a V 1 \ V 2 .
A QCN N = (V, C) is -consistent or closed by weak composition if, and only if, C(vi , vj ) a C(vi , vk )C(vk , vj ) for all vi , vj , vk a V .
The weak composition closure of the QCN N , denoted by (N ) is the largest (for a) -consistent sub-QCN of N .
This closure may be obtained by iterating the operation C(vi , vj ) a C(vi , vj )aS(C(vi , vk )C(vk , vj )) for all vi , vj , vk a V until a dZxpoint is reached.
The worstcase time-complexity of this method is O(m3 ), with m the number of variables.
For some classes of relations, such as the set of the ORD-Horn relations or the set of the convex relations [14], [15] of IA, the consistency problem of a QCN can be decided by enforcing -consistency.
Hence, a -consistent ORD-Horn QCN with no empty constraint is a consistent QCN.
The class of convex relations admits a stronger property : each -consistent convex QCN non trivially inconsistent is globally consistent [16].
We conclude this section with some dedZnitions about trees.
Given a rooted tree (a connected acyclic graph with a root) T = (X, F ) and a node Xi a X, we denote by desc(Xi ) (resp.
asc(Xi )) the set of the descendant nodes (resp.
the ancestor nodes) of Xi (note that Xi belongs to desc(Xi ) and asc(Xi )).
Given X fi a X a non-empty subset of nodes, lca(X fi ) denote the node of T which is the lowest common ancestor of the nodes belonging to X fi .
The set leaves(T ) corresponds the set of the leaf nodes of T .
Finally, given a Xi a X, TXi denotes the sub-tree of T rooted in Xi .
X0 = {v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10} X1 = {v0, v1, v2, v3, v4, v5, v6, v7}  X2 = {v0, v6, v8, v9, v10}  X3 = {v0, v1, v2, v3, v6, v7} X4 = {v1, v4, v5} X7 = {v0, v1, v2, v6, v7}  X5 = {v0, v6, v8, v9} X6 = {v8, v9, v10}  X8 = {v2, v3} Figure 3(a).
A RecPart T = (X, F ) decomposition of N .
X0 = {v0, v6} X1 = {v1}  X2 = {v8, v9}  X3 = {v2}  X4 = {v1, v4, v5}  X7 = {v0 , v1, v2, v6, v7}  X5 = {v0, v6, v8, v9}  X6 = {v8, v9, v10}  X8 = {v2, v3} Figure 3(b).
A tree decomposition of N corresponding to T .
within the framework of the discrete CSPs we dedZne a tree decomposition of a QCN as a decomposition of its constraint graph: DedZnition 1: Let N = (V, C) be a QCN and G(N ) = (V, E) be its constraint graph.
A tree decomposition of N is a tree T = (X = {X0 , .
.
.
, Xn }, F ) with n a positive integer, where X is a family of subsets of variables of V (Xi a V ), such that :  (1) {Xi a X} = V ; (2) a(v, v fi ) a E, there exists Xi a X with v, v fi a Xi ; (3) for all Xi , Xj , Xk a X, if Xj is on the unique path between Xi and Xk then Xi aS Xk a Xj .
Given a tree decomposition T = (X = {X0 , .
.
.
, Xn }, F ) of a QCN, the treewidth of T is equal to max{|Xi | a 1 : Xi a X}.
Furthermore, every set of variables Xi is called a cluster.
In Figure 3(b), a tree decomposition of the QCN N of Figure 2 is represented.
III.
D ECOMPOSITIONS OF QCNS A.
Tree decompositions  B.
The RecPart decompositions  The relation I" consists of all the possible base relations of B and is satisdZed by any pair of elements of the domain D. A constraint between two variables of a QCN dedZned by the relation I" specidZes that locally there is no constraint concerning the relative position of both entities represented.
So, in a natural way, we dedZne the graph of constraints of a QCN N = (V, C), by the undirected graph G(N ) = (V, E) with (v, v fi ) a E if, and only if, N [v, v fi ] = I" and v = v fi .
In the sequel we suppose that given a QCN N , G(N ) is connected.
In the contrary case, N may be trivially split in two independent QCNs without common variables.
As  Recently, Li et al.
[11] proposed a method allowing to translate QCNs of the Interval Algebra into boolean satisdZability problem (SAT instances).
This method recursively decomposes at each step a QCN N = (V, C) into two QCNs N 1 and N 2 such that N = N 1 aS N 2 .
The constraints dedZned by the relation I" in the QCN N not belonging to N 1 and N 2 are characterized as not necessary in the search of a solution of the initial QCN and thus not translated.
The advantage of such a translation is that the obtained SAT instance is of smaller size than an instance stemming from a complete translation.
Taking inspiration from this  151  we can assert that N [v, v fi ] = I" and that (v, v fi ) is not an edge of G(N ).
Moreover, we have previously assumed that for every QCN N considered, G(N ) is connected.
Consequently, for all v a Xj and v fi a Xk , there exists a path of G(N ) between v and v fi .
Moreover this path passes necessarily through two edges (v, v fifi ) and (v, v fififi ) with v fifi a V \ {Xj aS Xk } and v fififi a V \ {Xj aS Xk }.
As Xj aS Xk = Xi , we have v fifi a Xi .
Let Xl be the nearest common ancestor of Xi such that v fifi a Xl .
Let Xm and Xo be the two child nodes of Xl with Xm a asc(Xi ).
We have v fifi a Xm and v a Xm .
Moreover, v fifi a Xo since Xo aS Xm = Xl .
We also know NXl = NXm aS NXo .
Consequently, we have N [v, v fifi ] = I".
We know that (v, v fifi ) is an edge of G(N ).
There is a contradiction.
We conclude that Xj aS Xk = a.
(2) Let Xi , Xj , Xk a X with Xk = lca({Xi , Xj }).
Assume that Xk = Xi and Xk = Xj .
We have necessarily Xk a leaves(T ).
Let us denote by Xl and Xm the two child nodes of Xk .
We have Xi a desc(Xl ) and Xj a desc(Xm ) or, Xi a desc(Xm ) and Xj a desc(Xl ).
Hence, from Proposition 1 (1), we have Xi a Xl and Xj a Xm or, Xi a Xm and Xj a Xl .
Consequently, we have Xi aS Xj a Xm aS Xl .
We conclude that Xi aS Xj a Xk .
(3) Let Xi a X.
First, consider the case where Xi a leaves(X).
By dedZnition, Xi = Xi , hence the property is satisdZed.
Now, assume that Xi a leaves(X) and let Xk and Xl be the two child nodes of Xi .
We have Xk aS Xl = Xi = a.
Let v a Xi , we have v a Xi .
From Proposition 1 (4), there exists Xj a leaves(T ) aS desc(Xi ) such that v a Xj .
From the property (2) of DedZnition 2,  we have Xk aS Xl a Xj since (Xk aS Xl ) aS Xj = a.  method, we dedZne particular decompositions of QCNs, called RecPart decompositions (for recursive partitioning), in the following way: DedZnition 2: Let N be a QCN = (V, C).
A RecPart decomposition of N is a rooted tree T = (X = {X0 , .
.
.
, Xn }, F ), with n a positive integer, where X is a family of subsets of V (Xi a V ) and Xr = V with Xr the root of T .
Moreover, each node of T has two or no child nodes and, given Xi , Xj , Xk a X such that Xj and Xk are child nodes of Xi , T must satisfy the following properties : (1) NXi = NXj aS NXk , Xj \ Xk = a and Xk \ Xj = a.
(2) For every Xm a desc(Xi ), if Xm aS (Xj aS Xk ) = a then (Xj aS Xk ) a Xm .
In Figure 3(a) is represented a RecPart decomposition of the QCN N illustrated in Figure 2.
We dedZne the treewidth of a RecPart decomposition T = (X, F ) by max{|Xi | a 1 : Xi a leaves(T )}.
Note that from the property (1) of the previous dedZnition, Xi = a for every Xi a X.
A RecPart decomposition satisdZes the following properties : Proposition 1: Let T = (X = {X0 , .
.
.
, Xn }, F ) be a RecPart decomposition of a QCN N = (V, C).
For each Xi a X, we have : (1) For each Xj a X such that i = j, Xi = Xj and moreover, if Xj a desc(Xi ) then Xj a Xi ; (2) TXi is aRecPart decomposition of NXi ; (3) NXi = {NXj : Xj a leaves(TXi )} ; (4) Xi = {Xj a leaves(TXi )}.
The proofs of these properties are omitted, they can be directly established from DedZnition 2.
Note that from the previous property (1), we have for all Xi , Xj a X, the sets Xi and Xj which are distinct sets if, and only if, i = j.
Hence, for each Xi a X, the set of variables belonging to Xi characterises one and only one node of T .
Let T = (X, F ) be a RecPart decomposition of a QCN N = (V, C).
Given Xi a X, Xi will denote the set Xi in the case where Xi a leaves(T ).
In the case where Xi a leaves(T ), Xi is dedZned by the set Xj aS Xk with Xj and Xk the two child nodes of Xi .
Note that Xi a Xi since Xj a Xi and Xk a Xi .
Moreover, we have the following properties : Proposition 2: Let T = (X = {X0 , .
.
.
, Xn }, F ) be a RecPart decomposition of a QCN N = (V, C).
(1) For each Xi a X, Xi = a.
(2) Given Xi , Xj , Xk a X with Xk = lca({Xi , Xj }), if Xk = Xi and Xk = Xj then Xi aS Xj a Xk .
(3) For each Xi a X, there exists Xj a leaves(X) such that Xi a Xj .
Proof.
(1) Consider the case where Xi a leaves(T ) (for the case where Xi a leaves(T ) the property is trivially satisdZed since Xi = Xi and Xi = a).
Let Xi , Xj , Xk a X such that Xi is the parent node of Xj and Xk .
Suppose by contradiction that Xj aS Xk = a.
From DedZnition 2, we have NXi = NXj aS NXk .
Hence, for all v a Xj and v fi a Xk ,  IV.
F ROM RecPart DECOMPOSITIONS TO TREE DECOMPOSITIONS  In this section, we are going to show that from a RecPart decomposition T of a QCN we can dedZne a tree decomposition T fi with same treewidth and considering the same clusters of variables (more exactly the same binary constraints).
Before this, we introduce a new notation : given  v8  {o} {di} {o, d, s}  {p, o, m}  v9 {f i}  {p}  v10  {f i}  v6  {m}  v7  {o, f i}  {oi} {o, f i} {eq, o, f i} {f } v1 v0 {o}  {o, m} v2  {o, mi, f i}  {s}  v3  {oi} v4  {pi, oi, mi}  {di} v5  {eq, d, di, o, oi, s, si, f, f i}  Figure 4.
152  N  a ORD-Horn   aconsistent X  sub-QCN of N .
0 the property is trivially satisdZed.
Now, assume that the property is satisdZed for each path with a length l aL 0 and let us show in an inductive way that the property holds for each path between Xi and Xk of length l + 1.
First, assume that Xi a desc(Xk ) and Xk a desc(Xi ) w.r.t.
T .
By examining the dedZnition 3 we notice that for T a path between Xi and Xk necessarily passes through Xo with Xo = lca({Xi , Xk }).
From Proposition 2 (2) we have Xi aS Xk a Xo .
Consequently, v a Xo .
By considering the two paths Xi , .
.
.
, Xo and Xo , .
.
.
, Xk which have a length lower or equal to l, and by using the induction hypothesis, we can assert that the nodes on the path Xi , .
.
.
, Xo and the nodes on the path Xo , .
.
.
, Xk contain v since Xi , Xo and Xk contain v. Now, assume that Xi a desc(Xk ) in T (the case Xk a desc(Xi ) can be handled in a similar way).
The case Xi = Xk is a trivial case, assume that Xi = Xk .
We have Xi a desc(Xo ) with Xo one of the child nodes of Xk in T .
By examining DedZnition 3 we remark that for T , a path between Xk and Xi passes necessarily through Xm  with Xm = lca(X k Xo ).
From Proposition 3 (2), we know that Xk a Xm .
It results that v a Xm .
By considering the paths Xi , .
.
.
, Xm and Xm , .
.
.
, Xk which have a length lower or equal to l, and by using the induction hypothesis, we can assert that the nodes of the path Xi , .
.
.
, Xm and the nodes of the path Xm , .
.
.
, Xk contain v since Xi , Xm and Xk contain v.   Xi , Xj a X with Xj child node of Xi , X i Xj will denote the set {Xk : Xk a desc(Xj ) and Xi a Xk }.
Concerning  X i Xj , we have the following properties : Proposition 3: Let T = (X, F ) be a RecPart decomposition of a QCN N = (V, C) and let Xi , Xj a X with  Xj a child node of Xi .
We have : (1) X i Xj = a, (2)   lca(Xi Xj ) a Xi Xj .
Proof.
(1) We know that Xi = a (Proposition 2 (1)), hence there exists v a Xi .
By dedZnition of Xi , we know that v a Xj .
From Proposition 1 (4), there exists Xk a leaves(T ) aS desc(Xj ) such that v a Xk .
From the property (3) of DedZnition 2, we can assert that Xi a Xk .
  Hence, Xk a X i Xj and we can conclude that Xi Xj = a.
  (2) Let Xl = lca(Xi Xj ).
There exists Xk , Xm a X i Xj such that Xl = lca({Xk , Xm }).
In the case where Xl = Xk or Xl = Xm the property is trivially satisdZed.
In the case where Xl = Xk and Xl = Xm , from Proposition 2 (2) we have Xk aS Xm a Xl .
As Xi a Xk and Xi a Xm we can assert that Xi a Xl .
Moreover, since Xl = lca({Xk , Xm }), Xk a desc(Xj ) and Xm a desc(Xj ),  we have Xl a desc(Xj ).
We conclude that Xl a X i Xj .
 Now, we dedZne from a RecPart decomposition T of a QCN N a tree denoted by T .
We will prove in the sequel that this tree is a tree decomposition of the QCN N satisfying some particular properties.
DedZnition 3: Let N be a QCN and T = (X = {X0 , .
.
.
, Xn }, F ) a tree decomposition of N .
From T and an element Xi a X, we inductively dedZne a rooted tree T Xi = (XXi , FXi ) with root Xi in the following way : aV Base case : Xi a leaves(T ), T Xi = ({Xi }, a).
aV Inductive case : Xi a leaves(T ).
By considering T , let  Xj and Xk the child nodes of Xi , Xl = lca(X i Xj )  and Xm = lca(Xi Xk ).
XXi and FXi are dedZned by XXi = XXj aS XXk aS {Xi }, FXi = FXj aS FXk aS {(Xi , Xl ), (Xi , Xm )}.
T is dedZned by the rooted tree T Xr with Xr the root of T .
Let us show that the tree T is a tree decomposition of the QCN N for which T is a RecPart decomposition.
Proposition 4: Let N = (V, C) be a QCN and a RecPart decomposition T = (X = {X0 , .
.
.
, Xn }, F ).
We have T = (X = {X0 , .
.
.
, Xn }, F ) which is a tree decomposition of N such that for each Xi a X there exists Xj a leaves(T ) with Xi a Xj .
Proof.
Properties (1) and (2) of the dedZnition 1 arise from the fact that for each Xi a leaves(X), Xi = Xi and from Proposition 1.
Now, let us prove that the property (3) of DedZnition 1 is satisdZed by T .
Let Xi , Xj , Xk a X with Xj on the unique path between Xi and Xk w.r.t.
T .
We are going to show that if v a Xi and v a Xk then v a Xj .
If the length of the path between Xi and Xk is  The fact that for each Xi a X, there exists Xj a leaves(T ) such that Xi a Xj results from Proposition 2 (3).
 V. T REE DECOMPOSITIONS AND CONSISTENCY OF QCNS In this section we are going to show that to decide the consistency of a QCN from one of its tree decomposition we can leave aside some of its constraints.
In particular, we show that for some classes of relations, the closure by weak composition restricted to constraints of the clusters stemming from a tree decomposition is complete for the consistency problem.
First of all, we introduce a new local consistency corresponding to the property of -consistency restricted to some subsets of variables of a QCN: DedZnition 4: Let N = (V, C) be a QCN and X = {X0 , .
.
.
, Xn } a family of subsets of V .
N is X -consistent if, and only if, for each Xi a X, the QCN NXi is a -consistent QCN.
Given a QCN N = (V, C) and X = {X0 , .
.
.
, Xn } a family of subsets of V , we will denote by X (N ) the larger (for a)  X -consistent sub-QCN of N .
The following result extends the one of Li et al.
on atomic networks.
It concerns QCNs whose constraints are dedZned by relations stemming from a class C for which any QCN closed by weak composition is globally consistent.
As illustration, we can consider the QCNs dedZned by relations belonging to the class of the convex relations of the Interval Algebra which admits this property.
153  Theorem 1: Let N = (V, C) be a QCN dedZned on a class of relations C for which each QCN -consistent is globally consistent, and let T = (X = {X0 , .
.
.
, Xn }, F ) be a tree decomposition of N .
If N is a non trivially inconsistent and  X -consistent QCN then N is a consistent QCN.
Proof.
We suppose without loss of generality that T has a root.
Let Xi a X and TXi = (XXi , FXi ) the sub-tree of T .
Given a partial instantiation s on V fi with V fi aS Xifi a Xi for each Xifi a XXi and such that for each Xj a X with Xj a V fi , sXj is a solution of NXj .
We are going to prove the following property : s can  be extended to a partial instantiation sfi on V fifi = V fi aS {Xifi a XXi } such that for each Xj a X with Xj a V fifi , sfiXj is a solution of NXj .
We are going to prove this property in an inductive way on the size of XXi .
aV Base case: |XXi | = 1.
We have XXi = {Xi }.
Since N is a X -consistent QCN, we have the QCN NXi which is a QCN -consistent and hence globally consistent.
sV  aSXi is a partial solution of NXi which can be extended to a solution sfifi of NXi .
We dedZne by sfi the partial instantiation on V fi aS Xi in the following way : if v a V fi then sfi (v) = s(v) else sfi (v) = sfifi (v).
We have sfiXi which is a solution of NXi and more generally sfiXk is a solution of NXk for each Xk a X and Xk a V fi aS Xi .
aV Inductive step: |XXi | > 1.
We assume that the property holds for each sub-tree TXj = (XXj , FXj ) with |XXj | < |XXi |.
As in the previous case, we extend s to a partial instantiation sfi on V fi aS Xi such that sfiXk is a solution of NXk for each Xk a X and Xk a V fi aS Xi .
By the induction hypothesis, this partial instantiation sfi can be extended to the set of variables belonging to the descendant nodes of Xi .
Indeed, consider Xl a child node of Xi .
First, we remark that by denoting by TXl = (XXl , FXl ) the sub-tree of T , we have |XXl | < |XXi |.
Moreover, as T is a tree decomposition, we have for each Xm a XXl , Xm aS (V fi aS Xi ) a Xl (from the property (3) of the dedZnition 1).
Hence, the induction hypothesis can be applied on TXl = (XXl , FXl ).
By applying the previous property on Xr the root of T , we know  that there exists an instantiation s on the set of variables {Xi : Xi a X} such that sXi is a solution of the QCN NXi for each Xi a X.
First, from  the property (1) of DedZnition 1 we can assert that V = {Xi : Xi a X}.
Hence, s is an instantiation on V .
Moreover we can show that s is a solution of N .
Indeed, let v, v fi a V , if N [v, v fi ] = I" we have s(v) and s(v fi ) which satisfy the constraint N [v, v fi ].
Now, assume that N [v, v fi ] = I".
From the property (2) of DedZnition 1, there exists Xi a X such that v a Xi and v fi a Xi .
We know that s(v) and s(v fi ) satisfy NXi [v, v fi ].
As NXi [v, v fi ] = N [v, v fi ] we can assert that s(v) and s(v fi ) satisfy N [v, v fi ].
We can conclude that s is a solution of N   particular class of the ORD-Horn relations of the Interval Algebra.
In [15], Ligozat attributes a dimension (an integer included between 0 and 2) to each base relations of the Interval Algebra : the dimension of the base relations p, pi, o, oi, d, di is 2, this one of the base relations m, mi, s, si, f, f i is 1, and the dimension of eq is 0.
A partial solution of maximal dimension is a solution satisfying for every pair of variables a base relation of maximal dimension with regard to the dimensions of the base relations belonging to the constraint.
For illustration, consider the QCN N fi in Figure 4, a maximal instantiation s of N fi {v0 ,v1 ,v2 ,v6 ,v7 } is represented in Figure 5(b), the atomic QCN corresponding to this solution is given in Figure 5(a).
For example, the base relation satisdZed between s(v0 ) and s(v1 ) is the base relation o of dimension 2, it is a maximal dimension w.r.t.
to the dimensions of the base relations of the relation N fi [v0 , v1 ] = {eq, o, f i}.
Given a QCN N closed by weak composition dedZned by ORD-Horn relations, in the general case N is not a globally consistent QCN.
Nevertheless we have a nearest property which is satisdZed : each partial solution of maximal dimension of N can be extended to a maximal solution of N (see Proposition 6 in [15]).
From this property we can establish the following result : Theorem 2: Let N = (V, C) be a QCN dedZned by relations of the ORD-Horn class of the Interval Algebra and let T = (X = {X0 , .
.
.
, Xn }, F ) be a tree decomposition of N .
If N is a X -consistent QCN non trivially inconsistent then N is consistent.
Proof.
The proof is similar to the proof of Theorem 1 except that the manipulated partial instantiations are maximal partial instantiations.
  {m}  v6 {oi} {oi}  v0 {o}  v7  {o}  {o}  {o}  v1  {o} {o}  v2 Figure 5(a).
An N  {v0 ,v1 ,v2 ,v6 ,v7 } s(v6)  {oi}  atomic  sub-QCN  of  s(v2) s(v7)  s(v0) s(v1)  Figure 5(b).
A maximal solution of N  {v0 ,v1 ,v2 ,v6 ,v7 }  We are going to characterize a similar result for the  154  We proved in the previous section that given a QCN N and a RecPart decomposition T = (X = {X0 , .
.
.
, Xn }, F ) of this QCN we can dedZne a tree decomposition T fi = (X fi = {X0fi , .
.
.
, Xnfi }, F ) = T such that for each Xifi a X fi there exists Xj a leaves(T ) such that Xifi a Xj .
From this property and the previous theorems we can establish the following properties : Corollary 1: Let N = (V, C) be a QCN dedZned on a class of relations C and let T = (X = {X0 , .
.
.
, Xn }, F ) a RecPart decomposition of N .
aV If C is such that each -consistent QCN dedZned on C is globally consistent and if N is a leaves(T ) -consistent QCN then N is consistent.
aV If C is the ORD-Horn class of the Interval Algebra and if N is a leaves(T ) -consistent QCN then N is consistent.
100  80  %  60  40  20  (i,j) - PartRec decompositions (i,j) - Tree decompositions LexBFS (i,j,k) - PartRec decompositions (i,j,k) - Tree decompositions LexBFS  0  4  6  8  16 14 12 10 Density of non trivial constraints  18  20  22  Figure 6(c).
Percentages of pairs and triples of variables belonging to the clusters  VI.
F ROM QCNS TO BOOLEAN FORMULAE  1  To decide the consistency problem of QCNs, recent studies [9], [10] propose to exploit the theoretical and practical framework of the propositional logic, by using SAT encodings.
Given a QCN N = (V, C), a dZrst part of these encodings allows to represent the possible base relations of C(vi , vj ) for each pair of variables vi , vj a V .
A second part is dedZned by a set of clauses allowing to the SAT solver to enforce the property of -consistency during search.
Intuitively, these clauses represent the possible condZgurations for each triple of variables vi , vj , vk a V with regard to the weak composition operation.
Hence, a SAT instance resulting of these encodings will be consistent if, and only if, there exists a -consistent sub-QCN of N .
The encoding proposed in [9] leads to a sub-QCN dedZned by singleton relations whereas the approach proposed in [10] leads to a convex sub-QCN.
From Theorem 1, we can restrict these encodings to the constraints belonging to clusters of a tree decomposition of N .
For illustration, we consider two kinds of decompositions : RecPart decompositions obtained by a method similar as in [11], and tree decompositions obtained from triangulation of the constraint graphs of the QCNs by using the lexBFS algorithm [17].
We have focused on QCNs of the Interval Algebra, randomly generated by following the model A(n, d, s) [7].
This model involves the generation of QCNs according to three parameters: n the number of variables, d the density of constraints not dedZned by the relation I" (the average degree of the nodes in the constraint graph) and s the average number of base relations in each constraint.
The results presented concern QCN instances from series A(100, d, 6.5) for d varying from 4 to 24 with a step of 0.25, for each point We generated 100 networks for each serie.
In Figure 6(c) are given the percentages of pairs and triples of variables belonging to clusters for each kind of tree decompositions.
Clearly, we can observe that the lexBFSbased tree decompositions discard much more constraints  0.8  Ratio  0.6  0.4  0.2  PartRec decompositions Tree decompositions LexBFS  0  4  6  8  16 14 12 10 Density of non trivial constraints  18  20  22  Figure 6(d).
Ratios of the size of the SAT instances by using tree decompositions to the size of the SAT instances by using the complete encoding.
than the RecPart decompositions.
Remark that the less is the density of non-trivial constraints, the more is the number of discarded constraints.
In Figure 6(d) are given the ratios of the size of the SAT instances using tree decompositions to the size of the SAT instances using the complete encoding.
The SAT encodings used are based on the SAT encoding dedZned in [10].
Unsurprisingly, the using of the LexBFSbased tree decompositions always performs the using of RecPart decompositions.
Figure 6 shows the number of solved instances against CPU time.
The results are given for QCN instances with the parameter d varying from 8 to 12, and Minisat 2.2 [18] was used to solve generated SAT instances.
CPU time is restricted to solving time, and QCN instances are not preprocessed before encoding into SAT instances.
As we can see, the lexBFS-based tree decompositions allows to improve the performance for solving SAT instances.
155  [6] J. Renz, aMaximal tractable fragments of the region connection calculus: a complete analysis,a in Proceedings of the 16th international joint conference on ArtidZcal intelligence, ser.
IJCAI, vol.
1, 1999, pp.
448a454.
2000 1800  Number of solved instances  1600 1400  [7] B. Nebel, aSolving hard qualitative temporal reasoning problems: Evaluating the efdZcienty of using the ORD-Horn class,a in Proceedings of the 12th European Conference on ArtidZcial Intelligence, ser.
ECAI, 1996, pp.
38a42.
1200 1000 800  [8] Z. Gantner, M. Westphal, and S. WAsldZ, aGQR - a fast reasoner for binary qualitative constraint calculi,a in Proceedings of AAAIa08 Workshop on Spatial and Temporal Reasoning, 2008.
600 400 LexBFS RecPart Raw  200 0 0  Figure 6.
200  400  600 CPU Time (s)  800  1000  [9] D. N. Pham, J. Thornton, and A. Sattar, aModelling and solving temporal reasoning as propositional satisdZability,a ArtidZcial Intelligence, vol.
172, pp.
1752a1782, October 2008.
1200  Number of solved instances against CPU time.
[10] J.-F. Condotta and D. DaAlmeida, aQualitative constraints representation for the time and space in SAT,a in Proceedings of the 19th IEEE International Conference on Tools with ArtidZcial Intelligence, ser.
ICTAI, vol.
1, 2007, pp.
74a77.
VII.
C ONCLUSION AND FUTURE WORKS In this paper, we have introduced and studied the RecPart decompositions.
We proved that these decompositions are equivalent to particular tree decompositions.
Moreover, we have studied the consistency problem of QCNs with regard to tree decompositions.
We proved that, for some tractable classes of relations such as ORD-Horn class, we can decide the consistency problem of a QCN by enforcing the consistency restricted to the constraints belonging to clusters of a tree decomposition.
In order to illustrate these results, we have compared two kinds of decompositions : RecPart decompositions and tree decompositions obtained from triangulation of the constraint graphs of QCNs by using the lexBFS algorithm.
A future work is to conduct extensive experiments in order to compare more tree decompositions into the framework of SAT encodings of QCNs.
[11] J. J. Li, J. Huang, and J. Renz, aA divide-and-conquer approach for solving interval algebra networks,a in Proceedings of the 21st international jont conference on ArtidZcal intelligence, ser.
IJCAI, 2009, pp.
572a577.
[12] G. Gottlob, Z. MiklAls, and T. Schwentick, aGeneralized hypertree decompositions: NP-hardness and tractable variants,a Journal of the ACM, vol.
56, pp.
30:1a30:32, September 2009.
[13] J. Renz and G. Ligozat, aWeak composition for qualitative spatial and temporal reasoning,a in Proceedings of the 11th International Conference on Principles and Practice of Constraint Programming, ser.
CP, 2005, pp.
534a548.
R EFERENCES  [14] B. Nebel and H.-J.
BAzrckert, aReasoning about temporal relations: a maximal tractable subclass of Allenas interval algebra,a Journal of the ACM, vol.
42, pp.
43a66, January 1995.
[1] J. F. Allen, aAn interval-based representation of temporal knowledge,a in Proceedings of the 7th international joint conference on ArtidZcial intelligence, ser.
IJCAI, vol.
1, 1981, pp.
221a226.
[15] G. Ligozat, aA new proof of tractability for ORD-Horn relations,a in Proceedings of the thirteenth national conference on ArtidZcial intelligence, ser.
AAAI, vol.
1, 1996, pp.
395a401.
[2] G. Ligozat, aOn generalized interval calculi,a in Proceedings of the ninth National conference on ArtidZcial intelligence, ser.
AAAI, vol.
1, 1991, pp.
234a240.
[16] P. van Beek and R. Cohen, aExact and approximate reasoning about temporal relations,a Computational Intelligence, vol.
6, pp.
132a147, July 1990.
[3] R. A. Morris, W. D. Shoaff, and L. Khatib, aPath consistency in a network of non-convex intervals,a in Proceedings of the 13th international joint conference on ArtidZcal intelligence, ser.
IJCAI, vol.
1, 1993, pp.
655a660.
[17] D. J.
Rose, R. E. Tarjan, and G. S. Lueker, aAlgorithmic aspects of vertex elimination on graphs,a SIAM Journal on Computing, vol.
5, no.
2, pp.
266a283, 1976.
[18] N. EASn and N. SAsrensson, aAn extensible sat-solver,a in Proceeding of the 6th International Conference on Theory and Applications of SatisdZability Testing, ser.
SAT, 2003, pp.
502a518.
[4] A. K. Pujari, G. V. Kumari, and A. Sattar, aINDU: An interval and duration network,a in Proceedings of the 12th Australian Joint Conference on ArtidZcial Intelligence: Advanced Topics in ArtidZcial Intelligence, ser.
AI, 1999, pp.
291a303.
[5] D. A. Randell, Z. Cui, and A. G. Cohn, aA spatial logic based on regions and connection,a in Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, ser.
KR, 1992, pp.
165a176.
156
Proceedings of TIME-96  1  Gaining Efficiency and Flexibility in the Simple Temporal Problem Amedeo Cesta  Angelo Oddi  IP-CNR National Research Council of Italy Viale Marx 15, I-00137 Rome, Italy amedeo@pscs2.irmkant.rm.cnr.it  Dipartimento di Informatica e Sistemistica Universita di Roma "La Sapienza" Via Salaria 113, I-00198 Rome, Italy oddi@assi.dis.uniroma1.it  Abstract The paper deals with the problem of managing quantitative temporal networks without disjunctive constraints.
The problem is known as Simple Temporal Problem.
Dynamic management algorithms are considered to be coupled with incremental constraint posting approaches for planning and scheduling.
A basic algorithm for incremental propagation of a new time constraint is presented that is a modification of the Bellman-Ford algorithm for Single Source Shortest Path Problem.
For this algorithm a sufficient condition for inconsistency is given based on cycle detection in the shortest paths graph.
Moreover, the problem of constraint retraction from a consistent situation is considered and properties for repropagating the network locally are exploited.
Some experiments are also presented that show the usefulness of the properties.
1  Introduction  Knowledge-based architectures for planning and scheduling based on constraint propagation, e.g.
[5, 3, 8, 2], perform incremental constraint posting and retraction on a current partial solution.
A complete plan is created by efficiently searching in partial plans space, and, in other cases, it is adapted to new situations by partially removing parts of the solution.
A module for temporal constraint management that supports plan space search and current solution maintenance should be extremely efficient because is called into play at any modification (monotonic or not) of the current plan.
Such an efficiency is usually guaranteed by restricting the expressive power of the temporal representation.
Usually the so called Simple Temporal Problem (STP) [7] is used that allows the representation of binary quantitative constraints without disjunction.
In spite of the restriction of expressivity, also for STP it results useful to consider how the efficiency of manipulation primitives may be improved.
In our research, we have been investigating possible  algorithms for managing temporal information that: (a) allow dynamic changes of the constraint set for both incremental constraint posting and retraction; (b) exploit the localization of effects of any change in a subnetwork of the whole constraint graph; (c) do not compute the minimal network as done in [7] but just check for consistency.
A previous paper [1], in the same line of [6], has concerned the specialization of arc-consistency algorithm to the STP.
The choice of arc-consistency to propagate temporal constraints was motivated by the good trade-off wrt space and time complexity.
In the same paper some properties were given that were shown experimentally to improve the performance of the algorithm in the average case.
The present paper contains a further step in the direction of gaining efficiency in the solution of the STP.
After presenting the essentials of STP (Section 2), it presents dynamic algorithms based on the well known Bellman-Ford algorithm for computing Single Source Shortest Paths (Section 3).
It also introduces (Section 4) the concept of dependency that computes a particular spanning tree on the constraint graphs that allows the definitions of a sufficient condition for inconsistency detection (Section 5) and an algorithm for local constraint retraction (Section 6).
Some experiments (Section 7) show the usefulness of the properties.
2  The Temporal Problem  A Simple Temporal Problem is defined in [7] and involves a set of temporal variables {X1 , .
.
.
, Xn }, having continuous domains [lbi , ubi ] and a set of constraints {aij <= Xj - Xi <= bij }, where aij >= 0, bij >= 0 and aij <= bij .
A special variable X0 is added to represent the origin of the time (the beginning of the considered temporal horizon) and its domain is fixed to [0, 0].
A solution of the STP is a tuple (xi .
.
.
xn ) such that xi [?]
[lbi , ubi ] and every constraint aij <= Xj - Xi <= bij is satisfied.
An STP is inconsis-  Proceedings of TIME-96 tent if no solution exists.
In order to find the set of possible values [lbi , ubi ] for every variable Xi , a direct constraint graph Gd (Vd , Ed ) is associated to the STP, where the set of nodes Vd represents the set of variables {X1 , .
.
.
, Xn } and the set of edges Ed represents the set of constraints {aij <= Xj - Xi <= bij }.
Given a constraint aij <= Xj -Xi <= bij , we can rewrite it as a pair of inequalities: * Xj - Xi <= bij * Xi - Xj <= -aij For every linear inequality Xj - Xi <= wij (with wij equal to bij or -aij ) we have an edge (i, j) in Gd (Vd , Ed ) labeled with the weight wij .
Each path in Gd from the node i to the node j, i = i0 , i1 .
.
.
im = j induces between the variables Xj and Xi the constraint Xj - Xi <= lij , where lij is the sum of weights along the path, that is lij = w01 +w12 +.
.
.+w(m-1)m .
Considering the set of all paths between the nodes i and j, these paths induce a constraint Xj - Xi <= dij , where dij is the length of a shortest path between the nodes i and j.
Finally a cycle on the graph Gd is closed path i = i0 , i1 .
.
.
im = i and a negative cycle is a cycle with associated a negative length (lii < 0).
In [7] some useful properties of an STP are given and reported in the following theorems.
Theorem 1 [7] A Simple Temporal Problem is consistent iff Gd does not have negative cycles.
Defining d0i as the length of a shortest path on the graph Gd from the origin 0 and the node i and di0 as the length of a shortest path from the node i to the origin 0 we can also have the other following theorem.
Theorem 2 [7] Given a consistent Simple Temporal Problem, the set [lbi , ubi ] of feasible values for the variable Xi is the interval [-di0 , d0i ].
Theorem 2 shows that the Simple Temporal Problem is a Shortest Paths Problem and precisely we have to calculate two sets of shortest paths length: (a) the set of shortest paths from the node 0 (that represent the variable X0 ) to the nodes 1 .
.
.
n; (b) and the set of shortest paths from the nodes 1 .
.
.
n to node 0.
3  An Algorithm for the STP  To solve the basic STP we use the Bellman-Ford algorithm for the Single Source Shortest Paths Problem [4] giving an incremental version of the algorithm named Propagation, which accepts as an input the graph Gd and a new constraint Cij (where Cij = aij <= Xj - Xi <= bij ) and produces in output a new set of feasible values [-di0 , d0i ] for every variable Xi or a value fail in the case the new constraint induces a inconsistent situation.
To understand the algorithm, shown in Figure 1, some  2 simple definitions are useful: given a node i of the graph Gd we define EdgesOut(i) as the set of edges which leave from the node i and EdgesIn(i) as the set of edges which arrive to the node i. T and F are the boolean constants T rue and F alse.
The algorithm has two differences wrt the standard implementation on Bellman-Ford with a queue.
First, it calculates at the same time two sets of shortest distances.
Second, the algorithm has an internal test which detects negative cycles on the graph Gd which contain the reference node X0 .
In addition, every node u [?]
Vd has two boolean marks: LB(u) and U B(u).
This marks are useful in order to distinguish the two types of propagation in the graph Gd , that is, respectively U B(u) = T and LB(u) = T when a node is modified by the propagation process for the distance d0i and the distances di0 .
The Propagation calculates the set of distances {d0i } between Steps 6 and 14 and the set of distances {di0 } between Steps 16 and 24.
This last section of the algorithm, in order to calculates the set of distances di0 , (that is, the length of the shortest paths on the graph Gd between the nodes 1 .
.
.
n and the node 0) considers the set of direct edges in Gd as oriented in the opposite direction.
In this way when a shortest path between the nodes 0 and i is found, it is actually a shortest path in the opposite direction.
Finally, the tests at Steps 10 and 20 check for negative cycles in the graph Gd when they contain the node 0.
The algorithm calculates also two shortest path trees.
In fact Steps 11 and 21 respectively update the predecessor function pu, which represents the shortest path tree of the distances {d0i } and the predecessor function pl, which represents the shortest path tree of the distances {di0 }.
The complexity of the algorithm, as well known, is O(EN ).
Where N and E are respectively the number of nodes and the number of edges in Gd .
negative cycles  4  Focusing on Dependency  The temporal meaning of shortest path trees on the Gd graph is simple.
Every bound {d0i } (or {di0 }) is induced by the set of temporal constraints in the shortest paths between the origin 0 and the node i (or between the node i the origin 0).
The following definitions are useful: Definition 1 Let Gd a consistent distance graph.
The tree DTub of the shortest paths from the origin 0 to the nodes 1 .
.
.
n is called Upper Bounds' Dependency Tree.
Definition 2 Let Gd a consistent distance graph.
The tree DTlb of the shortest paths from to the nodes  Proceedings of TIME-96 Propagation (Gd , Cij ) 1. begin 2.
Q - {i, j} 2a.
LB(i) ::= T ; U B(i) ::= T 2b.
LB(j) ::= T ; U B(j) ::= T 3.
While Q 6= [?]
do begin 4. u - P op(Q) 5. if U B(u) then 6.
Foreach (u, v) [?]
EdgesOut(u) do 7. if d0u + wuv < d0v 8. then begin 9. d0v ::= d0u + wuv 10. if d0v + dv0 < 0 then exit(fail) 11. pu(v) ::= u 12.
U B(v) ::= T 13. if v 6[?]
Q then Q - Q [?]
{v} 14. end 15. if LB(u) then 16.
Foreach (u, v) [?]
EdgesIn(u) do 17. if du0 + wvu < dv0 18. then begin 19. dv0 ::= du0 + wvu 20. if d0v + dv0 < 0 then exit(fail) 21. pl(v) ::= u 22.
LB(v) ::= T 23. if v 6[?]
Q then Q - Q [?]
{v} 24. end 25.
LB(u) ::= F 26.
U B(u) ::= F 27. end 28. end Figure 1: Propagation algorithm  1 .
.
.
n to origin 0 is called Lower Bounds' Dependency Tree.
If a given graph Gd is consistent then the trees DTub and DTlb are always defined.
In fact, without negative cycles, the distances {d0i } and {di0 } are always defined.
In general, the trees DTub and DTlb may not be single.
In fact, the graph Gd may contain several paths with the same length.
A relevant situation is verified when the graph Gd contains at least a negative cycle.
In this case, the following Theorem holds.
Theorem 3 Give a distance graph Gd .
If during the update process of the Propagation algorithm the predecessor function pu (pl) represents a graph containing at least a cycle then the graph Gd is inconsistent.
3 Proof.
We give the proof for the distances {d0i }, but an analogous proof can be given for the distances {di0 }.
Suppose by hypothesis that during the update process of the algorithm, a dependency path exists between the nodes i and j named p1 : i = i0 , i1 .
.
.
ir = j, that is, a path such that pu(ik ) = ik-1 , with k = 1 .
.
.
r. If we sum the weights along this path, we have the following relation: d0j - d0i = w01 + w12 + .
.
.
+ w(r-1)r .
(1)  If successively the Propagation algorithm builds a dependency path p2 : j = j0 , j1 .
.
.
js = j, we can write the following relation: dnew - d0j = w01 + w12 + .
.
.
+ w(s-1)s .
0i  (2)  Where dnew is the new value of the distances d0i 0i updated along the path p2 .
If we sum the relations 1 and 2 we obtain the length of the cycle lii : lii = dnew - d0i .
0i  (3)  Observing that the link of two paths p1 and p2 is a cycle and dnew < d0i , then the length lii is negative 0i and this proves the inconsistency of the graph Gd .
2  5  Cycle Detection  In order to use the property expressed by Theorem 3 few changes are introduced in the Propagation algorithm.
Each edge (i, j) in the graph Gd have three new boolean marks: N EW ((i, j)), LBP ((i, j)) and U BP ((i, j)).
The mark N EW is useful in order to distinguish the new edges introduced in Gd , by the new temporal constraint Cij .
In fact, if in the graph there is at least a negative cycle, then it must contain at least one of the new edges introduced.
Instead, the two marks LBP ((i, j)) and U BP ((i, j)) are used to check when a bound changes two times as explained in the next Theorem 4: Theorem 4 Let Gd a consistent distance graph and Cij = aij <= Xj - Xi <= bij the new constraint added.
If during the propagation process the distance d0j (di0 ) changes two times, then the constraint Cij is inconsistent with the other constraints represented in Gd .
Proof.
We give the proof for the distances {d0j }, but an analogous proof can be given for the distances {dj0 }.
If the constraint represented by the edge (i, j) changes the distance d0j a first time, this means every new shortest paths built by the Propagation algorithm will contain the node j.
If the distances is changed a second time, then the algorithm has built a closed dependency path and for the Theorem 3 the graph Gd is inconsistent.
2  Proceedings of TIME-96 Figure 2 shows the modified version of the algorithm to check for cycle detection.
It is interesting to notice the complexity of the algorithm with cycles detection is the same of the Propagation algorithm.
In fact, the only difference with the previous algorithm is the check of the boolean marks N EW ((i, j)) LBP ((i, j)) and U BP ((i, j)).
Propagation-cd (Gd , Cij ) 1.
- 9. as in the Propagation algorithm 10a.
if d0v + dv0 < 0 10b.
then exit(fail) 10c.
else if N EW ((u, v)) 10d.
then if U BP ((u, v)) 10e.
then exit(fail) 10f.
else U BP ((u, v)) ::= T 11.
- 19. as in the Propagation algorithm 20a.
if d0v + dv0 < 0 20b.
then exit(fail) 20c.
else if N EW ((u, v)) 20d.
then if LBP ((u, v)) 20e.
then exit(fail) 20f.
else LBP ((u, v)) ::= T 24.
- 28. as in the Propagation algorithm  Figure 2: Differences introduced by cycle detection the average time  6  Retraction of Temporal Constraints from a Consistent Context  This paragraph deals with the problem of removing temporal constraints from a consistent graph Gd (a graph without negative cycles).
A basic way to do this consists of: physically removing the constraint from the graph Gd ; setting every distance {d0i } and {di0 } to the value +[?
]; finally, running the Propagation algorithm on the whole graph.
As a matter of fact, this method is not very efficient.
In fact, when retracting a constraint from the time map a lot of distances are likely not to be affected by the removal.
The dependency information may be used to focalize the part of the network actually affected by the removal and to run the Propagation algorithm on that part of the graph.
To state same properties some definitions are useful.
Given an upper bounds' dependency tree DTub (VDTub , EDTub ), each sub-tree STub [i](VSTub , ESTub ) of root i [?]
VDTub is called an Upper Bounds' Dependency Sub-tree.
Given a lower bounds' dependency tree DTlb (VDTlb , EDTlb )  4 every sub-tree STlb [i](VSTlb , ESTlb ) of root i [?]
VDTlb is called a Lower Bounds' Dependency Sub-tree.
Given a a distance graph Gd (VGd , EGd ) and a node i [?]
VGd , IN (i) is the set of start nodes of the edges which enter in the node i (in the edge (j, i), j is the start node and i is the end node).
The next Proposition explains the real effects of a removal constraints from a graph Gd and it is a starting point to write a new algorithm to remove temporal constraints from Gd .
Proposition 1 Let Gd be a consistent graph and DTub (VDTub , EDTub ) its upper bounds' dependency tree (DTlb (VDTlb , EDTlb ) its lower bounds' dependency tree).
The retraction of an edge (i, j) [?]
EDTub ( (i, j) [?]
EDTlb ) modifies at most the distances of the nodes k [?]
VSTub [j] ( k [?]
VSTlb [j] ).
No distances are modified when (i, j) 6[?]
EDTub ( (i, j) 6[?]
EDTlb ).
Proof.
We give the proof for the distances {d0i }, but an analogous proof can be given for the distances {di0 }.
The removal of an edge (i, j) [?]
EDTub can't modify a node's distance {d0k } in the case k 6[?]
VSTub [k].
In fact the removal of (i, j) does not change the shortest path between the origin 0 and the node k. If (i, j) 6[?]
EDTub then no distance is changed because no shortest path is changed.
2 The basic idea to write an efficient removal algorithm is run the Propagation algorithm on the only part of the Gd graph affected by the removal of the constraint.
The next Theorem formalize this concept and explains how to initialize the Propagation algorithm.
Theorem 5 Let Gd be a consistent distance graph.
To remove the effects of the constraint represented by the edge (i, j) [?]
EDTub ( (i, j) [?]
EDTlb ) the queue Q of the Propagation algorithm and the set of distances {d0i } ({di0 }) in the graph Gd need of the following initialize operations.
S S 1.
Q - k[?
]VST [j] IN (k) (Q - k[?
]VST [j] IN (k)) ub lb 2. d0u ::= +[?
], u [?]
VSTub [j] (du0 ::= +[?
], u [?]
VSTlb [j]) Proof.
We give the proof for the distances {d0i }, but an analogous proof can be given for the distances {di0 }.
By Proposition 1, for every node k [?]
VSTub [j], the distance {d0k } can change after the removal.
The Propagation algorithm have to rebuild the new shortest paths for every node k [?]
VSTub [j].
In order to update these distances to the new values, it is necessary to initialize them to the maximum possible value +[?].
In fact, it is not known what the new values will be and the Propagation algorithm can only reduce the bounds.
In addition, we have to put in the queue Q all  Proceedings of TIME-96 the nodes of the constraints (i, j) which enter in the set S of updated nodes.
That is, the nodes in the set k[?
]VSTub [i] IN (k).
In fact, these are the only nodes of the graph from which can start the new shortest paths of the nodes k [?]
VSTub [j].
2 The Remove algorithm is shown in Figure 3.
It accepts as an input a graph Gd and a constraint Cij which have to be removed from Gd and return the graph Gd updated.
At the step 13 is used the RePropagation algorithm that is similar to the Propagation algorithm but accepts as an input a list of nodes Q instead of an edge Cij .
The parameter Q is used as an initialization for the internal queue.
Moreover RePropagation does not check for the consistency of a modification because the removal of one or more constraints, relax the STP holding the consistency property.
Remove (Gd , Cij ) 1. begin 2.
Vm - [?]
3.
Q-[?]
4. if (i, j) [?]
EDTub 5. then Vm - Vm [?]
VSTub [j] 6. else if (j, i) [?]
EDTub 7. then Vm - Vm [?]
VSTub [i] 8. if (i, j) [?]
EDTlb 9. then Vm - Vm [?]
VSTlb [i] 7. else if (j, i) [?]
EDTlb 8. then Vm - Vm [?]
VSTlb [j] 9.
Foreach u [?]
Vm do begin 10.
Q - Q [?]
IN (u) 11. end 12.
EGd - EGd - {(i, j), (j, i)} 13.
RePropagation(Gd , Q) 14. end Figure 3: Remove algorithm  7  Performance Evaluation  In order to get some realistic evaluations of the algorithms, we have used a scheduling system described in [3] and the time network generated by the scheduler.
This scheduler solves instances of the Deadline Job Shop Scheduling Problem (DJSSP) by incremental precedence constraint posting between the activities until any conflict in the use of resources is resolved.
In the DJSSP, each activity in a job can request only one resource and a resource is requested only once in a job.
The sequence of resources requested by the activities in a job is random.
Every job has a  5 fixed release date and a due date.
More details on the random problem generator are described in [3].
All the evaluations are given as number of time points explored by the algorithms.
This choice is motivated from the fact that such number is both proportional to the time of computation and machine independent.
We have built two different types of time networks from the resolution of two different DJSSPs: the 8x8x8 (named P 8) and the 10x10x10 (named P 10), where the first number indicate the number of jobs, the second one the number of activities in a job and the third one the number of resources.
The data are obtained running ten instances of each type of problem.
Table 1 shows the number of time points N , the maximum number of distance constraints Emax and maximum connectivity Cmax for each problem.
The connectivity is defined as the ratio between the number of distance constraints E and the number of time points N .
The value N is two times the number of activities plus two (the origin point and horizon point).
The value Emax represents the maximum number of distance constraints which can be contained in a time network associated to the solution of the instance of the DJSSP.
Emax is obtained by the sum of the maximum values of the number of precedence constraints for each resource and the number of constraints before the scheduling algorithm starts to find a solution.
Table 2 and Table 3 present the perfor-  Table 1: Number of time points and maximum connectivity for the experimental time networks Problem P8 P 10  N 130 202  Emax 333 661  Cmax = Emax /N 2.56 3.27  mance of the Propagation algorithm when a modification is either consistent or inconsistent respectively.
This values are shown as a function of the average connectivity Av-conn, that is, every row of the table represents the average value obtained in the interval Av-conn +-0.25.
In order to get several values of the connectivity we have built a solution of an instance of a DJSSP and progressively reduced the number of edges and selected a time constraint Cij in random way.
In order to get the results showed in Table 2, we have modified the distance constraint selected Cij = aij <= Xj - Xi <= bij , in the constraint  Proceedings of TIME-96  6  Cij = aij + (dij - aij )U [0.05, 01] <= Xj - Xi <= bij .
Where U [x, y] represents a random value r with uniform distribution such that x <= r <= y and dij is minimal temporal distance between the nodes i and j on the Gd graph.
In this case, it is possible to make a comparison between the number of nodes scanned by the Propagation algorithm (Loc-prop values) and the number of nodes scanned by an algorithm which works from scratch (Scratch values).
In order to get the results showed in Table 3, we have induced an inconsistent situation by modifying the constraint Cij in the constraint dij (1 + U [0.05, 01]) <= Xj - Xi <= bij In this other case, it is possible make a comparison between the number of nodes visited by the Propagation algorithm which uses the property expresses by Theorem 4 (Cycle-det values) and the number without the previous property (No-cycle-det values).
Table 2: Incremental vs scratch propagation Problem P8  P 10  Av-conn 1.25 1.75 2.25 2.75 1.25 1.75 2.25 2.75 3.25  Loc-prop 38.76 52.33 34.08 39.51 51.42 67.20 64.34 57.00 63.92  Scratch 652.67 1111.47 1641.19 2048.28 1108.38 1928.54 2876.22 3817.79 4388.71  a solution; then we have reduced progressively the number of time constraints by using the Remove algorithm.
In this case, is possible to make a comparison between the average number of nodes scanned by the Remove algorithm (Loc-rem values) and the number of nodes scanned in the same case by a scratch algorithm (Scratch-rem values).
The scratch algorithm eliminates first the constraint from the time map; then puts all the bounds of the time points to the value +[?
]; finally updates all the network.
Table 4: Incremental vs scratch remove Problem P8  P 10  Av-conn 1.25 1.75 2.25 2.75 1.25 1.75 2.25 2.75 3.25  Loc-rem 2.37 35.34 56.02 96.35 2.69 33.12 55.06 70.58 156.97  Scratch-rem 652.67 1111.47 1641.19 2048.28 1108.38 1928.54 2876.22 3817.79 4388.71  Acknowledgments This research is partially supported by: ASI - Italian Space Agency, CNR Special Project on Planning, CNR Committee 04 on Biology and Medicine.
References [1] Cervoni, R., Cesta, A., Oddi, A., Managing Dynamic Temporal Constraint Networks, Proceedings of the Second International Conference on AI Planning Systems (AIPS94), AAAI Press, 1994.
Table 3: Propagation with and without cycle detection Problem P8  P 10  Av-conn 1.25 1.75 2.25 2.75 1.25 1.75 2.25 2.75 3.25  Cycle-det 3.02 2.92 2.47 1.92 3.21 2.78 2.68 2.55 2.63  No-cycle-det 114.42 77.30 43.87 9.75 199.45 133.81 86.85 27.15 14.58  Finally, Table 4 presents the performance of the Remove algorithm.
These results are obtained in the same way as the previous ones.
First we have built  [2] Cesta, A., Oddi, A., DDL.1: A Formal Description of a Constraint Representation Language for Physical Domains, Proceedings of the 3rd European Workshop on Planning (EWSP95), IOS Press, 1996.
[3] Cheng, C. Smith, S.,F., Generating Feasible Schedules under Complex Metric Constraints, Proceedings of the 12th National Conference on Artificial Intelligence (AAAI-94), AAAI Press, 1994.
[4] Cormen, T.H., Leierson, C.E., Rivest, R.L., Introduction to Algorithms, MIT Press, 1990.
[5] Currie, K., Tate, A., O-Plan: the open planning architecture, Artificial Intelligence, 52, 1991, 49-86.
[6] Davis, E., Constraint Propagation with Interval Labels, Artificial Intelligence, 32, 1987, 281-331.
[7] Dechter, R., Meiri, I., Pearl, J., Temporal constraint networks.
Artificial Intelligence, 49, 1991, 61-95.
[8] Ghallab, M, Laruelle, H., Representation on Control in IxTeT, a Temporal Planner, Proceedings of the Second International Conference on AI Planning Systems (AIPS94), AAAI Press, 1994.
2011 Eighteenth International Symposium on Temporal Representation and Reasoning  Synthesising Classic and Interval Temporal Logic Sven Schewe Department of Computer Science University of Liverpool Liverpool, United Kingdom sven.schewe@liverpool.ac.uk  Cong Tian ICTT and ISN Lab Xidian University Xi'an, 710071, P.R.China c.tian.xdu@gmail.com  Abstract--Linear-Time Temporal Logic (LTL) is one of the most influential logics for the specification and verification of reactive systems.
An important selling point of LTL is its striking simplicity, which might be a reason why none of the many extensions suggested to LTL have gained the same influence.
Interval based temporal logics like Interval Temporal Logic (ITL) are a more recent branch of temporal logics with their own niche of interesting applications.
On first glance, interval based temporal logics very little resemble LTL and the spread of these logics beyond their niche is hampered by a seeming structural incompatibility with LTL.
When competing for being applied on a larger scale, interval based temporal logics would fight a losing battle against a more established competitor with better complexity and mature tools.
In this paper, we suggest to extend ITL to Pop Logic (PL) by introducing a simple pop operator that revokes the binding of the chop operation--very much like the popping operation in a stack--and show that LTL can be viewed as a syntactic subset of PL.
This is a surprising twist: by strengthening the comparably exotic logic ITL slightly and by using the new pop and the old chop operator as primitive constructs, we obtain a logic for which LTL is a de-facto syntactic fragment.
The power of this extension is that it can, by subsuming both interval and classic temporal logics, synthesise both concepts to a common framework.
The charm of this extension is that PL does not sacrifice the simplicity that makes its sub-logics attractive.
power of LTL is restricted to star-free expressions.
To overcome this limitation, several extensions and variations have been proposed.
Notably, Quantified Linear Time Temporal Logic (QLTL) [17] and Extended Temporal Logic (ETL) [22], [21] are extensions of LTL for the expressiveness of full o-regular language.
Temporal Logic of Actions (TLA) is a variation of LTL where state changes can be easily handled through actions [12].
However, these extensions (or variations) affect the simplicity of LTL and make it less intuitive.
This might be one of the reasons why none of them has gained the same influence as LTL itself.
Interval based temporal logics are a more recent branch of temporal logics with their own niche of interesting applications.
The characteristic operator of these logics is the chop operator, often denoted by the symbol ';'.
Different from the traditional temporal operators (always) and U (until), a chop construct, p ; q, holds over a path (or an interval) if, and only if, the path can be split into two parts, such that p holds over the first part and q holds over the second part.
The chop operator was first used as a temporal construct by Harel, Kozen and Parikh [11] and studied in more depth by Chandra, Halpern, Meyer and Parikh [3].
Halpern, Manna, and Moszkowski showed that chop is a useful operator when reasoning about time-dependent digital hardware [10], which triggered the development Interval Temporal Logic (ITL), a temporal logic based on chop, chop star, next, and projection operations, by Moszkowski [13], [14].
Initially, ITL is confined within finite models.
Projection Temporal Logic (PTL) [5], [6], [7] is an extension of ITL with infinite models and a new projection construct, (P1 , .
.
.
, Pm ) pr j Q.
Compared to classic temporal logics, interval based temporal logics greatly simplify the formulation of certain correctness properties [8], which underlines the usefulness of these logics for specification and formal reasoning about concurrent systems.
Interval based temporal logics lend themselves particularly well to reasoning about properties with a 'scope'; such properties are very common in most programming languages.
Further, with chop operations, sequential behaviours can be described elegantly and succinctly; and full regular expressiveness can easily be achieved by the introduction of a chop star operator, which can be intuitively understood as the multi-time implementa-    I. I NTRODUCTION Temporal logics are popular formalisations that can express properties about the temporal order of events.
The family of temporal logics has grown over the years, containing linear [15] and branching time logics [4], [2], and, more recently, game, alternating time, and coordination logics [1], [9].
While linear time temporal logics are concerned with properties of paths, branching time logics describe properties that depend on the branching of computational tree structures.
There has been a long debate between linear time and branching time temporal logics, but three decades worth experiences have shown that branching time logics are hard to be understood and error-prone [16], [20].
In contrast, linear time temporal logics seem to lend themselves to the system designers.
This makes Linear-time Temporal Logic (LTL) [15], the original linear time temporal logic, one of the most influential logics in specification and verification.
From a theoretical point of view, one can show that the expressive 1530-1311/11 $26.00 (c) 2011 IEEE DOI 10.1109/TIME.2011.19  64  operator.
Intuitively, a chop operator pushes a new interval into an interval stack, while a pop-operator pops the top element of this stack (hence the name).
Just like ITL, its extension PL has a natural semantics for finite and infinite words.
tion of a chop operation.
Interval based temporal logics very little resemble LTL and the spread of these logics beyond their niche is hampered by a seemingly structural incompatibility with LTL.
When competing for being applied on a larger scale, interval based temporal logics would fight a losing battle against a more established competitor with better complexity and well developed tools.
This leads to the question of whether or not the differences between these logics can be bridged without affecting their simplicity.
A first approach would be to consider a simple merge of the operators.
Why not enrich LTL by a chop operator?
Or, likewise, ITL with an until?
The disadvantage of such a solution is that the strongest advantages of these logics is their simplicity: they are build around a single intuitive concept.
In this sense, each extension comes to the cost of elegance and effects the intuitive access to these logics.
In this paper, we discuss an alternative approach.
We introduce a natural extension of ITL, Pop Logic (PL), by introducing a simple operator pop operation, denoted as |, that revokes the binding of a chop operation.
(The name is inspired by the popping operation in a stack.)
The pop operation is interesting in itself: it can be used as a pseudo inverse of a chop operation, as (| ph) ; true is logically equivalent to ph, and it provides a fresh view on the interval temporal logics.
In PL, we view the scoping implied by the chop operator as the scoping invoked by a call.
The pop operation provides access to lower levels of the call tree, which implies a recognition of the call structure in the semantics of the logic.
This entails a semantics that accurately reflects this call structure.
But while it clearly provides some insight into the relation of calls and interval logic, the main advancement is the link it establishes with LTL: We show that LTL operators can be viewed as snippets of PL operators.
LTL can therefore justly be viewed as a defacto syntactic subset of PL.
This, in turn, provides another insight to interval temporal logics: Using the extension, we get--with LTL--a meaningful--and even popular--a PSPACE-complete sub-logic of PL.
We use this observation to define more general structural restrictions of PL that preserve this low complexity.
The remainder of the paper is organised as follows.
The following section presents the syntax and semantics of Pop Logic and we discuss its relation to ITL in Section III.
We then discuss the embedding of LTL into PL in Section IV and demonstrate the decidability of PL by embedding it in QLTL in Section V. (This proof simplifies, as a small side result, the known decidability proof of ITL.)
Finally, we study PSPACE-complete subsets of PL in Section VI.
A. Syntax of Pop Logic Pop Logic is interpreted over finite and infinite words over a countable set P of atomic propositions, which includes a special proposition  (true) that holds in every position of the word.
The syntax of Pop Logic is given by the grammar ph ::= p | !ph | ph [?]
ph |  ph | ph; ph | | ph,  where p [?]
P is an atomic proposition.
PL extends the syntax of ITL (see the following section) by the unary pop operator |.
B.
Semantics of Pop Logic We call a PL formula ph well formed if there exists no node in the formula tree of ph such that strictly more pop operators than chop operators occur on the way from the root of the formula tree to this node.
We define the PL semantics only for well formed formulas.
The intuition for the exclusion of ill formed formulas is that we would otherwise try to pop the bottom element of an interval stack.
For l, u [?]
o and u [?]
o  {[?
]}, [l, u] = {k [?]
o | l <= k <= u} and [l, u [= {k [?]
o | l <= k < u } are (integer) intervals.
The semantics of a well formed PL formula ph leans on the semantics of ITL, but as we have the power to revoke the effect of previous chop operators, we have to keep track of a stack of intervals, comparable to the call structure in recursive procedures.
Consequently, a sub-formula ps of ph needs to be interpreted in the context of this stack of intervals at the time where ps is evaluated.
PL is interpreted over a (finite or infinite) word s [?]
(2P )*  (2P )o .
When convenient, we interpret s as a function from [0, |s|[ to 2P , s : [0, |s|[- 2P .
In the following, I0 , .
.
.
, In (with n [?]
o) is a non-empty interval stack with [0, |s|[= I0 [?]
I1 [?]
.
.
.
[?]
In .
We first define the interpretation of a word s in an interval stack I0 , .
.
.
, In at a position k. s; I0 , .
.
.
, In ; k |= p s; I0 , .
.
.
, In ; k |= !ph s; I0 , .
.
.
, In ; k |= ph [?]
ps  II.
P OP L OGIC  iff k [?]
In and p [?]
s(k), iff s; I0 , .
.
.
, In ; k |= ph, iff s; I0 , .
.
.
, In ; k |= ph or s; I0 , .
.
.
, In ; k |= ps, s; I0 , .
.
.
, In ; k |= ph iff s; I0 , .
.
.
, In ; k + 1 |= ph, s; I0 , .
.
.
, In , [b, e[; k |= ph ; ps iff k [?]
[b, e[ and [?
]l [?]
[k, e[.
s; I0 , .
.
.
, In , [b, e[, [b, l]; k |= ph and s; I0 , .
.
.
, In , [b, e[, [l, e[; l |= ps, and s; I0 , .
.
.
, In , In+1 ; k |=| ph iff s; I0 , .
.
.
, In ; k |= ph.
In this section, we introduce Pop Logic (PL), a syntactical extension of ITL with a pop operator '|' that revokes the most recent effect (interval restriction) imposed by a chop  A finite of infinite word s is a model of ph, denoted s |= ph, if, and only if, ph holds initially on the complete word, that is, if, and only if, s; [0, |s|[; 0 |= ph holds.
65  Note that, as usual, for all finite words s and all k >= |s|, s; k |= .
No pop on the singleton stack.
: If the interval stack contains only one element, then the semantics of the pop operator is not properly defined.
Note that we could easily avoid this by defining 's; I0 ; k |= | ph if, and only if, s; I0 ; k |= ph'.
Choosing to do so would also allow us to treat ill formed formulas by a convention that could intuitively be phrased as 'an attempt to pop the bottom element of an interval stack is ignored'.
However, we consider it more natural to simply disallow such operations.
In PL, we have the following abbreviations: PUSH EVENTUALLY ALWAYS UNTIL  In order to obtain a simple logic, we have extended a basic version of ITL, ITL without star [5], [7], whose syntax simply represents the PL syntax without pop.
The semantics of ITL, however, is traditionally 'flat' in the sense that the semantics of ITL is normally not defined using an interval stack: Without the introduced pop operation, there is no requirement for it because preserving the top-most interval is unnecessary.
The traditional ITL semantics for chop is    s; [b, e[; k |= ph ; ps iff k [?]
[b, e[ and [?
]l [?]
[k, e[.
s; [k, l]; k |= ph and s; [l, e[; l |= ps.
This has no effect on the evaluation of s; [0, |s|[; 0 |= ph, because without a pop operation we would never refer to any other than the top interval on the interval stack.
= = = =  ps ; |th  : ps !
!ps   | (ps [?]
th) : th       V. D ECIDABILITY OF P OP L OGIC There are two obvious approaches to show the decidability of PL: A direct translation to automata and an embedding into QLTL.
We describe an embedding into QLTL, because it is a much simpler transformation.
It also simplifies the decidability proofs for the sub-logic ITL with finite [13] and infinite [5] word semantics.
The main reason for our choice, however, is that it again outlines the connection between PL (or ITL) and classic temporal logics.
The embedding of PL into QLTL is also a counter position to the embedding of LTL into PL discussed in the previous section.
QLTL: extends LTL slightly by introducing quantification [17], yielding the full power of o-regular expressions.
QLTL formulas are described by the following grammar:  IV.
E MBEDDING LTL IN P OP L OGIC In the following, we briefly present the related temporal logic LTL and discuss its embedding in PL.
The syntax of LTL is given by the following grammar: ph | ph Uph  The semantics of LTL formulas is only defined on infinite words.
Like with ITL, the concept of interval stacks does not exist in LTL and the interpretation of a formula ph at a position k is defined inductively by: s; k |= p s; k |= !ph s; k |= ph [?]
ps s; k |= ph s; k |= ph U ps     The first abbreviation introduces a push operator ':', which is closely related to the chop.
Different to chop, a push operation only increases the call stack on the left.
There is little difference in the effect of push and chop, as the evaluation of the truth of the formula on the right is started at the beginning of the second interval.
In our view, the push operation is the more useful, as it reflects a call and return situation; our intuition is that we first satisfy the formula on the right (pushing down one level) and then come back (pop) and satisfy the right side.
On infinite intervals, the eventually and always operators ' ' and ' ' have the same semantics as in LTL, with the natural extension for finite intervals (holds somewhere within the interval and holds throughout the interval, respectively).
A similar claim holds for until.
Using only the LTL operators, it is plain to see that we maintain the semantics of LTL.
Note that, in the LTL fragment, a chop (or pop) operator can only occur in the abbreviations for a temporal operator, and there it is 'guarded' in the sense that the stack cannot grow to a size of more than three.
III.
R ELATION OF P OP L OGIC TO ITL  ph ::= p | !ph | ph [?]
ph |  ps :th ps ps ps Uth  ph ::= p | !ph | ph [?]
ph |  ph | ph U ph | [?]x.
ph  p [?]
s(k), s; k |= ph, s; k |= ph or s; k |= ps, s; k + 1 |= ph, [?
]i >= k.s; i |= ps and [?]
j [?]
[k, i[.
s; j |= ph.
Likewise, the semantics of QLTL extends the semantics of LTL by introducing a rule for quantification,  A central advantage of Pop Logic is that it provides us with a very simple embedding of LTL, while preserving the scoping allowed for by ITL.
The LTL operators can be viewed as abbreviations of small snippets of PL, just as and operators in LTL can be viewed as snippets of LTL syntax.
where s [?]
sx : n - s(n)  sx (n) [?
]n [?]
o, to the inductive definition of the semantics of a formula.
While the quantifiers extend the expressiveness, quantification does not seem to be a concept that lends itself to human system analysts.
We freely confess that we would not trust ourselves when writing a QLTL specification, in    iff iff iff iff iff  s; k |= [?
]x.ph iff [?
]sx : o - 2{x} .
s [?]
sx ; k |= ph,    66   th fi = th, and thfi = th , and for a formula ps that appears par(ps),  fi = par( as a direct sub-formula of ps =| ps, we set ps psfi ).
 fi = psfi .
Otherwise, if ps is a direct sub-formula of ps , we set ps Using these terms, we define our translation k from PL to QLTL as follows:  particular with nested quantification under the scope of temporal operators.
A. Embedding Pop Logic into QLTL The embedding of PL into QLTL builds on a simple observation: The truth of a sub-formula depends on the interval stack.
In the interval stack, each interval but the interval at the bottom of the interval stack is introduced by a particular chop operator.
Each chop operator introduces two different intervals for its left and right sub-formulas and we index the interval in the interval stack with the respective sub-formula.
That is, for a sub-formula of a specification ph that is a chop formula ps ; th, we index with ps and th, respectively.
We index the interval at the bottom of the stack with ph.
An interval can be encoded by the existence of a proper assignment of truth values to interval propositions that are evaluated to true within the interval and to false outside of the interval.
We use pps to denote the truth values of an interval Ips .
This way, the existence of a suitable chop of an interval can be translated to a QLTL formula that intuitively says 'there is a chopping point for the given interval'.
The respective encoding requires that (1) the new intervals are proper intervals, (2) the last position of the left interval coincides with the first position of the right interval, and (3) the union of these intervals coincides with the chopped interval.
As the interpretation of a sub-formula depends--through the interval stack--on its position in the formula tree, its translation needs to take this position into account.
We call the complete formula ph and all direct sub-formulas th and th of a chop sub-formula th; th of ph interval identifiers.
ph can be used to identify the interval [0, |s|[ at the bottom of our interval stack, while th and th can be used to identify the left and right interval, respectively, which is added by the chop operation in th; th to the interval stack.
Note that th and th are defined by their positions in the formula tree; syntactically identical sub-formulas of ph have to be distinguished.
For a sub-formula ps of ph, we first look for the relevant interval identifier, which is the index of the top interval in the stack under which ps is interpreted.
The relevant interval identifier of ps can be found by, starting at ps, walking the formula tree upwards towards its root.
While walking up, we maintain a counter, which is initially 0.
The counter is incremented each time we pass a pop operator '|' and decremented each time we pass a chop operator ' ; ', reflecting the pushing and popping of the interval stack.
The first interval identifier we pass (including ps itself) with counter value 0 is the relevant interval identifier of ps, fi.
denoted ps In other words: if, for a true sub-formula of a specification ph, par(ps) denotes the sub-formula of ph whose direct subformula ps is, then the following holds.
For a specification fi = ph, for a chop formula ps = th; th , we set ps fi= ph, we set ph  *  *  * * *  leaves p (including ) of the formula tree are strengthened by a claim that the current position is within the top interval of the interval stack, reflected by the respective interval proposition: a sub-formula ps =  is translated to k(ps) = ppsfi and an atomic proposition ps = q is translated to k(ps) = ppsfi [?]
q; a sub-formula ps = !th is translated to k(ps) = !k(th) and a sub-formula ps = th [?]
th is translated to k(ps) = k(th) [?]
k(th ) (all boolean connectives can be translated fi = thfi = ps fi ); in this simple manner, note that th a sub-formula ps = th is translated to k(ps) = (k(th)), a sub-formula ps =| th is translated to1 k(th), and a sub-formula ps = th ; th is translated to [?
]pth , pth .
k(th) [?]
g(pth , pth , ppsfi ) [?]
(k(th ) [?]
pth [?]
pth ), where     g(p, q, r) = p [?]
((p [?]
q) - r) [?]
(p [?]
q) [?]
(q - !
p) simply checks if p and q define two intervals that properly chop the interval defined by r.          In order to ease the proof that a PL formula ph and its translation k(ph) to QLTL are semantically equivalent (that is, have the same models), we introduce a natural extension of the QLTL semantics to interval stacks.
Assuming without loss of generality that p0 , p1 , .
.
.
, pn are fresh propositional variables, we denote with PI0 ,...,In = P  {p0 , .
.
.
, pn } an extended set of atomic propositions.
For a word s = [0, |s|[- 2P , we denote by s; I0 , .
.
.
, In the o-word with * *  s; I0 , .
.
.
, In (k) [?]
P = s(k) and pi [?]
s; I0 , .
.
.
, In (k) if, and only if, k [?]
Ii .
Finally, we use s |= ph as an abbreviation for s; [0, |s|[; 0 |= ph.
Note that there is a difference between the bottom element of the stack and the remaining elements: While the bottom element--[0, |s|[--reflects the true length of a finite or infinite input word s, the other elements of the stack are introduced during the interpretation of the ph on s. Thus, the bottom element and the atomic proposition describing it (no matter if named p0 , pph , or pphfi ) are assumed to be explicitly given.
Theorem 5.1: For a PL formula ph and a word s, s |= ph holds if, and only if, s |= k(ph).
Proof: By induction over the structure of the formula, we show that s; Iph , .
.
.
, Ipsfi ; k |= ps holds for every sub-formula ps of ph if, and only if, s; Iph , .
.
.
, Ipsfi ; k |= k(ps).
1 This translation might look a bit surprising at first glance, because it may convey the impression that the | operator has no effect.
However, it is reflected in the fi th operations that identify the relevant interval identifiers-- and hence the interval propositions occurring in the translation.
67  The induction basis is trivial, as the claim holds by definition for the atomic propositions (including ).
The induction step for boolean connectives is also trivial.
For the next operation, we have s; Iph , .
.
.
, Ipsfi ; k |= ps s; Iph , .
.
.
, Ipsfi ; k + 1 |= ps =PL =IH s; Iph , .
.
.
, Ipsfi ; k + 1 |= k(ps) de f =QLT L s; Iph , .
.
.
, Ipsfi ; k |= k(ps) =k k(  the satisfiability problem and the word problem for finite and o-regular words.
For the lower bounds, we can use the matching hardness results of the syntactic sub-logic ITL for both finite and infinite [18] words.
VI.
A PSPACE-C OMPLETE S UBSET OF PL While Section V establishes the decidability and complexity of PL, the non-elementary complexity of PL is not appealing.
But we have also seen that the popular and inexpensive temporal logic LTL can be viewed as a de-facto syntactic sub-logic of PL, which implies that relevant sublogics of PL are in PSPACE.
In this section, we define a wider fragment of PL--which includes LTL--that is still decidable in polynomial space.
Depending on personal preferences, this sub-logic can be considered as a restriction of PL or as an extension of LTL.
To get an intuition for the extension, we adjust our translation k with complexity considerations in mind.
We approach finding a PSPACE fragment by looking at the translation of LTL, starting with the sub-logic of LTL that uses the eventually operator instead of until.
In LTL, ps is an abbreviation for  ; | ps, and this subformula translates to [?
]p , p|ps k() [?]
g(p , p|ps , p )[?]
; |ps , (p|ps [?]
k(| ps)).
g states that p and p|ps do chop p ; |ps and neither p nor p|ps occur in k(| ps).
In such a situation, we can avoid the existential quantification and simply translate k( ; | ps) to p [?]
(p [?]
k(| ps)).
; |ps ; |ps Adjusting k.: Avoiding quantification is a very useful tool, because without quantification the target language is LTL instead of QLTL.
In the remainder of the paragraph we therefore discuss properties of sub-formulas which allow either avoiding quantification, or at least to use it in a monotone and inexpensive way.
This raises the question of whether or not we can avoid the introduction of quantification.
For this we adjust our translation k from PL to QLTL to k, where we only touch the rules for chop sub-formula ps ; th.
For them we give two rules for cases, where the use of quantification can be avoided completely, and a fall-back rule that only avoids the introduction of the pth .
This fall-back rule, which is only used if neither of the two rules introduced later in this section apply, translates ps ; th to [?
]pps .k(ps) [?]
(pps [?]
pps;th  ) U (pps [?]
pps;th  [?]
k(th)[pth -  pps;th !pps ) .
] [?]
This fall-back rule is also a preparation for the more powerful rules in the special cases where quantification over pps can also be avoided, as it uses the concept of implicitly expressing the existence of a reasonable representation of the second interval.
The right side of the until marks the situation at the chopping point: pps holds, but ceases to do so in the next position, and the chopping point needs to be within the interval identified by pps;th  .
pth has to coincide with pps;th  from the chopping point onwards (and cannot  ps).
The induction step for the pop operator is also simple: s; Iph , .
.
.
, Ipsfi , I|ps  ; k |=| ps =PL s; Iph , .
.
.
, Ipsfi ; k |= ps =IH s; Iph , .
.
.
, Ipsfi ; k |= k(ps) de f =k s; Iph , .
.
.
, Ipsfi , I|ps  ; k |= k(| ps) For the last equivalence, note that the leading | operator fi ).
(Hence, its prevents that the variable p|ps  occurs in k(ps valuation does not matter.)
We conclude the inductive proof with the induction step for the chop operator, using the abbreviations Ips;th  = [b, e[, Ips = [k, c], and Ith = [c, e[.
We then get: s; Iph , .
.
.
, Ips;th  ; k |= ps; th PL = [?
]c [?]
[k, e[.
s; Iph , .
.
.
, Ips;th  , Ips ; k |= ps and , I s; Iph , .
.
.
, Ips;th  th ; c |= th IH = [?
]c [?]
[k, e[.
s; Iph , .
.
.
, Ips;th  , Ips ; k |= k(ps) and s; Iph , .
.
.
, Ips;th , I  th ; c |= k(th) QLT L s; Iph , .
.
.
, Ips;th =  ; k |= [?
]pps , pth .
k(ps)[?]
(k(th) [?]
pps [?]
pth ) g(pps , pth , pps;th ) [?]
de f =k          s; Iph , .
.
.
, Ips;th  ; k |= k(ps; th).
Note that we have to adjust k(ph) if we are interested in the satisfiability or validity problem as there is no word s to start with.
If we are only interested in infinite models, we can replace all occurrences of pph by , if are interested only in finite models, we can use k(ph) [?]
(pph U !pph ), and if we want to allow for both we can use their disjunction.
B.
Complexity of Pop Logic Having established a linear translation of well formed PL formulas to equivalent QLTL formulas, we can re-use the decision procedures of QLTL to decide PL specifications.
We thus inherit the non-elementary decision procedures for the satisfiability and word problem of QLTL from [17].
Matching hardness results are inherited from the syntactic sub-logic ITL of PL.
Theorem 5.2: The satisfiability, word, and model checking problems for PL are non-elementary decidable, and hard for this class even if restricted to finite or infinite words.
Proof: With k, we have established a linear translation from PL to equivalent QLTL specifications.
We therefore inherit the non-elementary decision procedures of QLTL for    68  appear in k(ps)).
We can therefore check the correctness of k(th)[pth - pps;th  ] instead of k(th) at the chopping point and avoid the introduction of pth .
Unfortunately, no similarly general technique for the left side of a chop operation can exist, because this would apply a lower complexity of Pop Logic.
But the observation that the introduction of pth can be avoided allows us to concentrate on pps when seeking sub-languages in PSPACE.
Our focus is on cases where the chopping point itself can be guessed.
We can avoid the introduction of (and quantification over) pps if we can identify a suitable chopping point within the interval identified by pps .
The simplest case in which this ;th is possible is, of course, if pps does not occur in k(ps).
This is, for example, the case in the de-facto sub-language that resembles LTL.
But we can do more.
We call a sub-formulas ps long for an interval proposition p if it holds that, if ps holds if p identifies the non-empty interval [b, e[, then it holds if p identifies the interval [b, e [ for all e >= e. Likewise, we call a sub-formula ps short for an interval proposition p if it holds that, if ps holds if p identifies the non-empty interval interval [b, e[, then it holds if p identifies the interval [b, e [ for all b < e <= e. We call a sub-formula ps finite if the interval stack Iph , .
.
.
, Ipsfi under which ps is evaluated contains an interval Ith stemming from the left side of a chop sub-formula th; th of ph.
(Finite simply guarantees that the respective interval is finite; in the finite semantics, all sub-formulas are finite.)
There are simple sufficient conditions for formulas to be long or short.
In particular, a sub-formula is both long and short for pps if pps does not occur in the translation k(ps).
This holds, for example, for ps =| ps .
Also, atomic propositions are short and long, longness is preserved by next operations, and shortness and longness are preserved by positive boolean combination, and shortness and longness are toggled by negation.
(That is, !ps is long if ps is short and !ps is short if ps is long.)
We can use a simplifying translation for ps; th in two cases: if ps is both short and long, and if ps is finite and long.
If we can identify the first case (to which we give preference to have an unambiguous rule) by the rules above we can define k(ps; th) to   k(ps)[pps - pps;th pps;th ] [?]
 [?]
k(th)[pth - pps;th ] .
Finally, we call chop operators safe if the sub-formula they govern is not translated to a quantified formula by k, and left if, on the path from the root to this formula, only left turns were taken at every chop operator.
As usual, we call these formulas positive if they are bound by an even number of negations, and negative otherwise.
A first observation is that, provided all chop operators are safe, the discussed translation goes to LTL, providing for a PSPACE complexity.
Theorem 6.1: The PL subset where all occurring chops are safe is a sub-logic of PL that contains LTL as a de-facto syntactic subset.
It has a PSPACE-complete satisfiability, validity, word, and model checking problem.
Proof: In the formulas from the LTL fragment of PL all chop operations are safe and the translation of PL formulas where all chop operations are safe go to LTL.
(Which also implies that this subset is no more expressive than LTL.)
Note that the formula tree of the target formula is not necessarily polynomial in the size of the source specification, because the 'long & finite' case adds multiple occurrences of (pps;th  [?]
k(th)[pth - pps;th  ]) in the translation of a chop sub-formula ps; th.
However, if we represent the formula as a directed acyclic graph (DAG), then this blow-up does not occur: there are merely multiple edges pointing to the same node.
Hence, the number of sub-formulas stays linear in the size of the PL formula.
This also outlines a difference between PL and LTL that cannot be bridged: While the valuation of a sub-formula of an LTL formula is independent of its position in the formula tree, the valuation of sub-formulas in PL depend on the interval stack under which they are interpreted.
We therefore cannot safely assume that the valuation is similar unless they must refer to the same interval stack when evaluated.
(Which 1 = ps 2 .)
is the case for two sub-formulas ps1 and ps2 if ps We can extend the relative tractability to larger classes of languages: There is no need for the target formula to be in LTL.
If we are interested in the satisfiability or word problem, then it suffices to reside in prenex QLTL with only existential quantification.
Theorem 6.2: The PL subset where all occurring unsafe chops are positive left formulas is a sub-logic with a PSPACE-complete satisfiability and word problem.
Proof: It is easy to show by induction that, provided all unsafe chop operations in a PL formula ph are positive left formulas, the target formula k(ph) has a formula DAG where no quantifier is bound by a temporal operator and all quantifiers occur positively.
We can hence re-write k(ph) to prenex normal form by simply moving all quantifiers to the front, which does not affect the size of the formula DAG.
For formulas of this type, the satisfiability and word problem are the same as for LTL, because leading existential quantification does not affect them.
Consequently, the co-problems of the negation of these formulas are also in PSPACE.
The right conjunct requires that there is a chopping point such that th holds in the right interval.
(Where, again, pth and pps;th  coincide on that interval.)
Shortness and longness together imply that ps holds on the left interval if, and only if, it holds on the interval identified by pps;th  ; it is therefore safe to use this interval instead.
If k(ps) is long for pps and ps; th finite, we can use the well defined last possible chopping point--the last point where a = (pps;th  [?]
k(th)[pth - pps;th  ]) holds.
We set k(ps; th) = k(ps)[pps - a] [?]
a.
69  ITL, but also the classic temporal logic LTL, as syntactic sub-logics.
As a result, we think that PL provides a useful bridge between classic and interval temporal logics: It allows for using both logics individually for sub-problems, and yet provides a simple framework to treat these specifications.
It therefore allows for naturally integrating aspects expressed by interval temporal logic in a predominantly classic LTL specification, or, less often, LTL aspects in a predominantly ITL specification.
In addition, we have characterised a relatively inexpensive (PSPACE-complete) fragment of PL, which includes and extends LTL.
We consider the identification of such sub-logics useful, as they can guide a system analyst in devising her specification: When the expensive steps can easily be identified, the decision to keep the specification in the current form--and pay the price in form of increased complexity--or to invest more work in reformulating the specification can be made informed.
Corollary 6.3: The PL subset where all occurring unsafe chops are negative left formulas is a sub-logic with a PSPACE-complete validity, word, and model-checking problem.
VII.
E XTENDED P OP L OGIC The logic PL introduced in Section II extends the most basic version of ITL.
In order to reach the full expressiveness of regular and o regular expressions, we extend the widespread version of ITL with star to Extended Pop Logic (EPL) in this section.
This provides us with the following grammar: ph ::= p | !ph | ph [?]
ph |  ph | ph; ph | | ph | ph*  Like the chop operator, the star operator pushes new intervals in the stack.
We extend the well formedness to: there exists no node in the formula tree of ph such that strictly more pop operators than chop and star operators (counted together) occur on the way from the root of the formula tree to this node.
For the star operator, we use the following semantics:  ACKNOWLEDGEMENT Sven Schewe is supported by the Engineering and Physical Science Research Council (EPSRC) through the grant EP/H046623/1 'Synthesis and Verification in Markov Game Structures'.
Cong Tian is supported by the NSFC Grant No.
61003078, 91018010, and 60910004, 973 Program Grant No.
2010CB328102, and ISN Lab Grant No.
ISN1102001.
Both Sven Schewe and Cong Tian are corresponding authors.
s; I0 , .
.
.
, In , [b, e[; k |= ph* iff k [?]
[b, e[ and there exist m [?]
N integers k = r0 < r1 < ... < rm = e such that [?
]i [?]
[0, m[.
s; I0 , .
.
.
, In , [b, e[, [ri , ri+1 + 1[; ri |= ph.
Lemma 7.1: EPL can be embedded in QLTL.
Proof: To prove this, it suffices to extend the function k and Theorem 5.1 accordingly.
The extension is a straight forward generalization of the rules (and proof) for the chop, with the difference that we mark finally many intervals instead of marking exactly two.
Technically this can be done by guessing the fringes of the intervals (existential quantification) and showing that all intervals defined by these fringes are suitable (universal quantification).
Theorem 7.2: EPL is decidable with non-elementary complexity.
It can express exactly the regular and o-regular languages.
Proof: The non-elementary lower bound and the expressiveness of EPL can be inferred from the respective lower bounds and expressiveness of ITL [18], [19].
The decidability and upper bound on the complexity are implied by Lemma 7.1.
R EFERENCES [1] R. Alur, T.A.
Henzinger, and O. Kupferman.
Alternating-Time Temporal Logic.
Journal of the ACM 49(5): pages 672-713, 2002.
[2] M. Ben-Ari, Z.
Manna, and A. Pnueli.
The temporal logic of branching time.
Acta Informatica 20: pages 207-226, 1983.
[3] A. Chandra, J. Halpern, A. Meyer, and R. Parikh.
Equations between regular terms and an application to process logic.
Proceedings of the Thirteenth Annual ACM Symposium on Theory of Computing (STOC 1981).
pages 384-390, 1981.
[4] E. M. Clarke and E. A. Emerson.
Design and syntesis of synchronization skeletons using branching time temporal logic.
In Proceedings of the IBM Workshop on Logics of Programs (LP 1981).
pages 52-71, 1982.
VIII.
D ISCUSSION  [5] Z. Duan.
An Extended Interval Temporal Logic and A Framing Technique for Temporal Logic Programming.
PhD thesis, University of Newcastle Upon Tyne, May 1996.
We have introduced Pop Logic, an interval temporal logic that synthesises the concepts of classic and interval temporal logic.
Pop Logic extends ITL only very modestly by introducing a pop operation that revokes the scoping of a previous chop operation.
This modest extension preserves the most important property of ITL: Pop Logic remains simple and intuitive.
But while the extension is sufficiently modest to preserve this important property, it is powerful enough to include not only  [6] Z. Duan, M. Koutny, and C. Holt.
Projection in Temporal Logic Programming.
In Proceedings of Logic Programming and Automated Reasoning (LPAR 94).
pages 333-344, 1994.
[7] Z. Duan, C. Tian, and L. Zhang.
A Decision Procedure for Propositional Projection Temporal Logic with Infinite Models.
Acta Informatica, 45(1): pages 43-78, 2008.
70  A PPENDIX : E MBEDDING LTL IN P OP L OGIC In this appendix, we show the semantic equivalence of the LTL fragment of PL in the PL semantics and the common LTL semantics.
Note that, for this comparison, the bottom element of the stack is always o = [0, [?][.
The inductive proof below makes use of the flatness of the translation.
As induction basis, the following obviously holds for all atomic propositions (including ) p [?]
P:  [8] E. A. Emerson.
Temporal and Modal Logic.
Computer Science Department, University of Texas at Austin, USA, 1995.
[9] B. Finkbeiner and S. Schewe.
Coordination Logic.
In Proceedings of the 19th Annual Conference of the European Association for Computer Science Logic (CSL 2010).
pages 305-319, 2010.
[10] J. Halpern, Z.
Manna, and B. Moszkowski.
A hardware semantics based on temporal intervals.
In Proceedings of the tenth International Colloquium on Automata, Languages and Programming (ICALP 1983).
pages 278-291, 1983.  s; o; k |=PL p =PL p [?]
s(k) =LT L s; k |=LT L p. For the induction step, we have to cover boolean connectives, next, and until.
Boolean connectives and next are trivial: s; o; k |=PL ph[?
]ps s; o; k |=PL ph or s; o; k |=PL ps =PL s; k |=LT L ph or s; k |=LT L ps =IH =LT L s; k |=LT L ph [?]
ps, s; o; k |=PL !ph s; o; k |=PL ph =PL =IH s; k |=LT L ph =LT L s; k |=LT L !ph, and s; o; k |=PL ph s; o; k + 1 |=PL ph =PL =IH s; k + 1 |=LT L ph =LT L s; k |=LT L ph,  [11] D. Harel, D. Kozen, and R. Parikh.
Process logic: expressiveness, decidability, completeness.
Journal of Computer and System Sciences 2: pages 144-170, 1982.
[12] L. Lamport.
The Temporal Logic of Actions.
ACM Transactions on Programming Languages and Systems 16(3): pages 872-923, 1994.
[13] B. Moszkowski.
Reasoning about digital circuits.
Ph.D Thesis, Department of Computer Science, Stanford University.
TRSTAN-CS-83-970, 1983.
[14] B. Moszkowski.
Compositional reasoning about projected and infinite time.
In Proceeding of the First IEEE International Conference on Enginneering of Complex Computer Systems (ICECCS 1995), pages 238-245, 1995.
Finally, for the until we have:  [15] A. Pnueli.
The temporal logic of programs.
In Proceedings of the 18th IEEE Symposium on Foundations of Computer Science (FOCS 1977).
pages 46-57, 1977.  s; o; k |=PL ps U th     de f = U s; o; k |=PL !
; | !
| (ps [?]
th) ; | th   =PL [?
]l >= k.s; o, [k, l]; k |=PL !
; | !
| (ps [?]
th) and s; o, [l, [?
][; l |=PL | th  =PL [?
]l >= k.s; o, [k, l]; k |=PL ; | !
| (ps [?]
th) and s; o; l |=PL th =PL [?
]l >= k.
[?
]m [?]
[k, l].
s; o, [k, l], [k, m]; k |=PL  and s; o, [k, l], [m, l]; m |=PL | !
| (ps [?]
th) and s; o; l |=PL th =PL  [?
]l >= k.
[?
]m [?]
[k, l].
s; o, [k, l], [m, l]; m |=PL | !
| (ps [?]
th)s; o; l |=PL th =PL [?
]l >= k.
[?
]m [?]
[k, l].
s; o, [k, l]; m |=PL !
| (ps [?]
th) and s; o; l |=PL th =PL [?
]l >= k.
[?
]m [?]
[k, l].
s; o, [k, l]; m |=PL | (ps [?]
th) and s; o; l |=PL th = [?
]l >= k.[?
]m [?]
[k, l].
s; o, [k, l]; m |=PL | (ps [?]
th) and s; o; l |=PL th =PL [?
]l >= k.[?
]m [?]
[k, l].
s; o; m |=PL ps [?]
th and s; o; l |=PL th =PL [?
]l >= k.[?
]m [?]
[k, l].
s; o; m |=PL ps or s; o; m |=PL th and s; o; l |=PL th =IH [?
]l >= k.[?
]m [?]
[k, l].
s; m |=LT L ps or s; m |=LT L th and s; l |=LT L th = [?
]l >= k.s; l |=LT L th and [?
]m [?]
[k, l[.
s; m |=LT L ps =LT L s; k |=LT L ps U th.
[16] T. Schlipf, T. Buechner, R. Fritz, M. Helms, and J. Koehl.
Formal verification made easy.
IBM Journal of Research and Development, 41(4-5): pages 567-576, 1997.
[17] A. P. Sistla.
Theoretical issues in the design and verification of distributed systems.
PhD thesis, Harvard University, 1983.
[18] C. Tian and Z. Duan.
Complexity of propositional projection temporal logic with star.
Mathematical Structures in Computer Science 19(1): pages 73-100, 2009.
[19] C. Tian and Z. Duan: Expressiveness of propositional projection temporal logic with star.
Theoretical Computer Science 412(18): pages 1729-1744, 2011.
[20] M. Y. Vardi: Branching vs.
Linear Time: Final Showdown.
In Proceedings of the Seventh International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS 2001).
pages 1-22, 2001.
[21] M. Vardi and P. Wolper.
Automata Theoretic Techniques for Modal Logics of Programs, Journal of Computer and System Sciences 32(2): pages 183-221, 1986.
[22] P. L. Wolper.
Temporal logic can be more expressive.
Information and Control, 56(1/2): pages 72-99, 1983.
71
Combining Simultaneous Values and Temporal Data Dependencies Avigdor Gal & Dov Dori Information Systems Engineering Department Faculty of Industrial Engineering and Management Technion - Israel Institute of Technology Haifa, 32000, Israel  Abstract  In temporal databases there are situations where multiple values of the same data item have overlapping validity times.
In addition to the common case of multi-valued properties, there are several possible semantics to multiple values with overlapping validity times of the same data item.
We refer to such data items as having simultaneous values.
This paper presents a polynomial algorithm for ecient handling of simultaneous values in a database with temporal data dependencies|integrity rules that dene relationships among values of dierent data items in a temporal database.
The algorithm is demonstrated using a case study from the game theory area.
An implementation of the algorithm is integrated in a prototype of a temporal active database.
keywords: temporal databases, simultaneous values, uncertainty, temporal data dependencies, action reasoning  1 Introduction and Motivation  A temporal database is a database that supports some aspects of time [5].
One of the basic temporal aspects supported by many temporal databases is the valid time, representing the time a data-item is considered to be true in the modeled reality [5].
There are situations where multiple values of the same data-item have overlapping valid times.
The multi-valued property is the most common case, where several values are grouped into a single property [4].
For example, a property that contains the languages that a person speaks, can have a set of values grouped into a single property.
There are situations, however, where multiple values with overlapping valid times of the same data-item exist in the database, but with dierent semantics than the multi-valued case.
We refer to these data-items as having simultaneous values.
While in the multi-valued case all values whose valid time include t are deemed to be valid in the modeled reality, it is possible that only part of the candidate values, i.e.
the values that were assigned to a data-item at time t, represent the data-item's value in the real world.
For example, a data-item that contains a spouse name is limited by law to be single The work was conducted while the author was in the Technion.
He is currently at the Department of Computer Science, University of Toronto, Toronto, Ontario, M5S 3H5 CANADA.
valued.
When there are several alternatives for the spouse name due to uncertain information, then only one value of the set is the data-item's value.
Each value of the set is possibly the data-item's value.
In temporal databases, change of decisions about the value and valid time of a data-item may cause a situation where two values of the same data-item have overlapping valid times.
For example, a value val1 valid during [Jan 1994, Mar 1994) of a data-item  is augmented at time point Aug 1993 by a value val2 valid during [Feb 1994, Apr 1994).
 has more than one value in the interval [Feb 1994, Mar 1994).
In some cases, the value that was inserted later corrects an erroneous value that was inserted earlier.
In other cases, both values are possibly correct, each with respect to a dierent time point.
Simultaneous values enable dierent semantics in mapping the stored values to the modeled reality values.
It is particularly useful in applications where a data-item may have multiple values representing the existence of dierent alternatives.
For example, if knowledge arrives from various sources, then no apriori selection of a single value should be enforced.
Instead, for each database retrieval operation, the user can choose the appropriate value, values or any aggregation of those values.
Handling simultaneous values in a temporal database requires the use of optimized update and retrieval mechanisms.
The maintenance problem of simultaneous values becomes more arduous in temporal active databases [2], where temporal data dependencies are enforced.
A temporal data dependency is a tool that supports rules for manipulating data-items which may have a variety of temporal characteristics.
Temporal data dependencies can be viewed as a type of integrity rules of the temporal active database.
Violating them, activates database operations that react to restore the database integrity.
As an example for the use of temporal data dependencies, we can consider decision support systems [3]|systems that model decisions about actions that should be performed in a target system.
Such systems consist of decision models that are rooted in the operations research or articial intelligence disciplines, and of a database, that stores the necessary data to support the decision models.
Decision support systems can benet signicantly from the temporal active paradigm.
As a concrete motivating case study, we present the following application of a decision support system, based on the Cournot game [7]; [1].
Three instant coffee manufacturers|Bilbo, Frodo and Gandalf, decide each month about the quantity of coee to be produced in the next month.
Each manufacturer bases the decision about its manufactured quantity upon estimation of the quantities manufactured by the other two manufacturers, its own strategy (maximum revenue, a certain market share, etc.
), and general knowledge about the market behavior.
Each manufacturer has its own deadline for making the production quantity decision.
We assume a single market price for the manufactured type of instant coee, which is determined periodically as a function of the total quantity produced in that period.
The relationships between the market price and the total quantity is modeled by the constraint Total ?
Quantity  Market ?
Price = Market ?
Constant (1) Each manufacturer attempts to estimate the best decision to be taken, based on its own competition strategy and the two competitors' decisions and competition strategies.
For example, Bilbo may assume that Frodo and Gandalf have an objective of maximum prot. Consequently, each manufacturer would like to produce as much coee as possible without lowering the price to a level that decreases its total prot. By assuming the competition strategy of both Frodo and Gandalf, Bilbo can estimate their production decisions and determine the optimal production level, based on the following temporal data dependency: Production-Decision q Market-Constant :=  Competitors-Total-Estimation ?
Unit-Cost Competitors-Total-Estimation  This temporal data dependency is a periodical result of maximizing the prot function of a single manufacturer.
The derivation of the temporal data dependency is given in Appendix A.
Other strategies would yield dierent temporal data dependencies.
Competitors-Total-Estimation is the sum of the production estimations of the other two manufacturers.
Since this information is often misleading, each manufacturer should collect as much estimations as possible on each one of the competitors.
The temporal dependency graph can be evaluated each time there is a change in one of the data-items MarketConstant, Competitors-Total-Estimation or the manufacturer's Unit-Cost.
Alternatively, it can be evaluated once each period, just before the manufacturer has to decide about the quantity to be produced for the following period.
Figure 1 presents the data over time of the dataitems Market-Constant, Competitors-Total-Estimation, Unit-Cost, and the resulting Production-Decision of Bilbo.
As the gure shows, the temporal validity of each value is bounded.
For example, Market-Constant has the value 10000 during the interval [Feb 94, June 94).1 The resulting values of Production-Decision are 1  We use a single month granularity, hence this interval is  Market Constant  10000 9500 9000 Feb 94  June 94  Sep Oct Dec Feb Apr 94 94 94 95 95  Aug 95  t  Aug 95  t  Aug 95  t  Aug 95  t  630  Competitors Total Estimations  600 570 540 Feb 94  June 94  Sep Oct Dec Feb Apr 94 94 94 95 95  Unit Cost  7 6 Feb 94  June 94  Sep Oct Dec Feb Apr 94 94 94 95 95  405 400  Production Decision  385 380 375 316 293  Feb 94  June 94  270  Sep Oct Dec Feb Apr 94 94 94 95 95  Figure 1: Exemplary data of Bilbo in the coee manufacturers case study valid during the time intervals as computed using all data-items that determine Production-Decision and shown in the bottom graph of Figure 1.
For example, a Market-Constant of 10000, a CompetitorsTotal-Estimations of 600, and a Unit-Cost of 6, yield a Production-Decision of 400.
Since during the interval [Jan 94, June 94), the value of Market-Constant is 10000, Competitors-Total-Estimations is either 600 or 570, and Unit-Cost is 6, Production-Decision in that interval is either 400 or 405.
As Figure 1 demonstrates, the number of values and their associated temporal intervals resulting from the computation of a single temporal data dependency may be very large.
These values are a subset of the Cartesian product of all the possible values of each data-item.
A naive approach would consider all the possible combinations in the Cartesian set (342=24 combinations in the example of Figure 1), yielding an algorithm with high time complexity.
However, due to the bound temporal validity of values, usually only a small subset of the combinations in the Cartesian set should be considered.
For example, in Figure 1 only interpreted as all the days from February 1, 1994 to May 31, 1994 (June 1, 1994 is not included).
A time interval is dened in [5] as \the time between two insatnces" and can be represented as either close or semi-open intervals.
8 combinations out of the 24 possible ones should be considered.
This work presents an algorithm that eciently computes temporal data dependencies.
Our approach for ecient evaluation of temporal data dependencies is based in part on previous works on computing temporal aggregates, including [8] and [6].
An aggregate function, such as selecting the minimumvalue of a set, is applied to a set of values (e.g.
relations in the relational database model) and yields a scalar value.
In temporal databases, the aggregate function is, in general, time dependent, i.e.
the result of the aggregate function is applied to a set of values, each possibly having a dierent temporal validity.
The calculation of temporal data dependencies is an extension of aggregate computing with temporal grouping, where the resulting values are grouped by time.
To carry out such calculation, it is necessary to know which values have overlapping validity intervals, and to consider each value in its own validity interval.
The approach proposed in [8] rst determines constant intervals as intervals within which there is no change in the data-item value.
It then selects tuples that overlap each of these constant intervals and calculates the result.
The work in [6] is based on a tree data structure for the time axis partition.
Extending these approaches to solve the problem of evaluating temporal data dependencies, we present a polynomialalgorithm for ecient evaluation of temporal data dependencies with simultaneous values.
The computation is not necessarily an aggregate operation that involves a single type of data-item with several values.
Rather, it is a formula that may involve several types of data-items, each of which may consist of simultaneous values.
The algorithm constructs a list sorted according to the time validity of data-items values, and then calculates the result as a function of the values in the list elements.
Section 2 presents the algorithm for calculating temporal data dependencies with simultaneous values, while the properties of the algorithm are discussed in Section 3.
2 Evaluation of temporal data dependencies with simultaneous values  In this section we provide an outline of the algorithm for evaluating temporal data dependencies with data-items that consist of simultaneous values.
The algorithm consists of two phases, namely generating a constant interval list and computing the value for each combination of each constant interval element, as follows.
The constant interval list is sorted by the starting time points of the constant intervals.
The algorithm generates a partition of the valid time interval within which the temporal data dependency is to be determined.
Each element of the constant interval list has a valid time , and it consists of all the values whose validity covers .
Initially, a constant interval element is generated s , te ), where ts and with a valid time interval of [t te are the start and end time points of the interval within which the temporal data dependency is to be  evaluated, respectively.
Each value is processed with respect to an interval that consists of its starting time point, as follows.
Let [ts , te ) be a valid time interval of a value val, and [tis , tie ) a constant time interval associated with a constant interval element cii .
If [ts, te )\[tis, tie )6= ;, then there are six possible relationships between [ts , te ) and [tis, tie ), which are listed below along with the corresponding actions taken by the algorithm.
1. ts = tis and te < tie : replace cii with two constant interval elements, ci with [ts , te ) and ci with [te, tie ).
ci and ci receive the values of cii , and val is added to ci .
2. ts = tis and te = tie: add val to cii .
3. ts = tis and te > tie: add val to cii , and process val again with a valid time of [tie , te ).
4. ts > tis and te < tie : replace cii with three constant interval elements, ci with [tis, ts), ci with [ts , te ) and ci with [te, tie ).
ci , ci and ci receive the values of cii , and val is added to ci .
5. ts > tis and te = tie : replace cii with two constant interval elements, ci with [tis, ts ) and ci with [ts, te ).
ci and ci receive the values of cii , and val is added to ci .
6. ts > tis and te > tie : replace cii with two constant interval elements, ci with [tis, ts ) and ci with [ts, te ).
ci and ci receive the values of cii , and val is added to ci .
In addition, process val again with a valid time of [tie, te ).
As an example of the activation of the rst part of the algorithm, consider the data set of Figure 1, and assume that the interval within which the temporal data dependency is to be evaluated is [Feb 94, Aug 95).
The initial element of the list would be h[Feb 94, Aug 95), Market-Constant=, Competitors-TotalEstimations=, Unit-Cost=i.
The market-Constant values were processed rst, then the CompetitorsTotal-Estimations values, and nally the Unit-Cost values.
The full constant interval list is presented in Figure 2.
To enhance comprehension, the gure presents all the elements that were generated throughout the process, in a form of a tree.
Each node in the tree (except the root node) is an element of the list that was generated as a result of processing a value.
A value at the bottom of a node represents the value whose processing resulted in splitting the node.
The nal Constant Interval List (CIL) is the set of all leaf nodes of the tree, represented in Figure 2 by bold rectangles.
All other nodes were deleted during the process.
The Production-Decision values, shown in Figure 1, are shown within the constant interval rectangles in Figure 2.
0  0  00  00  0  0  00  0  00  00  0  0  00  0  00  00  00  0  00  00  Constant interval: Market Constant: Competitors Total Estimation: Unit Cost: 10000  Constant interval: Market Constant:  Constant interval: 10000  Market Constant:  Competitors Total Estimation:  600, 570  Competitors Total Estimation:  Unit Cost:  6  Unit Cost:  9500  Constant interval:  Constant interval: Market Constant:  Market Constant: 9000  9500  Competitors Total Estimation:  Competitors Total Estimation:  Unit Cost:  Unit Cost:  600  Constant interval:  540  Constant interval:  Constant interval:  Constant interval:  Market Constant:  9500  Market Constant:  Market Constant:  9000  Market Constant:  9000  Competitors Total Estimation:  600, 570, 540  Competitors Total Estimation:  Competitors Total Estimation:  540, 630  Competitors Total Estimation:  630  Unit Cost:  Unit Cost:  Unit Cost:  6  9500  7  Unit Cost:  7  570  Constant interval: Market Constant:  3 Algorithm properties  Constant interval:  9500  This section discusses the algorithm complexity (Section 3.1) and the correctness of the algorithm (Section 3.2).
Market Constant: 9500  Competitors Total Estimation:  570, 540  Competitors Total Estimation:  Unit Cost:  6  Unit Cost:  540  6  Constant interval:  94).
The next constant interval element is scanned, and the same combination is found.
Therefore, the valid time of the combination is set to be [June 94, Oct 94).
The same combination is found again in the subsequent constant interval element, and the valid time of the combination is set to be [June 94, Dec 94).
At this point, the process is terminated since the following constant interval element does not consist of this combination.
The result of the second phase of the algorithm, applied on the data set of Figure 1 is the set of values of Production-Decision, which are also shown in Figure 1.
After deciding on the appropriate interval, the values are used for calculating the derived value for that interval.
For example, in the previous example, the derived value is calculated to be 385, valid during [June 94, Dec 94).
Constant interval:  Market Constant:  9500  Market Constant:  9500  Competitors Total Estimation:  540  Competitors Total Estimation:  540  Unit Cost:  6  Unit Cost:  7  Figure 2: The constant interval list (CIL) generation process A single constant interval element may consist of more than a single value for a data-item.
For example, the constant interval element with the constant interval [Feb 94, June 94) in Figure 2 has two sets of values: h10000, 600, 6i, and h10000, 570, 6i.
Each such set of values is a dierent combination for the calculation of the temporal data dependency, giving rise to a dierent value for the same interval.
The constant interval list may also be over split with respect to a combination, i.e.
it may have consecutive constant interval elements with identical sets of values.
For example, all the constant interval elements with the constant intervals [June 94, Sep 94), [Sep 94, Oct 94), and [Oct 94, Dec 94) consist of the combination h9500, 540, 6i.
This is a result of several overlapping values of the same data-item.
In this case, [June 94, Sep 94) and [Sep 94, Oct 94) are separate constant intervals, since the value 600 of CompetitorsTotal-Estimation is valid only during [June 94, Sep 94).
The second phase of the algorithm uses each of the possible value combinations in the constant interval elements to compute the new values.
The combinations are scanned for each constant interval element, starting from the constant interval element with the minimal valid time.
Subsequent constant interval elements are scanned to nd identical combinations.
If an identical combination is found, the valid time of the constant interval element is added to the valid time of the combination.
This process is repeated until no more identical combinations can be found.
For example, consider the example given in Figure 2.
The combination h9500, 540, 6i is selected from the constant interval element with the valid time of [June 94, Sep  3.1 Complexity  Let n be the number of processed values.
A value with a valid time interval of [ts, te ) can add two constant interval elements at the most, if for a constant interval element cii , ts > tis and te < tie , or if there are two constant interval elements cii and cij such that ts > tis and te < tje .
Consequently, if the number of processed values is n, then the upper bound on the number of constant interval elements is 2n.
For each value, the location of the rst constant interval element to be processed is searched.
This search is bounded by log2(2n).
In the worst case, a valid time of a value covers the valid times of all of the constant interval elements, resulting in 2n comparisons.
Hence, the time complexity of the CIL generation phase is bounded by O(n(log2 (2n) + 2n)) =O(n2 ).
The time complexity of the second phase of the algorithm is bound by O(m3 ), where: m is the number of all the valid combinations of a single value from all the data-items, i.e.
all the combinations for which values have valid time overlapping.
For example, in Figure 1, m=8 and the eight combinations are: h10000, 600, 6i, h10000, 570, 6i, h9500, 600, 6i, h9500, 570, 6i, h9500, 540, 6i, h9500, 540, 7i, h9000, 540, 7i, h9000, 630, 7i.
2n is the maximal number of constant interval elements.
for example, 18 is the maximal number of constant interval elements in Figure 1 since the number of state-elements is 9.
However, The actual number of constant interval elements is 7, as shown in Figure 2.
2mn is the maximal number of possible combinations in the list.
The algorithm generates all of the list combinations (2mn).
At each iteration of the algorithm, a single combination is processed.
The worst case is when at each iteration all the remaining combinations are scanned.
Thus, the worst case complexity is O(m2 n).
Since at each  constant interval element there is at least one combination, m  n. Therefore, the worst case complexity is bounded by O(m3 ).
From the discussion above we can conclude that the worst case complexity of the two phases of the algorithm is bounded by O(m3 ).
3.2 Correctness  Proposition 1 The partition of the time interval:  The entire set of constant interval elements constitute a partition of the evaluated interval.
The proof of Proposition 1 is done using induction on the number of constant interval elements.2 At each iteration we verify that each of the six possible relationships between a valid time of a value and a constant interval element results in a new constant interval list that maintains the partition assertion.
This proposition ensures the correctness of the list construction phase, where each value should allocate a single constant interval element.
Proposition 2 Algorithm correctness: The algorithm generates a correct result.
Given a set of values and a temporal data dependency, a correct result ensures that for each combination of values with overlapping valid times there is a value which is the result of applying the temporal data dependency on this combination, and its valid time consists of the intersection of the overlapping valid times of the values in the combination.
A simple algorithm, in which each combination of the Cartesian product is evaluated, can achieve a correct result but at a high computational cost.
The proof of Proposition 2 shows that if a combination is not processed by the algorithm, then it should not be in the resulting set.
4 Conclusion and future research  We have proposed an algorithm for ecient evaluation of temporal data dependencies in temporal databases with simultaneous values.
The algorithm consists of two phases, the rst generates a constant interval list and the second computes the value for each combination of each constant interval element.
A single constant interval element may consist of more than a single value for a data-item.
The constant interval list may also be over split with respect to a combination, i.e.
it may have consecutive constant interval elements with identical sets of values.
The time complexity of the calculation algorithm is bound by O(m3 ), where m is the number of all the valid combinations of a single value from all the data-items.
This result is less expensive, computation wise, than the 2 Full denitions and proofs of propositions in this paper can be obtained via anonymous ftp to ftp.technion.ac.il under directory/usr/local/servers/ftp/pub/supported/ie.
The le is called proofs.tex.
It is produced using LaTEX.
The proofs can also be obtained through the author's WWW home page, http://www.cs.toronto.edu/avigal.
result of scanning the Cartesian product (O(ni=1 mi ), where mi is the number of values of the i-th dataitem and n is the number of data-items involve in the calculation.
A prototype of a system that implements the algorithm exists on the basis of MAGIC 5.6 for DOS, under DOS 6.2.
Further research is aimed at a more general form of temporal data dependencies, where the valid time is dened indirectly through constraints, or relative to other time points.
References  [1] A. Cournot.
Researches into the Mathematical Principles of the Theory of Wealth.
Macmillan, New York, N.Y., 1897.
[2] O. Etzion, A. Gal, and A. Segev.
Temporal active databases.
In Proceedings of the International Workshop on an Infrastructure for Temporal Database, June 1993.
[3] K.M.
Van Hee, L.J.
Somers, and M. Voorhoeve.
A modeling environment for decision support systems.
Decision Support Systems, 7:241{251, 1991.
[4] R. Hull and R. King.
Semantic database modeling: Survey, application and research issues.
ACM Computing Surveys, 19(3):201{260, Sep 1987.
[5] C.S.
Jensen, J. Cliord, S.K.
Gadia, A. Segev, and R.T. Snodgrass.
A glossary of temporal database concepts.
ACM SIGMOD Record, 21(3):35{43, 1992.
[6] N. Kline and R.T. Snodgrass.
Computing temporal aggregates.
In Proceedings of the International Conference on Data Engineering, pages 223{231, Mar 1995.
[7] J. Tirole.
The Theory of Industrial Organization.
the MIT press, 1989.
[8] P.A.
Tuma.
Implementing historical aggregates in TempIS.
Master thesis.
Wayne State University, Nov. 1992.
Appendix A: The production decision temporal data dependency In this section we present the derivation of the temporal dependency graph given in Section 1.
The following notation is used: A  Prot B  Revenue C  Cost D  Market-Price E  Fixed-Cost F  Unit-Cost G  Market-Constant H  Total-Quantity I  Competitors-Total-Estimation X  Production-Decision We assume that Bilbo's strategy is to produce the amount that would maximize A, as follows.
A = B?C= X  D ?
(E + X  F) = X G H ?
(E + X  F) = X  X G+ I ?
(E + X  F) max (A) =) A0 = 0 =) G  (X(X+ +I) I)?2 X  G ?
F = 0 2 =) G  (X + I) ?
(XX + GI)?2 F  (X + I) = 0 =) F  X2 + 2  F  I  X + F  I2 ?
G  I = 0 p ?
2  F  I  4  F2  I2 ?
4  F  (F  I2 - G  I) =) X = = 2F qG  I ?I F  X is non-negative.
q  =) X = max( GF I ?
I, 0)
2011 Eighteenth International Symposium on Temporal Representation and Reasoning  Temporal Functional Dependencies Based on Interval Relations Pietro Sala Department of Computer Science University of Verona Verona, Italy Email: pietro.sala@univr.it  Carlo Combi Department of Computer Science University of Verona Verona, Italy Email: carlo.combi@univr.it  Abstract--In the last years the representation and management of temporal information has become crucial for several computer applications.
In the temporal database literature, every fact stored into a database may be equipped with two temporal dimensions: the valid time, that describes the time when the fact is true in the modeled reality, and the transaction time, that describes the time when the fact is current in the database and it can be retrieved.
Temporal functional dependencies (TFDs) add (transaction) valid time to classical functional dependencies (FDs) in order to express database integrity constraints over the flow of time.
Currently, proposals dealing with TFDs adopt a point-based approach, where tuples hold at specific time points.
Moreover, TFDs may involve the use of different granularities (i.e., partitions of the time domain), to express integrity constraints as "for each month, the salary of an employee depends only on his role".
At the best of our knowledge, there are no proposals dealing with interval-based temporal functional dependencies (ITFDs for short) where the associated valid time is represented by an interval.
In this paper, we propose a set of ITFDs based on the Allen's interval relations, we analyze their expressive power with respect to other TFDs proposed in the literature and we propose an algorithm for verifying ITFDs in a database system.
last 8 hours").
Moreover, very often in our natural language descriptions two different time intervals are linked together by some relation ("during the flight from Venice to Lubeck I red a nice book").
Moving back from the real world to the enchanted land of temporal databases, it appears reasonable to analyze in which context the interval representation of time may result useful, if not mandatory in some case, for representing constraints over the possible evolutions of our data.
In this paper, we propose a family of TFDs based on the Allen's interval relations [7] called Interval TFDs (ITFDs for short) and analyze their expressiveness by means of a simple example extracted from the clinical domain.
Moreover we show that verifying whether a temporal database satisfies a given ITFD can be done in O(n log n) (basically the cost of sorting the endpoints of the intervals involved).
The paper is organized as follows.
In Section II we give a short description of the literature on temporal functional dependencies.
In Section III we introduce an example based on a real world scenario, the management of medical data in our case, that will be useful through the following sections, to give an idea of how TFDs and ITFDs work.
In Section IV we introduce Interval Temporal Functional Dependencies and analyze their expressiveness.
Section V describes a family of new algorithms for evaluating in an efficient way Interval Temporal Functional Dependencies over a temporal database.
Finally, Section VI provides some concluding remarks and discusses further extensions of the current work.
I. I NTRODUCTION Temporal functional dependencies (TFDs) add a temporal dimension to classical functional dependencies (FDs) to deal with temporal data [1]-[5] (as a matter of fact, two temporal dimensions have been considered only in [6], where standard FDs are evaluated at every database snapshot).
As an example, while FDs model constraints like "employees with the same role get the same salary", TFDs can represent constraints like "for any given month, employees with the same role have the same salary, but their salary may change from one month to the next one" [1], [4] or "current salaries of employees uniquely depend on their current and previous roles" [2].
To the best of our knowledge all the TFDs proposed in literature, including the ones cited above, rely on some point-based semantics or, like in the case of granularities, on some fixed point-based temporal grouping.
On the other side, in a real world setting we are used to conceive time more like arbitrary intervals with a starting and an ending point in place of isolated time instants (e.g.
"my flight from Venice to Lubeck will take off at 10 o'clock and it will 1530-1311/11 $26.00 (c) 2011 IEEE DOI 10.1109/TIME.2011.15  II.
R ELATED WORK In this section we first introduce two contributions, one from the temporal database area and another from the AI area, dealing with some semantic issues when associating data to intervals; then, we provide a short overview of the main formalisms for TFDs proposed in the literature.
A. Interval-based semantics In [8] Terenziani and Snodgrass analyze the inadequacy of point-based semantics concerning models of natural language.
They propose a dichotomy between two types of fact.
Facts are partitioned in two classes, the telic ones (from the Greek "telos" meaning goal) and the atelic ones 23  2010" is a granule of the granularity Month).
A database schema R is extended to a temporal module schema which is a triple (R, G, ph), where G is a granularity and ph is a function, called time windowing function, that associates every tuple with the granules in G where the tuple is valid.
Bettini, Jajodia, and Wang's TFDs allow one to specify conditions on tuples associated with granules of a given granularity and grouped according to a coarser granularity.
A general formalism for TFDs on complex (temporal) objects has been proposed by Wijsen in [4].
It is based on a data model that extends the relational model with the notion of object identity, which is preserved through updates, and with the ability of dealing with complex objects, that is, objects that may have other objects as components.
The time domain is assumed to be (isomorphic to) N. A time relation is a subset of N [?]
N. A time granularity can be defined as a special case of time relation, called chronology.
For example, the granularity Month can be defined as the smallest set of pairs (i, j), where i and j belong to the same month and i <= j. Wijsen TFDs are written as c : X -a Y and can be intuitively explained as follows.
Let t1 and t2 be two objects of class c at time points i and j, respectively, where (i, j) belongs to the time relation a.
If t1 and t2 agree on X, then they must agree on Y as well.
It is not difficult to show that the class of Wijsen's TFDs subsumes the class of Bettini et al.
's TFDs.
More precisely, Bettini et al.
's TFDs are exactly all and only the TFDs on chronologies (the class TFD-C in Wijsen's terminology).
In an earlier work, Wijsen introduces a special notation for some relevant subclasses of TFDs [3].
In particular, he abbreviates X -next Y as XNY and for X -F orever Y as XGY .
Wijsen's TFDs allow one to specify conditions on tuples grouped according to any given time relation.
In [2] Vianu proposes a simple extension to the relational model in order to describe the evolution of a database over time.
According to it, a temporal database is viewed as a sequence of instances (states) over time.
A change in the state of the database is produced by the execution of an update, an insertion, or a deletion.
A database sequence is a sequence of consecutive instances of the database, together with "update mappings" from one instance (the "old" one) to the next instance (the "new" one).
Tuple are viewed as representations of domain objects.
Properties of the evolution of objects over time are expressed by "dynamic" dependencies (DFDs), which are defined by means of "action relations" associated with updates.
Intuitively, an action relation is generated by concatenating each tuple in the "old" instance with its updated version.
(the Greek 'a' as a prefix indicates negation).
Telic events are characterized by the fact that they reach a culmination (e.g., "John won the lottery") while atelic facts do not have an intrinsic culmination (e.g., "John is building an house").
Moreover, in [8] Terenziani and Snodgrass propose an algebraic framework which deals with combinations of telic and atelic facts and they show how to add these concepts to a temporal query language (SQL/Temporal [9]).
In [10] Shoham proposes a first order logic for dealing with the truth of propositions among intervals.
In particular, the author observes that the truth of a proposition over an interval is related to its truth over other intervals.
The author classifies propositions depending on the relations that have to be considered in order to determine their truth.
A proposition type x is downward-hereditary (written | x) if whenever it holds over an interval it holds over all of its sub-intervals, possibly excluding the two endpoints: for instance, "John played less than fourty minutes" is downward-hereditary.
Symmetrically a proposition type x is upward-hereditary (written | x) if whenever it holds over all the sub-intervals of a given interval, possibly excluding the two endpoints, it also holds over the given interval itself: for instance, "The airplane flies at 35000 feet" is upward-hereditary.
A proposition type x is liquid (written fi x) if it is both downward-hereditary and upward-hereditary (e.g.
the room is empty).
A proposition type x is concatenable if whenever it holds over two consecutive intervals it holds also over their union, for instance the proposition "John travelled an even number of miles".
A proposition type x is gestalt if whenever it never holds over two intervals one of which properly contains the other, for instance the proposition "Exactly six minutes passed" is gestalt.
A proposition type x is solid if whenever it never holds over two properly overlapping intervals; for instance, the proposition "The plane executed the LANDING procedure (from start to finish)" is solid.
As we will see in the following, some interesting properties that can be expressed using Shoham's proposition types cannot be captured by a point-based formalism.
B.
A quick tour in Temporal Functional Dependencies In this section we illustrate the most important (pointbased) temporal functional dependencies proposed in the literature.
In [6], [11] Jensen et al.
propose a bitemporal data model that allows one to associate both valid and transaction times with data.
The basic atomic entity of Jensen's TFDs is the so called bitemporal chronon which is an ordered pair consisting of a valid time and of a transaction time.
The schema of atemporal attributes is extended with a bitemporal chronon.
Jensen et al.
's TFDs make it possible to express conditions that must be satisfied at any (bitemporal) time point taken in isolation.
Bettini, Jajodia, and Wang's notion of TFD takes advantage of time granularity [12], [1].
Examples of granularities are Day, Month, and WorkingDay; a granule is an element of a given granularity (e.g.
"November  III.
A MOTIVATING EXAMPLE In the following we propose a little example of expressivity of the TFDs described in section II and we show an interesting constraint that cannot be expressed through pointbased TFDs.
24  # 1 2 3 4 5 6 7 8 9 10  Therapy antiviral analgesics cardiovascular antipyretics sedative anxiolytic antiviral cardiovascular analgesics antiviral  PatId 1 1 1 1 1 1 2 2 2 2  Phys Dorian Cox Turk Cox Turk Cox Kelso Quinlan Reid Reid  Drug acyclovir paracetamol atenolol paracetamol diazepam diazepam acyclovir atenolol paracetamol acyclovir  Qty 300 200 100 100 10 10 200 100 150 300  B 1 2 3 9 13 17 1 4 5 9  E 16 10 8 11 15 19 10 7 9 14  Dorian  PatId=1  Cox  Turk Cox  Turk  1  2  3  4  5  Cox  6  7  8  9 10 11 12 13 14 15 16 17 18 19  Quinlan  Reid  PatId=2  Reid Kelso  Figure 1.
An instance s of the relation P atient, storing data about therapies.
Most health care institutions collect a large quantity of clinical information about patients and physician's actions, such as therapies and surgeries, as well as about health care processes, such as, admissions, discharges, and exam requests.
All these pieces of information are temporal in nature and the associated temporal dimension needs to be carefully considered, in order to be able to properly repre- sent clinical data and to reason on them.
In this section, we briefly introduce a real-world example taken from clinical medicine, namely that of patient therapies.
Suppose to have patients which undergo several and different therapies: each therapy can be supervised by a physician, and consists of the administration of some drug to the patient.
Information about patients and therapies are stored in a relational schema P atient = (Therapy, PatId , Drug, Qty, Phys, B , E ), where Therapy identifies a medical treatment, PatId represents fa patient ID, Drug and Qty the drug prescribed and its quantity, respectively, and Phys the physician who made the prescription (and is responsible of the therapy).
Finally, attributes B and E represent the starting and ending time points of the tuple validity interval, respectively: they represent the bounds of the interval specified by the physician for each therapy.
An instance of relation Patient is provided in Figure 1.  want to change the quantity of that drug for the given patient.
It is worth to notice that this kind of constraints cannot be expressed by the Bettini, Jajodia, and Wang's TFDs, since every granule cannot overlap another one.
Finally, the requirement:"the new quantity for a drug depends only on the old quantity" may be captured by Vianu's DFDs.
Let us suppose that our database has to respect the following constraint.
Example 1.
The policy of the hospital is the following: 1) every patient may receive several therapies at the same time from different physicians; 2) overlapping therapies for the same patient must be prescribed by the same physician (in other words, if a patient during a therapy needs another therapy which lasts after the end of the current therapy, then this therapy must be prescribed by the current physician).
It is easy to see that in order to ensure this condition both the starting points and the ending points of every pair of tuples come into play.
Thus, the point-based TFDs proposed in Section II-B cannot be used to specify the above requirement related to the hospital policy.
IV.
I NTERVAL - BASED F UNCTIONAL D EPENDENCIES In this section we propose a new type of temporal functional dependency based on Allen's interval relations.
As an example, on this relation the requirement "at any time, the quantity of the prescribed drug depends on the type of drug and on the current therapy" can be expressed by Jensen's TFDs, while the requirement "every month, the physician who prescribes a given drug depends on the therapy " may be captured by Bettini, Jajodia, and Wang's TFDs.
Moreover, it is possible to express by Wijsen's TFDs the requirement " for every patient, the quantity of a drug cannot change within 16 days": it means that we have to wait for 16 days without prescribing a drug to a patient, if we  A. Interval relations Given a linear order O = O, <	, an interval I over O is a pair I = [b, e] where b, e [?]
O and b <= e. Given an interval I = [b, e] over O we identify with points(I) the set of points in O between b and e: points(I) = {p | p [?]
O and b <= p <= e}.
While the possible distinct relations between two points considering only the linear order are reduced to three (equality, successor, and predecessor), considering the order among the two endpoints of two intervals leads us to have  25  I6  value and w, t tuples of relation r. Moreover, assuming that the underlying domain for attributes A and B has a total order, comparison atomic formulas are either of the form t[A]thw[B] or of the form t[A]tha, with th [?]
{<, <=, >, >=}.
When we consider a temporal relation, it is important to denote the set of tuples valid "at" a specific time interval (i.e., the values of attributes B and E of the tuples match exactly with the endpoints of the interval, respectively).
Given a time interval I = [b, e] on O, the snapshot at interval I of the temporal relation r, denoted with rI , is the relation containing all and only the tuples of r having valid interval I = [b, e].
More formally, the snapshot at interval I of r is obtained as rI = {t | r(t) [?]
t[B] = b [?]
t[E] = e}.
I1 finishes I0 (I1 F I0 ) I2 during I0 (I2 D I0 )  I5  I3 starts I0 (I3 S I0 ) I4 overlaps I0 (I4 O I0 )  I4  I5 meets I0 (I5 M I0 ) I6 before I0 (I6 B I0 ) I0  I0 equals I0 (I0 = I0 ) I0 finished by I1 (I0 F I1 ) I0 contains I2 (I0 D I2 )  I1  I0 started by I3 (I0 S I3 ) I2  I0 overlapped by I4 (I0 O I4 ) I0 met by I5 (I0 M I5 ) I0 after I6 (I0 B I6 )  Figure 2.
I3  The thirteen Allen's relations between intervals.
C. ITFDs Let us now consider the basic definition of Interval-based Temporal Functional Dependency (ITFD).
In the following, we will consider only interval relations in the set A: indeed, in this case it is not meaningful to distinguish between a relation and its dual, as it will be clear from the following definition of interval-based temporal functional dependency.
thirteen possible relations.
These relations are depicted in Figure 2 according to the notation proposed by Allen in [7].
It is worth to note that every relation has its dual which is obtained by switching the position of the two intervals.
Consider, for example, two intervals I1 = [b1 , e1 ] and I2 = [b2 , e2 ]: we have that I1 D I2 ( I1 during I2 ), if and only if b2 < b1 < e1 < e2 ; by reverting the arguments, we have that I2 D I1 ( I2 contains I2 ), if and only if b2 < b1 < e1 < e2 , which is equivalent to I1 D I2 .
More precisely, given two intervals I1 = [b1 , e1 ] and I2 = [b2 , e2 ] we say that: (1) (2) (3) (4) (5) (6)  I1 I1 I1 I1 I1 I1  Definition IV.1.
Let X and Y be sets of atemporal attributes of a temporal relation schema R = R(U, B, E) and ~I [?]
A an Allen's Interval relation.
A database instance r of R satisfies an ITFD X -~I Y iff [?
]b, b , e, e [?]
O with b <= e , b <= e and [b, e] ~I [b , e ]  M I2 iff e1 = b2 ; S I2 iff b1 = b2 and e1 < e2 ; F I2 iff b1 > b2 and e1 = e2 ; O I2 iff b1 < b2 and b < e1 < e2 ; D I2 iff b2 < b1 and e1 < e2 ; B I2 iff e1 < b2 .
and [?
]s1 , s2 [?]
{t | rB (t) [?]
((t[B] = b [?]
t[E] = e)[?]
(t[B] = b [?]
t[E] = e ))}  we have s1 [X] = s2 [X] = s1 [Y ] = s2 [Y ].
In the following we will consider the (sub) set A = {M, S, F, O, D, B} of Allen's interval relations (without considering the dual ones and the equality relation).
Basically ITFDs group tuples whose B and E attribute values satisfy the interval relation ~I .
In the above definition all the possible tuples having as valid interval either [b, e] or [b , e ], where [b, e] ~I [b , e ] are considered together.
If there exist two tuples where the B and E attribute values match exactly the points b, e, b , and e , respectively, and both tuples agree on the values of atemporal attributes X, then the ITFD imposes that both the tuples must agree on the values of atemporal attributes Y .
Consider the medical relation schema P atient proposed in Section III and suppose that we want to express the constraint "prescriptions of a given therapy starting the same day must have the same physician": such a requirement is expressed by the ITFD Therapy -S Phys.
For a more significant example of the expressivity of our ITFDs we can recall the scenario depicted in Section III which can be rephrased as "overlapping drug administrations for a given patient must have the same physician" (as specified in Example 1).
This constraint can be expressed by the ITFD PatId -O Phys.
A time-oriented graphical account of tuples of relation Patient is provided in lower part of Figure 1.
B.
The interval-based temporal relational data model In discussing our new functional dependencies based on intervals within a relational framework, we will use a simple temporal (relational) data model based on the concept of temporal relation.
A temporal relation r is a relation on a temporal relation schema R defined on the attributes U [?
]{B, E}, where U represents a set of atemporal attributes and B, E are the temporal attributes describing the valid interval of a tuple.
We assume that the domain of both the attributes B and E is a totally ordered set O.
Clearly a tuple t [?]
r satisfies t[B] <= t[E].
We use the notation att(R) to denote the set of attributes (both atemporal and temporal) of the relation schema R and att- (R) to denote the set of its atemporal attributes.
We recall that equality (inequality) atomic formulas are expressions either of the form t[A] = w[B] (t[A] = w[B]) or of the form t[A] = a (t[A] = a), being A, B attribute names, a a constant  26  As we may notice, the relation satisfies the ITFD PatId -O P hys only for tuples related to the patient with PatId = 1: Dr. Cox added a therapy antipyretics, but the related valid interval is contained in the interval of therapy antiviral , prescribed by Dr. Dorian.
Tuples related to therapies of patient with PatId = 2, instead, do not satisfy ITFD PatId -O Phys, as both the intervals of therapies prescribed by Dr. Reid overlap a therapy prescribed by another physician.
It is easy to show that this kind of properties cannot be expressed through point-based TFDs.
Basically this lack of expressiveness depends on the fact that point-based TFDs refer only to database snapshots which are either evaluated in isolation towards TFDs or grouped together according to some granularity or joined to the next snapshot to consider some kind of tuple evolution.
In our example, intervals of prescriptions are considered in a holistic way and the considered temporal dependency is not checked against all the database snapshots, as it has to consider the specified interval relation.
In our example Dorian starts a therapy on the patient with PatId = 1 and Cox starts therapy analgesics for the same patient during this therapy.
After that, Cox adds another therapy (antipyretics).
Suppose that this last therapy of Cox would last until time 14: then, either this tuple or the tuple related to therapy by Turk having valid time [13, 14] violate the ITFD.
Suppose that the database must satisfy the ITFD PatId -O Phys, and that tuples are inserted according to the start of their valid time: in this case, the insertion of tuple #5 would be blocked.
Another constraint that can be expressed using ITFDs is "intersecting therapies made by the same physician must have the same prescription".
It is easy to see that the ITFD T herapy, P hys -{ S, F, O, D}Drug capture this property.
Verify-B(b)  //b is lexicographically ordered on (B, E) verif ied - |b|; i - 1; while i < verif ied [?]
j - search begin(b, bi [E]); [?]
[?]
[?]
[?]
if j < |b| + 1 [?]
[?]
[?]
[?]
[?]
[?]
if bi [Y ] = bj [Y ] [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
then return false ; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
for k - j + 1 to verif ied [?]
[?]
 do [?]
if bi [Y ] = bk [Y ] then [?]
[?]
[?]
[?]
do [?]
[?]
[?]
then return false ; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
if verif ied >j [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
then verif ied - j; [?]
[?]
[?]
i-i+1 return true ; Figure 3.
The algorithm verifying B-based ITFDs.
Verify-M(b, )  //b is lexicographically ordered on (B, E) // is lexicographically ordered on (E, B) a - retrieve endpoints(b); for i - 1 to |a| [?]
j - search begin(b, ai ); [?]
[?]
[?]
[?]
k - search end(, ai ); [?]
[?]
[?]
[?]
[?]
if j < |b| + 1 [?]
k < || + 1 [?]
[?]
[?]
[?]
 [?]
[?]
j -j+1: [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?
]while bj  [B] = bj [B] [?]
[?]
[?]
[?]
[?]
[?]
do [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
 [?]
[?]
[?]
[?
]if bj [Y ] = bj [Y ] [?]
do [?]
[?]
then return false [?]
[?]
[?]
[?]
[?]
[?]
[?
]j  - j  + 1; [?]
then [?]
[?]
[?]
[?]
[?]
 [?]
[?]
[?]
[?]
[?]
[?
]k - k : [?]
[?]
[?]
[?]
[?]
[?]
[?]
while k [E] = k [E] [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
 [?]
[?]
[?]
[?]
[?]
[?
]if k [Y ] = bj [Y ] [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
do [?]
then return false [?]
[?]
[?]
[?]
[?
]k - k + 1; return true  V. E VALUATING ITFD S In this section we describe a set of algorithms, one for each Allen's interval relation, we designed for evaluating ITFDs.
First, we recall the problem of evaluating ITFDs.
Let X -~I Y , where X [?]
Y [?]
U and R [?]
{M, S, F, O, D, B} be an ITFDs, moreover it is easy to show that if an ITFD X -~I Y holds over some temporal relation r of some schema R then the ITFD X -~I Y holds over r as well.
Hence we can ignore the ITFDs based on the inverse relations and the X -= Y relation which is trivial to verify, it suffices to group tuples with the same values on the attributes B and E and verify that the FD X - Y holds on every group.
Given a set of tuples T where for att(T ) = X [?]
Y [?]
{B, E}, we say that T satisfies f if and only if for each pair of tuples t, t [?]
T , if we have t[X] = t [X] and [t[B], t[E]] R [t [B], t [E]], then t[Y ] = t [Y ].
It is worth to notice that given an ITFD X -~i Y and a set of tuples T , we can create a partition T1 , ..., Tn of T where for each 1 <= i, j <= n and for each t [?]
Ti and t [?]
Tj , we have t[X] = t [X] if and only if  Figure 4.
The algorithm verifying M -based ITFDs.
i = j.
This partition can be easily obtained: it is enough to give an arbitrary linear order on each attribute U [?]
X and an arbitrary linear order on attributes of X, and then sort the tuples using this new lexicographic order using some wellknown O(n log n) sorting algorithm.
After this preliminary step we have to verify f over every Ti ; the applied algorithm depends on the relation R. In the following we propose an algorithm for each relation R [?]
{M, S, F, O, D, B}.
We propose an ad hoc implementation because checking  27  the proposed ITFDs represents a slightly different (and more simple) problem with respect to that of constraint propagation over interval networks faced by Allen in ( [7]): as we will see, it is in a lower complexity class.
In the following when we propose the algorithm for verifying if some ITFDs X -~I Y holds over some temporal relation r of some schema R we assume that the input tuples for such algorithm agree on the values for the attributes in X.
If it is not the case we can partition the tuples in our relation r accordingly to the values of X and then we apply the algorithm on every partition.
It is easy to see that the these partitions can be created starting from r using any wellknown sorting algorithm with O(n log n) complexity.
This algorithm is used to sort the tuples of r lexicographically on X, after that we can build the partitions by simply split the ordered vector of tuples into blocks (this can be done in linear time).
Summing up the complexity of this preliminary step does not exceed O(n log n) which is the complexity of the algorithms proposed.
In the following we assume, that n is the number of tuples present in the input for every algorithm proposed.
Verify-O(b, )  //b is lexicographically ordered on (B, E) // is lexicographically ordered on (E, B) main |a| - 1; a1 .low - 1; a1 .up - 1; a1 .status - f ree; a1 .max - b1 [E]; a1 .begin - b1 [B]; i - 2; j - 1; k - 1; while i <= |b| [?]
if bi [B] = ak .begin [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?
]ak .up = i; [?]
[?]
[?]
[?]
ak .max = bi [E]; then [?]
[?]
[?]
[?]
[?
]i - i + 1; [?]
[?]
[?]
[?]
[?]
[?]
[?]
>= j [E] [?]
[?
]if bi [B][?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
if !up clusters(b, , a, j) [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
then return false [?]
[?]
[?]
[?]
[?]
[?]
[?]
then [?]
[?]
[?]
[?]
[?]
k - |a|; [?]
[?]
[?]
[?]
do [?]
[?]
[?]
[?]
[?]
j [?]
[?]
[?]
- j + 1; [?]
[?]
[?]
[?]
[?]
[?
]|a| - |a| + 1; [?]
[?]
[?]
[?]
[?]
else [?]
[?]
[?]
[?]
k - k + 1; ak .low - i; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?
]ak .up - i; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
ak .status - f ree; else [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
ak .max - bi [E]; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
ak .begin - bi [B]; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
i - i + 1; return true ;  A.
Evaluating {S, F, B, M }-based ITFDs We start with the relation S and F which are the most trivial ones to be evaluated; nevertheless, the proposed algorithm contains the basic ingredients useful to describe the following algorithms.
For verifying X -S Y over a set of tuples T (att(T ) [?]
X [?]
Y [?]
{B, E}) sharing the same values for the attribute set X it is sufficient to sort the tuples lexicographically on (B, E) using some well-known O(n log n) sorting algorithm.
Let b the vector containing the tuples of T sorted lexicographically on (B, E) we refer to its i-th element as bi for every 1 <= i <= |b|.
We return that X -B Y is verified over T if and only if for every 1 <= i < |b| the condition bi [B] = bi+1 [B] implies bi [Y ] = bi+1 [Y ] (this operation can be performed in linear time).
In a symmetric way we can verify X -F Y by taking the lexicographic order of the tuples of T on (E, B) stored in a vector .
We return that X -S Y is verified over T if and only if for every 1 <= i < || the condition i [E] = i+1 [E] implies i [Y ] = i+1 [Y ].
Suppose that we have to verify X -B Y then we calculate the vector b and we launch the procedure in Figure 3.a.
The procedure considers the intervals from the one belonging to the first position of b and verifies if for every interval which begins after the end of the current interval shares the same values for the attributes in Y .
The function search begin takes a lexicographically ordered vector b of intervals and a point p and return the first position of b which contains an interval that begins after p, if such a position does not exist then search begin returns |b| + 1.
It is easy to see that this is a simple search in a ordered vector then the complexity is O(log(n)).
In order to avoid the repeated check of the same interval which will lead to a quadratic  Figure 5.
The algorithm for verifying the interval relation O.  complexity, we introduce a variable verified , this variable keeps track of the interval which has already been checked.
Since every position can be checked at most 2 times we have that the complexity of the procedure is O(n log(n)).
Consider now the M (meets) operator and suppose to have calculated both the vectors b and , for every point p if there exists two tuples t, t [?]
T with t[B] = t [E] = p then all the tuples t [?]
T which satisfy t[B] = p or t[E] = p must share the same value for the attributes in Y .
More precisely the procedure for checking an ITFD of the form X -M Y is represented in Figure 3.b.
This procedure first calculates a vector a representing the set of all the endpoints of all intervals in b by means of the function retrieve endpoints.
This function is designed in a way that the vector a does not contain repetitions, and thus the complexity of retrieve endpoints is O(n log(n)).
The function search end is the analogous of the function search begin considering the vector .
The procedure for every endpoint ai in a considers two blocks of consecutive tuples one consisting of the tuples t in b with t[B] = ai and the other consisting of the tuples t in  with t [E] = ai .
If both these two blocks are not empty, the procedure verifies  28  and the tuples which remains in the structure.
It is worth to notice that by construction if a tuple t is inserted after a tuple t in the queue then we have t [B] <= t[B] then the queue is lexicographically sorted on the attributes B and E. Let t be a tuple we must remove at the current step: for every tuple t with t[B] < t [B] which lies above t in the queue and it is not removed in the current step (which means t[E] < t [E]), we have to verify that t [Y ] = t[X].
After the removal of all the tuples which end in the current point we can add the tuples which begin on the current point to the top of the queue.
We give the intuition behind the proposed algorithm by means of the example depicted in Figure 7.
Suppose that you want to verify the ITFD X -O Y on the set of tuples T = {A0 , A1 , B0 , B1 , C0 , C1 , C2 , D0 } (assume that for all T [?]
T we have t[X] = t[Y ]).
At step 1 both tuples A1 and A0 are inserted in the queue and at step 2 the tuples B0 and B1 are inserted on the top of the queue.
At step 3 first we remove B0 , since all the intervals above B0 in the queue consist of the singleton B1 which shares the same starting point with B0 and then it is not yet checked for consistency.
Step 3 terminates with the addition of the tuples C0 , C1 and C2 on the top of the queue.
At step 4 tuples B1 and C0 are removed since B1 and C0 are removed in the same step they can differ on the values for the attributes Y .
Since C0 shared the same beginning point with all the tuples above it on the queue, then it can differ from C1 and C2 on the values for the attributes Y .
When we remove B1 , tuples C1 , C2 are still present in the queue and B1 [B] < C1 [B] = C2 [B] then we have to check B1 [Y ] = C1 [Y ] = C2 [Y ].
At step 5 we insert D0 at the top of the queue.
At step 6 the tuple C1 is removed, as we said before C2 is not checked for consistency because it shares the same beginning point with C2 then only D0 is checked for consistency and we verify C1 [Y ] = D0 [Y ].
At step 7 the tuple D0 is removed without check anything since it is on the top of the queue.
At step 8 the tuple A0 is removed and since the tuple C2 is not removed then it is checked for consistency with A0 (A0 [Y ] = C2 [Y ]).
Summing up the results at the end of the procedure we have that the ITFD X -O Y is respected by T if and only if B1 [Y ] = C1 [Y ] = C2 [Y ] = D0 [Y ] = A0 [Y ] and it is worth to notice that that all these intervals do not pairwise overlap (consider B1 and D0 for instance).
The procedure for verifying if the ITFDs X -O Y over a set of tuples which agree on the attributes X is given in Figure 5.
In order to give an efficient procedure for verifying X -O Y we partition the vector b into clusters.
A cluster is the maximal sequence of lexicographically ordered intervals which share the same beginning endpoint, it is straightforward to see, since b is ordered, that a cluster is a sequence of consecutive positions in b and thus can be represented as an interval on the positions of b.
The correct management of clusters is guaranteed by the function U p Clusters of Figure 6.
The procedure for checking ITFDs like X -D Y operates in a very symmetric way with respect to the procedure for  Up clusters(b, , a, n)  i - retrieve position(n ); i - retrieve cluster(a, i); if i < |a| [?]
max - n [E]; [?]
[?]
[?]
[?]
[?]
for j - i + 1 to |a| [?]
[?]
[?]
[?]
[?]
do [?]
[?]
[?]
[?]
[?]
[?][?
]if aj .max > max [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
then [?]
[?]
[?]
[?][?]
[?]
[?]
[?]
[?][?]
= f ree [?]
[?]
[?
]if aj .status [?][?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
for h - aj .low to aj .up [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?][?]
[?]
[?]
[?]
[?]
do [?]
[?]
[?]
[?]
[?]
[?]
then  [?]
[?]
[?]
[?]
[?][?]
if bh [Y ] = n [Y ] [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
[?]
then [?]
[?]
[?]
then return false [?]
[?]
[?]
[?][?]
 [?]
[?]
[?]
if aj .value = n [Y ] [?]
[?]
[?][?]
[?]
[?]
[?]
[?][?]
else [?]
[?]
[?]
[?]
[?]
then return false [?]
[?]
[?]
[?]
[?]
[?]
max - max(max, aj .max); [?]
[?]
[?]
if max > n [E] [?]
[?]
[?]
[?]
[?]
[?]
ai+1 .max - max; [?]
[?]
[?]
[?]
[?]
[?]
[?]
[?
]ai+1 .status - checked; [?]
[?]
[?]
[?]
then [?]
[?]
ai+1 .value - n [Y ]; [?]
[?]
[?]
[?]
[?]
[?]
[?
]|a| - i + 1 : [?]
[?]
[?]
[?]
[?]
[?]
else |a| - i : if ai .status = f ree then if ai .low < ai .up then ai .low - ai .low + 1; else if i < |a| then ai - ai+1 else |a| - i - 1; return true  Figure 6.
5.
The auxiliary function up cluster for the algorithm of Figure  if all the tuples of these two blocks share the same values for attributes in Y .
For evaluating the complexity it suffices to consider that every tuple is checked by the procedure at most two times (one for its right endpoint and one for its left one) and the number of evaluations of the functions search begin and search end is bounded by the number of endpoints, then the total complexity is O(n log(n)).
B.
Evaluating {O, D}-based ITFDs Now we consider the more complicated cases of verifying ITFDs X -O Y and X -D Y .
Informally our idea consists of exploring the space of intervals following the order of the endpoints associated to the tuples in T .
We use a queue to keep track of the active intervals at every step.
At every step we update the queue by removing the tuples which end at the current point and, then, by adding the tuples which begin in the current point in between this two operations we perform consistency check between the tuples removed  29  A1  considered as a case of interval-based temporal association rule.
A0  R EFERENCES  B1  [1] C. Bettini, S. G. Jajodia, and S. X. Wang, Time Granularities in Databases, Data Mining and Temporal Reasoning.
Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2000.
B0 C2 C1 C0  1  D0  2  3  4  5  6  A1  B1  C2  C2  D0  A0  B0  C1  C1  C2  1  A1  C0  A1  A0  B1  A0  2  A1  4  5  A0  [2] V. Vianu, "Dynamic functional dependencies and database aging," J. ACM, vol.
34, no.
1, pp.
28-59, 1987.
7  8  D0  C2  C2  C2  A0  C1  A0  8  A0  7  6  [3] J. Wijsen, "Design of temporal relational databases based on dynamic and temporal functional dependencies," in Temporal Databases, 1995, pp.
61-76.
9  [4] ----, "Temporal fds on complex objects," ACM Trans.
Database Syst., vol.
24, no.
1, pp.
127-176, 1999.
[5] ----, "Temporal dependencies," in Encyclopedia of Database Systems, L. Liu and M. T. Ozsu, Eds.
Springer US, 2009, pp.
2960-2966.
3  [6] C. S. Jensen, R. T. Snodgrass, and M. D. Soo, "Extending existing dependency theory to temporal databases," IEEE Trans.
Knowl.
Data Eng., vol.
8, no.
4, pp.
563-582, 1996.
Figure 7.
An example of the execution of the algorithm for the O and the D ITFDs.
[7] J. F. Allen, "Maintaining knowledge about temporal intervals," Commun.
ACM, vol.
26, no.
11, pp.
832-843, 1983.
X -O Y : it suffices to rewrite the algorithm in Figure 5 in order to look downward in the queue instead of upward.
We can conclude this section with the following theorem.
[8] P. Terenziani and R. T. Snodgrass, "Reconciling point-based and interval-based semantics in temporal relational databases: A treatment of the telic/atelic distinction," IEEE Trans.
Knowl.
Data Eng., vol.
16, no.
5, pp.
540-551, 2004.
Theorem V.1.
For every set of atemporal attributes X and Y of a temporal relation schema R = R(U, B, E) and for every Allen's Interval relation ~I [?]
A verifying if an instance r of R satisfies an ITFD X -~I Y takes at most O(|r| log(|r|)) steps.
[9] R. T. Snodgrass, Ed., The TSQL2 Temporal Query Language.
Kluwer, 1995.
[10] Y. Shoham, "Temporal logics in ai: Semantical and ontological considerations," Artif.
Intell., vol.
33, no.
1, pp.
89-104, 1987.
This result follows from the proofs of correctness and completeness for the algorthms proposed in subsections V-A and V-B which can be found in [13].
[11] C. S. Jensen and R. T. Snodgrass, "Temporally enhanced database design," in Advances in Object-Oriented Data Modeling, 2000, pp.
163-193.
VI.
C ONCLUSIONS AND FUTURE WORK In this paper we proposed a set of interval-based temporal functional dependencies and discussed its expressiveness by means of an example taken from the clinical domain.
Moreover, for each interval relation ~I we proposed an algorithm to verify, given an instance r of a temporal database, whether an ITFD based on ~I holds over r. We plan to implement the algorithm proposed and evaluate it over different real-worlds scenarios.
A further step towards interval-based temporal functional dependencies will be devoted to extend the proposed ITFDs to deal with multiple temporal granularities and with interval-based tuple evolutions, similarly to the Vianu's (point-based) approach.
As for the clinical domain, we plan to adapt and extend the proposed techniques to the data mining issue: indeed, in the clinical domain there is the need of mining temporal association rules among temporal data, often charachterized by intervals of validity.
ITDBs may be  [12] X. S. Wang, C. Bettini, A. Brodsky, and S. Jajodia, "Logical design for temporal databases with multiple granularities," ACM Trans.
Database Syst., vol.
22, no.
2, pp.
115-170, 1997.
[13] C. Combi and P. Sala, "Temporal functional dependencies based on interval relations," Department of Computer Science, University of Verona, Verona, Italy, Tech.
Rep. RR 82/2011, 2011.
30
In Proc.
of the Third International Workshop on Temporal Representation and Reasoning (TIMEa96) May 19-20, 1996, Key West, Florida.
IEEE Computer Society Press, pp.
144-151.
Guiding and Rening Simulation using Temporal Logic Giorgio Brajnik  Daniel J. Clancy  Dip.
di Matematica e Informatica Universita di Udine 33100 Udine, ITALY  Department of Computer Sciences University of Texas at Austin Austin, TEXAS 78712  Abstract  We illustrate TeQSIM, a qualitative simulator for continuous dynamical systems.
It combines the expressive power of qualitative dierential equations with temporal logic by interleaving simulation with model checking to constrain and rene the resulting predicted behaviors.
Temporal logic expressions are used to specify constraints that restrict the simulation to a region of the state space and to specify trajectories for input variables.
A propositional linear{time temporal logic is adopted, which is extended to a three valued logic that allows a formula to be conditionally entailed when quantitative information specied in the formula can be applied to a behavior to rene it.
We present a formalization of the logic with theoretical results concerning the adopted model checking algorithm (correctness and completeness).
We show also an example of the simulation of a non{autonomous dynamical system and illustrate possible application tasks, ranging from simulation to monitoring and control of continuous dynamical systems, where TeQSIM can be applied.
1 Introduction  Reasoning about change across time is a common problem within articial intelligence and computer science in general.
For systems with discrete state spaces, temporal logic (TL) provides a broad class of formalisms that have been used for such tasks as reasoning about the eect of actions, specifying and verifying correctness of reactive computer programs and synthesizing or analyzing discrete event systems [13, 6, 2, 8].
Qualitative reasoning [10] has been used to reason about continuous change within the eld of dynamical systems in the presence of incomplete knowledge.
The expressiveness of the models used within qualitative simulation, however, is often limited to structural equations constraining the potential values for related variables.
The modeler is unable to express behavioral information about the trajectory of a variable or relationships between the trajectories of interconnected variables.
Such an information allows the modeler to restrict the simulation to a region of the state space and to specify trajectories for input variables.
 The research reported in this paper has been performed while visiting the Qualitative Reasoning Group at the University of Texas at Austin.
The Temporally Constrained QSIM (TeQSIM, pronounced tek'sim) algorithm combines the expressive power of these two paradigms by interleaving temporal logic model checking with the qualitative simulation process.
Temporal logic is used to specify qualitative and quantitative trajectory information that is incorporated into the simulation to constrain and rene the resulting behaviors.
Qualitative simulation constructs a set of possible behaviors consistent with a model of a dynamical system represented by a qualitative dierential equation (QDE).
The QSIM algorithm [10] represents the behavior of a dynamical system by an incrementally generated tree of qualitative states.
Each state describes the system at either a time{point or over a time{interval between two points by a tuple of qualitative values for the variables specied within the QDE.
Each qualitative value is described by a magnitude and a direction of change: the direction of change represents the sign of the variable's time derivative while the magnitude is dened upon a totally ordered set of distinctive landmark values and is either a landmark value or an interval between two landmark values.
The simulator uses the constraints specied within the QDE along with continuity to derive a branching{ time behavioral description.
Each path within the tree represents a potential behavior of the system: branches result from inherent ambiguity within the qualitative description.
Semi{quantitative simulation incorporates quantitative information into the qualitative simulation in the form of numeric ranges for landmark values and bounding envelopes for functions.
TeQSIM interleaves temporal logic model checking with the qualitative simulation process to obtain two major benets.
Behavior ltering tests each partial behavior against the set of temporal logic expressions representing trajectory constraints as the set of behaviors is incrementally generated.
A behavior is eliminated from the simulation when it can be shown that all of its possible completions fail to model the set of temporal logic expressions.
Thus, the space of the behavioral description is restricted to include only behaviors that can satisfy the temporal logic expressions.
Behavior renement integrates numeric information contained within the temporal logic expressions into the qualitative simulation to provide a more precise numerical description.
This process restricts an individual behavior to include only those real valued inter-  Simulation & Model Checking  Preprocessing Extended TL Expressions Event List  QDE & Initial State  Event Replacement  QDE Modifier  TL Expressions  Modified QDE & Initial State  TLaGuide  Filtered and Refined Behavior Tree  QSIM  Figure 1: TeQSIM architecture.
pretations which model the set of temporal logic expressions and therefore improves the precision of the prediction.
The integration of temporal logic model checking and qualitative simulationwas initially investigated by Kuipers and Shults [11].
They use a branching{time temporal logic to prove properties about continuous systems by testing the entire behavioral description against a temporal logic expression.
The appropriate truth value is returned depending upon whether or not the description models the expression.
Our work focuses on constraining the simulation as opposed to testing a simulation after it is completed.
The next section provides an overview of the TeQSIM algorithm.
Section 3 provides an example along with a discussion of some of the applications of this technique while section 4 describes the formal syntax and semantics of our temporal logic.
Soundness and completeness theorems are presented for the TL{ guide algorithm.
Finally, section 5 provides a discussion of some of the extensions that will be investigated in the future.
2 TeQSIM Overview  TeQSIM has been designed to provide the user with a mechanism for specifying trajectory constraints to guide and rene the qualitative simulation process.
By trajectory of a set of variables over a time interval (a; b)  < we mean a mapping from (a; b) to variable values ( < ).
Trajectory constraints on a set of variables restrict the possible trajectories for those variables.
Figure 1 provides an overview of the system architecture.
In general, the algorithm can be divided into two main components: a preprocessing stage that combines the trajectory information provided by the modeler into the qualitative model and generates the appropriate TL expressions; and a simulation and model checking stage that integrates model checking into the simulation process by ltering and rening qualitative behaviors according to a set of temporal logic expressions.
Trajectory information is specied in the form of an event list and a set of extended temporal logic statements.
An event is a time{point distinguished within the simulation.
The event list is a sequence of named, quantitatively bounded events not represented within the QDE that are incorporated into the simulation.
An extended temporal logic statement is simply a tem-  poral logic formula which may include direct references to events occurring within the event list.
These references are replaced by the appropriate formulae.
The simulation provides a complete temporal ordering between these externally dened events and other events dened within the model.
Model checking and behavior renement is performed by TL{guide.
Each time QSIM extends a behavior by the addition of a new state, the behavior is passed to TL{guide.
The behavior is ltered if there is sucient information within the partially formed behavior to determine that all completions of the behavior fail to model the set of TL expressions.
If the behavior can potentially model the set of TL expressions, then it is rened by the incorporation of any relevant quantitative information contained within the TL expressions.
Otherwise the behavior is retained unchanged.
3 Problem solving with TeQSIM  Incorporating temporal logic model checking into the qualitative simulation process allows the modeler to control the simulation by restricting the behavior of input and dependent variables.
Trajectory constraints can be used for a variety of tasks, including simulation of non{autonomous systems, incorporating observations into simulation, analysis of continuous control laws and performing goal oriented simulation.
The TeQSIM algorithm has been tested on a range of examples demonstrating each of the tasks above.
The following example demonstrates the use of TeQSIM to simulate a non{autonomous system incorporating information obtained via observation.
The system being simulated is a very simple one, which generalizes to the real{world problem of water supply control in the domain of lakes, rivers and dams [7].
Consider an open tank, with an uncontrolled inow u, a regulated outow y, valve opening v and amount of liquid A in the tank.
The system is modeled by the dierential equation A_ = u ?
y; y = f (A; v) where f (A; v) is an unknown monotonically increasing function on both arguments, numerically bounded.
This model can be straightforwardly specied using the QSIM QDE language.
Figure 2 shows the trajectory constraints used by TeQSIM for simulating the regulated tank.
Part (a) of the gure shows a totally ordered event list that provides quantitative temporal bounds for external events corresponding to two opening actions on the outow valve.
Four events are dened corresponding to the beginning and the end of each of these actions.
Part (b) contains the trajectory constraints that specify the behavior of the outow valve along with constraints on inow and level (up to the end of the rst opening action; the second action, not shown, is similarly specied): i. the variable Inflow is constant3 and its value is within the range [200, 220] cm /s, ii.
the valve opening is constant at 0.5 until the beginning of the rst opening action, iii.
between events b-open1 and e-open1 (i.e.
the duration of the rst opening action) the valve  (event (event (event (event  b-open1 e-open1 b-open2 e-open2  :time :time :time :time  (30 30)) ; sec (35 36)) (150 150)) (153 155))  (a) External event declaration.
i)  (always (and (qvalue InFlow (nil std)) (value-in InFlow (200 220))) ii) (until (and (value-in Valve (0.5 0.5)) (qvalue Valve (nil std))) (event b-open1)) iii) (between (event b-open1) (event e-open1) (and (qvalue Valve (nil inc)) (qvalue Level (nil inc)))) iv) (occurs-at (event e-open1) (value-in Valve (0.65 0.7)))  (b) Trajectory constraints (rst opening action only).
Figure 2: Input to TeQSIM.
opening is increasing and Level is observed to increase, and iv.
valve reaches a value in [0.65, 0.7] at the end of the rst opening action.
Figure 3 shows the result of the simulation.
TeQSIM yields a single behavior where Level increases and reaches a new equilibrium value, well below the High threshold.
Correctness properties of TeQSIM guarantee that this is the only possible outcome of any real plant that is validly described by the QDE model, the initial state and the trajectory constraints.
This example is very simple but it shows one possible use of trajectory constraints to extend the scope of qualitative simulators (like QSIM, that are limited to simulation of initial value problems only).
A brief description of other tasks to which TeQSIM can be applied along with a discussion of how each task can be demonstrated on the model described above is contained in gure 4.
Additional examples are contained in [5].
4 Guiding and rening simulation  TeQSIM guides and renes the simulation based upon a specication formulated using a variation of propositional linear time logic (PLTL).
PLTL combines state formulae, that express information about an individual state, with temporal operators such as until, always, and eventually to extend these state formulae across time and represent change.
We have extended PLTL by using a three valued logic that allows an expression to be conditionally entailed when quantitative information contained within the expression can be applied to a behavior to rene the description.
A renement condition species numerical bounds extracted from the TL expressions.
Application of these conditions to the behavior eliminates the region of the  state space that extended beyond the quantitative information specied in the TL expression.
In addition, the TL{guide algorithm is designed to handle the incremental nature of a qualitative simulation.
An undetermined result occurs whenever the behavior is insuciently determined to evaluate the truth of a TL expression.
4.1 TL specication language  This section provides a formal description of the syntax and semantics for the TL language.
The syntax and semantics are derived from work done by Emerson [6] and Kuipers and Shults [12].
A discussion of the TL{guide algorithm along with soundness and completeness theorems are presented in the following subsections.
Proofs of these theorems along with additional lemmas and corollaries can be found in [5].
Syntax.
The syntax and semantics for the state for-  mulae are described in gure 5(a).
Path formulae are derived by applying the temporal operators until and strong-next along with boolean operators to state formulae.
Path formulae P are formally dened as P ::= Sj (and P P )j(not P )j(strong-next P )j(until P P ), where S is the set of state formulae.
Informally, (until p q) is true for a path if p holds in all states preceding the rst one where q holds, while (strong-next p) is true for a path if p holds in the second state of the path which must exist.
Figure 5(b) gives a set of useful abbreviations.
We require that formulae are in positive normal form, i.e.
(i) until, releases and strong-next are the only temporal operators in the formula, (ii) for every not in the formula, its scope is an atomic proposition, and (iii) such a scope does not include any proposition constructed using value-<=, value->= or value-in.
The rst two requirements do not restrict the expressiveness of the language since the abbreviations shown above can be used to transform a formula to satisfy these conditions.
The latter requirement is due to the specic representation of numeric information in QSIM, which does not allow open numeric intervals.
Semantics.
Temporal logic formulae are given meaning with respect to the interpretation structures dened below.
These structures are extended from their typical denition (e.g.
[6]) in order to accommodate the renement process.
Path formulae are interpreted against an interpretation structure M = <S; ; ?
; I ; C ; M> where:  S is a set of states;  : S !
S is a partial function, mapping states  to their successors (we are dening a linear{time logic, hence each state has at most one successor);  I : S  S !
ft; f; ?g is an assignment of truth values to propositions and states (?
denotes the \unknown" truth value);  T1  T2  T3  T4  ..a T5 [153 +INF] .
... .... a  HIGH [75 75]  ... L-20 [30.8 37.4] .
..... ..... ..... ..... ..... ..... ..... ..... .. Adeg .... a a a a a a a a a a L* [30 35] 0 [0 0]  0 [0 0] T0  INF  TOP [100 100]  1 [1 1]  ..... ..... ....Adeg Adeg Adeg V-56 [0.900 0.950] ..a. .
.
.
V-28 [0.650 0.700] .. ..... ..... ... Adeg Adeg Adeg ..a ... ..... ..... V* [0.500 0.500] Adeg Adeg Adeg  MINF  T5  T0  VALVE  T1  T2  T3  T4  T5  ..a .
... .... a ...a .
.
.
.... a  .....a ...a ..a.. .
.
.
.
.... a a T0  T1  T4 [153 155] T3 [150 150] T2 [35 36] T1 [30 30] T0 [0 0]  T2  T3  T4  T5  TIME  LEVEL  Figure 3: Output of TeQSIM.
 ?
is a set of renement conditions.
?
is closed with respect to the standard boolean operators f^; :g and contains the distinguished item TRUE;  C : S  S !
?
is a function (condition gener-  ator) that maps state formulae and states into  renement conditions that disambiguate a formula truth value; we require that C ('; s) = TRUE i I ('; s) = t and C ('; s) to be dened when I ('; s) =?.
 M: ?
 S !
S is a function (state modier) that maps a condition and a state into a rened state.
For any state s, M(TRUE; s) = s and M(:TRUE; s) = ?.
We require that if ' is an atomic proposition then renement conditions are necessary and sucient for resolving the ambiguity, i.e.
if C = C ('; s) then I ('; M(C; s)) = t and I ('; M(:C; s)) = f (unless C = TRUE, in which case M(:C; s) = ?).
As customary, a path x is a sequence of states x = <s0 ; s1 ; : : :> such that for any pair of consecutive states (s ; s +1) we have that (s ) = s +1 .
The length of a path is denoted by jxj, which for innite paths is 1.
For all non negative integers i < jxj, x denotes the sub{path <s ; : : :> and x(i) denotes s .
A full{ path extension of a nite path x, denoted with xb, is an innite path formed by concatenating x with an innite sequence of states.
Finally, M is naturally extended to paths in order to rene paths.
In the specic case of QSIM, I may give ?
only for propositions including value-<=, value->= and value-in (as illustrated in g. 5(a)).
A renement condition is an inequality between the partially known numeric value of a variable in a state and an extended real number (or a boolean combination of conditions).
The condition that the QDE variable X in state s has to be less than 5 is written \X < 5".
Notice that ambiguity is not purely a syntactic property, but it depends on state information.
For example, (value-<= X .3) will be (unconditionally) true on a state s where R(X; s) = [0; 0:25], but only conditionally true on s0 where R(X; s0 ) = [0; 1:0].
Because of ambiguity, to dene the semantics of formulae we need to introduce two entailment relations.
The rst one, called models (j=), will be used to characterize non{ambiguous true formulae; the second one, i  i  i  i  i  i  i  s  called conditionally{models ( j=? )
will characterize formulae that are ambiguous.
We will say that an interpretation M and a state s falsify (6j=) a formula ' when neither s j= ' nor s j=? '
hold.
Figure 5(c,d) gives the semantics of the language.
To simplify the analysis of the renement process, the usage of ambiguous formulae must be restricted.
The problem is that an arbitrary ambiguous formula may yield several alternative renement conditions.
A disjunction of renement conditions cannot be applied to states without requiring a change in the successor function  and the introduction of a new behavior which is qualitatively identical to the original behavior in the tree.
Two dierent types of disjunction can result from certain ambiguous formula.
A state disjunction results from a disjunction of ambiguous state formulae.
For example, when interpreted against a particular state (or (value-<= X 0.5) (value->= Y 15)) may yield the condition (X  0:5 _ Y  15).
When applying such a condition to a state, M(C; s) yields two states { s0 in which X is restricted to be  0:5 and s00 where Y  15.
A path disjunction, on the other hand, occurs when an ambiguous formula is included in a path formula in such a manner that a sub{formula can be conditionally true for more than one sub{path.
For example, in the path formula (until p (value-<= X 0.5)) a disjunction occurs across sub{paths regarding when (value-<= X 0.5) should be conditionally true.
The following denitions restrict the syntax to formulae that are well{behaved.
A potentially ambiguous formula is any TL formula that (i) is an atomic proposition constructed using one of the following operators value-<=, value->= or value-in, or (ii) is a path formula which contains a potentially ambiguous sub{formula.
Admissible formulae are those formulae ' that satisfy the following conditions: 1. '
is in positive normal form, and 2. if '  (until p q) then q is not potentially ambiguous, and 3. if '  (releases p q) then p is not potentially ambiguous, and 4. if '  (or p q) then at most one of p and q is potentially ambiguous.
It can be proved that for all admissible formulae ' s  s0  s00  s  Continuous feedback control  A control law is expressed in terms of a set of formulae relating the value of the monitored variable (say Level) with the required value, or trend, of the control variable (say Valve).
The resulting closed{loop behaviors can then be analyzed with respect to the controller's goal.
The following trajectory constraint provides a partial specication of a control law to avoid overowing the tank.
It states that the valve opening must be increasing whenever the magnitude of Level is greater than high and the valve hasn't yet reached its maximum opening max.
(always (between (qvalue Level ((high nil) nil)) (qvalue Level (high dec)) (implies (qvalue Valve ((min max) nil)) (qvalue Valve (nil inc)))))  Continuous feed{forward control  The control law is expressed in terms of a set of formulae relating a predicted value of the monitored variable to the current value or trend of the control variable.
The following trajectory constraint species that if the tank can potentially overow then the valve opening should be increased until it reaches its maximum value or level becomes smaller than high.
(always (implies (eventually (qvalue Level (top nil))) (until (qvalue Valve (nil inc)) (or (qvalue Level (high dec)) (qvalue Valve (max nil))))))  Goal Oriented Simulation  The statements reported below can be used to check whether the tank will overow within a specied time frame.
Since TeQSIM is sound, if no behaviors are produced then the modeled system can not violate these constraints (assuming that the QDE model is valid).
The following trajectory constraint limits the simulation to behaviors in which the tank Level reaches high within 150 seconds.
(and (event horizon :time 150) (before (qvalue Level (high nil)) (event horizon)))  Figure 4: Applying TeQSIM to other tasks using the regulated tank model.
and for any interpretation M and path x, if x j=? '
then any necessary and sucient condition C for rening x into a model for ' (i.e.
M(C; x) j= ' and M(:C; x) 6j= ') is either a single condition or a conjunction of conditions.
Even though the restriction to admissible formulae reduces expressiveness, such a restriction does not hinder the practical applicability of TeQSIM.
As long as important distinctions are qualitatively represented (using landmarks or events), most trajectory constraints can be cast into admissible formulae.
For example, the constraint that \until level goes above 50 the input ow rate has to be below 200" could be expressed with the following non{admissible formula (until (value-<= InFlow 200) (value->= Level 50)) where the two distinctions (200 and 50) do not correspond to qualitative landmarks.
By adding a landmark to the quantity space of Level corresponding to the value 50, the formula can be rewritten in an admissible form (i.e.
(until (value-<= InFlow 200) (qvalue Level (lm-50 nil)))).
QSIM computes in nite time a set of behaviors, each representing a class of trajectories of the system being simulated.
Although a QSIM behavior is a nite structure, it may represent innite trajectories of the simulated system.
In fact, quiescent states are nite descriptions of xed{point trajectories1 .
For-  mally, a QSIM behavior b is a nite sequence of non repeating states <s0 ; : : :; s > such that 8i; 0  i < n : (s ; s +1 ) belongs to the QSIM relations successor or transition.
A behavior b is closed i QSIM detected that s is a quiescent state or that s is a transition state that has no possible successor.
1 QSIM may identify cyclic behaviors as well and represent them throughcycles in a directed graph.
The use of quantitative information, however, only makes sense if time is not cyclic;  furthermore the renement of behaviors requires that they do not share sub{behaviors.
For these reasons cycle detection is disabled within TeQSIM.
n  i  i  n  n  4.2 Model checking  The model checking algorithm is designed to evaluate a behavior with respect to a set of admissible formulae as the behavior is incrementally developed.
This allows behaviors to be ltered and rened as early as possible during the simulation.
Our algorithm is derived from the one described in [11]; however, it has been modied to deal with conditionally true formulae and to cope with behaviors which are not closed.
A detailed discussion of the algorithm is provided in [5].
The algorithm computes the function  : P  Behaviors !
fT; F; Ug Conditions: A denite answer (i.e.
T or F) is provided when the behavior contains sufcient information to determine the truth value of the formula.
For example, a non{closed behavior b, for all interpretations M , will not be suciently determined with respect to the formula ' (eventually p) if p is not true for any sux of b, since p may become true in the future.
A behavior is considered to be suciently determined with respect to a formula whenever there is enough information within the behavior to determine  (a) Syntax and semantics of state formulae.
In the denitions of the most important state formulae given below, v denotes a QSIM variable, R(v; s) the range of potential values for v in state s, and vs the unknown value of v in s. n, ni denote extended real numbers.
(qvalue v (qmag qdir )) where qmag is a landmark or open interval dened by a pair of landmarks in the quantity space associated with v, and qdir is one of finc, std, decg.
NIL can be used anywhere to match anything.
Such a proposition is true exactly when the qualitative value of v in the state s matches the description (qmag qdir ).
(value-<= v n) is true i 8x 2 R(v; s) : x  n; it is false i 8x 2 R(v; s) : n < x; it is unknown otherwise.
In such a case the renement condition is that the least upper bound of the possible real values of v is equal to n (i.e.
vs  n).
(value->= v n) is similar.
(value-in v (n1 n2 )) is true i R(v; s)  [n1 ; n2 ]; it is false i R(v; s) \ [n1 ; n2 ] = ;.
It is unknown otherwise, and the renement condition is that the greatest lower bound is equal to n1 and the least upper bound is equal to n2 (i.e.
n1  vs ^ vs  n2 ).
Non{atomic propositions are dened using standard boolean operators (and, not); standard propositional abbreviations are also allowed (true, false, or, implies, iff).
(c) Entailment relations for state formulae.
(a ranges over atomic propositions, p and q over S ): s j= a i I (a; s) = t s j=?
a i I (a; s) =?
s j= (and p q) i s j= p and s j= q s j=?
(and p q) i s j=?
p and s j= q, or s j= p and s j=?
q, or s j=?
p and s j=?
q s j= (not p) i s 6j= p s j=?
(not p) i s j=?
p  (b) Path formulae abbreviations.
(or p (releases p (before p (eventually (always (never (starts p (follows p (occurs-at (between p  q) q) q) p) p) p) q) q)           p q) q r)     (not (and (not p) (not q ))) (not (until (not p) (not q ))) (not (until (not p) q )) (until true p) (releases false p) (always (not p)) (releases p (implies p (always q ))) (releases p (implies p (strong-next (always q )))) (releases p (implies p q )) (releases p (implies p (strong-next (until r q ))))  The intuitive meaning for some of these forms is: p q): q is true up until and including the rst state in which p is true.
(starts p q ): q holds from the rst occurrence of p. (follows p q ): similar to starts, but q should hold just after the rst occurrence of p. (occurs-at p q ): q is true at the rst occurrence of p. (between p q r ): r holds in the open time interval between the rst occurrence of p and the subsequent rst of q.
(releases  (d) Entailment relations for path formulae.
(p 2 S and '; 2 P ): x j= p i x(0) j= p x j=?
p i x(0) j=?
p x j= (strong-next ') i jxj > 1 and x1 j= ' x j=?
(strong-next ') i jxj > 1 and x1 j=? '
x j= (until ' ) i 9i  0 : xi j= and 8j < i : xj j= ' x j=?
(until ' ) i 9i  0 : (xi j= or xi j=? )
and ? ')
and 8j < i : (xj j= ' or xj j= ?
occurs at least once j= The semantics of (and ' ) and (not ') is similar to the propositional case.
Figure 5: Syntax and semantics of the language.
a single truth value for all completions of the behavior.
If a behavior is not suciently determined for a formula, then U is returned by  and the behavior is not ltered out by TL{guide.
Notice that indeterminacy is a property independent from ambiguity: the former is related to incomplete paths, while the latter deals with ambiguous information present in states of a path.
The following recursive denition characterizes determinacy.
Given an interpretation M , a path x is suciently determined for a positive normal formula ' (written x  ') i one of the following conditions is met: 1. x corresponds to a closed behavior or ' is a proposition or x j= ' or x j=? '
2. '
 (strong-next p) and jxj > 1 and x1  p  3. '
 (until p q) and 9i: i < jxj and x 6j= p and x  p and 8j  i: x 6j= q and x  q 4. '
 (releases pq) and 9i: i < jxj and x 6j= q and x  q and 8j  i: x 6j= p and x  p 5. '
 (and p1 p2) and 9i: x 6j= p and x  p 6. '
 (or p1 p2 ) and 8i: x 6j= p and x  p We will write x = ' to signify that x is not suciently determined for '.
We are now ready to state the main correctness and completeness theorem on model checking.
i  i  j  j  i  j  j  i  i  i  i  i  Theorem 1 ( is sound and complete) For any  admissible formula ' and for any QSIM behavior b the following statements hold:  1.
('; b) = (T; TRUE) () there exists an interpretation M such that b j= '.
2.
('; b) = (T; C ) and C 6= TRUE () there exists an interpretation M such that b j=? '
and if b0 ; b00 exist such that b0 = M(C; b) and b00 = M(:C; b) then b0 j= ' and for all full{path extensions bb00 of b00: bb00 6j= '.
3.
1 ('; b) = F () for all interpretations M and for all full{path extensions bb: bb 6j= ' and b  '.
4.
('; b) = (U; C ) () for all interpretations M , b = ' and if b0 = M(:C; b) exists then for all full{path extensions bb0 : bb0 6j= '.
Proof is based on induction on formula length.
It follows by a case{by{case analysis of the algorithm.
4.3 Guiding and rening the simulation  When given a behavior b and an admissible formula ', TL{guide computes  ('; b) = (v; C ).
The behavior b is refuted i v = F; it is retained unmodied i v 6= F and C = TRUE; and it is rened into M(C; b) i v 2 fT; Ug and C 6= TRUE.
The following theorem justies our use of temporal logic model checking for guiding and rening the simulation.
Theorem 2 (TL{guide is sound and complete)  Given a QSIM behavior b and an admissible formula ' then TL{guide: 1. refutes b i for all interpretations M and for all full{path extensions bb: bb 6j= ' and b  '.
2. retains b without modifying it i (a) there exists an interpretation M such that b j= '; or (b) for all interpretations M , b  = ' and there is0 no necessary condition C such that if b = M(:C; b) exists then for all full{path extensions bb0: bb0 6j= '.
3. replaces b with b0 i (a) there exists an interpretation M such that b j=? '
and exists C such that b0 = M (C; b) j= '00 and C is necessary (i.e.
exists b00 such that b = M(:C; b) and for all full{path extensions bb00: bb00 6j= '); or (b) for all interpretations M , b  = ' and there is a necessary condition C such that b0 = M(:C; b) and for all full{path extensions bb0: bb0 6j= '.
Proof follows almost directly from the previous theorem.
5 Discussion and future work  TeQSIM is designed to provide a general methodology for incorporating trajectory constraints into the qualitative simulation process.
The current trajectory specication language is, however, insucient to express certain constraints relevant to dynamical systems (e.g.
stability requirements for controllers).
Three dierent extensions to the language are currently being investigated.
Limited rst order expressiveness - The temporal logic used is limited to PLTL and is unable to quantify over attributes of states.
Certain trajectory constraints require the ability to refer to values across states within the behavior.
For example, the specication of a decreasing oscillation requires the ability to compare the magnitude of a variable across states.
A limited form of rst order logic may provide a suciently expressive language while still giving satisfactory performance with respect to complexity.
Metric temporal logic - Due to the introduction of landmarks during the simulation process, QSIM behaviors are potentially innite structures.
Getting a denite answer for formulae such as (eventually p) is not always possible when potentially innite behaviors are encountered since it is always possible for p to occur in the future.
Metric temporal logic [1] allows the denition of a horizon for a temporal logic expression.
This would allow statements such as \within 50 seconds the tanks level reaches 70 inches."
This statements is only expressible within our logic using an external predened event.
Such an extension oers the modeler more exibility to express relevant constraints.
Functional envelopes - Semi{quantitative reasoning [3] within TeQSIM uses interval bounds and static functional envelopes for monotonic functions to derive quantitative information about a behavior.
NSIM [9] derives dynamic envelopes describing a variable's behavior with respect to time.
Currently, only interval information can be specied within TeQSIM trajectory constraints.
Extending the language to include information about bounding envelopes with respect to time would increase the precision of solutions computed by TeQSIM.
Finally, the current algorithm for incremental model checking is inecient if compared to the on{ the{y model checker algorithm developed by Bhat and colleagues [4].2 We plan to incorporate it within TeQSIM.
6 Conclusions  Qualitative simulation and temporal logic provide two alternative formalisms for reasoning about change  2 In all the examples we have run so far, the practical time{ complexity of a TeQSIM simulation is denitely dominated by other operations(like quantitativeinferences)rather than model checking.
across time.
TeQSIM integrates these two paradigms by incorporating trajectory information specied via temporal logic into the qualitative simulation process.
Behaviors that do not model the set of temporal logic expressions are ltered during simulation.
Numeric information specied within the TL expressions can be integrated into the simulation to provide a more precise numerical description for the behaviors which model these expressions.
The correctness of the TL{guide algorithm along with the correctness of QSIM guarantee that all possible trajectories of the modeled system compatible with the QDE, the initial state and the trajectory constraints are included in the generated behaviors.
In addition, the completeness of TL{guide ensures that all behaviors generated by TeQSIM are potential models of the trajectory constraints specied by the modeler.
Acknowledgments  We would like to thank Benjamin Shults for letting us use part of his program to implement TeQSIM, and to the Qualitative Reasoning Group for many fruitful discussions.
Thanks also to a careful anonymous referee.
QSIM and TeQSIM are available for research purposes via anonymous ftp at ftp.cs.utexas.edu in the directory /pub/qsim.
These and other results of the Qualitative Reasoning Group are accessible by World-Wide Web via http://www.cs.utexas.edu/users/qr.
This work has taken place in the Qualitative Reasoning Group at the Articial Intelligence Laboratory, The University of Texas at Austin.
Research of the Qualitative Reasoning Group is supported in part by NSF grants IRI-9216584 and IRI-9504138, by NASA grants NCC 2760 and NAG 2-994, and by the Texas Advanced Research Program under grant no.
003658-242.
References  [1] R. Alur and T. Henzinger.
Real{time logics: complexity and expressiveness.
Information and Computation, 104(1):35{77, 1993.
[2] M. Barbeau, F. Kabanza, and R. St-Denis.
Synthesizing plant controllers using real-time goals.
In Proc.
of IJCAI{95, pages 791{798.
IJCAI, Morgan Kaufman, August 1995.
[3] D. Berleant and B.J.
Kuipers.
Using incomplete quantitative knowledge in qualitative reasoning.
In Proc.
of the Sixth National Conference on Articial Intelligence, pages 324{329, 1988.
[4] G. Bhat, R. Cleaveland, and O. Grumberg.
Ecient on{the{y model checking for CTL*.
In Proc.
of Conference on Logic in Computer Science (LICS{95), 1995.
[5] G. Brajnik and D. J. Clancy.
Temporal constraints on trajectories in qualitative simulation.
Technical Report UDMI{RT{01{96, Dip.
di Matematica e Informatica, University of Udine, Udine, Italy, January 1996.
[6] E.A.
Emerson.
Temporal and modal logic.
In J. van Leeuwen, editor, Handbook of Theoretical Computer Science, pages 995{1072.
Elsevier Science Publishers/MIT Press, 1990.
Chap.
16.
[7] A. Farquhar and G. Brajnik.
A semi{quantitative physics compiler.
In Tenth International Conference on Applications of Articial Intelligence in Engineering, Udine, Italy, July 1995.
Presented also at the Eighth International Workshop on Qualitative Reasoning on Physical Systems, 1994, Nara, Japan.
[8] D. Jonescu and J.Y.
Lin.
Optimal supervision of discrete event systems in a temporal logic framework.
IEEE Transactions on Systems, Man and Cybernetics, 25(12):1595{1605, Dec. 1995.
[9] H. Kay and B.J.
Kuipers.
Numerical behavior envelopes for qualitative models.
In Proc.
of the Eleventh National Conference on Articial Intelligence.
AAAI Press/MIT Press, 1993.
[10] B.J.
Kuipers.
Qualitative Reasoning: modeling and simulation with incomplete knowledge.
MIT Press, Cambridge, Massachusetts, 1994.
[11] B.J.
Kuipers and B. Shults.
Reasoning in logic about continuous change.
In J. Doyle, E. Sandewall, and P. Torasso, editors, Principles of Knowledge Representation and Reasoning, San Mateo, CA, 1994.
Fourth International Conference (KR{94), Morgan Kaufmann.
[12] B. Shults and B. J. Kuipers.
Qualitative simulation and temporal logic: proving properties of continuous systems.
Technical Report TR AI96{244, University of Texas at Austin, Dept.
of Computer Sciences, January 1996.
[13] J.G.
Thistle and W.M.
Wonham.
Control problems in a temporal logic framework.
International Journal on Control, 44(4):943{976, 1986.
INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE  Logical time and temporal logics: Comparing UML MARTE/CCSL and PSL  NAdeg 7459 December 7, 2010  apport de recherche  ISRN INRIA/RR--7459--FR+ENG  ThA"me COM  ISSN 0249-6399  inria-00540738, version 1 - 7 Dec 2010  RASgis Gascon a FrASdASric Mallet a Julien DeAntoni  inria-00540738, version 1 - 7 Dec 2010  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL RASgis Gason , FrASdASri Mallet , Julien DeAntoni  ThA"me COM  SystA"mes ommuniants Projet AOSTE  inria-00540738, version 1 - 7 Dec 2010  Rapport de reherhe nAdeg 7459  Deember 7, 2010  22 pages  Abstrat:  The UML Prole for Modeling and Analysis of Real-Time and Embedded sys-  tems (MARTE) provides a means to speify embedded systems.
The Clok Constraint  Speiation Language (CCSL) allows the speiation of ausal, hronologial and timed properties of MARTE models.
Due to its purposedly broad sope of use, CCSL has an  expressiveness that an prevent formal veriation.
However, when addressing hardware  eletroni systems, formal veriation is an important step of the development.
The IEEE Property Speiation Language (PSL) provides a formal notation for expressing temporal logi properties that an be automatially veried on eletroni system models.
We want to identify the part of MARTE/CCSL amenable to support the lassial analysis methods from the Eletroni Design Automation (EDA) ommunity.
In this paper, we ontribute to this goal by omparing the expressiveness of CCSL and the Foundation Language of PSL.
We show that none of these languages is subsumed by the other one.
We identify the CCSL onstruts that annot be expressed in temporal logis and propose restritions of these operators so that they beome tratable in temporal logis. Conversely, we also identify the lass of PSL formulas that an be enoded in CCSL.
We dene translations between these fragments of CCSL and PSL using automata as an intermediate representation.
Key-words:  High-level design, Linear temporal logi, Language equivalene, Automaton  based approah  UnitAS de recherche INRIA Sophia Antipolis 2004, route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex (France) TASlASphone : +33 4 92 38 77 77 a TASlAScopie : +33 4 92 38 77 65  Temps logique et logiques temporelles: Comparaison de UML MARTE/CCSL et PSL RASsumAS :  Le prol UML MARTE (Modeling and Analysis of Real-Time and Embedded  systems) permet la spASiation de systA"mes embarquASs.
Le langage assoiAS CCSL (Clok Constraint Speiation Language) est ore la possibilitAS de spASier des propriAStASs ausales, hronologiques et temporelles sur les modA"les MARTE.
En raison de son large spetre d'appliations, CCSL a une grande expressivitAS qui empAShe l'appliation de ertaines tehniques de vASriation formelle.
Cependant, la vASriation formelle est une AStape importante du dASveloppement dans le domaine des hardware eletroni systems.
Pour e faire, le  standard IEEE PSL (Property Speiation Language) fourni des notations formelles pour l'expression de propriAStASs en logique temporelles qui peuvent AStre automatiquement vASriASe sur le modA"le du systA"me ASletronique.
Nous voulons identier le fragment de MARTE/CCSL suseptible de supporter les mASthodes d'analyses lassiques utilisASes dans la ommunautAS EDA (Eletroni Design Auto-  inria-00540738, version 1 - 7 Dec 2010  mation).
Dans e papier, nous ontribuons A  e but en omparant l'expressivitAS de CCSL et du fragment de PSL orrespondant A  la logique temporelle linASaire.
qu'auun de es langages n'est inlus dans l'autre.
Nous montrons  Nous identions les onstruteurs de  CCSL qui ne peuvent AStre exprimASs par les logiques temporelles propositionnelles et proposons en onsASquene des restritions de es opASrateurs de maniA"re A  les rendre exprimable dans PSL.
RASiproquement, nous identions la lasse de propriAStASs de PSL qui peuvent AStre odASes dans CCSL.
Nous dASnissons des tradution entre es deux fragment utilisant des automates omme reprASsentation intermASdiaire.
Mots-lASs :  Coneption haut niveau, Logique temporelle linASaire, Aquivalene de langages,  Approhe A  base d'automates.
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  3  1 Introdution The UML Prole for Modeling and Analysis of Real-Time and Embedded systems (MARTE [8a) provides a mean to speify several aspets of embedded systems, ranging from large software systems on top of an operating system to spei hardware designs.
The Clok Constraint Speiation Language (CCSL [1a) oers a general set of notations to speify ausal, hronologial and timed properties on these models and has been used in various subdomains [6, 5, 2a.
From this speiation, it is possible to simulate the behavior of a CCSL speiation at the model level.
CCSL has been formally dened; however, due to its broad sope of use CCSL has an expressiveness that an prevent formal veriation, sine the speied system an be, by intention, non-deterministi, innite, unbound.
Very wide speiations at the system level should be progressively rened into more preise desriptions down to a point where ode generation, shedulability, formal analysis beome possible.
MARTE/CCSL oers a support at all the renement steps.
In the domain of hardware eletroni systems, whih one of the subdomains targeted  inria-00540738, version 1 - 7 Dec 2010  by MARTE, formal veriation is an important step of the development.
To allow simulation and formal veriation of suh systems, the IEEE Property Speiation Language (PSL [10a) provides a formal notation for the speiation of eletroni system behavior, ompatible with multiple eletroni system design languages (VHDL, Verilog, SystemC, SystemVerilog).
Even though a MARTE/CCSL speiation overs a broad sope and several subdomains, the intent remains to oer exhaustive veriation apabilities when fousing on spei aspets within a subdomain.
When fousing on hardware eletroni systems, MARTE provides a support to apture strutural or behavioral, funtional or non-funtional aspets.
Its time model and CCSL , as part of MARTE, are natural andidates to express safety properties on MARTE models.
Two questions arise.
Is MARTE expressive enough to apture an abstrat view of hardware systems ?
Is CCSL expressive enough to express properties usually modeled in PSL ?
Some eorts has been made to answer the rst question [9, 13a.
We are addressing here the seond question.
The main ontribution of this paper is then the omparison of PSL and CCSL expressiveness.
The rst result is that none of these languages subsume the other one.
Consequently, we identied the CCSL onstruts that annot be expressed in temporal logis and proposed restritions to these operators so that they beome tratable in temporal logis. Conversely, we also identify a lass of PSL formulas that an be enoded in CCSL .
Then, We dene translations between these fragments of CCSL and PSL using automata as an intermediate representation.
These transformations make possible the ombined use of both formalisms to adequately address the right level, CCSL at the model level and PSL at the implementation level.
They also oer a way to provide an exhaustive analysis support for a lass of CCSL speiations.
The remaining of this paper is organized as follows.
In Set. 2 we introdue CCSL and PSL and determine whih kind of properties annot be expressed in eah language.
We  dene in Set. 3 the lass of Boolean automata whih is used in Set. 4 to dene translations between fragments of CCSL and PSL.
Set. 5 ontains onluding remarks and future work.
RR nAdeg 7459  R. Gason , F. Mallet , J. DeAntoni  4  2 Denitions of the languages We dene here the languages that we onsider in this paper and give rst omparisons related to their expressive power.
2.1 Clok Constraint Speiation Language CCSL is the ompanion language of MARTE UML prole for the design of embedded systems.
It ombines onstruts from the general net theory and from the synhronous languages.
CCSL oers a set of ausal and timed patterns lassially used in embedded systems.
More formally, the language CCSL is based on the notion of  loks  whih is a general name  to denote a totally ordered sequene of event ourenes, alled the Instants do not arry values.
CCSL denes a set of  lok relations :  instants  of the lok.  c1  is a sublok  inria-00540738, version 1 - 7 Dec 2010  r ::= c1 a c2 | c1 # c2 | c1 as c2 | c1 4 c2 .
where  c 1 , c2  represent loks of the system.
Informally,  c 1 a c2  means that  c2 , c1 # c2 that the instants of the two loks never our at the same time and c1 as c2 nth ourrene of c1 stritly preedes the nth ourrene of c2 for every n a Na .
The relation c1 4 c2 is the non strit version of the preedene relation.
of  that the  CCSL is a high level multilok language and the original semantis does not require totally ordered models.
However, at lower level or for simulation purposes, one needs to  represent the exeution as a totally ordered sequene. In this ontext, a possible semantis, introdued in [1a, identies loks with Boolean variables evolving along time .
In the  belongs to a set of propositions VAR and CCSL models VAR are nite or innite sequenes of elements in 2 .
The set of instants of the lok c  remaining, we will onsider that  c  c holds.
D be a CCSL model.
For suh a sequene, we denote in the following by |D| the length of D and we assume that |D| = D when D is an innite word.
We also use the notations D(i) th element of D and D i for the sux of D starting at the ith position.
To evaluate the for the i orresponds to the set of positions where the variable Let  satisfation of preedene relations, we need to know the number of ourrenes of the loks at eah position of  D.  We dene the funtion  DD  suh that for every  iaN  and  c a VAR  we  have  DD (c, i) = |{j a N  s.t.
ja$?i  and  c a D(j)}|.
The satisfation of CCSL relations is dened by:  A D |=ccsl c1 a c2  i for every  the oinidene relation  =  0 a$?
i a$?
|D|, if c1 a D(i) then c2 a D(i).
We also dene D |=ccsl c1 = c2 i D |=ccsl c1 a c2 and  suh that  D |=ccsl c2 a c1 .
A D |=ccsl c1 # c2  i for every  0 a$?
i a$?
|D|  we have  c1 6a D(i)  or  c2 6a D(i).
INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL A D |=ccsl c1 as c2 i for every 0 a$?
i a$?
|D| have DD (c1 , i) > DD (c2 , i).
A D |=ccsl c1 4 c2  i for every  0 a$?
i a$?
|D|  suh that  we have  DD (c1 , i) > 0  and  DD (c2 , i) > 0  we  DD (c1 , i) aL DD (c2 , i).
CCSL an also express more ompliated relations between loks by using  tions.
5  lok deni-  CCSL lok denitions allows one to dene a lok by ombination of other loks  given as arguments.
A lok denition is of the form  expression  c , e  where  c a VAR  and  e  is a  lok  dened by the following grammar:  e := c | e + e | e a e | e  e|e  e|e  e | e H bw | e $e n | e aSS e | e a" e  c a VAR, n a Na and bw : Na a B is a binary word.
The expressions e1 + e2 and e1 a e2 represent respetively the union and intersetion of e1 and e2 .
The strit and non strit sample expressions are denoted respetively by e1 e2 and e1 e2 .
The delay th ourrene of e .
operation e1 $e2 n is a variation of sampling that samples e1 on the n 2 The expression e1 e2 is the preemption (e1 up to e2 ), e H bw represents the ltering operation.
Finally, e1 aSS e2 (resp.
e1 a" e2 ) represents the fastest (resp.
slowest) of the loks that are slower (resp.
faster) than both e1 and e2 .
This orresponds to greatest lower bound  inria-00540738, version 1 - 7 Dec 2010  where  and lowest upper bound.
Given a lok expression  i  holds at position  of  D.  e  and a CCSL model  D  we note  D, i |=ccsl e i the expression e DD to expressions in  To dene this relation, we extend the funtion  a natural way:  DD (e, i) = |{j a N  s.t.
ja$?i  and  D, j |=ccsl e}|.
The satisfation relation for expressions is dened by:  A D, i |=ccsl c  i  c a D(i).
A D, i |=ccsl e1 + e2  i  A D, i |=ccsl e1 a e2  i  A D, i |=ccsl e1  i  e2  D, i |=ccsl e1 D, i |=ccsl e1  or  D, i |=ccsl e2 .
and  D, i |=ccsl e2 .
 D, i |=ccsl e2 ,   0 a$?
j < i D, k 6|=ccsl e2 .
there is  A D, i |=ccsl e1  e2  suh that  D, j |=ccsl e1  and for every  j < k < i  we have  suh that  D, j |=ccsl e1  and for every  j < k < i  we have  i   D, i |=ccsl e2 ,   RR nAdeg 7459  0 a$?
j a$?
i D, k 6|=ccsl e2 .
there is  R. Gason , F. Mallet , J. DeAntoni  6  A D, i |=ccsl e1 $e2 n   D, j |=ccsl e1   there is a position  k a {1, .
.
.
, n} e2  suh that  and  there are exatly  A D, i |=ccsl e1  0a$?ja$?i  n  i 1 , .
.
.
, i n (i n = i ) D, ik |=ccsl e2 .
distint positions  j < ik a$?
i  we have  and  suh that for every  i   D, i |=ccsl e1 ,   for every  j<i  A D, i |=ccsl e H bw  D, j 6|=ccsl e2 .
we have  i  inria-00540738, version 1 - 7 Dec 2010   D, i |=ccsl e  bw (DD (e, i)) = 1.
A D, i |=ccsl e1 a" e2  i either   DD (e1 , i) > DD (e2 , i) and D, i |=ccsl e1 ,   or  DD (c1 , i) < DD (c2 , i)  and  D, i |=ccsl e2 ,    or  DD (e1 , i) = DD (e2 , i)  and  D, i |=ccsl e1  A D, i |=ccsl e1 aSS e2  and  D, i |=ccsl e2 .
i either   DD (e1 , i) > DD (e2 , i) and D, i |=ccsl e2 ,   or  DD (e1 , i) < DD (e2 , i)  and    or  DD (c1 , i) = DD (c2 , i)  and we have  D, i |=ccsl e1 , D, i |=ccsl e1  or  D, i |=ccsl e2 .
A CCSL speiation is a list of denitions and relations seen as a onjuntion of onstraints.
We an represent it by a triple  A C a VAR A Def A Rel A model  A  hC, Def , Reli  suh that  is a set of loks,  is a set of denitions, is a set of relations.
D  over  2C  satises the speiation i  for every denition  c , e  in  Def  we have  c a D(i)  i  D, i |=ccsl e,  INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL A  every relation in  Rel  is satised by  7  D.  From the basis CCSL language, one an dene other expressions and relations.
For  instane, the following expressions will be useful in the following:  A c1 a c2  is the dierene of loks  enoded with the denition  A c $c n  c1  and  c1 , c + c2  c2 .
The denition  and the relation  c , c1 a c2  an be  c # c2 .
is a partiular ase of delay expression that we denote  c $ n.  This expression  represents the usual synhronous delay operation.
The resulting expression starts at the  A  nth  ourrene of  Alternane relation  inria-00540738, version 1 - 7 Dec 2010  ca,1 , c1 $ 1.  c  and then oinides with  c1 az= c2  Similarly,  c.  is dened by the relations  c1 =az c2  is dened by  c1 4 c2  c1 4 c2 and  and  c2 as ca,1  where  c2 as ca,1 .
2.2 Property Speiation Language The IEEE standard PSL [10a is a textual language to build temporal logi expressions.
PSL assertions are used for instane in hadware design and they an be validated by modelheking or equivalene heking tehniques.
Compared with the lassial linear temporal logi LTL, PSL provides sugaring onstruts to build expressions in an easier and more onise way.
However PSL is as expressive as LTL.
As it would be tedious to onsider the dierent sugaring operators of PSL in formal reasoning, we use in this paper the minimal ore language dened in [3a.
Let  VAR  be a set of propositions (Boolean variables) that aims at representing signals  of the system.
PSL atomi formulas are alled  Sequential Extended Regular Expressions  (SERE).
SEREs are basially regular expressions built over the Boolean algebra:  b ::= x | x | b aSS b | b a" b where  x a VAR  is a Boolean variable.
We also onsider the standard operators  1  a  and  a  that an be dened from the grammar above .
The set of SEREs is dened by:  r ::= b | r AV r | r aS r | ra where  b  is a Boolean formula.
onatenation,  r1 aS r2  The operators have their usual meaning: r1 AV r2 is the ra is the Kleene star operator.
From these regular  the union and  expressions, PSL linear properties  2 are dened by:  D ::= r | D aSS D | AZD | XD | DUD | r O D. 1 x a y is equivalent to x a" y 2 PSL standard also denes a  RR nAdeg 7459  and x a y to (x a y) aSS (y a x).
branhing time part that we do not onsider here.
R. Gason , F. Mallet , J. DeAntoni  8  where  r  is a SERE.
The operators  X  (next) and  U (until) are the lassial temporal logi FD aA a$?UD (eventually) and GD aA AZFAZD  operators.
We also use the lassial abbreviations  r O D is a sux onjuntion operator meaning that there must r and that D must be satised at the position orresponding  (always).
The formula  exist a nite prex satisfying to the end of this prex.
The semantis of PSL is dened in suh a way that properties an be interpreted over innite words as well as nite or trunated words.
This is important for some appliation domains of PSL suh that simulation or bounded model-heking.
Similarly to CCSL, the VAR that represents the set models of PSL are nite or innite sequenes over elements of 2 of variables that holds at eah position.
VAR and p a VAR, we note For every X a 2  X |=b p i p a X |=b is obvious.
The remaining of the Boolean satisfation relation (possibly empty) prex of the model.
So  D  and  X |=b p  i  p 6a X .
SEREs refer to a nite  is supposed to be nite in SERE satisfation  relation (whih is not the ase in PSL satisfation relation).
The SERE satisfation is dened  inria-00540738, version 1 - 7 Dec 2010  by indution as following:  A D |=re b  i  |D| = 1  A D |=re r1 AV r2  and  D(0) |=b b,  i there exist  A D |=re r1 aS r2  i  D |=re r1  A D |=re ra i either D = CT a and D2 |=re r .
D1 , D2  and  suh that  D = D1 D2  D1 |=re r1  and  and  D2 |=re r2 .
D |=re r2 .
or there exist  D1 , D2  suh that  D1 6= CT, D = D1 D2 , D1 |=re r  Finally, the satisfation of PSL properties is dened as following.
A D |=psl AZD  i  D 6|=psl D,  A D |=psl D1 aSS D2 A D |=psl XD  i  i  D |=psl D1  |D| > 1  and  and  D |=psl D2 ,  D 1 |=psl D,  A D |=psl D1 UD2 i j have D |=psl D1 ,  there is  A D |=psl r O D i and D2 |=psl D,  there is a nite prex  A D |=psl r r O a$?.
0 a$?
i < |D|  i for every nite prex  D1  suh that  of  D1 D  of  D  D i |=psl D2 and  D2  and for every  suh that  there is a nite word  D2  0a$?j<i  we  D = D1 D2 , D1 |=re r suh that  D1 D2 |=re  The addition of SEREs in PSL does not add expressiveness to the lassial temporal logi LTL.
Indeed, SEREs an be translated into LTL formulas.
However, this would imply an exponential blowup of the size of the formulas.
INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  9  2.3 Comparing PSL and CCSL Sine CCSL and PSL share ommon models, we an ompare their expressive power.
Let be a CCSL speiation over a set of variables of variables  VD a VAR.
D is  and every model of  S S.  We will say that also a model of  VS a VAR  and  D  is enoded by (or simulated by)  The onverse simulation relation is a bit dierent.
S  a PSL formula over a set  D  i  VS a VD  CCSL models have the properties  that one an add an unbounded amount of empty states between two relevant states and left the satisfation unhanged.
This an easily be proved by indution on the struture of a CCSL speiation.
Lemma 1. i a$?
|D|  S  Let  the model  be a CCSL speiation.
For every model  Da,  D  satisfying  S  and every  0a$?
dened by  inria-00540738, version 1 - 7 Dec 2010  D a, (j) = D(j) for every j < i D a, (i) = a D a, (j) = D(j a 1) for every i < j a$?
|D| + 1 also satises  S.  This property is a onsequene of the multilok aspet of CCSL.
Even with the semantis we have introdued, it is not possible to ompletely link the exeution of a CCSL speiation to a global lok. However, the states where no loks hold are irrelevant in CCSL point of view as they do not make the system evolve.
So it is not really a problem to disard them.
Atually, this is what is done in the CCSL simulator TimeSquare.
We will say that simulated by of  S  i  VD a VS  and every model of  S with no irrelevant states  D  is  is also a model  D. By examining the denitions PSL and CCSL, we an already make the following obser-  vations.
Some CCSL relations or expressions impliitly introdue unbounded ounters.
For  c1 and c2 (or at least the c1 4 c2 .
The orresponding  instane, one have to store the number of ourrenes of the loks dierene between them) to enode the preedene relation  language is made of all the words suh that every nite prex ontains more ourrenes of  c1  than  c2 .
Suh a language is neither regular nor  D -regular  and annot be enoded in  PSL whih is as expressive as LTL and regular expressions.
The same remark holds for the expressions  c1 a" c2  and  c1 aSS c2 .
On the other hand, the dierent CCSL relations and expressions only states safety onstraints.
As a speiation is a onjuntion of suh onstraints the result is always a safety property.
CCSL annot express liveness like the reahabily property  Fp.
A similar problem  ours for the next operator in ase of nite exeutions.
There is no way to express that the model must have a next position whih an be stated by  Xa$?
in PSL.
To summarize, the  preliminary omparison of expressiveness of CCSL and PSL gives the following results.
Lemma 2.
(I) There are PSL formulas that annot be enoded in CCSL.
(II) There are CCSL speiations that annot be enoded in PSL.
RR nAdeg 7459  R. Gason , F. Mallet , J. DeAntoni  10  It is now lear that PSL and CCSL are not omparable in their whole denition.
However, we will see in the remaining of this paper that we an dene large fragments of these languages that an be enoded in eah other.
To that aim we will rst introdue a intermediate lass of automata well tted to dene translations between these fragments.
3 Boolean automata Translating diretly PSL properties into CCSL is not obvious.
For example, let us onsider the following PSL formula:  G(p0 a AZ(p1 Up2 )).
One an try to translate this property by onsidering its general meaning whih is there is always  p1  in an interval starting with  p0  and ending with  p2 .
It is more diult to dene a  modular approah by omposing atomi translations from PSL operator to CCSL.
We use an automaton based approah. We introdue in this setion a lass of automata manipulating  inria-00540738, version 1 - 7 Dec 2010  Boolean variables that we will use to establish relations between PSL and CCSL fragments.
3.1 Denition We onsider automata that handle propositional variables in  VAR.
The transitions of these  automata are labeled by Boolean formulas interpreted like guard.
automaton A Q  is a struture  A = hQ, q0 , F, A, V, I'i  is a set of states and  A F aQ  and  A V a VAR  AaQ  q0 a Q  Formally, a  Boolean  suh that:  an initial state,  are respetively the set of nal and aepting states,  is a set of propositions,  A I' : Q A Bool (V ) A Q formulas over VAR.
is a transition relation where  Bool (V )  is the set of Boolean  We use the denitions of Set. 2.2 for Boolean formulas.
A Boolean automaton is deterministi i for every state in Q there do not exist two outgoing transitions labeled with a, suh that D aSS D is satisable.
D  and  Da,  A onguration of A is a pair hq, Xi omposed of a state in Q and a subset of V .
We D D note hq, Xi a a hq a, , X a, i i there is a transition q a a q a, suh that X |=b D. A run of A is a V sequene D : N a (Q A 2 ) suh that D(0) is of the form hq0 , X0 i (one starts in the initial Di a D(i + 1).
A nite run is aepting state) and for every i a N, there exists Di suh that D(i) a i it ends in a nal state.
An innite run is aepting i it visits innitely often an aepting state (BAzhi ondition).
The language aepted by 2V orresponding to aepting runs.
A  in made of the words on the alphabet  Boolean automata an be omposed as following.
Consider two automata  A2 = hQ2 , (q0 )2 , V2 , I'2 i. hQ, q0 , V, I'i suh that: and  The produt automaton  A = A1 A A2  A1 = hQ1 , (q0 )1 , F1 , V1 , I'1 i  is the struture  INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  11  A Q = Q1 A Q2 A {0, 1} where the last omponent of eah state (in {0, 1}) is only needed for the BAzhi aeptane ondition,  A q0 = h(q0 )1 , (q0 )2 , 0i, A F = F1 A F2 A {0, 1}  and  A = Q1 A A2 A {1},  A V = V1 aS V2 ,  inria-00540738, version 1 - 7 Dec 2010  A  For every  hq1 , q2 , ii  and  hq1a, , q2a, , ia, i  D1  Q  in  D2    there exist    if  i=0  then  ia, = 1  i  q1 a A1 ,    if  i=1  then  ia, = 0  i  q2 a A2 .
a q1a, q1 a  and  a q2a, q2 a  we have  s.t.
D  D  hq1 , q2 , ii a a hq1a, , q2a, , ia, i  is equivalent to  i  D1 aSS D2 ,  Note that the last omponent of eah state is not needed when every state is aepting (A1  = Q1  and  A2 = Q2 ),  whih will be the ase in the following.
3.2 CCSL and Boolean automata Sine CCSL express only safety, the aeptane ondition of automata annot be enoded.
However, if every run is aepting we an enode a deterministi Boolean automaton into a CCSL speiation.
Lemma 3.
Every deterministi Boolean automaton suh that every exeution is aepting  an be simulated by a CCSL speiation.
Proof.
Consider a Boolean automaton  A = hQ, I, V, I'i.
The sets of aepting and nal  states are not needed sine every exeution is aepting.
So, we forget them here.
We dene the set of loks denitions.
C = V a Q.
To enode  A,  we need the following CCSL  We dene a global lok and a lok orresponding to the set of states  Q  as  following:  (1) Glob , c  X  cQ ,  and  caC where  P  caX  c  lok  Iq  X.  X |=b D.  X X  qa, a aq  RR nAdeg 7459  X.
Similarly, we will note  For ease of presentation, we note For every state  orresponding to the inoming transitions of  (2) Iq ,  q  qaQ  is the CCSL union of all the loks in  CCSL intersetion of all the loks in D is a transition q a a q a, in A suh that  X  qa, a (  Y  paX  p) a (  X  p6aX  qa a  q a Q \ {q0 },  q:  p) .
X  Q  caX c the a, q i there  we dene the  R. Gason , F. Mallet , J. DeAntoni  12  Now we build the set of CCSL relations.
First we express that at every position in the run, exatly one state of the automaton holds.
This orrespond to the relations  (3) cQ = Glob  q # qa,  and  for every  q, q a, a Q (q 6= q a, ).
We also impose that the global lok always oinides with a valid transition in order to avoid unexpeted behaviours:  (4) Glob =  X  IQ .
qaQ The transition relation is suh that every state alternates with its inoming transitions.
This means that for every  qaQ q0 az= Iq 0  (5) The relation is symmetri for  q0  Iq =az q.  and  sine the exeution starts in this state.
The alternane is  inria-00540738, version 1 - 7 Dec 2010  not strit on the side of the inoming transition sine it is allowed to return to the same step (loops).
D i a N,  We have to show that a model  D of A c a Xi .
run  suh that for every  satises the CCSL speiation obtained i there is a for every  First we observe that for any model  q a D(i + 1)  for every  i a N.  D  and omplete (f  (2)).
Iq  we have  c a D(i)  i  D(i) = hqi , Xi i  satisfying the CCSL speiation, if  The alternane relations allows a lok  has oured between the last ourene of denitions of the dierent  caV  q  q  and the urrent position (f  and  Iq a D(i) then Iq  to our only if  (5)).
However, the  A whih is deterministi Iq belongs to D(i) for every i a N. So, to D(i + 1) is q .
By (3), exatly one  are dened w.r.t.
transition relation of  This implies that exatly one  Iq a D(i) the only element of Q that an belonb element of Q must hold at eah position.
This onlude  if  the demonstration.
We proeed by indution on the position of the sequenes.
Suppose that we are given  D).
For every i a N we note D(i) = hqi , vi i.
We show for every i a N position j < i and variable c a VAR we an build D (resp.
D ) suh that (resp.
A c a D(j) A  and  i  D  that for every  c a Xj ,  qi + 1 a D(i + 1)  i  qi + 1  is the state of  D(i + 1).
Q that an belong to D(0) is q0 .
Indeed, q a Q from ouring beause of alternane A is always q0 .
At the begining of any model, the only lok in no lok  Iq  has oured whih prevent the other  relations (see Now let  D  until position  (5)).
Similarly, the initial sate of  be a model of the CCSL speiation.
We suppose that the property holds  i  and that we have  qi a D(i)  and the state of  D(i) a,  is  qi .
Sine the transition D suh that q a a q a, and  relation is omplete and deterministi, there is a unique q a Q a, a, As a onsequene, Iq a D(i) whih implies that q a D(i + 1) as we shown before.
D a q a, and setting c a Xi We an do the orresponding move in A by hoosing the transition q a  D(i) |= D.  INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  13  c a D(i) aS V .
By indution, one an build a run D of A suh that for every i a N, for c a VAR we have c a D(i) i c a D(i).
Conversely, let D be a run of A.
We suppose that the property holds until position i, D(i) = hqi , vi i and qi a D(i).
The demonstration is symmetrial.
There is a unique transition i  every  D  a qi+1 suh that vi |= D beause the transition relation is deterministi and omplete.
qi a Let set D(i) suh that for every c a VAR we c a D(i) i D(i) = hqi , vi i and vi (c) = a$?.
By onstrution, we must have Iq i+1 a D(i) and so qi+1 a D(i + 1).
Thus, one an build by indution D verifying the property.
The onverse translation is not possible.
CCSL speiations annot be enoded by  Boolean automata for the same reasons that prevent enoding CCSL speiations into PSL properties.
Some relations or operators like preedene annot be enoded by using nite state systems (see Set. 2.3).
3.3 PSL and Boolean automata inria-00540738, version 1 - 7 Dec 2010  It is well known that one an build a nite automaton or a BAzhi automaton that aepts respetively the nite and innite models of a given PSL formula.
Given a PSL formula  D,  the onstrution dened in [3a an easily be adapted to build a Boolean automata aepting the set of models of  D.  This onstrution itself is a slight extension of the automaton for LTL  originally dened by [12a.
We do not develop this onstrution now sine the onstrution in the proof of upoming Lemma 6 will follow the same main steps.
Lemma 4.
From any PSL properties  language aepted by  A  D  one an build a Boolean automata  is exatly the set of models of  AD  suh that the  D.  The onverse translation is easy sine the denition of LTL is inluded in PSL.
By using the onstrution in [11a one an enode the behaviour of a Boolean automaton into a LTL formula.
Lemma 5.
From any Boolean automaton  set of models of  DA  A,  one an build a PSL formula  is exatly the set of runs of  DA  suh that the  A.
4 Translations between CCSL and PSL fragments We dene in this setion large fragments of CCSL and PSL that an be simulated in eah other.
We dene the translations between these fragments using intermediate Booelan automata enoding.
4.1 From PSL to CCSL Lemma 3 states that Boolean automata an be enoded in CCSL when every run is aepting.
Thus we restrit ourselves to the lass of PSL formulas that an be translated into this sublass of Boolean automata.
We onsider the safety fragment of PSL dened similarly to [4a by restriting the use of negations.
A PSL formula belongs to  RR nAdeg 7459  safety PSL  formulas  R. Gason , F. Mallet , J. DeAntoni  14  i (S1) subformulas of the form  D1 UD2  and  r OD  never our under an even number of  negations, and (S2) SEREs never our under an odd number of negations.
Note that one an dene safety fragments of PSL by restriting temporal modalities but this one is more general.
For the nite ase, we also have to restrit the denition of the next operator to its weak variant (s.t.
the formula is satised also if the model has no next position).
Lemma 6.
For every property in safety PSL, one an build an automaton suh that every  exeution is aepting.
Proof.
In [3a is desribed a way to build automata from PSL properties.
We reall below  the main steps of this onstrution and show that the restritions we have made allow us to obtain an automaton suh that every run respeting the transition relation is aepting.
inria-00540738, version 1 - 7 Dec 2010  First, one an easily build a nite automaton aepting the set of nite words that orresponds to a given SERE.
Indeed, SERE are essentially regular expressions.
So we f VAR assume that for every SERE r there is a nite automaton Ar = h2 , Qr , Ir , Fr , I'rf i suh that D a L(Ar ) i D |=re r. From this automaton one an build a BAzhi automaton Ar = h2VAR , Qr , Ir , Qr , Qr , I'r i suh that D a L(Ar ) i D |=psl r. The transition relation I'r f is obtained by adding the following rules to I'r :  hqf , X, qf i a I'r  for every  qf a Fr  and  X a 2VAR .
This automaton has only aepting and nal states.
Indeed, aording to PSL satisfation relation, every prex that an be extended to an expression satisfying the SERE must be aepted.
Then we proeed by indution on the struture of the formula.
The result of the onstrution is an alternating automata.
This allows running automata for the SERE atomi formulas in parallel of the temporal logi part.
Then, it is known that an alternating BAzhi automaton an be translated into a standard BAzhi automaton [7a.
The base ase is given above.
So we suppose that for every subformula D of D we an build AD = h2VAR , QD , ID , AD , FD , I'r i suh that suh that every run is aepting  an automaton  D a L(AD ) i D |=psl D .
There are atually two onstrutions beause the ase where D is of the form AZ(r O D) must be treated separately.
In that ase, AD is built f VAR , Qr , Ir , Fr , I'rf i and AD = h2VAR , QD , ID , QD , QD , I'D i from the nite automaton Ar = h2 and  the formula as follows.
A  the set of states is the union of  A  the set of initial states is  A  the set of nal states is the union of  A  the set of aepting states is the union of  Qr  and  QD  and an additional state  qt ,  Ir , qt , Q r  and  FAZD ,  qt , Q r  so  FD = QD  and  AAZD ,  beause  so  FAZD = QAZD ,  AD = QD  beause  AAZD = QAZD ,  INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL A  For every  qf a Fr  and  X a 2VAR  15  we have  ^  I'(qf , X) =  q a, aSS I'AZD (q0 , X)  qa, aI'r (q,X) where  A  q0  For every    if  is the initial state of  q a Qr \ Fr  I'r (q, X)  and  AAZD .
X a 2VAR  is dened then  I'(q, X) =  ^  qa,  qa, aI'r (q,X) ,  inria-00540738, version 1 - 7 Dec 2010    I'(q, X) = qt ,  otherwise  A  for every  A  nally  q a QAZD  the transition relation oinides with  I'(qt , X) = qt  for every  I'AZD ,  X a 2VAR .
Note that we only have to onsider negated ourrenes of  rOD  by denition of the safety  fragment.
For the other ases,  A  is dened as follows.
The set of states is omposed of  A  the set of states of the automata  A  the set of states of the automata  A  the set of subformulas of  The initial state is  A I'(p, X) = a$?
D.  i  D  Ar  for every SERE  AAZ(rOD)  for every subformula  I'  q0r  is the initial state of  Ar .
A I'(D1 aSS D2 , X) = I'(D1 , X) aSS I'(D2 , X).
A I'(D1 a" D2 , X) = I'(D1 , X) a" I'(D2 , X).
A I'(AZD, X) = I'(D, X).
A I'(XD, X) = D. A I'(D1 UD2 , X) = I'(D2 , X) a" (I'(D1 , X) aSS D1 UD2 ).
Where the overlined expressions are interpreted as follows:  RR nAdeg 7459  D,  rOD  AZAZD  is dened reursively:  p a X. where  ourring in  and their negation (we identify  The transition relation  A I'(r, X) = I'(q0r , X)  r  with  ourring in  D ).
D,  R. Gason , F. Mallet , J. DeAntoni  16  A a aSS b = a a" b, A a a" b = a aSS b, A I'(q0AZr , X) = I'(q0r , X)  where  AZ(rOD)  A I'(q0rOD , X) = I'(q0 A D = AZD ,  q0r  , X)  is the initial state of the automaton  where  AZ(rOD)  q0  is the initial state of  for every subformula (we still identify  AZAZD  with  Note that beause we onsider the safety fragment the ases  Ar ,  AAZ(rOD) ,  D ).
I'(q0r , X) and I'(q0rOD , X) never  our (see restritions of negation).
In the general onstrution, the aepting states would be those of the form the states of the automata  AAZ(rOD)  and  Ar .
AZD1 UD2  or  However, for formulas in the safety fragment  the onstrution above is partiular.
For every run of the automaton obtained it annot be the ase that an innite branh does not enounter one of those nal states.
inria-00540738, version 1 - 7 Dec 2010  We proeed by indution.
If we are in a state of the form in the ases  r  or  are aepting.
property.
AZ(r O D)  p, the branh is nite.
D and its I'(D, X) goes  Now we suppose that every subformula of  In almost all ases, the dierent branhes of  strit subformulas of  D.  Similarly,  we are done sine all the states of the orresponding automata negation satisfy the to states labeled by  In that ases we an use the indution hypothesis to onlude.
The  only remaining ase is when  D  is of the form  D1 UD2  or  AZD1 UD2 .
The rst ase annot arise  sine we are in the safety fragment.
In the seond ase the transition rule is the follows:  I'(AZD1 UD2 ) = I'(D1 UD2 ) = I'(AZD2 , X) aSS (I'(AZD1 , X) a" AZ(D1 UD2 )).
We an use the indution hypothesis on the branh orresponding to  D2 .
For the other  branh, we an prove by indution that  A  either we reah a position when  AZD2  and  AZD1  hold and then we an use the indution  hypothesis,  A  or  AZ(D1 UD2 )  So we an set  is visited innitely often.
Sine this state is aepting we are also done.
AD = FD = QD .
By onstrution, every state of the alternating BAzhi automaton obtained is nal and aepting.
If we use the powerset onstrution of [7a to build an equivalent non-alternating automaton, the sets of nal and aepting states are also equal to the whole set of states.
So every run of the resulting automaton is aepting.
The proof is given in Appendix  ??
is a variant of the onstrution in [3a.
We just have  to ensure that every exeution is aepting.
By Lemmas 6 and 3 we an enode every safety PSL formula into CCSL speiations.
Lemma 7.
Every safety PSL formula an be enoded by a CCSL speiation.
INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  17  p0 p0 aSS p1 aSS p2  p1 aSS p2  q0  q1 p1  p0 aSS p1 Figure 1: Boolean automaton for  G(p0 a AZ(p1 Up2 ))  For instane, Figure 1 represents the automaton orresponding to the formula  AZ(p1 Up2 )) after simpliations.
This automaton hV, Def , Reli suh that V = {p0 , p1 , p2 } and  inria-00540738, version 1 - 7 Dec 2010  Def =  Rel =  dLa dL' dL' dL' dL' dL,  Q , q0 + q1  Glob , Q + p0 + p1 + p2 ,  (q0 a p0 ) + (q0 a p0 a p1 ) + (q1 a p1 ) , ,  Iq0 , dL' dL' dL' dL' dLl Iq , ((q a p ) a (p + p )) + (q a (p + p )) 0 1 0 1 2 1 0 1 (  Glob = Q  ,  q0 # q1  q0 =az Iq0  ,  G(p0 a  orresponds to the CCSL speiation  ,  Glob = Iq0 + Iq1 ,  Iq1 az= q1  dLz dL' dL' dL' dL' dL"  ,  dL' dL' dL' dL' dLz  )  .
4.2 From CCSL to PSL To obtain a fragment of CCSL that an be enoded in PSL, we restrit the preedene relations and the operators  c 1 a" c2  and  c1 aSS c2 .
We dene a preedene relation suh that  asn and 4n where DD (c2 , i) < DD (c1 , i) a$?
the advane of the fastest lok is bounded.
We denote these relations  n a N.  A model  D  satises  c 1 as n c2  i for every  iaN  we have  4n is dened similarly with non strit inequalities.
We dene c1 aSSn c2 and c1 a"n c2 that restrit the dierene of the loks c1 and c2 to be bounded by n. Suh expressions are partiular sine they also imposes impliit onstraints  D(c2 , i) + m.  The relation  similar variants  on the parameters.
However, this is the most onvenient way of dening a syntati fragment of CCSL that an be translated into CCSL.
We all  bounded CCSL  the language obtained by replaing in CCSL the preedene  relations, greatest lower bound and lowest upper bound operators by their bounded variants.
This language is a fragment of CCSL.
Indeed, the operators an be dened in full CCSL:  A c1 as n c2  is equivalent to  preedene ase is similar.
RR nAdeg 7459  c1 as c2  and  c2 4 ca,1  where  ca,1 , c1 $ n.  Non strit  R. Gason , F. Mallet , J. DeAntoni  18  A c , c1 aSSn c2  c , c 1 a" c2  is equivalent to the onjuntion of  with the relations  c1 4 ca,2 and c2 4 ca,1 where ca,1 , c1 $ n and ca,2 , c2 $ n. This equivalene make lear the relations impliitly imposed on the parameters of the expression.
The operator  c1 a"n c2  an be dened similarly.
These restritions allow us to establish the following results.
Lemma 8.
(I) Every bounded CCSL speiation an be enoded by a Boolean automata.
(II) Every bounded CCSL speiations an be enoded by a PSL formula.
Proof.
(I) We proeed by indution on the struture of CCSL speiations.
As every state in the resulting automata are nal and aepting, we do not mention them.
First, let us onsider CCSL relations.
For every Boolean formula  inria-00540738, version 1 - 7 Dec 2010  Boolean automaton with a self loop labeled by  A  The subloking relation  A  Similarly, the exlusion relation  A  The bounded preedene relation  n  c 1 a c2  D  we denote by  an be enoded by  c1 # c2  that store the advane of  c1 on c2 .
c2 is true  an be enoded by an automaton with  So one needs to move to the next state when  c1 aSS c2  0  c1 aSS c2  1  0  c2 aSS c1 c1 aSS c2  c 1 as 3 c2  c1 4n c2 is similar an additional loop labeled c1 aSS c2 1 bak to state 0.  and a transition from state  A denition of the form  Ae  3  c1 aSS c2  Figure 2: Boolean automaton for  on state  c1 aSS c2  2  c1 aSS c2  The onstrution for the relation  is  c1 aSS c2  c2 aSS c1 c1 aSS c2  c1  n = 3. c1 aSS c2  If  B(c1 a"c2 ) .
and to stay in the same state when both (or none)  c1 aSS c2  A  B(c1 a"c2 ) .
an be enoded by  c 1 as n c2  are true.
Fig.
2 is the automaton for  where  the single state  states.
These states simulate the inrementation and derementation of a ounter  true, to move bak when  A  BD  D.  c , e  an be enoded by the produt automaton  Ae A Bcae  is dened below.
e is of the form e1 + e2 B((e1 a"e2 )ae) .
then  Ae  an be obtained by making the produt of  Ae1 , Ae2  and  A  The automaton for  e1 a e2  is built similarly by replaing the third automaton by  B((e1 aSSe2 )ae) .
INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL A  19  e2 is a bit more omplex.
Consider two opies A and Aa, of the a, a, produt automaton Ae1 A Ae2 .
We denote by q0 , q1 .
.
.
the states of A and q0 , q1 .
.
.
a, a, the states of A suh that qi and qi represent the same state in the dierent opies.
The enoding of  e1  To build the automaton Ae we use A to simulate the part where e1 has not ourred a, yet and A the part where e1 has ourred and we wait for the next ourrene of e2 .
a, So, we have to move from A to A when e1 is true.
Then we move bak to A and set  e  to true when  transformations on  (a)  (aa)  e2 is true.
A and Aa, .
D a qj in A we replae the label by For every transition qi a DaSSe1 aSSe a, transition qi a aaaa qj from A to Aa, .
D  a qja, qia, a  For every transition  a, DaSSe2 aSSe transition qi a aaaa  inria-00540738, version 1 - 7 Dec 2010  This automaton is obtained by making the following  qj  from  in  Aa,  we replae the label by  a,  to  A.
A  D aSS e1 aSS e  and add the  D aSS e2 aSS e  and add the  Obviously if the Boolean formula of a label redues to false then the orresponding transition is removed (or not added).
A  The enoding of  e1  e2  e2 .
The dierene is that when  are true then  e is also true and we stay in e1 is true and e2 is false.
So  is very lose to the ase  we are in the rst opy and both  e1  and  e2  e1  the same opy.
We only move to the seond opy when the step  (a)  has to be replaed by  D a qj in A we replae the label by For every transition qi a DaSSe1 aSSe2 aSSe a, DaSSe1 aSSe2 aSSe transitions qi aaaaaa a qj and qi aaaaaaa qj .
D aSS e1 aSS e  and add the  two  A  The enoding of  e1 $e2 n  holds we have to wait for opies of  Ae1 A Ae2 .
e1 n+1  is a generalization of the previous onstrution.
When  n  positions where  e2  holds.
This an be done with  Another point of view is that a ounter is enoded in the states of  the resulting automaton.
In the same way than the onstrution for the ase  e1  e2  we add transitions between the dierent opy as following:    from the rst opy to the seond when    from the  ith    from the  n+1th to the rst when e2 ours and this orresponds to the transitions  where  A  e  to the  i + 1th  when  e2  e1  ours,  ours for  2 a$?
i a$?
n + 1,  must our.
expression an also be enoded  e1 H bw .
Suppose that bw = u AV v D .
The similarly with |u| + |v| opies of Ae1 .
Eah opy is  bw  in a natural way.
The transition from a opy to the  Now we onsider the ltering operation assoiated with positions in  RR nAdeg 7459  R. Gason , F. Mallet , J. DeAntoni  20  next one is done when  e1  holds and after the last opy we jump to the  one (periodi part).
The variable position in  A  bw  is equal to  e  ours i  e1     e is of the form e1 e2 an easily A = Ae1 A Ae2 A B((e1 aSSe2 )ae) as following.
We add a sink state  qs  with a loop  We replae every transition DaSSe2 a qs .
transition q aa  D  qa a qa,  The way of enoding  e1 aSSn e2  be obtained from the produt  e  qs a a qs .
in  A (q, q a, 6= qs )  This operation prevents future ourrenes of  A  ours in a opy whose orresponding  1.
The automaton when automaton  e  as soon a  inria-00540738, version 1 - 7 Dec 2010  2n + 1  DaSSe2  by  q aaa q a,  e2  has oured.
states.
The expression  e  c1  n = 2.  c1 aSS c2 aSS e  c2  c1 aSS c2 aSS e c1 aSS c2 aSS e  a2  c1 aSS c2 aSS e  The ase  e  and  e  e1 a"n e2  c2 .
So  c2 aSS c1 aSS e c1 aSS c2 aSS e  is quite similar.
For  c1 aSS c2 aSS e  1  n=2  2 c2 aSS c1 aSS e  c1 aSS c2 aSS e  Figure 3: Boolean automaton for  A  is greater than  c1 aSS c2 aSS e  0 c2 aSS c1 aSS e  c1 aSS c2 aSS e  c1  c1 aSS c2 aSS e c1 aSS c2 aSS e  a1 c2 aSS c1 aSS e  To do this we  is true.
The left part is symmetrial.
c1 aSS c2 aSS e c1 aSS c2 aSS e  c2 .
The right part (positive labels)  orresponds to positions where the number of ourrenes of is true in this part when  and  holds when the variable that has the less  ourrenes holds.
Fig 3 is the automaton for  c  and we add the  is lose to the bounded preedene relation sine we  need to store the dierene between the ourrenes of need here  (|u| + 1)th  c1 aSS c2 aSS e  c1 aSS2 c2  the automaton is obtained by swithing  in the transitions that are not loops in Fig.
3.
The global automaton orresponding to a given CCSL speiation is the produt of all the automata orresponding to the dierent denitions and relations.
The set of models  orresponding to suh an automaton is the same than the set of models of the CCSL speiation.
A areful analysis of the dierent steps shows that this onstrution stritly follows CCSL semantis.  (II)  This seond part is a diret onsequene of  (I)  and Lemma 5, even if the PSL  formula obtained by omposing the two transformations is not minimal.
We an dene  a diret translation from bounded CCSL to PSL.
However, the result of the translation remains ompliated.
We still have to enode the ounters of relations like preedene,  ltering, delay.
.
.
whih is tedious when using only propositional variables.
INRIA  Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL  21  Here we have arbitrarily hosen to bound the preedene operators.
There are examples where the ontext already bounds the dierene between the arguments of a preedene relation (see for instane the denition of alternane in Set. 2.1).
So, bounded CCSL is not the largest fragment that an be enoded in PSL.
Determining whether the state spae of a CCSL speiation is nite is an open question.
Moreover it seems very diult to  determine a syntati fragment orresponding to suh CCSL speiations.
5 Conlusion In this paper, we have ompared the expressiveness of CCSL and PSL, two formal languages used for similare purposes but at dierent levels.
We have identied the CCSL onstruts that annot be expressed in PSL and the lass of PSL formulas that annot be stated in CCSL .
We have also dened the ommon fragments between CCSL and PSL so that one an be translated into the other.
A suient ondition to translate CCSL speiations into  inria-00540738, version 1 - 7 Dec 2010  PSL is to bound the integer ounters used to ount the number of ourrenes of loks.
Preisely, the relative advane of the loks put in relation by these CCSL onstruts must be bounded.
This translation is an important step towards the formal veriation of a CCSL speiation and the exploration of its state spae. In the future, we an also take benets of the intermediate translation to automata to establish omparison with other languages.
Conversely, we have dened the translation of PSL safety properties into CCSL.
CCSL annot express the lass of liveness properties.
CCSL has not been designed for this purpose.
However, it an be interesting to apture all the expressive power of PSL in a higher level desription language.
A solution to ll the gap ould be to introdue temporal modalities in a CCSL -like language while keeping the multi-loks aspets.
CCSL is indeed a language that is still evolving.
We are urrently dening a minimal kernel from whih all the relations and expressions introdued in this paper (and possibly others) an be derived.
In this  development, we should maintain the orrespondenes with the other languages involved in system design suh as PSL.
Referenes [1a C. AndrAS.
Syntax and semantis of the lok onstraint speiation language.
Tehnial Report 6925, INRIA, 2009.
[2a C. AndrAS, F. Mallet, and J. DeAntoni.
VHDL observers for lok onstraint heking.
In  Industrial Embedded Systems (SIES), 2010 International Symposium on, pages 98107,  July 2010.
[3a D. Bustan, D. Fisman, and J. Havliek.
Automata onstrution for PSL.
Tehnial  report, IBM Haifa Researh Lab, 2005.
[4a R. LaziAV.
Safely freezing LTL.
In  RR nAdeg 7459  In FST&TCS'06,  pages 381392.
Springer, 2006.
R. Gason , F. Mallet , J. DeAntoni  22  [5a F. Mallet, C. AndrAS, and J. DeAntoni.
Exeuting AADL models with UML/Marte.
In  ICECCS'09 - UML&AADL'09,  pages 371376, Potsdam, Germany, June 2009.
IEEE  Computer Press.
[6a F. Mallet, M.-A.
Peraldi-Frati, and C. AndrAS.
timing requirements.
In  ISORC'09,  Marte CCSL to exeute East-ADL  pages 249253, Japan, Tokyo, Marh 2009.
IEEE  Computer Press.
[7a S. Miyano and T. Hayashi.
Alternating nite automata on  puter Siene, 32(3):321  330, 1984.
[8a OMG.
UML Prole for MARTE, v1.0.
D -words.
Theoretial Com-  Objet Management Group, November 2009.  formal/2009-11-02.
[9a P. Peil, J. Medina, H. Posadas, and E. Villar.
Generating heterogeneous exeutable  speiations in SystemC from UML/MARTE models.
inria-00540738, version 1 - 7 Dec 2010  Software Engineering, 6:6571, 2010.
Innovations in Systems and  10.1007/s11334-009-0105-4.
[10a IEEE standard for Property Speiation Language (PSL), IEEE std 1850-2005.
[11a A. Sistla and E. Clarke.
The omplexity of propositional linear temporal logi.
J. ACM,  32(3):73374, 1985.
[12a M. Vardi and P. Wolper.
An automata-theoreti approah to automati program veriation (preliminary report).
In  LICS'86,  pages 332344.
IEEE, 1986.
[13a J. Vidal, F. de Lamotte, G. Gogniat, P. Soulard, and J.-P. Diguet.
A o-design approah for embedded system modeling and ode generation with UML and MARTE.
In  DATE,  pages 226231, 2009.
INRIA  inria-00540738, version 1 - 7 Dec 2010  UnitAS de recherche INRIA Sophia Antipolis 2004, route des Lucioles - BP 93 - 06902 Sophia Antipolis Cedex (France) UnitAS de recherche INRIA Futurs : Parc Club Orsay UniversitAS - ZAC des Vignes 4, rue Jacques Monod - 91893 ORSAY Cedex (France) UnitAS de recherche INRIA Lorraine : LORIA, TechnopA'le de Nancy-Brabois - Campus scientifique 615, rue du Jardin Botanique - BP 101 - 54602 Villers-lA"s-Nancy Cedex (France) UnitAS de recherche INRIA Rennes : IRISA, Campus universitaire de Beaulieu - 35042 Rennes Cedex (France) UnitAS de recherche INRIA RhA'ne-Alpes : 655, avenue de laEurope - 38334 Montbonnot Saint-Ismier (France) UnitAS de recherche INRIA Rocquencourt : Domaine de Voluceau - Rocquencourt - BP 105 - 78153 Le Chesnay Cedex (France)  Aditeur INRIA - Domaine de Voluceau - Rocquencourt, BP 105 - 78153 Le Chesnay Cedex (France) http://www.inria.fr  ISSN 0249-6399
ficha MOKHTARI Institut dInformatique USTHB BP 32 El Alia Alger Algdrie mokhtari @ist .ibp.dz  Daniel KAYSER LIPN URA 1507 du CNRS Institut GalilCe Universitk Paris-Nord 93430 Villetaneuse France Daniel.Kayser@ural507.univ-paris 13.fr  Abstract  inferences can be achieved without ever making that choice (see e.g.
[4]), we adopt in this paper a pointbased point of view, for reasons which will appear in the next section.
However, it is likely that an interpretation in terms of intervals of what we call below time points would not change drastically the core of our approach.
The next section motivates our choices, in order to satisfy the kind of reasoning we wish to capture.
We then go on to provide a formalism intended to link an incomplete description with any normal course of the world: we give preliminary notations and definitions, then describe a theory of action, and compare it with related works.
We conclude with a discussion about current and future work.
This paper discusses the temporal aspect of a causal theory based on an "interventionist" conception of causality, i.e.
a preference to select causes among a set of actions which an agent has the ability to perform or not to perform (free will).
Casting causal reasoning in this framework leads to explore the problem of reasoning about actions, generally considered as a nonmonotonic temporal reasoning.
Most of the works on nonmonotonic temporal reasoning have used simple temporal ontologies, such as situation calculus, or temporal logic with discrete time.
The theory presented in this paper also has a simple temporal ontology based on "time points" organized on branching "time lines ", with the possibility of modelling continuous evolutions of the world for various fitures (prediction) or pasts (diagnostic).
2.
Actions, effects, and time points Actions and effects will be the only temporal propositions considered in our framework.
An effect can be, among other things, an event or a fact.
But as argued in [13], a fine distinction is unnecessary.
In order to introduce temporal aspects, some choices must be made.
The first one concerns the basic temporal element: point or interval ?
Intervals can be related in various ways: "I1 is completely before 12"; "I1 abuts I2", "I1 overlaps I2", etc.[l].
All these relations are possible between a cause and an effect, but they are subsumed by the general principle, according to which effects never precede their causes; therefore we find it simpler to use only t i m e points.
We do not mean to reduce causation merely to a temporal relationship: what we present below shows the contrary.
Let us mention, in addition, that most approaches choose discrete sets, isomorphic to integers, to represent time.
In order to better reflect our intuitions on continuity, we prefer to take reals, but we do not consider this choice as critical,  1.
Introduction A definition of the concept of cause, if at all possible, would involve deep philosophical questions ; we do not need to tackle them, however, in order to use a practical notion of cause.
Intuitively, this notion is necessary in our everyday reasoning, both to anticipate what should happen if we decide to perform an action, and to diagnose what might have happened to yield a given state of affairs.
We propose to prune the collection of propositions which might be considered as causes by preferring to take as causes the result of the free will of an agent, i.e.
hidher ability to opt for performing or not performing a given action.
Casting causal reasoning in this framework leads to explore the problem of reasoning about actions, generally considered to be a nonmonotonic (i.e.
defeasible) temporal reasoning.
Temporal reasoning is said to require a choice among two ontologies : point-based or intervalbased.
Although we consider that many non-trivial  14 0-8186-7528/96 $5.00 0 1996 IEEE  the result of causal relations.
The possibility of having a branching past implies that the "interesting propositions" do not include "historical" statements, since otherwise different pasts could never lead to the same time point.
Having time points defined both by the subset of true propositions and by the date allows to distinguish several occurrcnces of the same state of affairs.
If we need to represent cyclic phenomena, where this distinction is useless, we may add an equivalence relation on time points: t l E t2 if they differ only by their date, and then reason on the quotient set.
The alternative, i.e.
define time points only by the subset of true propositions, does not allow to restore the notion of date when needed.
To extract the date of a time point, we define a function date : T I+ 93 which maps every time point on a real number representing its date.
To simplify, we write date(t) as dt.
especially as our examples need only to consider a finite number of time points.
Our second choice amounts to select either a linear or a branching model of time; time is intuitively linear.
However, as we deal with choice making, the very representation of a choice immediately suggests the use of branching time.
Among the time points, some particular ones, called choice points, are intended to represent states of affairs where an agent can take the decision of performing or not an action: obviously, not all time points are choice points, since the conditions allowing for the action are not always satisfied.
The decision of the agent is represented as a time line splitting into two futures, or more accurately, as two distinct time lines having the same time points up to the choice point.
This is consonant with most systems, which have a branching future [lo].
But we consider as well a branching past [14], because we often need to examine two different courses of events leading to the same situation.
We also allow time lines to meet again in the future (case of an action without long-range effects, for example).
Fig.
1 below will provide an illustration.
We now present more formally the general framework corresponding to our choices.
Definition 2: We call time line 1 (somehow similarly to McDermott's "chronicle" [IO]) a set of time points in bijection with the set of dates, meant to represent a possible evolution of the universe.
A time line hence conveys the complete evolution of the truth value of the "interesting propositions".
The time points of a time line are supposed to comply with the general principle: "there is no effect without a cause".
Their propositions are then the result of cause-effect relations governed by causal rules.
The set of causal rules is gathered in a rule base called BR.
The time points of a time line are totally ordered by a precedence relation written "I",where tKt2 means that time point t2 does not precede t l , hence whenever tlSt2 we have dtlSdt2, but the converse does not hold (see Fig.1).
3.
Temporal ontology Definition 1: A time point t is a "snapshot" state of the universe defined by a subset of true propositions at a certain date and by this date.
T is the set of time points.
The subset mentioned in the definition is not arbitrary: we sometimes refer to it as the set of "interesting propositions", i.e.
in our framework,  15  dO  d2  dl  Figure 1: the structure of branching time in the past and in the future.
The thick line represents a time line, I, including among others time points to, t i , t2.
The other curved lines represent other time lines.
tO c tl c t2 holds, as do tO < t"2 and t i < t'2, but there is no relation between t i and t"2, although dtl< d t y is true.
- L is the set of time lines, 4.
The language  -  3 is the set of real numbers, if t has exactly as  - t E 1 is true in the model  its true propositions the set I(l,dt), - v(p,l,dt) is true in the model iff p E Z(l,dt), i.e.
proposition p is true at the time point determined by time line 1 and date dt.
It follows that nocc(p,l,dt,A) is true in the model iff (b't') ((t'E1 A dtld&+A) p 6i Z(1,dtt)).
The proposed langage A!
is defined at two levels: * the first level is meant to represent static information.
It is a plain propositional language in which: P is a set of propositions we are interested in, A, subset of P, is a set of actions, and E, subset of P, is a set of effects, with A n E = 0 and A v E = P. the second level expresses dynamic information.
It contains predicates with time variables.
If p is a formula of the first level, I a time line, t E 1 a time point, a formula of the second level has the form: - v(p, I , d t ) with the intended meaning that formula p is true in 1 at the date of time point t, and: - nocc(p,l,d,A) with the intended meaning that p is never true in line 1 from the date of time point t on, during the delay A.
In other words, nocc(p,l,dt,A) is a short-hand for : (Vt') ((t'E I A O 2 d t d f < A) 3 -~V(p,Z,df))  =I  The dependence of the effect on the cause may vary according to the context.
We shall therefore introduce a subset of preferred time lines and augment the language with an operator denoted "a'' meaning normally implies (in a more comprehensive presentation, see [ 111, we also have an operator "-+" meaning implies in all cases).
The intuitive idea behind these two new notions is as follows: when an agent chooses to perform an action, he or she does not anticipate every possible outcome of his or her choice: several circumstances, unknown to, or neglected by, the agent at the moment of the choice, may alter the predictable effect of the action.
Informally, the "preferred" time lines are the futures that the agent normally "had in mind" when he or she opted to perform the action.
The effects which are present in all "preferred time lines" following an action are said to be "normally implied" by the action.
The idea of "normal implication" is inspired by the work of  We are going to extend gradually this language, but first let us define its semantics.
The associated model theory is a generalization of Kripke [8] possible world semantics.
In this model, an interpretation is defined as function I mapping the Cartesian product L X % into a subset of propositions, i.e.
Z : L X 93 I+ 2 p , where:  16  Delgrande [3].
We defer a more precise explanation until we introduce some more notions.
To make sense of the notion of "normality" requires to reason with uncertain information: in the absence of specific information, we are entitled to believe that things behave normally.
This brings us to a problem similar to the well-known "frame problem", which is inherent to any theory of change.
We must therefore take into account: the preconditions of an action a , i.e.
represent what is reasonable to assume whenever performing a is considered; the hindrances of an action a, i.e.
represent the effects of other actions that can inhibit the effects of a; the persistence of states, corresponding to the fact that some propositions continue to hold true for some duration, unless an external event entails their falsity.
All these aspects generally require the use of a nonmonotonic reasoning.
That is the reason why we devote next section to this issue.
time line, as we introduced it in 54.
Its definition requires the preliminary notion of coincidence, viz.
Definition 3: Two time lines  11 and 12 coincide up to time point t, property written coincide(ll,12,t) ifffor every time point t'preceding t, t' E 11 = t' E 12.
In other words, a model satisfies coincide (Zi, 12,t) iff (b't')(t'lt 2 Z(ll, dti)=Z(12,dtl))  Definition 4: The set of preferred time lines for line 1 ut time point t, noted Lp(1,dt) is a subset of L obtained by a function Lp :L X 3'I+ 2L such that: (Vl,l',t) (I' E Lp(l,dt) 3 coincide(l,l',t)) We are now in position to define formally normal implication:  Definition 5: Action a normally implies effect e within the delay A, noted a 3 e [A], ifs (Vl,t ) ( C l A C2) where C1 and C2 stand for the following conditions: C1 {tv(a,Wt) A (YP)(pcnorm(a)3 v ( p , W t ) ) l 3 { Vl') (l'sLp(1,dt)I> [(dt') (t'sl' A dtldt.ldt+A A v(e,l',dt~))v (3e',t") (e'EUR inhibit(e,a) A t"s1' A v(e',l ',dy)A dt.GQGit+A)l)} C2 { v ( - r a , l , d t ) I> (31') ( I ' E L p ( l , d t ) A noccte,l',dt,A))J  5.
Nonmonotonicity In [ l l ] , we show how to include implicit premises in a normal inference.
We suppose the existence of a function, called norm, to define the normal conditions under which an action is executed.
Technically, norm : A I+ 2p is such that for any action a , n o r m ( a ) contains those propositions (preconditions) which are true unless otherwise specified when an agent considers to perform a.
Extending the domain of norm to our "first-level" language, i.e.
defining compositionally norm (a op a') where op is a boolean operator is not a trivial task, if we want to remain compatible with our intuitions.
We will not treat this problem here.
As we saw the importance of defining "hindrances", we suppose similarly the existence of a function inhibit that, for any couple <e,a> where e is a normal effect of a, determines the events which are liable to prevent e from following a .
Technically, inhibit : E X A + 2E is such that inhibit(e,a) is the subset E' of E where e' E E' iff whenever e' occurs during the delay after a where e should turn true, e may actually remain false.
Notice that action a' causing e' may happen before, with, or after a.
Similarly, extending the domain of inhibit to couples of formulas instead of couples of atoms is a very thorny issue.
We turn now to what we mean by "normal case".
This notion is often attached to a preference ordering, but we notice that the definition of a socalled "correct order" is rather difficult; therefore, we find it more convenient to use the notion of preferred  This rather intricate definition calls for some explanations: C1 tells that whenever a occurs under normal conditions, in all preferred futures, either there exists a subsequent occurrence of event e within the delay A, or there is an occurrence of event e' known to inhibit the effect of a ; e' must then occur after t within the prescribed delay (notice that, even in this case, e may become true); C2 checks that if a is not executed, there exists at least one preferred future in which e will not occur within the specified delay A.
This condition reflects the implicit counterfactuality always present in causation: we are not ready to say that a normally implies e if we think that, even without performing a, e will nevertheless occur in every likely future.
We now turn to the last problem related with the "frame problem", namely persistence.
Example 1: Suppose that the following facts and rule are given.
They represent the well-known "Yale Shooting Problem" (Y.S.P.)
according to our no tation: - v(Fred is alive,l,dto) - v(gun is loaded,l,dtl)  17  one in which the action is performed, the other in which it is not.
The free will of the agent is exactly histher ability to choose which of these two lines will correspond to reality.
- v(shoot at Fred,l,dt2) - shoot at Fred lalive Fred [A]  *  with dtoldt11dt2 and A: a few seconds.
Two problems have to be considered in relation with the persistence of a given event e: 1. temporal nonmonotonicity, i.e.
the possibility that an external event prevents e from remaining true, and 2. the estimation of the duration of the persistence of a fact, i.e.
how long, after e has begun to be true, is it likely that it is still true ?
Suppose that we heve the answer to point 2., and let a be the "normal duration" of fact e. We can define persistence as follows:  Definition 7: t is called a choice point relative to action a, among lines 11 and 12 {noted pchoix(a,11,12,t)) iff ( V t ' ) ((t'<t 3 coincide (11,12,t')) A v(a,li,dt) A v(-a,L2,dt)) The set of causal rules BR and the definitions provided so far allow us to define the set of voluntary causes of an effect e observed on time line I' at time point t':  Definition 6 (persistence): We note persist(e,d)  Definition 8: the voluntary causes are defined as a partial function: causev .
E x L x T + 2A defined only if v(e,l',dtf)holds.
Then, causev (e,l',t') is the subset A ' of A such that U E A ' iff a satisfies conditions C K 4 (the scope of t and 1 extends from C2 to C4, and of A includes C1 and C2): C l ( 3 A ) (a 3 e[A] E BR) C2 (3t,1,1") (pchoix(a,1, l",t) A dt_<ti_<t+RelevantDelay), where: if ( 33) (persist(e, 3) E TP) then Relevant-Delay = A + delse Relevant-Delay = A, c3 1'E Lp(1,dt) C4 v( T e ,1,d,) .
the fact that, without any external influence, event e is believed to remain true for a duration d. We have: (t'E1 A persist(e,d) 2 {Vto,l) ((v(e,l,dto)A (3') nocc(e,l,t',dt,-dtI))) 3 {Vl',t) ( ( t e l l A C1 A C2 A C3) 3 v(e,l',dt))) where C l , C2, and C3 abbreviate the following conditions: C1 I'E Lp(1,dtO) C2 dtoldtldto+ d 7 e [ A ] ) ~ B RI> nocc(a',l',dto-A, C3 { Va',A) ((a' dt-dto+A)) to is the time point where fact e becomes true in time line 1; C1 expresses that persistence is predicted at least in the preferred futures; C2, that persistence lasts at least for (without prohibiting it beyond this duration), provided that no action a', known in B R to make e false, occurs during the relevant lapse (C3).
(We cannot use the function inhibit here, since we want the persistence of an event to be defined without reference to its cause, while inhibit defines a set of events related to both a cause and its effect).
In the same way as implications are gathered in a rule base BR, the known persistences are collected in a "table of persistences" TP.
We now have all the prerequisites necessary to investigate which set of actions can reasonably be held as causally responsible for a given event e.  C1 selects the set of causal rules of B R containing the effect e in their right part (we examine in [ 111 the possibility of exploring what we call closure(BR) instead of BR, in order to take into account the actions which are known to cause an effect e ' , of which e is a tautological consequence); C2 means that the agent had the choice (at a time which is relevant for the observation of e ) between doing and not doing action a, and that he or she chose to do a ... C3 ... in a time line 1 for which time line I' (where event e has actually occurred) is among the preferred futures at the time where the choice has been made; C4 specifies the relevance of the action to the observed event: e must not already be true at the moment of executing a in 1.  a  6.
Explanation The reader should remember that the notion of action is essential in our theory, since we decided to privilege, when asked to find the causes of a state of - which we take to be actions executed by agents in virtue of their free will - over "natural laws".
We that a choice point is a time point from which stem (at least) two different time lines,  Suppose that we have a description of the evolution of a world by of a set D L of statements using the predicates and nocc.
The above definition can be used to solve the explanation problem, if we also have at our disposal general information such as BR and TP, and provided that some assumptions concerning the completeness of  18  DL are accepted.
[ll] gives further results, and  simultaneously providing the same result) and the fact that we require the actions to be instantaneous.
extends Definition 8 to the case where an operator + for "implies in all cases" is added.
8.
Conclusion  7, Related works  In this paper, we have developped:  - a simple temporal ontology,  Recent publications [ 12,151 contain thorough discussions of other approaches, namely chronological minimization [6,7,13] or causal minimisation [9].
They show why such approaches fail to handle adequately prediction, explanation, or ramification problems.
The aim of this section is not to restart these discussions.
However, we would like to show briefly how we tackle the central problem illustrated by the already mentionned Y.S.P.
To DL and BR given in section 5, we add TP containing the facts that alive and loaded persist indefinitely; we add also the fact that inhibit( - d i v e , shoot) contains facts like deviation-of-bullet and so on.
The conflict of persistence between alive and loaded does not arise in our approach.
As a matter of fact, the assumption of completeness on DL enables us to derive that no inhibiting fact prevents - d i v e to occur, once shoot has been done; therefore, we predict lalive.
If we also have a rule like shoot 4oaded in BR, definition 6 cannot be used to predict the persistence of loaded.
Knowing what belongs to inhibit(Tloaded, shoot) - or assuming this set to be empty, in the absence of any information on the subject -, we predict lloaded as well.
We now consider backward reasoning, adding to D L a statement such as v(Fred is alive,l,dt~)and dt2+A<dt3 : if we have to explain this anomalous state, our approach will consider two possible tracks to follow: the persistence of loaded has stopped (the gun has somehow become unloaded between dtl and dt2) or some inhibiting effect (e.g.
deviation-ofbullet) has occurred between the action shoot and its normal effect lalive, that is between dt2 and dt3.
However, we cannot prefer one track over the other, nor can we guess exactly when, in the intervals defined, the anomalous fact took place.
In contrast to this intuition, the chronological systems tend to prefer the sequence of world states where the gun becomes unloaded just before shooting, because this sequence postpones the change as long as it is consistent to do so.
More recent approaches [2,12,151 do not present these anomalies, but they should be augmented with the possibility of inhibiting effects after the action; otherwise, they are not able to propose the second kind of explanations.
Finally, the solution advocated for in this paper also runs into some difficulties.
An important one concerns concurrent actions (two or more actions  - the role of an agent in the evolution of the  world.
This approach seems to provide an intuitively correct analysis of the main problems encountered in the A.I.
literature: the explanation problem, the prediction problem, and the ramification problem (see [ 111 for examples).
Our approach should easily extend to the case where the first-level language is first-order.
We do not anticipate too many difficulties to take into account the duration of actions: instead of a threeplace predicate v(a,t,dt), we might abbreviate the formula: ( V t ) ( t l < t < t 2 3 v ( a , l , d t ) ) into v(a,1,dtl ,dt2), a four-place predicate.
This should also help us to handle the case of concurrent actions.
As another direction of further research, we are taking advantage of a cospus of car-crash reports, which is currently studied in our Laboratory [ 5 ] .The goal is to determine what should be put in BR and TP in order to find intuitively correct answers to questions concerning the causes of the accident.
As it is often the case in Artificial Intelligence, real-size problems reveal issues which are not even visible in toy problems, such as those which illustrate the present paper.
REFERENCES [l] James ALLEN: Towards a general theory of action and time.
Artificial Intelligence vo1.23 pp.
123-154,  1984 [2] A.B.BAKER: A simple solution to the Yale Shooting Problem.
Intern.
Con$ on Knowledge Representation and Reasoning pp.
11-20, 1989 [3] James P.DELGRANDE: A first-order conditional logic for prototypical properties.
Artificial Intelligence vo1.33 pp.105-130, 1987 Frangoise GAYRAL, Philippe GRANDEMANGE: Evtnements : ponctualitt et durativitt.
81hA F C E T RFIA Congress pp.905-910, Lyon (F), Nov. 1991 [5] Frangoise GAYRAL, Philippe GRANDEMANGE, Daniel KAYSER, FranGois LEVY: InterprCtation des constats d'accidents : reprksenter le rCel et le potentiel Approches se'maiztiques t.a.1.
vo1.35 n"1 pp.65-81, 1994 [6] B.A.HAUGH: Simple causal minimization for  [PI  temporal persistence and projection.
AAA1 pp.218223.
1987  19  [7] Henry A.KAUTZ: The logic of persistence.
Y h National Conference on Artificial Intelligence pp.401-  [12] Erik SANDEWALL: The range of applicability of nonmonotonic logics for the inertia problem.
13th IJCAI pp.738-743, Chambery, 1993 [I31 Yoav SHOHAM: Reasoning about change: time and causation from the standpoint of Artificial Intelligence.
M. I. T.Press 1988 [14] Yoav SHOHAM: Time for Action : On the Relation Between Time, Knowledge and Action.
l l t hIJCAI pp.954-959 & 1173, Detroit, 1989 [ 151 Lynn A.STEIN, Leora MORGENSTERN: Motivated action theory: a formal theory of causal reasoning.
Artificial Intelligence voI.7 1 pp.
1-42, 1994  405, 1986 [8] Saul A.KRIPKE: Semantical considerations on modal logic.
Acta philosophica fennica vo1.16 pp.8394, 1963 [9] Vladimir LIFSHITZ: Computing Circumscription.
9th IJCAI pp.121-127, Los Angeles, 1985 [ l o ] Drew V.McDERMOTT: A Temporal Logic for Reasoning about Processes and Plans.
Cognitive Science vo1.6 pp.101-155, 1982 [ 111 Aicha MOKHTARI: Action-based causal reasoning.
Applied Intelligence to appear  20
Annals of Mathematics and Artificial Intelligence manuscript No.
(will be inserted by the editor)  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT Davide Bresolin * Dario Della Monica * Angelo Montanari * Guido Sciavicco  Received: date / Accepted: date  Abstract Decidability and complexity of the satisfiability problem for the logics of time intervals have been extensively studied in the recent years.
Even though most interval logics turn out to be undecidable, meaningful exceptions exist, such as the logics of temporal neighborhood and (some of) the logics of the subinterval relation.
In this paper, we explore a different path to decidability: instead of restricting the set of modalities or imposing severe semantic restrictions, we take the most expressive interval temporal logic studied so far, namely, Venema's CDT, and we suitably limit the negation depth of modalities.
The decidability of the satisfiability problem for the resulting fragment, called CDTBS , over the class of all linear orders, is proved by embedding it into a well-known decidable quantifier prefix class of first-order logic, namely, Bernays-Schonfinkel class.
In addition, we show that CDTBS is in fact NP-complete (Bernays-Schonfinkel class is NEXPTIME-complete), and we prove its expressive completeness with respect to a suitable fragment of BernaysSchonfinkel class.
Finally, we show that any increase in the negation depth of CDTBS modalities immediately yields undecidability.
Keywords Interval temporal logic * Tableau methods * Decidability * Complexity 1 Introduction In the recent years, the study of temporal reasoning via interval-based (logical) approaches has been very intensive.
Since the seminal work by Halpern and Shoham [18] and VenD.
Bresolin Dept.
of Computer Science, University of Verona, Italy E-mail: davide.bresolin@univr.it D. Della Monica ICE-TCS, School of Computer Science, Reykjavik University, Iceland E-mail: dariodm@ru.is A. Montanari Dept.
of Mathematics and Computer Science, University of Udine, Italy E-mail: angelo.montanari@uniud.it G. Sciavicco Dept.
of Information and Communication Engineering, University of Murcia, Spain E-mail: guido@um.es  2  Davide Bresolin et al.
ema [33], a series of papers on interval temporal logics has been published, e.g., [5, 6, 9-11, 23, 24, 29].
As an effect, the problem of classifying all "natural", genuinely interval-based (that is, all intervals over a linear order are considered, and no projection principle is applied [17]) logics with respect to their expressive and computational power has been extensively studied and almost completely solved.
Propositional interval temporal logics are modal logics, interpreted over linearly- or partially-ordered sets, whose proposition letters are evaluated over intervals instead of over points.
They differ from each other in the number and type of basic relations between intervals that are captured by their modalities, by the linear order(s) over which they are interpreted, and by the inclusion or exclusion of point-intervals (intervals with coincident endpoints).
In the hierarchy of existing interval temporal logics based on their expressive power, the top element is Venema's CDT [33], whose language features three binary modalities, corresponding to the three possible ways to place a point with respect to the two endpoints of a given interval, and a modal constant, that identifies point-intervals.
The second-highest logic in the hierarchy is Halpern and Shoham's HS [19], which features one unary modality for each Allen's relation between pairs of intervals [1].
Both in CDT and in HS, satisfiability turns out to be undecidable, no matters what class of linear orders is considered (all, discrete, dense, finite, the linear order of natural numbers, and so on) [19].
In the recent years, some fragments of HS with a better computational behavior have been identified.
Meaningful examples include, but are not limited to, AA (a.k.a.
Propositional Neighborhood Logic, PNL), which features two modalities for Allen's relations meets and met by, and is decidable over all meaningful classes of linear orders [8, 16]; its extension AABB [28], that includes modalities for Allen's relation's starts and started by, and its mirror image AAEE, with additional modalities for Allen's relations finishes and finished by, which are decidable over the class of finite linear orders and undecidable everywhere else; and BBDDLL (and its mirror image EEDDLL), with modalities for Allen's relations starts, started by, during, contains, before, and after, which is decidable over dense linear orders [27] and undecidable over finite and (weakly) discrete linear orders (as a matter of fact, one-modality logics D and D are already undecidable over the classes of finite and discrete linear orders [23])1 .
The situation with classical first-order logic is somehow similar.
Since it has been shown that satisfiability for the full language is undecidable, a great effort has been made in order to identify more and more expressive decidable fragments.
At least three different strategies have been pursued: (i) limiting the number of variables of the language, (ii) limiting the type of formulas allowed by relativizing quantification (guarded fragments), and (iii) limiting the structure and the shape of the quantifier prefix.
First-order logics with a restriction on the number of variables have been already studied in connection with interval temporal logics.
Most notably, AA has been proved to be expressively equivalent to the two-variable fragment of first-order logic over linear orders.
Such a fragment of first-order logic has been shown to be NEXPTIME-complete over various classes of linear orders in [30].
Decidability of AA over the same classes of orders immediately follows.
Guarded fragments of first-order logic (see [2] for an introduction) have been shown to be quite useful to explain the good computational properties of modal logics, but, to the best of our knowledge, they have never been considered in the framework of interval temporal logics.
As a matter of fact, mapping interval temporal logics into guarded fragments of first-order logic would require (i) the use of a relation in the guards 1  In all these cases, including or excluding point-intervals makes no difference.
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  3  which is (or can be forced to behave as) a linear order, (ii) at least three distinct variables, (iii) uninterpreted predicates which are at least binary, and (iv) quantifications with Boolean combinations of atomic formulas as guards.
Such requirements are not met by known decidable guarded fragments of first-order logic2 .
In this paper, we explore an original path to decidability of interval temporal logics, which follows the third strategy: we look for meaningful interval temporal logics that can be embedded into decidable quantifier prefix classes of first-order logics.
The decidability of the latter family of logics does not depend on the shape of the quantifier prefix only, but also on the number and the arity of predicate and function symbols that are allowed in the formulas, and on the presence/absence of equality.
Seven different decidable classes have been identified in the literature (a survey on quantifier prefix classes of first-order logic can be found in [4]).
We focus our attention on the prefix vocabulary class identified by Bernays and Schonfinkel in 1928 (a.k.a.
Bernays, Schonfinkel, and Ramsey class, as Ramsey proved that decidability is preserved even when equality is included) [4].
It consists of all and only formulas in prenex form whose quantifier prefix is of the form [?
]x1 .
.
.
[?
]xn [?
]y1 .
.
.[?
]ym and whose matrix may include predicate symbols of any arity (but no function symbols) and, possibly, equality.
It is well known that Bernays-Schonfinkel fragment of first-order logic is expressive enough to model a linear order devoid of specific properties such as discreteness or density.
Moreover, it can express simple frame properties, commonly studied in the interval temporal logic literature, like, for instance, boundedness.
We identify a syntactic fragment of CDT [33], called CDTBS , whose standard translation fits into Bernays-Schonfinkel class, by limiting the negation depth of the modalities to one, that is, by constraining temporal operators to occur in the scope of at most one negation.
Decidability of CDTBS , over the class of all linear orders, immediately follows.
Then, a precise characterization of CDTBS expressive power is given by showing that it is expressively complete with respect to a suitable fragment of Bernays and Schonfinkel class.
A decision procedure for CDTBS is then obtained by tailoring the non-terminating tableaubased deduction system for CDT developed in [15] to it.
As a by-product, we prove that the satisfiability problem for CDTBS is NP-complete, in sharp contrast with that of BernaysSchonfinkel class, which is NEXPTIME-complete, when relation symbols of unbounded arity are allowed, and PSPACE, when relation symbols have bounded arity, e.g., only binary relations are allowed, as it is the case for interval logics.
Finally, we show that any increase in the negation depth of CDTBS modalities immediately yields undecidability.
The paper is structured as follows.
In Section 2, we provide background knowledge about Bernays and Schonfinkel fragment of first-order logic.
In Section 3, we define syntax and semantics of CDTBS , and we define its standard translation.
Decidability immediately follows from the inclusion of the resulting set of formulas in Bernays and Schonfinkel class.
Next, in Section 4, we prove the expressive completeness of CDTBS with respect to a suitable fragment of such a class.
In Section 5, we devise a sound, complete, and terminating tableau method for CDTBS .
Finally, in Section 6, we show that fairly natural extensions of CDTBS do not preserve decidability.
An assessment of the work done and possible future research directions are given in Section 7.
2 Extended guarded fragments includes loosely guarded fragments, which allow guards to be more complex than simple atoms [3], and guarded fragments with transitive guards (in general, transitivity cannot be expressed as a guarded formula) [31].
4  Davide Bresolin et al.
2 Bernays-Schonfinkel class Bernays-Schonfinkel prefix vocabulary class, denoted here by FOBS , consists of all and only those first-order formulas, making use of any relational symbol of any arity, including equality, that can be put in prenex form by using a quantifier prefix of the form [?
]x [?
]y, where x = x1 .
.
.
xn and y = y1 .
.
.
ym are (possibly empty) vectors of first-order variables.
It is well known that the satisfiability problem for FOBS is NEXPTIME-complete [4].
Moreover, FOBS is closed under conjunction and disjunction, since all its formulas can be thought of as sentences (free variables can be existentially quantified), but it is not closed under negation.
To simplify the proofs of the results given in the paper, we introduce an alternative definition of FOBS via the following abstract grammar:  a ::= a[?]
| a [?]
a | a [?]
a | [?
]x.a | !a[?]
for a[?]
of the form [?]x.a[?]
a[?]
::= A(x) | !A(x) | a[?]
[?]
a[?]
| a[?]
[?]
a[?]
| [?]x.a[?]
A(x) ::= any relational symbol of arbitrary arity, including equality  (1) (2) (3)  Grammar (1) generates a fragment of first-order logic consisting of all and only those formulas where existential quantifiers can occur in the scope of at most one negation.
While any prenex formula of the form [?
]x [?
]y b can be generated by grammar (1), the converse is not true, since grammar (1) can generate also formulas which are not in prenex form.
However, it is not difficult to show that any formula generated by grammar (1) can be transformed into an equivalent prenex formula of the correct form, as shown by the following proposition.
Proposition 1 Any formula generated by grammar (1) can be transformed into a prenex formula of the form [?]x[?
]yb , with b quantifier-free.
Proof Let a be a formula generated by grammar (1).
We show that there exists an equivalent formula t (a ) of the required form by structural induction.
We start with the set of formulas generated by the sub-grammar for a[?]
, and we show that each of them can be transformed into a formula of the form [?
]xb , with b quantifier-free.
The case in which a is a relation or the negation of a relation is trivial.
Consider now the case of formulas a = a[?]
[?]
a[?]'
.
By inductive hypothesis, t (a[?]
) = [?
]zb and t (a[?]'
) = [?
]wb ' , for some quantifier-free b and b ' .
Without loss of generality, we can assume z [?]
w = 0/ (if this is not the case, we can apply a suitable variable substitution), and thus a is equivalent to [?
]zw(b [?]
b ' ).
The case of disjunction is similar, and thus omitted.
Consider now the case of formulas a = [?]x.a[?]
.
By inductive hypothesis, t (a[?]
) = [?
]wb , for some quantifier-free b , with x 6[?]
w, and thus a is equivalent to [?]x[?
]wb .
Let us consider now an arbitrary formula generated by grammar (1).
The only interesting case is the one for the negation of existential quantifiers.
Let a = ![?]x.a[?]
.
By inductive hypothesis, t ([?]x.a[?]
) = [?]x[?
]wb , for some quantifier-free b , with x 6[?]
w. Hence, a is equivalent to the formula (in prenex form) [?]x[?
]w!b .
[?]
[?]
Thanks to the above result, from now on we will assume that any FOBS -formula has been generated by grammar (1).
3 Decidability of the logic CDTBS over the class of all linear orders Interval temporal logics are usually interpreted over a linearly ordered set D = hD, <i.
In this setting, an interval on D is an ordered pair [di , d j ] with di <= d j (we refer to such a case as  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  5  C di  dk  dj  Fig.
1 The ternary relation chop, splitting the interval [di ,d j ] into the subintervals [di ,dk ] and [dk ,d j ].
the non-strict semantics, in contrast with the strict one, that excludes degenerate intervals of the form [di , di ]).
The set of all intervals on D is denoted by I(D).
The variety of all possible relations between any two intervals has been studied by Allen [1], who identified 12 distinct binary relations plus the equality relation.
Halpern and Shoham modal logic of intervals, abbreviated HS, can be viewed as the modal logic of Allen's relations as it features one modality for each such relation.
As we already mentioned, HS turns out to be undecidable over any meaningful class of linear orders [19].
In [33], the ternary relation chop, depicted in Figure 1, has been taken into consideration.
The corresponding binary modality C, together with the two conjugated modalities D (done) and T (to do), and the modal constant p for point-intervals define the interval temporal logic CDT.
It can be easily shown that CDT subsumes HS (in fact, it is strictly more expressive than HS), and thus it is undecidable whenever HS is.
In [20], Hodkinson et al.
systematically investigate the three fragments of CDT with only one binary modality each (C, D, or T ), showing that each of them is undecidable.
Formulas of CDT are built on a set of proposition letters A P = {p, q, .
.
.
}, the Boolean connectives !
and [?
], the three binary modalities C, D, and T , and the modal constant p , by the following abstract grammar [33]:  ph ::= p | p | !ph | ph [?]
ph | ph C ph | ph D ph | ph T ph .
The other Boolean connectives can be viewed as suitable short forms, as usual.
Similarly, universal counterparts of the existential modalities C, D, and T can be defined by means of negation in the standard way; CDT has not any special notation for them.
The semantics of CDT-formulas can be given in terms of concrete models of the form M = hI(D),Vi, where V : A P - 2I(D) is a valuation function, as follows: M, [di , d j ]  p if and only if [di , d j ] [?]
V (p), M, [di , d j ]  p if and only if di = d j , M, [di , d j ]  !ph if and only if M, [di , d j ] 6 ph , M, [di , d j ]  ph [?]
ps if and only if M, [di , d j ]  ph or M, [di , d j ]  ps , M, [di , d j ]  ph C ps if and only if there exists di <= dk <= d j such that M, [di , dk ]  ph and that M, [dk , d j ]  ps , - M, [di , d j ]  ph D ps if and only if there exists dk <= di such that M, [dk , di ]  ph and that M, [dk , d j ]  ps , - M, [di , d j ]  ph T ps if and only if there exists dk >= d j such that M, [d j , dk ]  ph and that M, [di , dk ]  ps .
- - - - -  The standard translation is the usual way to express the semantics of a modal or temporal formula in first-order logic.
Let ph be a CDT-formula and, for every p [?]
A P, let us denote by the same symbol p the corresponding binary relation.
The standard translation function ST (ph )[x, y] is defined as follows: - ST (ph )[x, y] = x <= y [?]
ST ' (ph )[x, y], where x, y are two first-order variables and ST ' (ph )[x, y] is inductively defined as follows: - ST ' (p)[x, y] = p(x, y),  6  Davide Bresolin et al.
- - - - - -  ST ' (p )[x, y] = (x = y), ST ' (!ph )[x, y] = !ST ' (ph )[x, y], ST ' (ph [?]
ps )[x, y] = ST ' (ph )[x, y] [?]
ST ' (ps )[x, y], ST ' (ph C ps )[x, y] = [?
]z(x <= z <= y [?]
ST ' (ph )[x, z] [?]
ST ' (ps )[z, y]), ST ' (ph D ps )[x, y] = [?
]z(z <= x [?]
ST ' (ph )[z, x] [?]
ST ' (ps )[z, y]), ST ' (ph T ps )[x, y] = [?
]z(y <= z [?]
ST ' (ph )[y, z] [?]
ST ' (ps )[x, z]).
As a general rule, the standard translation makes it possible to reduce the satisfiability problem for a modal logic to a first-order satisfiability problem: a modal formula ph is satisfiable if and only if its standard translation, evaluated on a pair of points x, y, is (first-order) satisfiable.
Now, we ask ourselves the following question: which CDT-formulas are such that their satisfiability problem can be reduced to a first-order satisfiability problem in BernaysSchonfinkel class?
To answer this question, we define an abstract grammar that generates only CDT-formulas suitably limited in the negation depth of modalities:  ph ::= ph[?]
| ph [?]
ph | ph [?]
ph | ph C ph | ph D ph | ph T ph | !(ph[?]
C ph[?]
) | !(ph[?]
D ph[?]
) | !(ph[?]
T ph[?]
)  ph[?]
::= p | !p | p | !p | ph[?]
[?]
ph[?]
| ph[?]
[?]
ph[?]
| ph[?]
C ph[?]
| ph[?]
D ph[?]
| ph[?]
T ph[?]
(4) (5)  The above grammar generates a fragment of CDT, that we call CDTBS , which consists of all and only those formulas where the modalities C, D, and T can occur in the scope of at most one negation.
The next lemma shows that the above-defined standard translation maps CDTBS -formulas into Bernays-Schonfinkel class.
It is easy to check that the syntactic limitations of CDTBS do not prevent it from expressing all HS modalities (it only constrains the way in which they can be composed).
As an example, hBiph is captured by ph C !p .
Similar encodings can be given for the other HS modalities [33].
Lemma 1 For every CDTBS -formula ph , its standard translation ST (ph )[x, y] is an FOBS formula, with free variables x and y.
Proof The proof is by structural induction.
We start with the set of formulas generated by the sub-grammar for ph[?]
, and we show that the standard translation of each of these formulas belongs to the sub-grammar for a[?]
and it has x, y as its free variables.
As for the base case, let ph[?]
= p, for some proposition letter p. By definition, ST (p)[x, y] = x <= y [?]
p(x, y); the thesis immediately follows.
The cases !p, p , and !p are similar, and thus omitted.
As for the case of conjunction, let ph[?]
= ph[?]'
[?]
ph[?]''
.
By definition, ST (ph[?]'
[?]
ph[?]''
)[x, y] = x <= y [?]
ST ' (ph[?]'
)[x, y] [?]
ST ' (ph[?]''
)[x, y].
By inductive hypothesis, both ST (ph[?]'
)[x, y] and ST (ph[?]''
)[x, y], and thus ST ' (ph[?]'
)[x, y] and ST ' (ph[?]''
)[x, y], belong to the sub-grammar for a[?]
and have x, y as their free variables.
It immediately follows that ST (ph[?]'
[?]
ph[?]''
)[x, y] has the required form.
The case of disjunction is similar, and thus omitted.
Now, let ph[?]
= ph[?]'
C ph[?]''
.
By definition, ST (ph[?]'
C ph[?]''
)[x, y] = x <= y [?]
[?
]z(x <= z <= y [?]
ST ' (ph[?]'
) [x, z] [?]
ST ' (ph[?]''
)[z, y]).
By inductive hypothesis, ST ' (ph[?]'
)[x, z] is an a[?]
-formula with x, z as its free variables, and ST ' (ph[?]''
)[z, y] is an a[?]
-formula with z, y as its free variables.
Hence, the formula x <= y [?]
[?
]z(x <= z <= y [?]
ST ' (ph[?]'
)[x, z] [?]
ST ' (ph[?]''
)[z, y]) is an a[?]
-formula with x, y as its free variables.
The other two cases for D and T can be dealt with in a similar way.
Let us consider now an arbitrary formula generated by the grammar.
The only interesting cases are those for the negation of modalities.
Let ph = !(ph[?]'
C ph[?]''
).
By definition, ST (!(ph[?]'
C ph[?]''
))[x, y] = x <= y [?]
!ST ' (ph[?]'
C ph[?]''
)[x, y], and ST ' (ph[?]'
C ph[?]''
)[x, y] = [?
]z(x <= z <= y [?]
ST ' (ph[?]'
)[x, z] [?]
ST ' (ph[?]''
)[z, y]).
We have already shown that both ST ' (ph[?]'
)[x, z] and ST ' (ph[?]''
)[z, y] are a[?]
-formulas with x, z and z, y as their free variables, respectively.
Hence,  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  7  [?
]z(x <= z <= y [?]
ST ' (ph[?]'
)[x, z] [?]
ST ' (ph[?]''
)[z, y]) is an a[?]
-formula with x, y as its free variables.
It immediately follows that !ST ' (ph[?]'
C ph[?]''
)[x, y] is an a -formula with x, y as its free variables, and thus the thesis, as the conjunction of two a -formulas is an a -formula.
The other two cases can be dealt with in a similar way.
[?]
[?]
In order to prove the main theorem, it suffices to observe that the linear order < is captured by the following axioms [4], whose conjunction Ph belongs to FOBS : 1.
2.
3.
4.
[?]x!
(x < x); [?
]x, y(x < y - !y < x); [?
]x, y, z(x < y [?]
y < z - x < z); [?
]x, y(x = y [?]
x < y [?]
y < x).
Theorem 1 The satisfiability problem for CDTBS over the class of all linear orders is decidable.
Proof By Lemma 1, if ph is a CDTBS -formula, then [?
]x, yST (ph )[x, y] (the existential closure of ST (ph )[x, y]) belongs to Bernays-Schonfinkel class.
Satisfiability of ph can thus be reduced to satisfiability of the FOBS -formula Ph [?]
[?
]x, yST (ph )[x, y].
Since the satisfiability problem for FOBS is decidable, decidability of CDTBS immediately follows.
[?]
[?]
The satisfiability problem for FOBS has been shown to be NEXPTIME-complete.
The proof relies on the observation that an FOBS -formula is satisfiable if and only if it has a model with a number of elements bounded by the number of existential quantifiers [4, Proposition 6.2.17].
This immediately leads to a nondeterministic exponential-time procedure for satisfiability checking.
However, when we restrict our attention to formulas where the arity of relational symbols is bounded (to two, in our case), the complexity of such a procedure becomes PSPACE, since in this case a candidate model for the formula can be represented using only a polynomial amount of memory.
Hence, Theorem 1 gives us a PSPACE upperbound to the complexity of CDTBS .
In Section 5, we will show that this bound is not tight, by providing an NP decision procedure for the satisfiability of CDTBS .
4 Expressive completeness of CDTBS In Section 3, we showed that CDTBS formulas can be translated into Bernays-Schonfinkel class FOBS of first-order logic with equality, thanks to the fact that the linear order < can be expressed in this fragment.
Inspired by the observation that the translation uses only binary predicates, we now ask ourselves the following question: for every formula in Bernays-Schonfinkel class of first-order logic, interpreted over the linear order < and limited to binary predicates, is there an expressively equivalent CDTBS -formula?
Similar expressivity comparison issues have been already investigated for various point- and interval-based logics.
A partial list includes basic results about the completeness of LTL with respect to the first-order fragment of monadic second-order logic over Dedekind-complete linear orders and generalizations (Kamp's Theorem and its extensions [12-14, 21, 22, 25]), the completeness of CDT with respect to the three-variable fragment of first-order logic over linear orders, where at most two variables are free [33], the completeness of AA with respect to two-variable first-order logic over linear orders [8], and the completeness of its metric extension, called MPNL, with respect to a fragment of two-variable first-order logic extended with a successor function over N [7].
8  Davide Bresolin et al.
We focus our attention on first-order logic interpreted over the linear order < and limited to binary predicates, denoted by FO[<].
We will denote by FOn,m [<] the n-variable fragment of FO[<], where at most m variables are free, and by FOo ,m [<] the fragment of FO[<] with a denumerable set of variables, where at most m are free.
Since interval logics are interpreted over intervals (represented as pairs of points), the standard translation of any interval logic formula is a formula with two free variables, and thus it belongs to FOo ,2 [<].
By analogy with the case of other interval logics, e.g., [8, 33], to establish an expressive completeness result for CDTBS , we will limit the number of variables of the corresponding first-order frago ,m n,m [<]) the n-variable fragment (resp., the fragment ment.
We denote by FOBS [<] (resp., FOBS with a denumerable set of variables) of the language defined by grammar (1), where at most m variables occur free.
In the following, we compare interval and first-order logics with respect to their ability of expressing properties of a given interval in a model.
We distinguish three cases: (i) the comparison of two interval logics, (ii) the comparison of two fragments of first-order logic, and (iii) the comparison of an interval logic and a fragment of first-order logic.
Given two interval logics (resp., fragments of first-order logic) L and L', we say that L' is at least as expressive as L, denoted by L  L' , if there is an (effective) translation t from L to L' such that for every model M, interval [di , d j ] (resp., pair of points di , d j ) in M, and formula ph of L, M, [di , d j ]  ph iff M, [di , d j ]  t (ph ) (resp., M |= ph (di , d j ) iff M |= t (ph )(di, d j )).
Furthermore, we say that L' is as expressive as L, denoted by L' [?]
L, if both L'  L and L  L' , and we say that L' is strictly more expressive than L, denoted by L [?]
L' , if L  L' and L' 6 L. To compare the expressive power of an interval logic and a fragment of first-order logic, we must cope with a technical problem: interval models constrain interval logic formulas to be evaluated on ordered pairs [di , d j ], with di <= d j , only, while relational models do not impose such a constraint.
To solve it, we map each binary relation p of the considered fragment of first-order logic into two distinct proposition letters p<= and p>= of the interval logic.
From [8], we borrow the following definition.
Definition 1 Let M = hI(D),VM i be an interval model.
The corresponding relational model e (M) is the pair hD,Ve (M)i, where, for every proposition letter p, Ve (M)(p) = {(a, b) [?]
D x D : [a, b] [?]
VM (p)}.
Conversely, let M = hD,VM i be a relational model.
The corresponding interval model z (M) is the pair hI(D), Vz (M) i, where, for every binary relation p and interval [di , d j ], [di , d j ] [?]
Vz (M) (p<= ) iff (di , d j ) [?]
VM (p) and [di , d j ] [?]
Vz (M) (p>= ) iff (d j , di ) [?]
VM (p).
Given an interval logic LI and a fragment of first-order logic LFO , we say that LFO is at least as expressive as LI , denoted by LI  LFO , if there exists an effective translation t from LI to LFO such that for any interval model M, interval [di , d j ], and LI -formula ph , M, [di , d j ]  ph iff e (M) |= t (ph )(di, d j ).
Conversely, we say that LI is at least as expressive as LFO , denoted by LFO  LI , if there exists an effective translation t ' from LFO to LI such that, for any relational model M, pair of points (di , d j ), and LFO -formula ph , M |= ph (di , d j ) if and only if z (M), [di , d j ]  t ' (ph ), if di <= d j , or z (M), [d j , di ]  t ' (ph ), otherwise.
LI [?]
LFO , LI [?]
LFO , and LFO [?]
LI are defined as usual.
In [32], Venema shows that the hierarchy of fragments FOn,2 [<], for n >= 2, is strict.
Theorem 2 For every n >= 2, FOn,2 [<] [?]
FOn+1,2 [<] (over the class of all linear orders).
The expressive completeness of the interval logic of temporal neighborhood AA with respect to FO2,2 [<] and of CDT with respect to FO3,2 [<] have been proved by Bresolin et al.
in [8] and by Venema in [33], respectively.
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  t i, j (xi = x j ) t i, j (x j = xi ) t i, j (xi = xi ) t i, j (x j = x j ) t i, j (xi < x j ) t i, j (x j < xi ) t i, j (xi < xi ) t i, j (x j < x j ) t i, j (p(xi ,x j )) t i, j (p(x j ,xi )) t i, j (p(xi ,xi )) t i, j (p(x j ,x j ))  = = = = = = = = = = = =  p t i, j (!a (xi ,x j )) p [?]
t i, j (a (xi ,x j ) [?]
b (xi ,x j )) [?]
!p t i, j (a (xi ,x j ) [?]
b (xi ,x j )) [?]
t i, j ([?
]xk (a (xi ,xk ) [?]
b (xk ,x j ))) [?]
[?]
p<= p>= (p [?]
p<= )C [?]
[?
]C (p [?]
p<= )  9  = !t i, j (a (xi ,x j )) = t i, j (a (xi ,x j )) [?]
t i, j (b (xi ,x j )) = t i, j (a (xi ,x j )) [?]
t i, j (b (xi ,x j )) = t k,i (a (xi ,xk )) D t k, j (b (xk ,x j ))[?]
t i,k (a (xi ,xk ))C t k, j (b (xk ,x j ))[?]
t j,k (b (xk ,x j )) T t i,k (a (xi ,xk ))  Table 1 The mapping of FO3,2 sp [<] into CDTBS : translation rules.
Theorem 3 AA [?]
FO2,2 [<].
Theorem 4 CDT [?]
FO3,2 [<].
The proof of Theorem 2 shows that for any given n >= 2, there exist two models M1 and M2 such that M1 and M2 satisfy the same set of FOn,2 [<]-formulas, and there exists an FOn+1,2 [<]-formula which is satisfied by M1 and not by M2 .
Equivalence of M1 and M2 with respect to FOn,2 [<]-formulas is established by a game-theoretic argument, while the FOn+1,2 [<]-formula that differentiates the two models is the following one: ^  [?
]x1 [?
]x2 .
.
.
[?
]xn [?
]xn+1 !p(xi , x j ) .
(6) xi 6=x j  Since such a formula belongs to Bernays-Schonfinkel fragment of first-order logic, the very n+1,2 same argument can be used to prove that FOn,2 BS [<] [?]
FOBS [<], for any n >= 2.
Moreover, n,2 by Theorem 4, it holds that FOBS [<] [?]
FOn,2 [<], for every n >= 3: on the one hand, it o ,2 n,2 trivially holds that FOn,2 BS [<]  FO [<]; on the other hand, decidability of FOBS [<] and n,2 n,2 undecidability of CDT imply that FO [<] 6 FOBS [<].
Finally, we have that, for every n+1,2 n+1,2 n >= 3, FOn,2 [<] and FOBS [<] are incomparable: on the one hand, FOBS [<] 6 FOn,2 [<], n+1,2 as formula (6) belongs to FOBS [<] and there is not an equivalent formula in FOn,2 [<]; n+1,2 on the other hand, FOBS [<] is decidable, while FOn,2 [<] is not, and thus FOn,2 [<] 6 n+1,2 FOBS [<].
Hence, the following theorem holds.
Theorem 5 For every n >= 3, it holds that: n-1,2 n,2 1.
FOBS [<] [?]
FOBS [<]; n,2 n,2 2.
FOBS [<] [?]
FO [<]; n+1,2 3.
FOn,2 [<] and FOBS [<] are incomparable  (over the class of all linear orders).
We conclude the section by showing that CDTBS is expressively complete with respect to FO3,2 BS [<].
One direction is straightforward: since the standard translation of CDTBS formulas given in Section 3 makes use of 3 variables only, it holds that CDTBS  FO3,2 BS [<].
We now show that the converse holds as well, that is, FO3,2 [<]  CDT .
By analogy BS BS to the case of the mapping from FO3,2 [<] to CDT defined by Venema [33], as a preliminary step, we provide a suitable characterization of FO3,2 BS [<]-formulas.
10  Davide Bresolin et al.
Definition 2 Let {i, j, k} [?]
{1, 2, 3}.
The language FO3,2 sp [<] is defined by the following abstract grammar:  b (xi , x j ) ::= b[?]
(xi , x j ) | b (xi , x j ) [?]
b (xi , x j ) | b (xi , x j ) [?]
b (xi , x j ) | [?
]xk (b (xi , xk ) [?]
b (xk , x j )) | !b[?]
(xi , x j ) for b[?]
(xi , x j )  (7)  of the form [?
]xk (b[?]
(xi , xk ) [?]
b[?]
(xk , x j ))  b[?]
(xi , x j ) ::= A(xi , x j ) | !A(xi , x j ) | b[?]
(xi , x j ) [?]
b[?]
(xi , x j ) | b[?]
(xi , x j ) [?]
b[?]
(xi , x j ) | [?
]xk (b[?]
(xi , xk ) [?]
b[?]
(xk , x j )) A(xi , x j ) ::= xi = x j | x j = xi | xi = xi | x j = x j | xi < x j | x j < xi | xi < xi | x j < x j | p(xi , x j ) | p(x j , xi ) | p(xi , xi ) | p(x j , x j )  (8) (9)  3,2 Lemma 2 For every formula in FO3,2 BS [<], there is an equivalent formula in FOsp [<].
3,3 Proof We prove the following stronger claim on the 3-variable fragment FOBS [<], which includes formulas where all three variables occur free:  for every formula a in FO3,3 BS [<] there is equivalent formula t (a ), which is a 3,2 Boolean combination of FOsp [<]-formulas, with the same free variables as a .
The proof is by structural induction.
The base cases (a is an atomic formula or a is the negation of an atomic formula) and the case of logical connectives (a is a conjunction or a disjunction of formulas) are straightforward.
In particular, as for the base case, it suffices to remind that we restricted our attention to fragments of first-order logic with binary predicates only.
Let a be of the form [?
]xk g (xi , x j , xk ).
By the inductive hypothesis, g (xi , x j , xk ) is equivalent to a formula t (g (xi , x j , xk )), that we may assume, without loss of generality, to be a disjunction of conjunctions of formulas in FO3,2 the existential quansp [<].
By distributing W tifier [?
]xk over disjunctions, we obtain a formula of the form m h=1 [?
]xk gh (xi , x j , xk ), where each gh (xi , x j , xk ) is a conjunction of formulas.
Since only binary predicates are allowed, we can rewrite each gh (xi , x j , xk ) as xh (xi , x j ) [?]
xh (xi , xk ) [?]
xh (x j , xk ).
Since variable xk does not occur free in xh (xi , x j ), we can rewrite [?
]xk gh (xi , x j , xk ) as xh (xi , x j ) [?]
[?
]xk (xh (xi , xk ) [?]
3,2 xh (x j , xk )).
This latter formula is a conjunction of FOsp [<]-formulas with the same free variables as a .
The case in which a is of the form ![?
]xk g (xi , x j , xk ) can be dealt with in a very similar way.
[?]
[?]
We are now ready to define the translation t from FO3,2 sp [<] to CDTBS .
For the sake of brevity, we write t i, j for t [xi , x j ], with xi <= x j .
Translation rules for atomic and complex formulas are given in Table 1.
Lemma 3 Let a (xi , x j ) be an FO3,2 sp [<]-formula.
Then, for every pair of points (di , d j ), M |= a (di , d j ) if and only if di <= d j and z (M), [di , d j ]  t i, j (a (xi , x j )), or d j <= di and z (M), [d j , di ]  t j,i (a (xi , x j )).
Proof The proof is by induction on the structure of a (xi , x j ).
The cases of atomic formulas and Boolean connectives are straightforward.
Once more, the only interesting case is the one of existential quantifiers.
Let a (xi , x j ) be the formula [?
]xk (b (xi , xk ) [?]
g (xk , x j )) and di <= d j .
By the semantic clauses for FO3,2 sp [<], it  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  11  FOo ,2 [<] ,2 FOo BS [<]  ...  FO4,2 [<] CDT [?]
FO3,2 [<] PNL [?]
FO2,2 [<]  ...  FO4,2 BS [<]  [?]
CDTBS FO3,2 BS [<]  Fig.
2 A classification of the considered interval logics and fragments of first-order logic with respect to their expressive power.
holds that M |= [?
]xk (b (di , xk ) [?]
g (xk , d j )) if and only if there exists a point dk such that M |= b (di , dk ) and M |= g (dk , d j ).
Since we are interpreting our formulas over a linear order, there are three possible ways to place dk with respect to di and d j : either dk <= di , or di <= dk <= d j , or d j <= dk .
By the inductive hypothesis, we have that M |= a (di , d j ) if and only if:   z (M), [dk , di ]  t k,i (b (xi , xk )) and z (M), [dk , d j ]  t k, j (g (xk , x j ))   or z (M), [di , dk ]  t i,k (b (xi , xk )) and z (M), [dk , d j ]  t k, j (g (xk , x j ))   or z (M), [d j , dk ]  t j,k (g (xk , x j )) and z (M), [di , dk ]  t i,k (b (xi , xk )) .
By the semantics of the C, D, and T operators, we can conclude that M |= a (di , d j ) if and only if z (M), [di , d j ]  t i, j (a (xi , x j )), as required.
[?]
[?]
Theorem 6 CDTBS is as expressive as FO3,2 BS [<].
3,2 Proof By Lemma 2 and Lemma 3, FO3,2 BS [<]  FOsp [<]  CDTBS .
Moreover, by Lemma 3,2 1, CDTBS  FO3,2 [?]
[?]
BS [<].
Hence, CDTBS [?]
FOBS [<].
Figure 2 gives a graphical account of the relationships among the considered logics (interval logics and fragments of first-order logic) in terms of their expressive power (the contributions of the present work are in boldface).
5 A tableau method for CDTBS In [15], Goranko et al.
propose a tableau method for CDT interpreted over partial orders with the linear interval property, that is, partial orders in which every interval is linear (BCDT+ for short).
The method provides a semi-decision procedure for BCDT+ (it is not guaranteed to terminate).
This does not come as a surprise as BCDT+ is undecidable.
In this section, we show how to turn the method into an NP decision procedure CDTBS .
In particular, we show how to exploit BCDT+ syntactic restrictions to guarantee termination.
Let us start with some basic terminology.
A finite tree is a finite directed acyclic graph in which every node, apart from one (the root), has exactly one incoming edge.
A successor of a node n is a node n' such that there is an edge from n to n' .
A leaf is a node with no  12  Davide Bresolin et al.
successors.
A path is a sequence of nodes n0 , .
.
.
, nk such that, for all i = 0 .
.
.
k - 1, ni+1 is a successor of ni ; a branch is a path from the root to a leaf.
The height of a node n is the maximum length (number of edges) of a path from n to a leaf, while its depth is the length of the (unique) path from the root to it.
If two nodes n and n' belong to the same branch and the height of n is less than (resp., less than or equal to) the height of n' , we write n [?]
n' (resp., n  n' ).
Definition 3 Let D be a finite linear order.
A labeled formula over D is a pair (ps , [di , d j ]), where ps [?]
CDTBS and [di , d j ] [?]
I(D).
Definition 4 Let T be a (finite) tree and let n be a node of T .
The decoration n (n) of n is a tuple hps , [di , d j ], D, p, ui, where D is a finite linear order, (ps , [di , d j ]) is a labeled formula over D, p [?]
{0, 1}, and u is a local flag function which associates the values 0 or 1 with every branch B containing n. Definition 5 A decorated tree is a finite tree T enriched with a decoration n (n) for each node n of T , apart from the root.
The tableau construction described below generates a decorated tree T .
Given a branch B and a node n belonging to it, with decoration n (n), u(B) = 1 means that n can be expanded on B.
Given a branch B, B * (n1 * .
.
.
* nh ) is the result of the expansion of B with the sequence of nodes n1 *.
.
.
*nh (for h = 1, we simply write B*n), while B*(n1,1 *.
.
.
*n1,h )| .
.
.|(nk,1 *.
.
.
*nk,h ) is the result of the expansion of B with k sequences of h nodes (for h = 1, we simply write B * n1 | .
.
.|nk ).
The auxiliary flag p has been added to simplify termination and complexity proofs.
It records the nature of formula ps : if ps is a ph[?]
-formula, then p = 0; otherwise, p = 1.
Finally, if n is the leaf of a branch B, we denote by DB the finite linear order in n (n).
Since in CDTBS negation can occur only in front of proposition letters or modalities, we need to introduce the notion of dual formula of a formula ph , denoted by ph .
It is inductively defined as follows: - - - - -  p = !p and !p = p, for every p [?]
A P [?]
{p }; ph [?]
ps = ph [?]
ps; ph [?]
ps = ph [?]
ps; ph R ps = !
(ph R ps ), for R [?]
{C, D, T }; !
(ph R ps ) = ph R ps , for R [?]
{C, D, T }.
Notice that the dual of a generic CDTBS -formula does not necessarily belong to CDTBS .
This is the case, for instance, with the formula pC !
(qC r).
However, the following lemma guarantees that dual formulas of ph[?]
-formulas are CDTBS -formulas.
Such a lemma will play a crucial role in the proof of correctness of the tableau method.
Lemma 4 Let ph be a ph[?]
-formula.
Then, ph is a CDTBS -formula.
Proof The cases of proposition letters and Boolean connectives can be proved by a straightforward structural induction.
To prove that the thesis holds also for modalities, let us assume ph = ps C t to be a ph[?]
-formula.
By definition, the dual formula ph is !
(ps C t ).
Since ps , t are ph[?]
-formulas, we can conclude that ph is a CDTBS -formula.
The other cases can be dealt with in a similar way.
[?]
[?]
The construction of a tableau for a CDTBS -formula ph to be checked for satisfiability starts from a three-node tree (initial tableau) consisting of a root and two leaves with decorations hph , [d0 , d0 ], {d0 }, 1, 1i and hph , [d0 , d1 ], {d0 < d1 }, 1, 1i, respectively.
The procedure exploits  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  13  a set of expansion rules, adapted from those given in [15], to add new nodes to the tree.
In particular, the original rules for modalities have been revised to restrict the search for possible models to linear orders only.
Definition 6 Given a tree T , a branch B in T , and a node n [?]
B with decoration hps , [di , d j ], D, pn , un i such that un (B) = 1, the branch-expansion rule for B and n is defined as follows (in all considered cases, un' (B' ) = 1 for all new nodes n' and branches B' ).
R1 If ps = x0 [?]
x1 , then expand B to B*n0 *n1 , where n0 is decorated with hx0 , [di , d j ], DB , pn , un0 i and n1 is decorated with hx1 , [di , d j ], DB , pn , un1 i. R2 If ps = x0 [?]
x1 , then expand B to B*n0 | n1 , where n0 is decorated with hx0 , [di , d j ], DB , pn , un0 i and n1 is decorated with hx1 , [di , d j ], DB , pn , un1 i. R3 If ps = !
(x0 C x1 ) and d is a point in DB , with di <= d <= d j , which has not been used yet to expand n in B, then expand B to B * n0 |n1 , where n0 is decorated with hx0 , [di , d], DB , 0, un0 i and n1 is decorated with hx1 , [d, d j ], DB , 0, un1 i. R4 If ps = !
(x0 D x1 ), and d is a point in DB , with d <= di , which has not been used yet to expand n in B, then expand B to B * n0 |n1 , where n0 is decorated with hx0 , [d, di ], DB , 0, un0 i and n1 is decorated with hx1 , [d, d j ], DB , 0, un1 i. R5 If ps = !
(x0 T x1 ), and d is a point in DB , with d j <= d, which has not been used yet to expand n in B, then expand B to B* n0 |n1 , where n0 is decorated with hx0 , [d j , d], DB , 0, un0 i and n1 is decorated with hx1 , [di , d], DB , 0, un1 i. R6 If ps = x0 C x1 , then expand B to B * (ni * mi )| .
.
.|(n j * m j )|(n'i * m'i )| .
.
.|(n'j-1 * m'j-1 ), where: (a) for all i <= k <= j, nk is decorated with hx0 , [di , dk ], DB , pn , unk i and mk is decorated with hx1 , [dk , d j ], DB , pn , umk i; (b) for all i <= k <= j - 1, Dk is the linear ordering obtained from DB by inserting a new point d between dk and dk+1 , n'k is decorated with hx0 , [di , d], Dk , pn , un' i and m'k is k decorated with hx1 , [d, d j ], Dk , pn , um' i. k  R7 If ps = x0 D x1 and d0 is the least point of DB , then expand B to B * (n0 * m0 )| .
.
.|(ni * mi )|(n'0 * m'0 )| .
.
.|(n'i * m'i ), where: (a) for all 0 <= k <= i, nk is decorated with hx0 , [dk , di ], DB , pn , unk i and mk is decorated with hx1 , [dk , d j ], DB , pn , umk i; (b) for all 0 <= k <= i, Dk is the linear ordering obtained from DB by inserting a new point d between dk-1 and dk (for k = 0, d is placed immediately before d0 ), n'k is decorated with hx0 , [d, di ], Dk , pn , un' i and m'k is decorated with hx1 , [d, d j ], Dk , pn , um' i. k  k  R8 If ps = x0 T x1 and dN is the greatest point of DB , then expand B to B * (n j * m j )| .
.
.|(nN * mN )|(n'j * m'j )| .
.
.|(n'N * m'N ), where: (a) for all j <= k <= N, nk is decorated with hx0 , [d j , dk ], DB , pn , unk i and mk is decorated with hx1 , [di , dk ], DB , pn , umk i; (b) for all j <= k <= N, Dk is the linear ordering obtained from DB by inserting a new point d between dk and dk+1 (for k = N, d is placed immediately after dN ), n'k is decorated with hx0 , [d j , d], Dk , pn , un' i and m'k is decorated with hx1 , [di , d], Dk , pn , um' i. k  k  Finally, for each branch B' extending B, let um (B' ) = um (B), for each node m 6= n in B, and let un (B' ) = 0, unless ps = !
(x0C x1 ), ps = !
(x0 Dx1 ), or ps = !
(x0 T x1 ) (in such cases un (B' ) = 1).
14  Davide Bresolin et al.
We briefly explain the behavior of the branch-expansion rule in cases R6 (x0 C x1 ) and R3 (!
(x0C x1 )).
The corresponding cases for modalities D and T are similar.
R6 deals with two possible scenarios: either there exists dk [?]
DB such that x0 holds over [di , dk ] and x1 holds over [dk , d j ], or such a point must be added to DB .
The successors (ni * mi )| .
.
.|(n j * m j ) created by the rule cover the former case, while the successors (n'i * m'i )| .
.
.|(n'j-1 * m'j-1 ) cover the latter case.
As for R3, the formula !
(x0 C x1 ) states that, for all di <= d <= d j , either x0 holds over [di , d] or x1 holds over [d, d j ].
R3 imposes such a condition for a single point d [?]
DB and keeps the flag equal to 1.
In such a way, all points in DB are eventually considered, including those points that will be added in subsequent steps of the tableau construction.
Definition 7 A branch B is closed if one of the following conditions holds: 1. there are two nodes n, n' in B such that n (n) = hps , [di , d j ], D, p, ui and n (n' ) = hps , [di , d j ], D' , p' , u' i for some formula ps and di , d j [?]
D; 2. there is a node n such that n (n) = hp , [di , d j ], D, p, ui and di 6= d j ; 3. there is a node n such that n (n) = h!p , [di , d j ], D, p, ui and di = d j ; If none of the above conditions hold, the branch is open.
Definition 8 The branch-expansion strategy for a branch B in a decorated tree T is defined as follows: 1. apply the branch-expansion rule to a branch B only if it is open; 2. if B is open, apply the branch-expansion rule to the closest to the root node n such that un (B) = 1 and the application of the rule generates at least one node with a new decoration (if any).
Definition 9 A tableau T is any decorated tree obtained from the initial tableau by the application of the branch-expansion strategy.
We say that a tableau T is closed if and only if all its branches are closed, otherwise it is open.
We conclude the section by giving a couple of examples of the application of the proposed method.
As a first example, we consider the satisfiable formula ph = (!p D !p )C !p .
A portion of a tableau for ph is given in Figure 3, where thick edges highlights an open branch representing a four-point model for the formula.
As a second example, let ps be the unsatisfiable formula p T !([?
]C p).
A closed tableau for ps is given in Figure 4.
It is worth pointing out that there is an abuse of notation in the last component of the node decorations: while it is formally defined as a function from a set of branches to {0, 1}, in the pictures it is represented as a constant (either 0 or 1).
The reason is that in the proposed examples the function is constant for each node, that is, for each n we have that the value of the function un (B) is the same for every branch B containing n. In the following, we will show that to establish the satisfiability of a CDTBS -formula ph it is sufficient to start with the initial tableau for ph , and keep expanding it for as long as it is possible: if the resulting tableau is open, then ph is satisfiable, otherwise it is not.
Moreover, we will prove that this expansion procedure terminates and it can be executed by a nondeterministic machine that uses only a polynomial amount of time.
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  15  root     (!p D !p )C !p , [d0 , d0 ], {d0 }, 1, 0     (!p D !p )C !p , [d0 , d1 ], {d0 < d1 }, 1, 0   !p D !p , [d0 , d0 ], {d0 }, 1, 1     !p , [d0 , d0 ], {d0 }, 1, 1  x           !p D !p , [d0 , d0 ], {d0 < d1 }, 1, 1     !p D !p , [d0 , d1 ], {d0 < d1 }, 1, 1     !p , [d1 , d1 ], {d0 < d1 }, 1, 1   !p D !p , [d0 , d2 ], {d0 < d2 < d1 }, 1, 0     !p , [d2 , d1 ], {d0 < d2 < d1 }, 1, 1  x   !p , [d0 , d1 ], {d0 < d1 }, 1, 1 ***         !p , [d0 , d2 ], {d0 < d2 < d1 }, 1, 1      !p , [d3 , d0 ], {d3 < d0 < d2 < d1 }, 1, 1      !p , [d0 , d0 ], {d0 < d2 < d1 }, 1, 1      !p , [d3 , d2 ], {d3 < d0 < d2 < d1 }, 1, 1  x Fig.
3 A portion of an open tableau for the formula (!p D !p )C !p .
5.1 Soundness In this subsection, we prove that the proposed tableau method is sound, that is, given a formula ph and a tableau T for it, if T is closed, then ph is not satisfiable.
In the next subsection, we will show that the method is also complete.
Lemma 5 (Soundness) Let ph be a CDTBS -formula and T be a tableau for it.
If T is closed, then ph is not satisfiable.
Proof Let n be a node in the tableau T , and let Dn = {d0 < .
.
.
< ds } be the linear ordering from n (n).
We will prove the following claim by induction on the height h of the node: if every branch including n is closed, then the set S(n) of all labeled formulas in the decorations of the nodes between n and the root is neither satisfiable in I(Dn ) nor in any extension of it.
If h = 0, then n is a leaf and the unique branch B containing n is closed.
Then, either S(n) contains both the labeled formulas (ps , [dk , dl ]) and (!ps , [dk , dl ]), for some CDTBS formula ps and dk , dl [?]
Dn , or the labeled formula (p , [dk , dl ]), for some dk 6= dl , or the labeled formula (!p , [dk , dl ]), for some dk = dl .
Take any model M = hI(D' ),V i, where D' extends Dn .
It holds that M, [dk , dl ]  ps if and only if M, [dk , dl ] 6 !ps , and, therefore, (ps , [dk , dl ]) and (!ps , [dk , dl ]) cannot be jointly satisfied.
Similarly, M, [dk , dl ]  p (resp., M, [dk , dl ]  !p ) if and only if dk = dl (resp., dk 6= dl ), and therefore (p , [dk , dl ]) (resp., (!p , [dk , dl ])) cannot be satisfied when dk 6= dl (resp., dk = dl ).
Now, suppose that h > 0.
Then, either n has been generated as one of the successors, but not the last one, when applying cases R1, R6, R7, or R8 of the branch-expansion rule, or the branch-expansion rule has been applied to some labeled formula (ps , [dk , dl ]) [?]
S(n) \{t }, where t is the labeled formula in the decoration n (n), to extend the branch at n. We  16  Davide Bresolin et al.
root       p T !([?
]C p),[d0 ,d0 ],{d0 },1,0   p,[d0 ,d0 ],{d0 },1,1     !([?
]C p),[d0 ,d0 ],{d0 },1,1    [?
],[d0 ,d0 ],{d0 },0,1     !p,[d0 ,d0 ],{d0 },0,1  x  x      p,[d0 ,d1 ],{d0 < d1 },1,1     !([?
]C p),[d0 ,d1 ],{d0 < d1 },1,1     [?
],[d0 ,d1 ],{d0 < d1 },0,1     !p,[d0 ,d1 ],{d0 < d1 },0,1  x  x        p T !([?
]C p),[d0 ,d1 ],{d0 < d1 },1,0   p,[d1 ,d1 ],{d0 < d1 },1,1     !([?
]C p),[d0 ,d1 ],{d0 < d1 },1,1    [?
],[d0 ,d1 ],{d0 < d1 },0,1     !p,[d1 ,d1 ],{d0 < d1 },0,1  x  x      p,[d1 ,d2 ],{d0 < d1 < d2 },1,1     !([?
]C p),[d0 ,d2 ],{d0 < d1 < d2 },1,1     [?
],[d0 ,d1 ],{d0 < d1 < d2 },0,1     !p,[d1 ,d2 ],{d0 < d1 < d2 },0,1  x  x  Fig.
4 A closed tableau for the formula p T !([?
]C p).
detail the latter case; the former one can be dealt with in the same way, and thus its analysis is omitted.
First, we observe that every branch passing through any successor of n must be closed.
It immediately follows that the inductive hypothesis applies to all successors of n. We consider the possible cases for the application of the branch-expansion rule to extend the branch at n, restricting our attention to the conceptually different ones only (the other cases can be dealt with in a similar way): - If ps = x0 [?]
x1 , R1 has been applied.
Then, there are two nodes n0 , n1 such that n (n0 ) = hx0 , [dk , dl ], D, p0 , u0 i, n (n1 ) = hx1 , [dk , dl ], D, p1 , u1 i.
Without loss of generality, we can assume n0 to be the successor of n and n1 to be the successor of n0 .
Since each branch containing n is closed, then each branch containing n1 is closed as well.
By the inductive hypothesis (n1 [?]
n), S(n1 ) is not satisfiable.
Since every model satisfying S(n) must, in particular, satisfy (x0 [?]
x1 , [dk , dl ]), and hence (x0 , [dk , dl ]) and (x1 , dk , dl ]), it follows that S(n), S(n0 ), and S(n1 ) are equi-satisfiable.
Therefore, S(n) is not satisfiable.
- If ps = x1 [?]
x2 , R2 has been applied.
Then, there exist two successor nodes n0 and n1 of n such that n (n0 ) = hx0 , [dk , dl ], D, p0 , u0 i, n (n1 ) = hx1 , [dk , dl ], D, p1 , u1 i, and both  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  17  n0 [?]
n and n1 [?]
n. Since each branch containing n is closed, then each branch containing n0 or n1 is closed as well.
By the inductive hypothesis, S(n0 ) and S(n1 ) are not satisfiable.
Since every model satisfying S(n) must also satisfy (x0 , [dk , dl ]) or (x1 , [dk , dl ]), it follows that S(n) is not satisfiable.
- If ps = !
(x0 C x1 ), R3 has been applied.
For the sake of contradiction, let us assume S(n) to be satisfiable.
Then, since (!
(x0 C x1 ), [dk , dl ]) [?]
S(n), there is a model M = hI(D' ),V i such that D' extends Dn and M, [dk , dl ]  !
(x0C x1 ).
Hence, for each dt such that dk <= dt <= dl , M, [dk , dt ] 6 x0 or M, [dt , dl ] 6 x1 .
By construction, the two immediate successors of n are two nodes n0 and n1 and there exists a point dt , with dk <= dt <= dl , such that (x 0 , [dk , dt ]) is in n (n0 ) and (x 1 , [dt , dl ]) is in n (n1 ).
By the inductive hypothesis (both n0 [?]
n and n1 [?]
n), S(n0 ) and S(n1 ) are not satisfiable.
But, from the hypothesis of our reductio-ad-absurdum argument, there is a model M = hI(D' ),V i, where D' is an extension of Dn , such that M, [dk , dt ]  !x0 or M, [dt , dl ]  !x1 .
Thus, either S(n0 ) or S(n1 ) is satisfiable (by model M), leading to a contradiction.
- If ps = x0 C x1 , R6 has been applied.
For the sake of contradiction, let us assume S(n) to be satisfiable.
Then, there is a model M = hI(D' ),V i such that D' extends Dn and M, [dk , dl ]  x0 C x1 .
Hence, M, [dk , d]  x0 and M, [d, dl ]  x1 for some dk <= d <= dl .
Two cases are possible: 1.
If d [?]
Dn , then d = dt for some dk <= dt <= dl .
By R6, n has a successor, say it nt , which, in turn, has a successor, say it nt' , with n (nt ) = hx0 , [dk , dt ], Dn , pt , ut i and n (nt' ) = hx1 , [dt , dl ], Dn , pt' , ut' i.
By the inductive hypothesis (nt [?]
n and nt' [?]
nt ), S(nt' ) = S(n) [?
]{(x0 , [dk , dt ]), (x1 , [dt , dl ])} is not satisfiable.
But, from the hypothesis of our reductio-ad-absurdum argument, there is a model M = hI(D' ),V i, where D' is an extension of Dn , such that M, [dk , dt ]  x0 and M, [dt , dl ]  x1 .
Thus, S(nt' ) is satisfiable (by model M), leading to a contradiction.
2.
If d [?]
/ Dn , then there exists t such that k <= t <= l - 1 and dt < d < dt+1 .
By R6, n has a successor, say it nt , which, in turn, has a successor, say it nt' , with n (nt ) = hx0 , [dk , d], Dn [?]
{d}, pt , ut i, n (nt' ) = hx1 , [d, dl ], Dn [?]
{d}, pt' , ut' i.
By the inductive hypothesis (nt [?]
n and nt' [?]
nt ), S(nt' ) = S(n) [?
]{(x0 , [dk , d]), (x1 , [d, dl ])} is not satisfiable, which, as in the previous case, leads to a contradiction.
[?]
[?]
5.2 Completeness In this subsection, we prove that the proposed tableau method is complete, that is, whenever ph [?]
CDTBS is valid, every tableau T for !ph must be closed.
To this end, we need to preliminary prove some partial results.
Definition 10 Let ph be a CDTBS -formula and T0 be the initial tableau for it.
The limit tableau T for ph is the decorated tree generated as follows.
For all i >= 0, let Ti+1 be the tableau generated by the simultaneous application of the branch-expansion strategy to each branch in Ti .
If we ignore all flags from the decorations of the nodes in every Ti , we obtain a chain of decorated trees ordered by inclusion: T1 [?]
T2 [?]
.
.
.
[?]
Tk [?]
.
.
..
The limit tableau T is equal to  o S  Ti .
i=0  Notice that the above definition does not prelude the limit tableau from being infinite.
Later on, we will prove that it cannot be the case, that is, the limit tableau is always finite.
Nevertheless, finiteness (of the limit tableau) is not necessary to prove that the tableau method is complete.
18  Davide Bresolin et al.
The definitions of open and closed branch and tableau directly apply to the limit tableau as well.
In addition, we introduce the notion of saturated branch and tableau.
Definition 11 A branch in a (limit) tableau is saturated if there are no nodes on that branch to which the branch-expansion rule is applicable on the branch.
A (limit) tableau is saturated if every open branch in it is saturated.
We now show that the set of all labeled formulas on an open branch in a limit tableau has the saturation properties of a Hintikka set in first-order logic.
Lemma 6 Every limit tableau is saturated.
Proof Let B be a branch B in the limit tableau T and n be a node in B.
We prove that after every step of the expansion of that branch at which the branch-expansion rule becomes applicable to n (because n has just been introduced or a new point has been added) and the application of the rule generates at least a new node, then that rule is subsequently applied on B to that node.
The proof is by induction on depth(n) (the depth of node n).
Let us assume that depth(n) = l and the branch-expansion rule has become applicable to n. By the inductive hypothesis, the thesis holds for all nodes with depth(n) < l. If there are no nodes between the root (including the root) and n (excluding n) to which the branch-expansion rule is applicable at that moment, the next application of the branchexpansion rule on B is necessarily to n. Otherwise, let n* be the closest-to-n node between the root and n to which the branch-expansion rule is applicable, or will become applicable, on B at least once thereafter.
(Such a node exists because there are only finitely many nodes between n and the root.)
Since depth(n* ) < depth(n), by the inductive hypothesis, the branch-expansion rule has been subsequently applied to n* .
Then, the next application of the branch-expansion rule on B must have been to n and that completes the induction.
Suppose now that there exists a branch B in a limit tableau which is not saturated.
Let n be the closest-to-the-root node on B to which the branch-expansion rule is applicable.
If the case applicable to n is different from R3, R4, and R5, then the branch-expansion rule has become applicable to n at the step when n is introduced, and by the claim above, it has been subsequently applied.
Hence, the node has become unavailable thereafter, which contradicts the assumption.
Let us consider now the case of R3, that is, the formula in n (n) is !
(x0 C x1 ) (cases R4 and R5 are similar, and thus they are omitted).
An application of R3 on B would create two immediate successors with labeled formulas (x 0 , [di , d]) and (x 1 , [d, d j ]), at least one of them new on B.
For R3 to be applicable, points di , d j , and d must have been already introduced at some step of the construction of B.
Hence, at the moment when the three of them, and n, have appeared on the branch, the branch-expansion rule has become applicable to n. By the above claim, the rule has been subsequently applied on B and such an application must have introduced the labeled formulas (x0 , [di , d]) and (x1 , [d, d j ]) on B, which again contradicts the assumption.
[?]
[?]
Corollary 1 Let ph be a CDTBS -formula and T be the limit tableau for ph .
For every open branch B in T , the following closure properties hold: - If there is a node n [?]
B such that n (n) = (x0 [?]
x1 , [di , d j ], D, pn , un ), then there are a node n0 [?]
B such that n (n0 ) = (x0 , [di , d j ], D, pn0 , un0 ) and a node n1 [?]
B such that n (n1 ) = (x1 , [di , d j ], D, pn1 , un1 ).
- If there is a node n [?]
B such that n (n) = (x0 [?]
x1 , [di , d j ], D, pn , un ), then there are a node n0 [?]
B such that n (n0 ) = (x0 , [di , d j ], D, pn0 , un0 ) or a node n1 [?]
B such that n (n1 ) = (x1 , [di , d j ], D, pn1 , un1 ).
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  19  - If there is a node n [?]
B such that n (n) = (x0 C x1 , [di , d j ], D, pn , un ), then there are two nodes n0 , n1 [?]
B such that n (n0 ) = (x0 , [di , d], D' , pn0 , un0 ) and n (n1 ) = (x1 , [d, d j ], D' , pn0 , un0 ), for some d [?]
DB , with di <= d <= d j , .
- If there is a node n [?]
B such that n (n) = (x0 D x1 , [di , d j ], D, pn , un ), then there are two nodes n0 , n1 [?]
B such that n (n0 ) = (x0 , [d, di ], D' , pn0 , un0 ) and n (n1 ) = (x1 , [d, d j ], D' , pn0 , un0 ), for some d [?]
DB , with d <= di .
- If there is a node n [?]
B such that n (n) = (x0 T x1 , [di , d j ], D, pn , un ), then there are two nodes n0 , n1 [?]
B such that n (n0 ) = (x0 , [di , d], D' , pn0 , un0 ) and n (n1 ) = (x1 , [d j , d], D' , pn0 , un0 ), for some d [?]
DB , with d >= d j , .
- If there is a node n [?]
B such that n (n) = (!
(x0 C x1 ), [di , d j ], D, pn , un ), then, for each d [?]
DB , with di <= d <= d j , there is a node n' [?]
B such that n (n' ) = (x 0 , [di , d], D' , pn' , un' ) or a node n' [?]
B such that n (n' ) = (x 1 , [d, d j ], D' , pn' , un' ).
- If there is a node n [?]
B such that n (n) = (!
(x0 D x1 ), [di , d j ], D, pn , un ), then for each d [?]
DB , with d <= di , there is a node n' [?]
B such that n (n' ) = (x 0 , [d, di ], D' , pn' , un' ) or a node n' [?]
B such that n (n' ) = (x 1 , [d, d j ], D' , pn' , un' ).
- If there is a node n [?]
B such that n (n) = (!
(x0 T x1 ), [di , d j ], D, pn , un ), then, for each d [?]
DB , with d >= d j , there is a node n' [?]
B such that n (n' ) = (x 0 , [di , d], D' , pn' , un' ) or a node n' [?]
B such that n (n' ) = (x 1 , [d j , d], D' , pn' , un' ).
The proof of Corollary 1 is straightforward, and thus it is omitted.
Lemma 7 (Completeness) If the limit tableau for some formula ph [?]
CDTBS is closed, then some finite tableau for ph is closed.
Proof Let us assume the limit tableau for ph to be closed.
Then, every branch closes at some finite step of the construction, and then it is not further expanded (it remains finite).
Since the branch-expansion rule always produces finitely many successors, every finite tableau is finitely branching, and hence so is the limit tableau.
Then, by Konig's lemma, the limit tableau, being a finitely branching tree with no infinite branches, must be finite.
This allows us to conclude that its construction stabilizes at some finite stage.
At that stage, a closed [?]
[?]
tableau for ph is constructed.
5.3 Termination and Complexity In this last subsection, we prove that the proposed tableau method is terminating, and we determine its computational complexity.
The proof rests on a pair of basic lemmas.
As a preliminary step, we define a counting function Count on B as follows: Count(B) =  [?]
|psn | * pn * un (B),  n[?
]B  where psn and pn are the formula and the p-flag in the decoration of n, respectively.
The following lemma proves that Count is non-increasing with respect to branch expansions.
Lemma 8 Let ph be a CDTBS -formula, B be a branch in a tableau for ph , and B' be an expansion of B generated by the application of the branch-expansion strategy of Definition 8.
Then, Count(B' ) <= Count(B).
Moreover, if B' is obtained from B by the application of R1, R2, R6, R7, or R8 to a node n with pn in n (n) equal to 1, then Count(B' ) < Count(B).
20  Davide Bresolin et al.
Proof Let T be a tableau for ph , B be a branch on it, and n be the closest-to-the-root node for which the branch-expansion rule is applicable.
Moreover, let B' be a branch obtained by the application of the branch-expansion strategy on B.
We consider the cases of the application of R1, R3, and R6 to n. The missing cases are similar to the considered ones (R2 is similar to R1, R4 and R5 to R3, R7 and R8 to R6), and thus they are omitted.
- R1 is applied to n. Then, n (n) = hx0 [?]
x1 , [di , d j ], D, pn , un i and B' = B * n' * m' , with x0 belonging to n (n' ) and x1 belonging to n (m' ).
Since pn' = pm' = pn , un' (B' ) = um' (B' ) = 1, un (B' ) = 0, and um (B' ) = um (B) for each m 6[?]
{n, n' , m' }, Count(B' ) = Count(B) - |x0 [?]
x1 |+|x0 |+|x1 | < Count(B), when pn = 1, and Count(B' ) = Count(B) when pn = 0.
- R3 is applied to B.
Then, n (n) = h!
(x0 C x1 ), [di , d j ], D, pn , un i and B' = B * n' , with x0 or x1 belonging to n (n' ).
In both cases, pn' in n (n' ) is equal to 0, and thus Count(B' ) = Count(B).
- R6 is applied to B.
Then, n (n) = hx0 C x1 , [di , d j ], D, pn , un i and B' = B * n' * m' , with x0 belonging to n (n' ) and x1 belonging to n (m' ).
Since pn' = pm' = pn , un' (B' ) = um' (B' ) = 1, un (B' ) = 0, and um (B' ) = um (B) for each m 6[?]
{n, n' , m' }, Count(B' ) = Count(B) - |x0 C x1 | +|x0 | +|x1 | < Count(B) when pn = 1, and Count(B' ) = Count(B) when pn = 0.
Summing up, whatever Ri one applies, Count(B' ) <= Count(B).
Moreover, when R1, R2, R6, R7, or R8 are applied to a node n with pn in n (n) equal to 1, Count(B' ) < Count(B).
[?]
[?]
Lemma 9 Let ph be a CDTBS -formula, T be a tableau for ph , and n be a node in T with decoration n (n) = hps , [di , d j ], D, pn , un i.
It holds that if pn = 0, then ps [?]
ph[?]
.
Proof Let n be a node on a branch B in T with decoration n (n) = hps , [di , d j ], D, pn , un i.
We prove the claim by induction on depth(n).
Base case.
If depth(n) <= 2, then n is either the root or one of the leaves of the initial tableau.
In both cases, the claim follows trivially.
Inductive step.
Let depth(n) > 2.
By the inductive hypothesis, the claim holds for each ancestor of n in B.
Let n' be the node to which the branch-expansion rule has been applied during the construction of T to obtain node n. As in the proof of Lemma 8, we restrict our attention to R1, R3, and R6.
The other cases can be dealt with in a similar way.
- Rule R1 has been applied to n' .
Then, n (n' ) = hx0 [?]
x1 , [di , d j ], D, pn' , un' i and either x0 or x1 belong to n (n).
Let us assume that x0 belongs to n (n) (the case in which x1 belongs to n (n) is analogous) and pn = 0.
By definition of R1, pn' = pn = 0.
By the inductive hypothesis, x0 [?]
x1 = x0 [?]
x1 [?]
ph[?]
.
From the grammar rules for CDTBS , it follows that x0 [?]
ph [?]
.
- Rule R3 has been applied to B.
Then, n (n' ) = h!
(x0 C x1 ), [di , d j ], D, pn' , un' i and either x0 or x1 belong to n (n).
Let us assume that x0 belongs to n (n) (the case in which x1 belongs to n (n) is analogous).
By definition of R3, pn = 0.
By the grammar rules for CDTBS , it holds that x0 [?]
ph[?]
.
The thesis immediately follows from x0 = x0 .
- Rule R6 has been applied to B.
Then, n (n' ) = hx0 C x1 , [di , d j ], D, pn' , un' i and either x0 or x1 belong to n (n).
Let us assume pn' = 0.
By the inductive hypothesis, it follows that x0Cx1 = !
(x0Cx1 ) [?]
ph[?]
(contradiction).
Hence, it holds that pn' = 1, and thus, by R6, pn = 1.
[?]
[?]
By exploiting Lemma 8 and Lemma 9, we now prove that the length of any branch B of any tableau for ph is polynomially bounded by the length of the formula.
Lemma 10 (Termination) Let ph be a CDTBS -formula, T be a tableau for ph , and B be a branch in T .
Then, |B| <= 2 * |ph |3 + 8 * |ph |2 + 8 * |ph |.
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  21  Proof Let B be a branch in a tableau T for ph .
Given the branch-expansion rule and the branch-expansion strategy, there cannot be two nodes n, n' in B such that the same formula and the same interval belong to both n (n) and n (n' ).
Since for any node n in B, the formula in n (n) is either a subformula of ph or the dual of a subformula of ph , it holds that |B| <= 2 * |ph | * |DB|2 .
To give a bound on the number of points in DB , it suffices to observe that: 1. only the application of R6, R7, and R8 add new points to DB ; 2. by Lemma 9, they can be applied only to nodes where the flag p is equal to 1; 3. by Lemma 8, every application of them strictly decreases the value of Count(B).
Now, let B0 be the two-node prefix of B consisting of the root and one of its successors labeled with ph .
Since |DB0 | <= 2 and Count(B0 ) = |ph |, |DB | <= |ph | + 2, and thus |B| <= 2 * |ph | * (|ph | + 2)2 <= 2 * |ph |3 + 8 * |ph |2 + 8 * |ph |.
[?]
[?]
Theorem 7 The proposed tableau method for CDTBS is sound and complete, and the satisfiability problem for CDTBS is NP-complete.
Proof By Lemma 5 (soundness) and Lemma 7 (completeness), it holds that satisfiability of a formula ph can be reduced to the search for an open limit tableau for it.
A direct consequence of Lemma 10 is that this search can be performed by a nondeterministic algorithm that guesses an open and saturated branch of the limit tableau, using only a polynomial amount of time.
NP-hardness immediately follows from that of propositional logic.
[?]
[?]
6 Undecidable extensions of CDTBS In the previous section, we have proved that the satisfiability problem for CDTBS is NPcomplete.
Since the full logic CDT is undecidable, one may wonder whether CDTBS can be extended preserving decidability.
In this section, we show that the most natural extension of CDTBS is already undecidable.
In CDTBS -formulas, modalities can occur in the scope of at most one negation.
We slightly extend CDTBS by allowing one more nesting of negations and modalities.
The resulting logic includes formulas like !(!
(pCq)Cq) or !(pC!(qCr)).
In [20], Hodkinson et al.
have shown that CDT is undecidable over the class of all linearly-ordered domains even if we restrict ourselves to formulas where only one modality occurs.
Undecidability has been proved by reducing the problem of finding a solution to the octant tiling problem to the satisfiability problem for the logic.
The undecidability proof below is based on the observation that the entire construction given in [20] exploits formulas where modalities occur in the scope of at most two negations.
Given a set of tiles T = {t1 , .
.
., tk }, the octant tiling problem is the problem of establishing whether T can tile an octant of the Cartesian plane over the integers.
Let us consider the second octant O = {(p, q) | p, q [?]
N, p <= q}.
Each tile ti has four colors, namely, right(ti ), le f t(ti ), up(ti ), and down(ti ).
Neighboring tiles must have matching colors.
Formally, we say that a set T can tile O if there exists a function f : O 7- T such that right( f (p, q)) = le f t( f (p + 1, q)) and up( f (p, q)) = down( f (p, q + 1)), where f (p, q) represents the tile to be placed in the position (p, q), provided that all relevant coordinates ((p, q), (p + 1, q), etc.)
lie in O.
Using Konig's lemma, one can prove that a tiling system tiles the second octant if and only if it tiles arbitrarily large squares if and only if it tiles N x N if and only if it tiles Z x Z. Undecidability of the first problem immediately follows from that of the last one [4].
22  Davide Bresolin et al.
Let T = {t1 , .
.
., tk } be an instance of the octant tiling problem.
We will assume that A P contains at least the propositional letters u,t1 , .
.
.,tk .
CDTBS makes it possible to define the "somewhere in the future" operator F (we assume future to be non-strict) as follows: F ph ::= [?]
T (ph T [?]).
(10)  The universal operator G can be defined as the dual of F, that is: Gph ::= !F!ph .
(11)  Making use of G, we set our framework by forcing the existence of unit-intervals (or uintervals) working like atomic elements.
Such intervals will be denoted by the proposition letter u.
We force u-intervals to be disposed in an unbounded unique (uninterrupted) sequence by means of the following formula: uT [?]
[?]
G(u - uT !u).
(12)  Lemma 11 Let M be a model such that M, [d, d ' ]  (12).
Then, there exists an infinite sequence of points d0 < d1 < .
.
., such that 1. d ' = d0 ; 2. for every l [?]
N, M, [dl , dl+1 ]  u.
The following formulas associate a unique tile with every u-interval; moreover, they guarantee that tiles are placed in such a way that they respect conditions on colors (a graphical account of the encoding is given in Figure 5): |T |  _  G(u -  ti ),  (13)  !
(ti [?]
t j ),  (14)  i=1 |T |  G  ^  i, j=1,i6= j  G  |T |  |T |  ^  _  (ti - !
(uT !
i=1   G u-  t j )),  (15)   !
(ti T t j ) .
(16)  j=1,up(ti )=down(tj ) |T |  ^  i, j=1,right(tj )6=left(ti )  It is easy to check that, in (12), (13), and (14), modalities occur in the scope of at most two negations.
Moreover, formulas (15) and (16) can be easily rewritten in such a way that modalities occur in the scope of at most two negations as well.
Now, let phT be the following formula: (12) [?]
(13) [?]
(14) [?]
(15) [?]
(16).
(17) We prove that the encoding is sound and complete.
Lemma 12 Let T = {t1 , .
.
.
, tk } be a set of tiles.
It holds that phT is satisfiable if and only if T tiles the second octant O.
The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  23  NN  t2 *  * t3  t3  u  t1 *  t2  99K  t1  u  ^ N Fig.
5 A pictorial representation of the encoding.
Proof (Soundness) Let M, [d, d ' ] |= phT .
We show that there exists a tiling function f : O 7- T .
By Lemma 11, we know that there exists an infinite sequence of points d0 < d1 < .
.
.
such that d ' = d0 and, for every i [?]
N, M, [yl , yl+1 ] |= u.
Now, for each l, m [?]
N, with l <= m, we put: f (l, m) = t whenever M, [dl , dm+1 ] |= t. First, we have to show that f is well-defined, that is, that each f (l, m) is a tile.
We proceed by induction on (m - l).
If (m - l) = 0, then, by Lemma 11, we are on a u-interval and thus, by (13), there exists a tile associated with it.
Since by (14) such a tile is unique, f is welldefined.
Suppose now that f (l, m) is a tile whenever m - l <= p, and consider m - l = p + 1.
Since (m - 1) - l <= p, by the inductive hypothesis f (l, m - 1) is a tile, say ti , which means W|T | that M, [dl , dm ] |= ti .
By (15), M, [dl , dm ] |= !
(uT !
j=1,up(ti )=down(tj ) t j ).
Hence, for every d >= dm , if M, [dm , d] |= u, then it must be the case that M, [dl , d] |=  W|T |  j=1,up(ti )=down(tj ) t j .
Since M, [dm , dm+1 ] |= u, this applies to the particular case d = dm+1 .
Thus, we have that M, [dl , dm+1 ] |= t j , that is, f (l, m) = tj , for some j such that down(tj ) = up(ti ) (again, since by (14) such a tile is unique, f is well-defined).
This not only guarantees us that f is well-defined, but also that it respects the 'vertical' condition of a tiling function.
To conclude the proof, we need to show that the 'horizontal' condition is respected as well.
To this end, let us consider f (l, m) and f (l + 1, m).
By definition, the corresponding tiles are those associated with [dl , dm+1 ] and [dl+1 , dm+1 ].
Since, by definition, the interval [dl , dl+1 ] is a u-interval, by (16) it cannot be the case that le f t( f (l + 1, m)) 6= right( f (l, m)), which implies that le f t( f (l + 1, m)) = right( f (l, m)).
[?]
[?]
(Completeness) For simplicity, let us assume the linearly ordered set to be (N, <).
One can force the truth of phT over [0, 0] by letting u be true over all intervals of length 1 and each ti be true over all intervals of the form [l, m + 1], where f (l, m) = ti .
[?]
[?]
Theorem 8 The satisfiability problem for any syntactic extension of CDTBS where modal operators occur in the scope of two negations is undecidable.
Proof The thesis directly follows from Lemma 12.
It is worth noticing that only modality T occurs in phT .
An alternative proof of Lemma 12 can be given by making use of modality C or of modality D only.
This shows that any fragment of CDT containing at least one modality among C, D, and T , where modalities are allowed to occur in the scope of two negations, is undecidable.
24  Davide Bresolin et al.
7 Conclusions and future work In this paper, we studied a syntactic fragment of Venema's CDT logic, that we called CDTBS , whose standard translation to first-order logic fits into Bernays-Schonfinkel class of quantifier prefix formulas.
Decidability of CDTBS directly follows from that of BernaysSchonfinkel class.
We first focused our attention on expressiveness issues.
We considered the following question: "can every formula in Bernays-Schonfinkel class of first-order logic over the linear order <, limited to binary predicates, be turned into a CDTBS -formula?".
We proved that this is not the case.
In [33], Venema showed that CDT is expressively complete with respect to FO3,2 [<].
In this paper, we showed that CDTBS is expressively complete with respect to 3,2 the corresponding fragment of Bernays-Schonfinkel class FOBS [<].
Next, we developed a tableau-based decision procedure for CDTBS , and we proved that the satisfiability problem for CDTBS is NP-complete.
Finally, we showed that any natural relaxation of the syntactic restrictions we imposed on CDTBS yields undecidability, as it makes the resulting logic expressive enough to encode the (undecidable) octant tiling problem.
The present work can be developed in a number of future research directions.
From a theoretical point of view, one can think of the possibility of identifying the interval temporal logic counterparts of other decidable classes of first-order formulas.
Moreover, the relationships between interval temporal logics and (extended) guarded fragments are still unexplored.
For instance, It would be interesting to give an account of the good computational properties of decidable fragments of CDT and HS (including CDTBS ) in terms of suitable guarded fragments.
From a more practical point of view, we expect CDTBS to be applicable in a variety of areas such as, for instance, planning and synthesis of plan controllers, temporal description logics, and sequencing problems in computational genetics.
Acknowledgements This work has been partially supported by the following research projects: EU project FP7-ICT-223844 CON4COORD (D. Bresolin), Italian PRIN project Innovative and multi-disciplinary approaches for constraint and preference reasoning (A. Montanari and D. Della Monica), Spanish MEC projects TIN2009-14372-C03-01 and RYC-2011-07821 (G. Sciavicco), and project Processes and Modal Logics (project nr.
100048021) of the Icelandic Research Fund (D. Della Monica).
References 1.
Allen, J.: Maintaining knowledge about temporal intervals.
Communications of the ACM 26(11), 832- 843 (1983) 2.
Andreka, H., van Benthem, J., Nemeti, I.: Back and forth between modal logic and classical logic.
Logic Journal of the IGPL 3(5), 685-720 (1995) 3.
Benthem, J.V., Thomason, S.K.
: Dynamic bits and pieces (1997) 4.
Borger, E., Gradel, E., Gurevich, Y.: The Classical Decision Problem.
Springer (1999) 5.
Bresolin, D., Della Monica, D., Goranko, V., Montanari, A., Sciavicco, G.: Decidable and undecidable fragments of Halpern and Shoham's interval temporal logic: towards a complete classification.
In: Proc.
of LPAR'08, LNCS, vol.
5330, pp.
590-604.
Springer (2008) 6.
Bresolin, D., Della Monica, D., Goranko, V., Montanari, A., Sciavicco, G.: Undecidability of interval temporal logics with the overlap modality.
In: Proc.
of TIME'09, pp.
88-95.
IEEE Comp.
Society (2009) 7.
Bresolin, D., Della Monica, D., Goranko, V., Montanari, A., Sciavicco, G.: Metric Propositional Neighborhood Logics.
Journal of Software and System Modeling (2012).
DOI: 10.1007/s10270-011-0195-y 8.
Bresolin, D., Goranko, V., Montanari, A., Sciavicco, G.: Propositional interval neighborhood logics: expressiveness, decidability, and undecidable extensions.
Annals of Pure and Applied Logic 161(3), 289-304 (2009)  The Light Side of Interval Temporal Logic: the Bernays-Schonfinkel fragment of CDT  25  9.
Bresolin, D., Montanari, A., Sala, P., Sciavicco, G.: Optimal tableaux for right propositional neighborhood logic over linear orders.
In: Proc.
of JELIA'08, LNAI, vol.
5293, pp.
62-75.
Springer (2008) 10.
Bresolin, D., Montanari, A., Sala, P., Sciavicco, G.: What's decidable about Halpern and Shoham's interval logic?
The maximal fragment ABBL.
In: Proc.
of LICS'11, pp.
387-396.
IEEE Comp.
Society Press (2011) 11.
Della Monica, D., Goranko, V., Montanari, A., Sciavicco, G.: Expressiveness of the interval logics of allen's relations on the class of all linear orders: Complete classification.
In: Proc.
of IJCAI'11, pp.
845-850 (2011) 12.
Etessami, K., Vardi, M.Y., Wilke, T.: First-order logic with two variables and unary temporal logic.
Information and Computation 179(2), 279-295 (2002) 13.
Gabbay, D., Hodkinson, I., Reynolds, M.: Temporal Logic: mathematical foundations and computational aspects.
Oxford University Press (1994) 14.
Gabbay, D., Pnueli, A., Shelah, S., Stavi, J.: On the temporal analysis of fairness.
In: Proc.
of POPL'80, pp.
163-173.
ACM Press (1980) 15.
Goranko, V., Montanari, A., Sala, P., Sciavicco, G.: A general tableau method for propositional interval temporal logics: theory and implementation.
Journal of Applied Logic 4(3), 305-330 (2006) 16.
Goranko, V., Montanari, A., Sciavicco, G.: Propositional interval neighborhood temporal logics.
Journal of Universal Computer Science 9(9), 1137-1167 (2003) 17.
Goranko, V., Montanari, A., Sciavicco, G.: A road map of interval temporal logics and duration calculi.
Applied Non-classical Logics 14(1-2), 9-54 (2004) 18.
Halpern, J., Shoham, Y.: A propositional modal logic of time intervals (short version).
In: Proc.
of LICS'86, pp.
279-292.
IEEE Comp.
Society (1986) 19.
Halpern, J.Y., Shoham, Y.: A propositional modal logic of time intervals.
J. ACM 38, 935-962 (1991) 20.
Hodkinson, I., Montanari, A., Sciavicco, G.: Non-finite axiomatizability and undecidability of interval temporal logics with C, D, and T. In: Proc.
of CSL'08, LNCS, vol.
5213, pp.
308-322.
Springer (2008) 21.
Immerman, N., Kozen, D.: Definability with bounded number of bound variables.
Information and Computation 83(2), 121-139 (1989) 22.
Kamp, H.: Events, instants and temporal reference.
In: Semantics from different points of view, pp.
27-54.
Springer (1979) 23.
Marcinkowski, J., Michaliszyn, J.: The ultimate undecidability result for the Halpern-Shoham logic.
In: Proc.
of LICS'11, pp.
377-386.
IEEE Comp.
Society Press (2011) 24.
Marcinkowski, J., Michaliszyn, J., Kieronski, E.: B and D are enough to make the Halpern-Shoham logic undecidable.
In: Proc.
of ICALP'10 - Part II, LNCS, vol.
6199, pp.
357-368.
Springer (2010) 25.
Montanari, A., Peron, A., Policriti, A.: Extending Kamp's theorem to model time granularity.
Journal of Logic and Computation 12(4), 641-678 (2002) 26.
Montanari, A., Puppis, G., Sala, P.: A decidable spatial logic with cone-shaped cardinal directions.
In: Proc.
of CSL'09, LNCS, vol.
5771, pp.
394-408.
Springer (2009) 27.
Montanari, A., Puppis, G., Sala, P.: A decidable spatial logic with cone-shape cardinal directions (extended version of [26]).
Research Report 3, Dipartimento di Matematica ed Informatica, Universita di Udine (2010) 28.
Montanari, A., Puppis, G., Sala, P.: Maximal decidable fragments of Halpern and Shoham's modal logic of intervals.
In: Proc.
of ICALP'10 - Part II, LNCS, vol.
6199, pp.
345-356.
Springer (2010) 29.
Montanari, A., Puppis, G., Sala, P., Sciavicco, G.: Decidability of the interval temporal logic ABB on natural numbers.
In: Proc.
of STACS'10, pp.
597-608 (2010) 30.
Otto, M.: Two variable first-order logic over ordered domains.
Journal of Symbolic Logic 66(2), 685-702 (2001) 31.
Szwast, W., Tendera, L.: The guarded fragment with transitive guards.
Annals of Pure and Applied Logics 128(1-3), 227-276 (2004) 32.
Venema, Y.: Expressiveness and completeness of an interval tense logic.
Notre Dame Journal of Formal Logic 31(4), 529-547 (1990) 33.
Venema, Y.: A modal logic for chopping intervals.
Journal of Logic and Computation 1(4), 453-476 (1991)
