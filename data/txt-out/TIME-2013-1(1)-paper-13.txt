2013 20th International Symposium on Temporal Representation and Reasoning  An algebraic system of temporal structures Tim French John Mc Cabe-Dansted Mark Reynolds School of Computer Science and Software Engineering, The University of Western Australia 35 Stirling Highway, Crawley WA 6009 Perth, Australia.
Abstract--Lauchli and Leonard, in 1966, described a series of operations which are able to build all linear temporal structures up to first order equivalence.
More recently these operations have been used to describe executions of continuous systems for the purposes of model checking real-time specifications.
In this paper we present an algebra over these operations and show that it is both sound and complete, in that it can generate all equivalences over these models.
[5] have increased the significance of these problems.
It is useful to have a complete set of algebraic identities for model expressions over general linear structures, but perhaps more useful to have a set of such identities over dense continuous structures, over the reals.
However, we see in [2] that these results come for free, as we can find a syntactic restriction over the set of all model expressions that guarantees the expression corresponds to the reals.
We aim to show that many other common linear orders can also be identified with syntactic restrictions of model expressions.
We anticipate that an algebraic approach for model expressions will be useful in the analysis of continuous systems.
Model expressions describing a trace of a continuous system may be simplified, reduced to a canonical form, or proven equivalent to another expression using this algebra.
I. I NTRODUCTION Standard temporal logics are based on a discrete, natural numbers model of time [1].
However, a dense, continuous or specifically real-numbers model of time may be better for many applications, ranging from philosophical, natural language and AI modelling of human reasoning to computing and engineering applications of concurrency, refinement, open systems, analogue devices and metric information.
One of the main results in the paper [2] was that a formula of Real-Time Logic (RTL) has a real-flowed model if has a constructable real model.
Here a real-flowed model means a model of linear temporal logic, whose underlying flow of time is represented by the real numbers, and a constructable real model refers to a real model definable using a formal modelbuilding language based on the operations of Lauchli and Leonard [3] (points, concatenation, leads, trails and shuffles, also described in [4]).
In this paper we consider the generalization to arbitrary linear temporal structures.
The operations of Lauchli and Leonard are able to generate expressions that correspond to temporal structures in such a way that any satisfiable formula in the monadic second order theory of < is satisfied by such a temporal structure.
We refer to the generated expressions as model expressions.
We will describe a number of known results for these model expressions: most importantly, 1) every satisfiable temporal logic formula is satisfied by a temporal structure that corresponds to some model expression; and 2) the class of temporal structures that correspond to a given model expression is an isomorphism class.
That is, models expressions are able to finitely describe a satisfying structure for every satisfiable temporal logic formula.
We will make this claim precise later.
The main result of this paper is to present an algebra over these operations that is adequate for determining whether two model expressions are equivalent.
Model expressions are a natural artifact for model-checking and synthesis problems over general linear time, and recent applications of timed and hybrid automata 1530-1311/13 $26.00 (c) 2013 IEEE 1550-1311/13 DOI 10.1109/TIME.2013.18  II.
L INEAR TEMPORAL S TRUCTURES Fix a countable set L of atoms.
Here, frames (T, <), or flows of time, will be irreflexive linear orders.
Structures T = (T, <, h) will have a frame (T, <) and a valuation h for the atoms i.e.
for each atom p [?]
L, h(p) [?]
T .
An isomorphism is a bijective mapping from one structure to another that preserves the temporal relation < and the valuation h. This is an important notion of equivalence for us, as we will show that equivalent structures satisfy the same set of formulas in L(U, S).
DEFINITION 1: We say two structures T = (T, <, h) and T  = (T  , < , h ) are isomorphic (written T ~ = T  ) if and only if there is a bijection f : T -- T  where for all x, y [?]
T x < y if and only if f (x) < f (y), and for all p [?]
P x [?]
h(p) if and only if f (x) [?]
h (p).
We say (T, <, h) and (T  , < , h ) are disjoint isomorphic if they are isomorphic and T and T  are disjoint.
To simplify notation below, given a structure (T, <, h), and  some T  [?]
T , we let (T  , <, h) refer to the structure (T  , <T T T  , h ) where < is the restriction of < to the set T and  hT is the restriction of h to the domain T  .
Isomorphisms between structures preserve formulas of temporal logic just as bisimulations preserves formulas of modal logic.
III.
U NTIL AND S INCE OVER GENERAL LINEAR TIME The language L(U, S, U  , S  ) is generated by the 2-place connectives U and S along with classical !
and [?]
and the Stavi connectives, U  and S  .
That is, we define the set of formulas recursively to contain the atoms and for formulas a and b we include !a, a [?]
b, U (a, b), S(a, b), U  (a, b 71 81  and S  (a, b).
For the detailed syntax and semantics of this language, see [6].
This logic has been shown to be expressively complete for monadic first-order logic over arbitrary linear orders [6], generalizing the result of Kamp for Dedekind complete linear orders.
This logic is decidable over arbitrary temporal structures and has been axiomatised [7].
...
Fig.
1.
I1 I1  I1  I1  - - The lead operation, where I = I1  For the inductive cases we require the notion of an isomorphism (Definition 1).
Then:  IV.
B UILDING S TRUCTURES  I + J corresponds to a structure (T, <, h) if and only if T is the disjoint union of two sets U and V , where [?
]u [?]
U , [?
]v [?]
V , v < u (we write U < V , from here on) and I corresponds to (U, <, h) and J corresponds to (V, <, h).
- - * I corresponds to the structure (T, <, h) if and only if T is the disjoint union of sets {Ui |i [?]
o} where for all i, Ui+1 < Ui , and I corresponds to (Ui , <, h).
- - * I corresponds to the structure (T, <, h) if and only if T is the disjoint union of sets {Ui |i [?]
o} where for all i, Ui < Ui+1 , and I corresponds to (Ui , <, h).
* 	G  corresponds to the structure (T, <, h) if and only if T is the disjoint union of sets {Ui |i [?]
Q} where 1) for all i [?]
Q (Ui , <, h) corresponds to some g [?]
G, 2) for every g [?]
G, for every a = b [?]
Q, there is some k [?]
(a, b) where g corresponds to (Uk , <, h), 3) for every a < b [?]
Q, Ua < Ub .
PROPOSITION 1: Every satisfiable formula of L(U, S, U  , S  ) is satisfied by a temporal structure that corresponds to a model expression.
This is proven in [9].
It provides a strong motivation for investigating model expressions, as they are able to finitely represent temporal structures satisfying logical formulae, which is important for such tasks as model-checking, synthesis and counter-example generation [10].
We will give an illustration of the non-trivial operations - - below.
The lead operation, I = I1 corresponds o submodels, each corresponding to I1 , and each preceding the last, as illustrated in Figure 1.
The trail operator is the mirror image of the lead operation, - - whereby I = I1 corresponds to o structures, each corresponding to I1 and each proceeding the earlier structures.
The model expression I = 	G  (I is the shuffle of G) corresponds to a dense, thorough mixture of intervals corresponding to the elements of G, without endpoints.
We define the shuffle operation using the rationals, Q as they are a convenient linear order to describe a dense, thorough mixing of intervals.
The definition of model expressions is not deterministic, as the construct for the shuffle 	I1 , .
.
.
, In   does not specify how the structures corresponding to I1 , .
.
.
, In are mapped to the rationals.
We show that this inconsequential, and as long as the mapping is dense for each i from 1 to n, the resulting structures will be isomorphic.
LEMMA 1: Suppose that T = (T, <, h) and T  = (T  , < , h ) both correspond to a model expression I.
Then T and T  are isomorphic.
Proof: We prove this by induction over the complexity of model expressions.
The base cases for letters and l are trivial.
Model-checking and synthesis results require a description of a finite model, whereas the natural representation of general linear models is typically given over an infinite (and often uncountable) set of points.
From [8] and [3], we know of a set of operations that are able to generate sufficiently complex structures for model-checking and synthesis purposes.
These are described in the following section.
Our main artifact of study in this paper is a notation which allows us to describe temporal structures in sufficient detail to distinguish all concepts expressible in the monadic firstorder theory of <.
These structures are defined in terms of simple basic structures via a small number of ways of putting structures together to form larger ones.
The general idea is simple: using singleton structures (the flow of time is one point), we build up to more complex structures by the recursive application of four operations.
The operations are: * the concatenation of two structures, (placing one after the other) consisting of one followed by the other; * o repeats of a given structure trailing off into the future; * o repeats of a given structure trailing back into the past (or leading up to a point in the present) * and making a densely thorough shuffle of copies from a finite set of structures.
These operations are well-known from the study of linear orders (see, for example, [8]).
We transform these operations into syntactic artefacts called Linear Model Expressions, which are an abstract syntax for defining models.
Suppose that S is some alphabet (in the context of linear temporal logic, S would represent the set of propositional atoms true at a point.
Linear model expressions are constructed using the follow set of primitive operators: - - - - I ::= a | l | I + J | I | I | 	G   *  where a [?]
S, for some alphabet S (in the context of linear temporal logic, S would represent the set of atoms true at a point), and G is a finite non-empty set of linear model expressions.
We refer to these operators, respectively, as a letter, the empty order, concatenation, lead, trail, and shuffle.
Let E(S) be the set of all expressions generated over the alphabet S. DEFINITION 2 (Correspondence): Given S = 2L , a model expression I corresponds to a structure as follows: * l is the empty sequence and corresponds to the frame ([?
], <, h) where < and h are empty relations.
* a corresponds to any single point model ({x}, <, h) where < is the empty relation and h(p) = x if and only if p [?]
a.
82 72  I[?
]d  d  .. .
Fig.
2.
I  I  d  d  g1  g1  d  d  I  I  d  d  g2  g2  d. .
.
d  d. .
.
d  I  I  d  d  gn  gn  d  d  I  I   correspond to the same model Q to Q where Ui and Up(i) expression.
By the induction hypothesis Ui and Up(i) must be isomorphic, and thus the union of these isomorphisms will be an isomorphism from T to T  .
LEMMA 2: Suppose that T = (T, <, h) and T  = (T  , < , h ) are isomorphic.
Then for any model expression I we have T corresponds to I if and only if T  corresponds to I.
Proof: It is straightforward to see that the composition of an isomorphism and a correspondence will be a correspondence.
From these lemmas, we have the following definition.
DEFINITION 3: We say two model expressions I1 and I2 are similar (written I1  I2 ) if and only if there is some structure T = (T, <, h) such that both I1 and I2 correspond to T .
Note that from Lemmas 2 and 1 it follows that similarity () is an equivalence relation over the set of model expressions.
Model expressions give us a grammar that describes linear sequences in a similar manner to the way regular expressions describe words over a given alphabet.
However, there is an important difference in that while regular expressions contain non-deterministic operators (such as the Kleene star which can match any number of repetitions, or disjunctions), the interpretation of every operator in a model expression is deterministic up to isomorphism (Lemma 1).
Therefore, the better analogue for a model expression is a single word over a finite alphabet.
In future work we will examine an analogue of regular expressions for non-discrete time flows, such as a structure that admits general linear structures as traces.
However, it is important to provide a solid foundation for the individual linear structures first, which is the focus of this paper.
We now focus on the question of equivalence for two model expressions.
Definition 3 provides a semantic notion of what it means for two model expressions to represent the same information.
The following section examines an algebraic approach for demonstrating that two model expressions represent the same information.
d  d  .. .
The shuffle operation, where I = Gfi, and G = {g1 , g2 , .
.
.
, gn }.
For concatenation, suppose two structures T and T  correspond to the model expression I1 +I2 .
Then T = (U [?
]V, <, h) where (U, <, h) corresponds to I1 , (V, <, h) corresponds to I2 and every element of U is less than every element of V .
We also have T  = (U  [?
]V  , < , h ) with similar constraints, so by the induction hypothesis (U, <, h) is isomorphic to (U  , < , h ) and likewise (V, <, h) is isomorphic to (V  , < , h ).
Taking the union of these two isomorphisms we have an isomorphism from T to T  as required.
For trail, suppose two structures T and T  correspond to the  - - model expression I2 .
Then T = ( i[?
]o Ui , <, h) where for all i [?]
o, (Ui , <, h) corresponds to I1 , and for all i [?]
o, every element of  Ui is less than every element of Ui+1 .
We also have T  = ( i[?
]o Ui , < , h ) with similar constraints, so by the induction hypothesis (Ui , <, h) is isomorphic to (Ui , < , h ) for every i [?]
o.
Taking the union of these isomorphisms we have an isomorphism from T to T  as required.
The case for lead is similar so that leaves shuffles.
Suppose two structures T and T  correspond to the  model expression 	G .
From Definition 2 we have T = ( i[?
]Q Ui , <, h), and  T = ( i[?
]Q Ui , < , h ) where the Ui and Ui are disjoint, and correspond to the model expressions g [?]
G. As the correspondence between the Ui and the model expressions is dense, we can build a 1-1 mapping p [?]
Q x Q by a transfinite induction: we enumerate Q and process them in order to define the mappings px for x [?]
o.
Suppose that i is the xth element of the enumeration and Ui corresponds to g [?]
G. If i is not already paired with any element in px-1 , we let j be the least element greater than i where j is in the domain of px-1 , and the let k be the greatest element less than i that appears in the domain of px-1 .
Then select some  where px-1 (k) <  < px-1 (j), and where U corresponds to g. If no such j or k exists, we may ignore the corresponding constraint, and we can always find such an  because the shuffle is dense).
We can then repeat the process to find some  so that U is an isomorphic match for Ui , and add both pairs, (i, ) and ( , i), to the mapping to define px .
Note that the mapping is designed so that it is order-preserving (i.e.
pix (i) < px (j) only if i < j.
The limit step takes the union of all interim mappings and will define a total one-to-one order-preserving mapping from  V. A N ALGEBRA FOR MODEL EXPRESSIONS In this section we present an algebra for model expressions.
The algebra is presented as a series of identities or equivalences with the intent that any two equivalent model expressions are isomorphic to exactly the same set of temporal structures.
We write I [?]
J to indicate that two model expressions, I and J are equivalent in the algebraic sense.
DEFINITION 4: The model expression algebra is as follows.
Associativity 1.
I1 + (I2 + I3 ) [?]
(I1 + I2 ) + I3  The shuffle identities ------ 2.
Th  + th [?]
Th  where th [?]
Th ------ 3. th + 	Th  [?]
Th  where th [?]
Th 4.
Th  + th + 	Th  [?]
Th  where th [?]
Th 5.
G [?]
{th + 	Th  + th }  [?]
Th  where G [?]
Th, th, th [?]
Th  83 73  The lead/trail identities ----- ----- 6.
I1 + I2 [?]
I1 + I2 + I1 -------- - - 7.
I + .
.
.
+ I [?]
I ----- ----- 8.
I1 + I2 [?]
I2 + I1 + I2 -------- - - 9.
I + .
.
.
+ I [?]
I The l identities 10.
11.
12.
13.
14.
15.
I +l[?
]I l+I [?
]I - - l [?
]l - - l [?
]l 	l  [?]
l 	Th  [?]
Th [?]
{l}   The substitution rule If I [?]
J then K [?]
K[I\J ] where K[I\J ] is the expression K with all occurrences of the subexpression I replaced with the expression J .
We note that this algebra is actually a schema due to identities (2-5, 7 and 9) which apply to a qualified set of terms.
The identities (2-5) also refer to set operations which can further complicate derivations.
For example, we can show 	{I, I + l}  is equivalent to 	{I}  for any model expression I, by applying equivalence (10) to note that I + l [?]
I, and then applying the substitution rule to show 	{I, I + l}  is equivalent to 	{I, I} .
At this point we note that {I, I} is simply the set {I}, but this final step is in some sense external to our system as it appeals to the definition of a set.
EXAMPLE 1: For an example of a more complex identity, suppose that a [?]
S is some letter and consider the equivalence ------------- a + 	{a + a}  + a [?]
{a + a}  + a.
We can see that such an identity makes sense semantically.
On the right side we have a dense mix of {a + a} followed by a single point a.
On the left we have an o-sequence leading to the left of the point a, followed a dense mix of a + a, followed by a point a.
When we lay this o-sequence out we find the pattern: .
.
.
+ a + 	{a + a}  + a + a + 	{a + a}  + a + a + 	{a + a}  + a.
Now, each instance of 	{a+a} +a+a+	{a+a}  is equivalent to 	{a + a} , so the whole structure collapses down to 	{a + a} +a, and hence the expressions are semantically equivalent.
With respect to the algebra, we have the derivation: ------------- ------------- a + 	{a + a}  + a [?]
a + a + 	{a + a}  + a (8) [?]
{a + a}  + a (3)  VI.
S OUNDNESS We must first convince ourselves that the model expression algebra will only generate valid equivalences.
LEMMA 3 (Soundness): Suppose that I1 and I2 are model expressions such that I1 [?]
I2 .
Then I1  I2 Proof: (Sketch) It is sufficient to show that all rules preserve equivalence with respect to the correspondence relation, so that is I corresponds to T and I [?]
J is an identity of the model expression algebra, then J also corresponds to T .
As equivalence ([?])
is simply defined as the result of the iterated application of these rules, it follows that equivalence preserves the correspondence relation.
Showing that each rule preserves the correspondence relation is straightforward and we present brief arguments for some of the equivalences below: 1 I1 + (I2 + I3 ) [?]
(I1 + I2 ) + I3 : the concatenation operator is clearly associative.
------ 2 	Th  + th [?]
Th  where th [?]
Th: an o-sequence of shuffles is isomorphic to a shuffle.
4 	Th +th +	Th  [?]
Th  where th [?]
Th: this is the essential definition of a shuffle operator.
5 	G[?
]{th+	Th +th }  [?]
Th  where G [?]
Th and th, th [?]
Th: if G is a subset of Th then 	G [?]
{	Th }  is a dense mix of elements from G and 	Th .
However, as elements of G already appear densely in 	Th , so nothing is gained from having them appear independently of the elements in Th.
Likewise, within a shuffle, there is effectively no difference between a closed interval and an open interval, so the addition of th, th at the ends of 	Th  are negligible.
----- ----- 6 I1 + I2 [?]
I1 + I2 + I1 : an o-sequence alternating between I1 and I2 is the same as an o alternating between I2 and I1 , with I1 appended to the front.
-------- - - 7 I + .
.
.
+ I [?]
I : an o-sequence of a finite homogeneous sequence of I is just an o-sequence of I.
10-15 These rules capture how the empty sequence l acts as a kind of identity for all operators.
Finally we note that the substitution rule must be sound since any substructure that I corresponds to must also be a substructure that J corresponds to, so the correspondence of K to a structure will not be affected by the substitution.
VII.
C OMPLETENESS Completeness requires us to show that any two expressions that correspond to a common temporal structure, are provably equivalent using the model expression algebra.
LEMMA 4 (Completeness): Suppose that I and J are model expressions such that I  J .
Then I [?]
J .
This is the more complicated lemma to prove and will rely on a sequence of definitions and sub-lemmas.
We will give these below and bring them together in the proof of Theorem 1.
Our proof uses a two player game G(I, J ) derived from the two model expressions I and J .
The game is such that player Felix (the Duplicator) has a winning strategy if and only if I  J , and otherwise player Ralph (the Spoiler) has a winning strategy.
Then, from Felix 's winning strategy (and  EXAMPLE 2: A useful derivation to have is the fixed-point - - definition of a lead: I + I [?]
I.
We can show this with the following derivations: ---- - - I [?]
l+I (11) and substitution ---- [?]
I +l+I (8) - - [?]
I +I (10) and substitution.
In the next few sections we will show that the algebra is sound (so that I1 [?]
I2 only if I1  I2 ) and complete (so that I1 [?]
I2 if I1  I2 ).
84 74  Sketch: If I  J then both expressions correspond to a common linear structure, T = (T, <, h).
We will use this correspondence to guide a winning strategy for Felix in the game.
We will proceed by induction and we will suppose that we have game states (I i , J i ) where both I i and J i correspond to a structure T i .
The base of our induction is I 0 = I, J 0 = J and T 0 = T .
Now suppose that given a state (I i , J i ), Ralph plays a move I i [?]
I1 +I2 .
From Lemma 3 we must have that I1 + I2 also corresponds to T i = (T i , <i , hi ).
Applying Definition 2 this means that T i is the disjoint union of two sets U and V where V < U and I1 corresponds to (U, <, h) and I2 corresponds to (V, <, h).
As J i also corresponds to T i we need to find a derivation J i [?]
J1 + J2 where J1 corresponds to (U, <, h) and J2 corresponds to (V, <, h).
We can then show that as long as Felix continues to produce such derivations, then Ralph can never reach a winning state.
We will provide an inductive argument to show the Felix can always find a suitable derivation (and the previous two cases form the basis of this induction).
The claim is that given an expression K that corresponds to a structure, T = (T, <, h), and a partition of that structure into two sets U and V where V < U , we can always find a derivation K [?]
K1 + K2 such that K1 corresponds to (U, <, h) and K2 corresponds to (V, <, h).
We proceed by induction over the complexity of formulas, where the first two cases are the basis, and the inductive steps follow:  Ralph's lack of a winning strategy) we are able to extract a series of equivalences showing I [?]
J .
DEFINITION 5: Given two model expressions I and J we define G(I, J ) to be the equivalence game of I and J , where: 1) The game is played between two players, Felix and Ralph.
2) At any time, the state of game is a pair (I  , J  ) where I  and J  are model expressions, and the game starts at the state (I, J ).
3) Given the state (I  , J  ), the next step of the game proceeds as follows: a) Ralph performs a sequence of [?]
transformations to I  manipulating it into an expression I1 + I2 b) Felix performs a sequence of [?]
transformations to J  manipulating it into an expression J1 + J2 c) Ralph then selects the next state of the game to be either (I1 , J1 ) (the left), (J1 , I1 ) (the left switch), (I2 , J2 ) (the right), or (J2 , I2 ) (the right switch).
4) Ralph wins the game if it reaches a state a) (l, I) where I = l, b) (a, I) where a is an atom and I =  a, Otherwise Felix wins.
Note that the game is not necessarily finite, but the only way Ralph can win is to force the game into a final state in a finite number of moves.
LEMMA 5: For all model expressions I and J , the game G(I, J ) is determined.
That is, either Ralph or Felix has a winning strategy.
Proof: This follows from the fact that there are only a countable number of winning plays for Ralph, and they are all finite.
Therefore, an inductive construction of Ralph's winning set has a well-defined limit.
EXAMPLE 3: For an example of the game, consider Example 1.
Here it is clear that Felix has a winning strategy.
------------- Let I = a + 	{a + a}  + a and J = 	{a + a}  + a.
From the game state (I, J ), Ralph will move first and produce a derivation I [?]
I + I  .
Felix 's winning strategy is simply to first repeat the derivation in Example 1 and compose this derivation with which ever derivation Ralph produced, so we have J [?]
I + I  .
From then he can mimic exactly every move Ralph makes.
Ralph could reach states (a, a) or (l, l) but neither of these states are winning, so the game continues indefinitely (because the l-identities always ensure another move is available).
For a game in which Ralph has a winning strategy, suppose that I is defined as above, but J = 	{a + a} .
In this case Ralph could choose the derivation I [?]
{a + a}  + a that appeared in Example 1.
Whatever derivation J = J  + J  Felix tries, he will always find that J  contains a dense mix of {a + a} or l and is definitely not equal to a.
So Ralph wins the game by choosing the right.
We will show that a winning strategy for Felix in the game G(M1 , M2 ) is equivalent to both M1  M2 and M1 [?]
M2 .
We first prove the following sub-lemma, by induction over the complexity of formulas.
LEMMA 6: Felix has a winning strategy in the game G(I, J ) if and only if I  J .
*  *  *  *  85 75  If K = l, then T = [?]
and thus U and V are also the empty set.
Felix can produce the derivation K [?]
l + l using (11).
If K = a, where a [?]
S, then it must be the T is a single point, x, where hi (x) = a.
As I1i + I2i corresponds to T we must have either U = {x} and V = [?]
for U = [?]
and V = {x}.
In the first case Felix can produce the derivation K = a + l (11) and in the second case Felix can produce the derivation K = l + a (12).
If K = K1 + K2 then T i is the disjoint union of two sets U  and V  where for all u [?]
U  , for all v [?]
V  , u < v. Suppose without loss of generality V  [?]
V .
Let V * = V [?]
U  .
Then K1 corresponds to (U [?]
V * , <, h) where everything in U is less than everything in V * .
Applying the induction hypothesis K1 [?]
K3 +K4 where K2 corresponds to U and K4 corresponds to V * .
Applying the substitution rule we have K [?]
(K3 +K4 )+K2 and by (1), we can complete the derivation K [?]
K3 + (K4 + K5 ) where K3 corresponds to U and K4 + K5 corresponds to V. - - If K = K1 then by Definition 2, T is the disjoint union of sets {Ui |i [?]
o} where for all i, for all u [?]
Ui , for all v [?]
Ui+1 , v < u, and K1 corresponds to (Ui , <, h).
As T is totally  ordered by < there is some greatest j [?]
o such that i<j Ui [?]
V .
We can apply the derivation of - - Example 2 j times so that K [?]
K1 + jK1 .
Let U * = * U [?]
Uj , V = V [?]
Uj .
Then K1 corresponds to (U * [?]
V * , <, h) where everything in U * is less than everything in V * .
Applying the inductive hypothesis we have K1 [?]
K2 +K3 where K2 corresponds to U * and K3 corresponds to V * .
Using the substitution rule and (1), we can show  - - - - that K [?]
K1 + K2 + K3 + (j - 1).K1 where K1 + K2 corresponds to U and K3 + (j - 1).K1 corresponds to V .
- - - - * The case for K = K1 is the symmetric case to K = K1 .
* If K = 	G  where G = {I1 , .
.
.
, In } then T is the disjoint union of sets {Ui |i [?]
Q} satisfying the conditions laid out in Definition 2.
Let i be the element of Q such that Ui [?]
U and Ui [?]
V , if it exists (i.e.
Ui is the substructure that crosses from one partition into the other).
If such an element doesn't exist, then every Ui is either entirely in U or entirely in V and there are three cases to consider.
1) If there is a least Ui [?]
V (with respect to <) such that Ij corresponds to Ui , we have by (4), K [?]
G  + Ij + 	G , where 	G  corresponds to U and Ij + 	G  corresponds to V .
2) If there is a greatest Ui [?]
U such that Ij corresponds to Ui , we have by (4), K [?]
G  + Ij + 	G , where 	G  + Ij corresponds to U and 	G  corresponds to V .
3) If there is neither a greatest Ui [?]
U , nor a least Ui [?]
V , then by (15) K [?]
G [?]
{l}  and by (4) and (15) K [?]
G  + l + 	G  and finally by (12) K [?]
G  + 	G  where 	G  corresponds to both U and V .
Otherwise there is an element i [?]
Q such that Ui [?]
U and Ui [?]
V .
Let U * = U [?
]Ui , V * = V [?
]Ui and suppose that Ij corresponds to Ui .
By the induction hypothesis we have Ij [?]
K1 + K2 where K1 corresponds to U * and K2 corresponds to V * .
By (14) K [?]
G  + Ij + 	G , and applying the substitution rule we have K [?]
G  + K1 + K2 + 	G  where 	G  + K1 corresponds to U and K2 + 	G  corresponds to V .
Therefore, what ever choice Ralph makes, Felix can always respond finding a pair J1 , J2 corresponding to the respective partition of T .
The induction shows that Ralph will never be able to reach a winning state, so it must be a winning strategy for Felix .
Conversely, if Felix has a winning strategy in the game, we can show that the two expressions correspond to isomorphic structures by building a model extracted from all plays of the game according to Felix 's winning strategy.
We define a non-deterministic strategy for Ralph.
Since Felix has a winning strategy, Felix can win every game against this strategy.
However, this strategy is defined so that every play that reaches an atomic state ((a, a), since it is a winning state for Felix ), and this corresponds to a unique point in a linear structure T .
We will show the structure T corresponds to both I and J as required.
The strategy for Ralph, s maps game states (I, J ) to a derivation for I, s(I) = I  + I  where I [?]
I  + I  .
When I  + I  is played, Player Felix will respond by applying the winning strategy to select a derivation J = J  + J  .
Then Ralph non-deterministically selects the left (I  , J  ) or the right (I  , J  ).
The function s is defined inductively over the complexity of expressions: s(l) = l + l s(K + K ) = K + K - - - - s( K ) = K + K  In the last clause g is non-deterministically chosen from G [?]
{l}.
We consider all plays that may result from this nondeterministic strategy for Ralph against Felix 's winning strategy.
Let PIJ be the set of finite plays of game, p = p0 p1 .
.
.
pn where p0 = (I, J ) and pn = (a, a) for some a [?]
S. We define an ordering over PIJ by p < t if and only if, for the largest j where for all i < j, pi = ti , we have pj is a left move and tj is a right move.
Finally, we define the function I h : L - 2PJ , by p [?]
h(a) if and only if pn = (a, a).
Note that there are also plays winning for Felix that end in the state (l, l), but these may be ignored as they correspond to the empty flow of time, and do not affect the final structure.
We can then show that (PIJ , <, h) corresponds to both I and J , by induction over the complexity of I.
The induction hypothesis is that for all sub-expressions I  of I, for all J  , if Felix has a winning strategy in the game G(I  , J  ) then  (PIJ  , <, h) corresponds to both I  and J  .
The base case of I = J = a is obvious.
The operators concatenation, lead, trail and shuffle are simple applications of the recursive definition of correspondence, given the soundness of the model expression algebra (Lemma 3).
Therefore I  J as required.
The final part of the completeness proof will require us to show that Felix has a winning strategy in the game G(I, J ) if and only if I [?]
J .
The proof will proceed via induction over the complexity of model expressions, where the complexity of a model expression is given by the following definition.
DEFINITION 6: Model Expression Complexity We say one expression I is an equivalent subexpression of another J (written I  J ) if there exists expressions K and K such that K + I + K [?]
J .
The complexity of a model expression I, is a map c : E(S) -- o x o defined inductively over the formulaic complexity of model expressions as follows: * Atoms - c(l) = (0, 0) - c(a) = (0, 1) * Concatenation - c(I + I  ) = max(c(I), c(I  )).
* Lead/Trail - - - - - If c(I) = (a, b) and I  I, c( I ) = (a, b).
- - - - - If c(I) = (a, b) and I   I, c( I ) = (a, b + 1).
- - - - - If c(I) = (a, b) and I  I, c( I ) = (a, b).
- - - - - If c(I) = (a, b) and I  I, c( I ) = (a, b + 1).
* Shuffle - If for every g [?]
G we have 	G   g, then c(	G ) = max{c(g) | g [?]
G}.
- Otherwise if max{c(g) | g [?]
G} = (a, b) then c(	G ) = (a + 1, 0).
We note that over o x o, max is determined with respect to the lexicographical relation, so that (a, b) < (c, d) if and only if a < c or a = c and b < d. This complexity orders expressions in two dimensions.
Essentially every nesting of a lead or a trail increases the complexity by one in the second dimension, and every nesting  s(a) = undefined - - - - s( K ) = K + K s(	G ) = (	G  + g) + 	G   86 76  some b > 0.
Applying the same process from the previous case, for arbitrary n we may show that J [?]
Jn +.
.
.+J0 where for all i < n, Ji corresponds to (Ui , <, h).
The only operations that can generate such a sequence are shuffle or lead, and as a shuffle has been ruled out we - - must have J [?]
J  for some J  that corresponds to (U0 , <, h).
By the inductive hypothesis c(I  ) = (a, b) = c(J  ) for some (a, b) and hence c(I) = c(J ) = (a, b + 1).
- - * Suppose that I = I and I  J .
This case is simply the mirror image of the previous case.
* Suppose that I = 	G  and I  J .
We can find a partition of T , {Ui |i [?]
Q} such that for each a < b [?]
Q, Ua < Ub , and for each g [?]
G there is some c where a < c < b, and g corresponds to (Uc , <, h).
Again, the processes of Lemma 6 can be applied to show that J must be equivalent to some shuffle 	Th , where for every a < b [?]
Q, for every th [?]
Th, there is some c where a < c < b and th corresponds to (Uc , <, h).
By the induction hypothesis for every g [?]
G there must be some th [?]
Th such that c(g) = c(th) and vice versa.
Therefore, we must have c(I) = c(J ).
By induction over the syntax of expressions the Lemma must hold.
We note that as a corollary of Lemmas 6 and 8, if two expressions I and J have different model expression complexity, then Ralph must have a winning strategy in the game G(I, J ).
LEMMA 9: Felix has a winning strategy in the game G(I, J ) if and only if I [?]
J .
Proof: If I [?]
J then Felix has a clear winning strategy: his first move is to perform the deductive steps to transform J into I and append any deductions the Ralph made in his first move.
From then on he simply mirrors every one of Ralph's moves, guaranteeing a winning strategy.
of a shuffle increase the dimension by one in the first dimension and resets the second dimension to zero.
Therefore every expression with a shuffle as the outermost operator will always have complexity (a, 0).
There are a few cases where leads, trails and shuffles of expressions don't substantially change the expression (see the shuffle identities in Definition 4), and in these case the complexity is left at (a, 0).
Some examples of model expression complexities are: - c(- a ) = (0, 2) (1) c(	{a} ) = (1, 0) ---- c(a + 	{a} ) = (1, 0) ------- c(a + 	{a} ) = (1, 0) ------- c(b + 	{a} ) = (1, 1)  (2) (3) (4) (5)  These formulas give some idea of how the complexities build.
Each shuffle acts as a type of limit for the inductive application of lead and trails.
We see in the formula (3) and (4) the complexity does not increase with the application of concatenation or lead operations, as these are "absorbed" by the underlying shuffle (in fact we can see that the formula in (4) is equivalent to the formula in (2).
However, for (5) we see the complexity does increase because the sub-expression b cannot be absorbed by the shuffle (since the first clause for ------- the lead complexity does not hold: b + 	{a}   b + 	{a} ).
In this case we say the subexpression b is an impurity in the expression b + 	{a} .
LEMMA 7: If I [?]
J then c(I) = c(J ).
Proof: The result follows clearly from inspection of Definition 4.
As the model expression complexity of the left and right side of each equivalence are clearly equal, it follows by a simple inductive argument that equivalent expressions must have the same model expression complexity.
LEMMA 8: If I  J then c(I) = c(J ).
Proof: We give this proof by induction over the syntax of expressions.
The base cases of l and atoms, a [?]
S are straight forward: if a  J then J can only be an expression K + a + K where K and K are expressions built only from l, and as such both expressions must have complexity (0, 1).
The case for l is also trivial.
For the inductive steps we consider the model expression I, and suppose that both I and J correspond to some structure T = (T, <, h).
  * Suppose I = I + I and I  J .
Therefore J also corresponds to T and there are subsets U1 < U2 of T such that I  corresponds to (U1 , <, h) and I  corresponds to (U2 , <, h).
From Lemma 6, we know that J [?]
J  + J  , where J  corresponds to (U1 , <, h) and J  corresponds to (U2 , <, h).
By the induction hypothesis, c(I  ) = c(J  ) and c(I  ) = c(J  ) so the result follows from- -Definition 6.
* Suppose that I = I and I  J .
Therefore there is some partition {Ui |i [?]
o, Ui+1 < Ui } of T such that for every i [?]
o, I  corresponds to Ui .
There are two sub-cases to consider.
If each I also corresponds to each Ui , then c(I) = (a, 0) for some a, and the case may be treated as a shuffle below.
Otherwise we will have c(I) = (a, b) for  For the converse, if Felix has a winning strategy in the game G(I, J ) each move of Felix is going to involve a derivation.
We can use this winning strategy to construct a complete derivation of the equivalence I [?]
J , proceeding by induction over the complexity of formulas as defined in the Definition 6.
The induction hypothesis is that Felix has a winning strategy in the game G(I  , J  ), for all I  with a model expression complexity less than c(I), and also for all I  which are strict subexpressions of I.
The base of this induction will be expressions of complexity less than or equal to (0, 1).
* If c(I) = (0, 0) then it is clear from Definition 6 that I [?]
l. Therefore if Felix has a winning strategy in the game G(I, J ) then it must be the case that J [?]
l, otherwise Ralph would have a winning move of I [?]
l + l. * If c(I) = (0, 1) then from Definition 6 it follows that I is equivalent to a concatenation of atoms and l (as any instance of lead, trail or shuffle applied to an atom would increase the complexity beyond (0, 1).
If Felix has a winning strategy in the game G(I, J ) it must follow that for every decomposition I [?]
I  + I  , Felix can find some decomposition J [?]
J  + J  such that Felix  87 77  as c(J ) must be 0 in its second element, and any subexpression that cannot be reduced by the shuffle identities (Definition 4.2-5) can easily be exploited by Ralph to give a winning strategy.
Ralph can, for i = 1 .
.
.
m, play the derivation I [?]
I + Ii + I.
The winning strategy of Felix must be able to respond with J [?]
J + K + K + K + J where Felix has a winning strategy in the game G(Ii , K) and K + K + K [?]
Jj for some j.
By the induction hypothesis we have Ii [?]
K, and furthermore, I  K , K .
A similar equivalence may be given for Ji for i = 1 .
.
.
n, so the result follows by the substitution rule and the first shuffle identity (Definition 4.5).
Therefore the induction holds and we are able to construct a full derivation of the equivalence between I and J from Felix 's winning strategy in the game G(I, J ).
THEOREM 1: Given any two model expressions I and J we have I  J if and only if I [?]
J .
Proof: The right to left direction (I [?]
J implies I  J ) is simply Lemma 3.
The opposite direction (I  J implies I [?]
J ) corresponds to Lemma 4 which follows directly from Lemmas 6 and 9.
Therefore the model expression algebra (Definition 4) is sound and complete.
has a winning strategy in the left, right, left switch and right switch states.
The result follows by induction over the complexity of expressions (the standard definition, as opposed to the model expression complexity).
The base of this induction has I and J as the same atom (since Ralph cannot win) and for the inductive step we may assume that I  [?]
J  and I  [?]
J  , so the result follows immediately.
There are now a number of different inductive cases to consider:   * I = I + I In this case it is clear that as Felix has a winning strategy, if Ralph plays I  + I  then Felix can respond with a derivation J [?]
J  + J  .
As it is a winning strategy, this means that Felix will win both games G(I  , J  ) and G(I  , J  ).
By the induction hypothesis we must have I  [?]
J  and I  [?]
J  , so by the substitution rule it follows that I [?]
J as required.
- - * I = I .
Suppose that for some J , Felix has a winning strategy in the G(I, J ).
From this we can deduce that c(I) = c(J ).
Furthermore, we may suppose that c(I) = (a, b) where b > 0, otherwise we would have I being equivalent to a shuffle operation, and covered by the case below.
Given that c(J ) = (a, b) for b > 0 and Felix has a winning strategy in the game G(I, J ) - - we can see that J must be of the form J  + J  where   c(J ) <= c(J ).
(If the most complex subexpression of J was a trail, Ralph would have a winning strategy by generating an arbitrarily long sequence of I+I  +* * *+I  , and if the most complex subexpression of J was a shuffle, then c(J ) = (a , 0).)
In this game Ralph can force to match the derivations I [?]
I + I  and J [?]
- - Felix  J + (J + J  ).
Suppose that Felix does this with the - - respective derivations J [?]
(J  +K1 )+(K2 +mJ  +J  ) and I [?]
(I + L1 ) + (L2 + kI  ), where m and k are integers indicating repeated concatenation.
As Felix is applying a winning strategy the following hold (where A ~ B indicates Felix has a winning strategy in the game G(A, B)): - - - - I ~ J  + K1 J  ~ I + L1 I  ~ K2 + mJ  + J  J  + J  ~ L2 + kI  I  ~ L1 + L 2 J  ~ K1 + K 2  VIII.
C ONCLUSION AND F UTURE W ORK This work presents an important foundation in establishing a computational model for first order theories of linear order.
We have seen that model expressions are expressively complete for first order theories of linear order [9], [3] and the algebra of Definition 4 presents a practical resource for reasoning directly about model expressions.
A corollary of Theorem 1 is that determining equivalence of model-expressions is at most recursively enumerable.
The question of whether this is a lower bound is left to future work.
R EFERENCES [1] A. Pnueli, "The temporal logic of programs," in Proceedings of the Eighteenth Symposium on Foundations of Computer Science, 1977, pp.
46-57, providence, RI.
[2] T. French, J. C. McCabe-Dansted, and M. Reynolds, "Synthesis for temporal logic over the reals," in Advances in Modal Logic, 2012, pp.
217-238.
[3] H. Lauchli and J. Leonard, "On the elementary theory of linear order," Fundamenta Mathematicae, vol.
59, pp.
109-116, 1966.
[4] M. Reynolds, "Continuous temporal models," in Australian Joint Conference on Artificial Intelligence, ser.
Lecture Notes in Computer Science, M. Stumptner, D. Corbett, and M. J. Brooks, Eds., vol.
2256.
Springer, 2001, pp.
414-425.
[5] R. Alur, C. Courcoubetis, N. Halbwachs, T. Henzinger, P.-H. Ho, X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine, "The algorithmic analysis of hybrid systems," Theoretical Computer Science, vol.
138, no.
1, pp.
3 - 34, 1995.
[6] D. Gabbay, I. Hodkinson, and M. Reynolds, Temporal Logic: Mathematical Foundations and Computational Aspects, Volume 1.
Oxford University Press, 1994.
[7] Y. Gurevich, "Elementary properties of ordered abelian groups," Algebra and Logic, vol.
3, pp.
5-39, 1964, (Russian; an English version is in Trans.
Amer.
Math.
Soc.
46 (1965), 165-192).
[8] J. P. Burgess and Y. Gurevich, "The decision problem for linear temporal logic," Notre Dame J.
Formal Logic, vol.
26, no.
2, pp.
115-128, 1985.
[9] T. French, J. McCabe-Dansted, and M. Reynolds, "Indiscrete models: Model building and model checking over linear time," in Logic and Its Applications, ser.
Lecture Notes in Computer Science, K. Lodaya, Ed.
Springer Berlin Heidelberg, 2013, vol.
7750, pp.
50-68.
[10] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking.
Cambridge, Massachusetts: The MIT Press, 1999.
From these equations we can infer that K1 [?]
J  (applying the inductive hypothesis).
The first two identities recursively reference each other, and by applying the induction hypothesis and the substitution principle we are able to derive xI  [?]
L1 + K1  * *  and yJ  [?]
K1 + L1  (6)  where x and y are integers indicating repeated concatenation.
Then the equivalence I [?]
J follows from the lead identities (Definition 4.8-9).
- - I = I  .
This case is the mirror image of the previous case and may be treated in a similar way.
I = 	{I1 , .
.
.
, Im } .
For any J such that Felix has a winning strategy in the game G(I, J ) we may assume that J is equivalent to some shuffle J [?]
{J1 , .
.
.
, Jn } ,  88 78