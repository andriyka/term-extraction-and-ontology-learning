Behavior Discovery As Database Scheme Design Takao MIURA Dept.of Elect.& Elect.
Engr., Hosei University Kajinoc ho, Koganei, Tokyo, Japan Isam u SHIO YA SANNO College, Kamikasuya, Isehara, Kanaga wa, Japan Kohei WATANABE Dept.of Elect.& Elect.
Engr., Hosei University Kajinoc ho, Koganei, Tokyo, Japan (predicative) transitions.
Once we get such rules, we can utilize them as new knowledge, for instance we can learn how to design database schemes.
When there exist predicative transitions, it is possible to show that Mark ov property of behavior may cause stationary states.
In fact, we can predict behavior patterns that change occurs in a stable manner independent of current status and time.
Such Ergodic property improves inductive inference as a stochastic process.
Traditionally design of databases has been considered as one of heuristic arts, in other words, we don't have any evaluation theory based on qualitative or quantitative aspects.
Also there exists no way to revisit and follow the design during the growth of database contents, thus there has been no other ways except design from scratch in a top-down manner[1].
However, to our surprise, these stationary patterns of behaviors hint us a new scheme as the form of (con vergence)limit of transition called stationary schemes.
In the following, we will develop our theory for inductive database design that are completely dierent from traditional design methodology .
Section 2 contains some denitions.
In section 3, we introduce the relationship between database design and machine learning.
Section 4 contains temporal information from the viewpoint of inductiv e classication.
Then, in section 5, we dene how to classify transitions by changes of databases, and we show some experiments in section 6.
Abstract In this investigation, we propose an inductive classication method to a collection of temp oral information which me an behavior.
We assume Markov property and discuss Ergodic analysis by which we can extract stationary parts of the behavior.
And we discuss a design methodology for database schemes based on the theory.
Keywords { Temporal Learning and Discovery, Database Design  1 Motivation  In this work, we consider changes to databases as temporal information and discuss how to nd behavior rules by inductive classication.
Also we show a new design methodology to databases as one of the direct applications.
Essentially temporal data are different from time series data since the latter are considered independent with each other such as human heights and earthquake measurements while the former must be inuenced from its history .
Typical examples are odds of horse races and charts of stock market.
When we observe such feed-back from historical data, we have special rules as fashion, trends, learning and lesson, all these mean typical transition patterns (the way of changes) of information.
Formally stated, this is called Markov pr operty of transition which is an assumption that there exist common and time-independent patterns of transitions.
If we nd Marko v property of our changes, we extract characteristic aspects on which changes cause interesting 1  0-7695-0756-5/00 $10.00 AL 2000 IEEE  2 Inductive Scheme Design  stage of database design.
W e assume a common set of characteristics (attributes) A = fA ; ::; A g to C .
If we obtain conditions 1 ov er A to classify objects E correctly into one of C , we could examine and justify current classication, because we can restate classes by means of 1.
Such method is called class learning from examples or inductive classication.
A decision tree has been widely applied to a variety of applications.
This tree provides us with classication conditions.
Given an object d at an intermediate node labeled with an attribute A , we examine an attribute value of d (say, A (d)) and, according to the value, we go to an appropriate branch.
We repeat this process until we get to a leaf.
Each path from the root corresponds to a conjunctive condition A = " " ^ ::: ^ A = " " to identify answer classes.
To generate trees, if there is only one class c to which the relevant objects belong, we have a leaf of c. Otherwise, we make grouping at one of the attributes that are not yet selected, and we generate an intermediate node of this attribute.
Edges are generated according to the attribute values for branching.
The most important problem here is what attribute should be selected to go into lower levels.
Well known algorithms such as ID3 and C4.5 utilize entropy.
Entropy is dened by using probability of events (class membership in this case), and we regard the ratio of the number of objects of a class c to the total number as the probability.
To select attributes, they try to maximize information gain that is dened by means of relative entropy[14, 15].
This is the reason why decision trees have been widely utilized because we don't assume any domain knowledge but also sometimes we get uneasy and strange results.
Let us outline some relationship between decision trees and database design.
As we said, large sets of objects can be managed ecien tly by means of data structure techniques and ne sets can't be.
We can relieve this issue only by mer ging or restructuring classes.
But the solutions come from inspecting seman tics of classes and objects, that is, from design steps.
1  Database scheme is knowledge by which we classify information.
According to this kno wledge, we identify concepts and manage them consistently and uniformly .
Formally we say an object d is of a class c, or d belongs to c if d has the property that c carries.
In this investigation, we assume every object belongs to just one class (or we assume single hierarchy among classes).
W e call such a model instance-based since we assume every object carries its own membership information.
In this investigation, we dene C = fc ; ::; c g as all the classes in this database.
By database design, we give description of database scheme.
As well-known, it is hard to automate and evaluate database design process.
For example, class hierarchy is useful to obtain concise knowledge representation, but there is no systematic wa y to examine[5, 18].
To manage a collection of a class c eciently and uniformly, we discuss appropriateness[9] in this investigation.
By appropriateness we mean a condition that there exists some constant n such that the number of objects of a class c is greater than n for every c. Since we assume single class hierarchy, this means all the lowest classes are not ne.
Readers may see that large sets of objects can be managed eciently by means of B-trees and hash techniques but ne sets can't be and we have to obtain solutions from design steps.
If all the objects are appropriate, we can say granularity of classes in the database is not ne, thus we must have uniform, knowledgeable and ecien t classication for query execution/optimization, type-validation and database maintenance .
1  K  0  0  1  Machine le arning from datab ases is a technique targeted for automatic/semi-automatic modeling to the world of interests.
This technique takes input from databases (schemes and a collection of objects) and generate possibly improved schemes.
Generally database schemes fail to capture current contents very well because it had been designed before, and very often we obtain mismatch bet ween them.
The tec hnique might generate alternative ideas of schemes suitable for the contents.
One of the typical examples is an inductiv e classication for objects E in database.
Traditionally a collection C of classes had been given at the initial 1  See [9] for multiple class hierarchy.
0-7695-0756-5/00 $10.00 AL 2000 IEEE  m  i  i  1  1  l  l  During the growth of databases, the scheme should be evolved because of changes of the object' roles.
Unfortunately designated scheme can't alw ays capture the current contents since the scheme should be long-lived.
In fact, databases are not exible while very often information arrives with new in tension inside, then it doesn't bring any change of common knowledge into scheme change.
Here changes of database mean updates of class  mem bership as well as attribute values (characteristic values) to objects.
In this investigation we don't discuss any update operation of birth/death of objects nor of scheme evolution.
Each change is called a transition, and behavior to make changes is called a transaction.
A few design methodology has been proposed so far[16] mainly from the viewpoint of top-do wn approach but not of growth of database as proposed later.
Such situation could be relieved by clustering objects and concept formation[6].
In this work, we will analyze transition patterns inductively looking at changes of class membership and attribute v alues over objects considered as temporal information and put back into database schemes[11].
Characterizing classes by inductive approach should vary according to changes of databases.
Then let us dene a collection E of objects at time t by E , which can be seen as a set of temporal objects or a state at t. Let E !
E be all the changes of temporal objects at time t which also can be seen as transition of states.
Then inductive analysis of behavior depends on how we classify the set of transactions.
In the following, we discuss only collections of nite, discrete and non-numeric values and their (discrete) changes.
That is, we assume every object d can be changed as A(d) !
A(d) where A(d) means an attribute value of d at t. One of temporal aspects can be described by depth of states n. Given objects E , attributes A (i=1,..,n) and E over E 2 A 2 ::: 2 A , let E be a snapshot of E at t. Then an inductive classication over E 2 ::: 2 E can describe transitions to recent n snapshots.
Similarly we can think about transition of class mem bership by inspecting C 2 ::: 2 C instead of C , where each C means a snapshot of class mem bership at timet.
t  t  t+1  t+1  t  t  1  i  m  t  1  n  1  n  t  3 Markov Property of Temporal Data  Inductive classication by decision tree technique utilizes entropy as a base of induction (prediction).
Entropy is dened as 06 p log p where p > 0 means probability of event i, i = 1; ::; k (k < 1).
This value can be considered as average depth of binary decision trees to all the events[11].
To obtain decision trees, we consider the ratio p = n =N where the number n of objects of a class c to the total number N of objects.
Remember these p can be dened to each state E .
Thus we m ust have sequence of the probabilities p ; p ; ::; p ; ::.
For temporal information E ; ::; E ; ::, we might have sequences of changes to class membership or changes k i=1  i  2  i  i  i  i  i  i  i  t  (0)  (1)  (t)  i  i  i  1  t  0-7695-0756-5/00 $10.00 AL 2000 IEEE  of attribute values.
That is, let n be the number of objects of a changed to a where a is a class or a value, then the transition probability p(i !
j ) can be described as n =n .
Generally this value depends on time t and we can't always expect common patterns.
A transition is called Markovian (or it has Markov pr operty) if the transition probability p(i !
j ) doesn't depend on time but on histories (past states).
We say a transition is Markovian of depth n if n is the maximum depth of states on which transition depends.
Especially the transition of n = 1 is called simple Mark ovian.
It means that one step transition i to j is determined by i-th and j -th steps, but not dependent on time nor past states before i.
If our transition doesn't depend on any past state, it is called independent and we must have p(i ; ::; i !
j ) = q(j ) where q(j ) means an initial probability of the event i.
In a case of class mem bership, a simple Marko v transition is described by means of K -square matrix [p(i !
j )]; i; j = 1::K , while general Marko v transition of depth n by a K 2 K matrix [p(i ; ::; i !
j )] where p(i ; ::; i !
j ) = n 1 n =n 1 n , and n 1 n ; n 1 n mean the number of objects of a class c 1 changed to c 2 changed to .. to c n and the one nally changed to a class c respectively where C = fc ; ::; c g. Initially an object of c is changed to a class c with a probability p(i; j ) = q(i) 2 p(i !
j ).
Also p (i; j) means a probability with whic h that an object of an initial class c is changed to c after t steps, and obtained by 6 p 0 (i; k) 2 p(k !
j ).
Finally q (j ) is a probability that an object belongs to a class c after t steps, obtained by 6 q (k) 2 p (k; j ).
In a case of simple Marko v transition with the transition matrix P = [p(i !
j )], q = (q (1); ::; q (K )) can be calculated simply by q 1 P where q is a vector of initial probabilities of class membership.
Similar discussion holds in the case of attribute values.
i;j  i  j  i;j  1  i  i  n  n  1  i ;::;i  i ;::;i  1  n  i ;::;i  ;j  n  i ;::;i  ;j  i  i  i  j  1  K  i  i K k =1  j  (t)  j  (t 1)  (t )  (t)  K k =1  (t)  (0)  (t)  t  j  (t)  (0)  Of course we can think about decision trees on each state E and its incremental property[11, 12].
Here let us consider a theory for inductive classication of transition patterns.
When we assume all the transitions are simple Marko vian, the transition can be managed and manipulated easily once we get a transition matrix on eac h attribute and class membership.
Then, on a table over A 2 ::: 2 A , each object is described as a row and a means the probability of changes of the attribute values a !
a , and the changes c of class membership t  1  n  i  j  i;j  i;j  by c !
c .
Since we watch the transitions within each attribute and class mem bership, it seems nice for us to classify the changes over E 2E inductively.
Then we can apply our decision tree technique to this set in an obvious way.
Thus we get classication for transition patterns.
EXAMPLE 1 As our running example, let us consider some information about SUMO or Japanese wrestling.
W e assume 3 attributes and 1 class,Weight, Appetite, Spirit and a class Win.
Weight consists of a (heavy), b (middle) and c (light), Appetite contains p (good) and q (usual) and Spirit contains x (tough) and y (mild).
Win consists of 1 (y es) and 0 (no).
Observing changes of man y strong SUMO wrestlers, we want to decide which types of wrestlers win continuously.
And we examine tw o states between the wrestlers.
Let us describe the change as b : a which means a wrestler of a middle weigh t becomes heavy.
Here are our sample data: i  j  t  t+1  analyze behavior in a statistical manner and generate some scheme suitable for updates.
The second one is more serious.
Although result schemes are nice for the current contents, but how about future ?
W e believe hat we should examine the contents and extract the stationary parts into the form of schemes.
That's why we don't discuss probability of transition but Mark ov property.
4  Limit Schemes of Databases  In this section we assume simple Marko v transitions and discuss how to design schemes based on Ergodic theory.
Let us discuss transition of class membership for a while.
According to Ergodic theory of stochastic processes, if we have p (i !
j ) > 0 for t >> 0 W eight Appetite Spirit Win and every i; j , there exist both lim !1 q (i) and a:a p:p x:x 1:0 lim !1 p (j !
i) that are identical and not 0[3].
The a:a p:q x:x 0:1 solutions can be obtained by K + 1 equations (called a:b p:p x:x 1:0 limit e quations): a:c p:p x:x 1:0 b:a q:q x:x 1:0 X = 6 X 2 p(i !
j ); i = 1; ::; K b:c p:p x:x 0:1 6 X =1 c:a p:p x:x 0:1 c:b p:p x:x 0:1 The solution vector called limit distribution, q 1 = c:c p:q x:x 1:0 (::; q 1 (i); ::), means limit of distribution of class memc:c q:q x:x 0:1 bership of c ; ::; c after suciently large steps of tranConsidering all the values as units, we can analyze sitions.
Since this vector also means limit distribution them as usual.
Te maxim um gain can be obtained by of transition, that is, lim !1 q (i) = lim !1 p (j !
looking at W eight rst.
Then result tree talks about i), the solution becomes independent of time.
"Who wins SUMO wrestling ?".
From the viewpoint of database design, limit distribution implies a fact that we can calculate timeindependent part of schemes (called stationary part of future schemes).
Of course, we can think only about information of nite time and q (i) = q 1 (i)+ v (i) must contain a transient part v (i).
More specically, the dierence includes: (1) the transient part (i.e., errors which depend on time).
(2) observational errors of q (i !
j ) > 0 (i.e., no transition arises).
(3) no simple Mark ov transition.
For example, a transition of a : a on W eight and (4) probability errors.
Appetite p : q happens, then he could win at next W e can't avoid the case of (4) but other should be exround if he won this round.
amined.
Let us discuss others in the following sections.
Here we have two problems.
The rst problem is how can we design database scheme from the classiEXAMPLE 2 Let us explain limit distribution to our cation of transition patterns ?
To do that, we have to SUMO example.
Our class mem bership transition is (t)  t  (t)  t  (t)  i  i  j  j  i  (  (  1  K  t  (t)  (t)  t  (t)  (  (t)  (t)  0-7695-0756-5/00 $10.00 AL 2000 IEEE  )  )  )  (t)      described by means of a matrix 01 10 .
The limit equation x + x = 1; x = x has solution x = x = 1=2.
W eight attribute has 32 3 transition matrix : 1  2  1  2  1  2  !
1=2 1=4 1=4 1=2 0 1=2 1=4 1=2 1=2    1  2  3  3=4 1=4 0 1    The limit equation has the solution x = 0; x = 1.
Finally Spirit attribute has a transition matrix: 1    0 0 0 1    3=4 0  1=4 1  Then I 0 z 1 P becomes:  The limit equation has the solution x = 2=5; x = 1=5; x = 2=5.
As for Appetite attribute the transition matrix is:   (1) First of al, let us see the Appetite attribute.
The transition matrix P is:  1 0 (3=4)z 0  0(1=4)z 10z  The inverse matrix (I 0 z 1 P )0 becomes : 1  0 1  + 4  1 01  10z 0 1 4 0 3z 0 0 And t-th term of the power series at time t, H becomes :     0 1 1 01 0 1 + (3=4) 0 0 1    t  If q = (1; 0), then we have q = ((3=4) ; 1 0 (3=4) ), if q = (0; 1), then we have q = (0; 1), and if q = (1=2; 1=2), then we have q = ((1=2) 1 (3=4) ; 1 0 (1=2) 1 (3=4) ).
In any cases, we have q 1 = (0; 1).
  0 1 (2) Winner class can be described by 1 0 .
Then   0z .
We have the inverse I 0 z 1 P becomes 01z 1 0 matrix (I 0 z 1 P ) : 1  1=2 1=2  + 1  1=2 01=2  1 0 z 1=2 1=2 1 + z 01=2 1=2 And t-th term of the power series at time t, H : (0)  (t)  (0)  t  Unfortunately, in the above observation, we can't see what happens towards transition to 1 state and we may have no solution of limit equations when some transitions are impossible among classes .
However, by using Z transformation, it is possible to obtain transient parts as well as stationary parts[4] even if 6 p(i !
j ) = 0 for some i.
In the following let us summarize the calculation issue.
Given f (t) for time t as values f (0); f (1); ::, F (z) = 61 f (t)z is called Z transformation of f .
This function has a unique inverse transformation if jzj < 1.
Let us restate our limit equations to F (z ) by Z transformation with v ector coecients.
Then the function satises z0 (F (z ) 0 q) = F (z) 1 P and we must hav e F (z ) = q 1 (I 0 zP )0 .
Since there exists an inverse matrix (I 0zP )0 , t-th coecient H contains stationary and transient parts : H = P 1 + P 0 .
Remember q = q 1 H , but once we get a stationary part P 1 of H , we have q 1 = q 1 P 1 , that is, the number of objects of c at time t becomes q (i) 1 P 1 .
If it is completely Ergodic, this result doesn't depend on q .
EXAMPLE 3 Let us analyze some cases in our running example.
2  j  t  1  1  (t)  1  (t)  (t)  (  (0)  (  (0)  (  )  (t)  (t)  (t)  )  (  )  (0)  (  )  i  )  (0)  This is called non-complete Ergodic process where there might be no object in a class and 6 p = 0 for some i.
3 If P has no zero row, F (z) has (1=(1 0 z ) as an eigen value, but there might be no stationary part otherwise.
2  j  i;j  0-7695-0756-5/00 $10.00 AL 2000 IEEE  t  (t)  (0)  3    (t)  2  And the limit equation has no solution.
t=0    (t)  t  (  t  )  1  (t)    1=2 1=2  1=2 1=2    + (01)  t    1=2 01=2  01=2    1=2  This result says that the transition has periodic property and is not convergent although we have a stationary part (the solution of limit equation).
(3) Spirit attribute has no stationary part since the inverse matrix (I 0 z 1 P )0 becomes: (1 0 z ) (0z ) and has no stationary 0 0 1 part in t-th coecient.
1  1  1  z  Finally let us discuss how to make decision trees from stationary parts of1 (limit) schemes.
First of all, we assume we have P matrix, a stationary part of class membership transition of a scheme.
(  )  Although we don't assume birth and death of objects, the total number n 1 of objects may decrease because only stationary classes S = fc ; ::; c g are considered.
Now our goal is how to generate decision trees for stationary classes.
Remember there is no c hange to objects of stationary classes since1we don't assume birth and death of objects.
Let n ; ::; n 1 be the numbers of objects of the stationary classes.
Let us extract all the rows E 0 of the stationary classes from the initial step E .
By examining all the attributes of the objects of the stationary classes, we can generate decision trees at E that is not our goal.
Again we apply our theory to tran- 5 Experimental Results sitions of all the values dom(A ) to every attribute A , and we will obtain stationary values of each attribute domain.
Let R = [a ] a transition matrix dened over dom(A ) 2 dom(A ) where a means a is changed to a with the probability a .
It may contain zero rows W e examine a set of score data of students in a class since 6 a = 0 when no value is changed to a .
By room.
W e adopted the information since the students obtaining E0 [A ] 1 R 1 , we can get the total number get used to atmosphere and communic ationduring the of stationary values.
When there exists no stationary class management, the data must be historically senvalue, we ignore the attribute because we don't have sitive.
Assuming simple Marko v transitions and let us any hook at time 1.
There remain stationary attributes calculate limit decision trees.
and we project E 0 over the stationary attributes.
W e In our class room there are 47 students, each record 0 call it E again.
consists of student ID and 5 histories of evaluation.
Now let us describe how we generate limit de- Each evaluation contains roll, report, examination and cision trees.
First of all, we have the en- result.
We assume Roll information contains 1 and tropy of class membership in limit: log n 1 - 0, Report contains 1 and 0, and Examination includes 0,1,.., and 10 which we will divide by 2, and Result (1=n 1 )6 n 1 log n 1 1 1 contains classes a,b,c,d,e,f.
Considering Result as Although we obtain all the numbersn and n , object classes, we analyze other 3 attributes: For exwe don't always obtain limit states of individual obample, the rst record describe a student 63142, he atjects at every branch of our limit decision tree.
In tended 4 times, submitted 5 reports and he got scored this investigation, we adjust each num ber of the oc"1,3,2,3,0".
currences appeared in several parts of the tree based on P 1 of the total class membership.
F or instance, let W be a collection of objects (W  E 0 ) where A 63142 1:1:1:a 1:1:3:a 1:1:2:b 1:1:3:b 0:0:0:b value are equal to a (A is a stationary attribute), m 64159 1:1:1:a 1:0:4:c 1:0:3:c 0:0:0:f 0:0:0:f be the number of objects in W , and m be the num- 65265 0:1:1:d 1:1:4:a 1:1:4:a 1:1:8:a 1:1:3:b 67269 1:0:0:f 1:0:1:c 0:0:2:e 0:0:0:f 0:0:0:f ber of objects of c in W .
Then we dene m 1 =m 1 1:1:1:a 1:1:4:a 1:1:3:a 1:1:0:f 1:1:1:f as (m =m) 2 (n 1 =n 1 ).
Eventually we will obtain 68557 72015 1:1:1:a 1:1:2:a 1:1:2:b 1:1:8:a 1:1:1:f limit schemes of classes, their sizes and classication 72022 1:1:1:a 1:1:4:a 1:1:1:f 1:1:6:a 1:1:1:f conditions 11 .
72057 1:1:1:a 1:1:4:a 1:1:5:a 1:1:10:a 1:1:5:a 72098 1:1:1:a 1:1:3:a 1:1:4:a 1:1:5:a 1:1:1:f EXAMPLE 4 Let us continue to discuss our 72099 0:0:1:e 1:0:3:c 1:0:2:c 0:0:0:f 0:0:0:f SUMO example.
As stated previously , all the classes ........ 1 (yes) and 0 (no) classes are stationary.
However, as stated previously too, Spirit attribute is not stationary any more, and Appetite becomes singleton (only p).
Thus there remains only one First of all, we examine the transition from the rst attribute W eight to our limit decision tree.
The values a; b and c are stationary.
Since we have E = state to the second.
f(a; 1); (a; 1); (a; 1); (a; 0); (b; 1); (b; 0); (c; 0); (c; 0); (c; 0); (c; 1)g As a rst step, we examined Result classes.
The initial distribution is (37=47; 2=47; 7=47; 0; 0; 8=47).
The as an initial state, we obtain the tree.
(  )  1  ( 1  k  )  (  )  k  0  0  i  i  i;j  i  i  i;j  j  i  i;j  j  i;j  i  (  )  (0)  i=1;::;k  (  (  )  2  i  i  )  (  i  (  (  (  2  )  )  (  )  )  i  )  i  (  i  i  i  )  (  i  (  )  0-7695-0756-5/00 $10.00 AL 2000 IEEE  )  (  )  transition0 matrix becomes: B B B B B @  35=42 2=42 4=42 0 0 1=42 0 0 0 0 0 0 0 0 0 0 0 0 2=2 0 0 0 0 0 0 0 1=1 0 0 0 0 0 2=2 0 0 0  1 C C C C C A  Unfortunately we couldn't see the stationary part of this transition, i.e, we got 0.
This means w e can't obtain stationary classes and all the objects are transient.
W e examined the nal transition from the state 4 to 5.
Again we checked stationary classes: In this state Result has distribution as the probability (23=47; 6=47; 3=47; 0; 0; 15=47) and it contains the transition : 0 5=23 11=23 0 0 0 7=23 1 B 0 6=6 0 0 0 0C B C B C 0 1 = 3 0 0 0 2 = 3 B C B C 0 0 0 0 0 0 B C @ 0 0 0 0 0 0A 0 0 0 0 0 15=15 And its stationary part: 0 B B B B B @  0 0 0 0 0 0  0 1 0 0 0 0  0 0 0 0 0 0  0 0 0 0 0 0  0 0 0 0 0 0  0 0 0 0 0 1  1 C C C C C A  That means there are 2 stationary classes of objects, b and f in a limit decision tree where each class contains 6 and 15 students respectively.
And according the classes, we analyzed the relevant rows.
Roll has the limit distribution of (4=21;17=21),  4 = 4 and the transition matrix is 2=17 15=170 .
And   1 0 we have the stationary parts of Roll as 1 0 .
Thus the limit distribution is (4=21; 0).
We have 1 as only one stationary value.
Similarly, Report attribute has the distribution and the transition matrix is  (5=21; 16=21) 5=5 0 .
We have the stationary parts of 2=16 14=16  1 0 Report as 0 0 .
The nal distribution becomes (5=21; 0).
As before, we got 1 as only one stationary value.
In Examination we couldn't obtain a stationary part.
Eventually we have the limit decision tree:  0-7695-0756-5/00 $10.00 AL 2000 IEEE  We have assumed Mark ov transitions in this experiment.
Initially it seems for the students to feel uneasy to a teacher and his class management.
This might be true for the teacher.
That is why we couldn't obtain the stationary part of our limit scheme.
However, after a while, half of the students became stable, i.e., they were expected to get score of b or f constantly.
This was the same feeling of the teacher.
The classication became trivial but was obtained inductively by inspecting Report and Roll as indicated by our limit decision tree.
W e got the stationary part of scheme, and the tree says only sure part.
This is suitable for scheme design.
However one of the problems is that, the deeper we examine states, the better we go to schemes.
In this experiment, we assumed all the transitions were simple Markovian, and the dierence among the matrices were assumed as errors.
Clearly we have to validate this assumption although this is not easy task.
For example, we ha ve to watch all the transition and validate the depth if necessary to see when and why we have to revisit depth of Markov memory.
6  Related Works  Knowledge discovery from databases (KDD) is now centered as one of the important and attractive research issues, for sophisticated applications like design process and data warehouses[17, 2].
Among others, concept learning from databases is one of the major research topics over the intersection of both databases and knowledge processing.
Traditionally the research topic as scheme evolution in databases means how to obtain exible mechanism of databases at re-design in a top-down manner[1] but lack of feed-bac k from database instances to adjust schemes suitable for current databases.
Scheme disc overy is a technique to obtain schemes incrementally from current schemes and the instances, while scheme learning means a technique to generate schemes from collections (clusters)  of instances directly.
The latter approach might cause accuracy and eciency since the results depend on formalization of the problems.
When analyzing the description extensively as well as scheme, we might generate new t ypes.
Such knowledge discovery process considered databases as description of the meaning is called type scheme disc overy in databases.
W e could utilize multiple attributes, then we rene the classication.
Decision tree is one of the ways of type generation[14, 15, 18].
For these years, the authors have discussed scheme discovery of database, and proposed class design[8], scheme generation by means of class approximation and inductive classication[10].
We have already proposed design methodologies based on decision trees called CSOP (Conditional Sum Of Products) under the assumptions of class hierarchy[10].
There exists one approach using Markov chains to the mining of time series[7], and they hav e proposed the technique for modeling complex and multi-v ariant applications.
But neither Ergodic analysis nor its design feed-back appear.
7 Conclusion  In this investigation we have proposed a way to behavior discovery based on inductive classication.
W e have regarded objects' behavior as a collection of temporal information, and under the assumption of Mark ov transition, and we discussed how to extract stationary and transient schemes based on Ergodic theory.
Users can separate database schemes into two parts, stationary and variable ones.
The former becomes independent of temporal aspects that we could validate as classical scheme, while the latter described transient properties of databases which had been embedded into objects' own information so far.
There remain many issues to extend our theory in future.
The most importan t one is how we can obtain suitable depth of Mark ov memory.
We assumed simple Mark ovian in this work, and it is straightforward to extend for general Mark ovian.
But, the problem arises how we can obtain the depth ecien tly or how we can examine it is the best during the change of databases.
We have proposed ecient methodology for incremental update of decision trees[12] and we guess the technique can be applied to this theory.
References [1] Elmasri, R. and Navathe, S.: Fundamentals of Database Systems (2nd), Benjamin (1994)  0-7695-0756-5/00 $10.00 AL 2000 IEEE  [2] Fayyad, U.M., Piatetsky-Shapiro, G., Smyth, P. and Uthurusamy, R.
(Eds).
: Advances in Knowledge Discovery and Data Mining, MIT Press (1996) [3] Feller, W.: An Introduction to Probability Theory and Its Application, (Vol.
I, II), John Wiley (1950) [4] Howard, R.A.: Dynamic Programming and Mark ov Processes, MIT Press (1960) [5] Ishizuka, M.: Knowledge Representation and Ecient Inference, Maruzen (1995) in Japanese [6] Langley, P.: Machine Learning and Concept Formation, Machine L earning 3 (1989) [7] Massa, S. et al: A New Modeling T echnique Based on Markov Chains in Some Behavioral Patterns in Event Based Time Series, proc.DaWaK (1999) [8] Miura, T. and Shioy a, I.: Knowledge Acquisition for Classication Systems, proc.
ICTAI (1996).
[9] Miura, T. and Shio ya, I.: Paradigm for Scheme Discovery, Intn'l Symposium on Cooperativ e Database Systems for Advanced Applications (CODAS) (1996) [10] Miura, T. and Shio ya, I.
Learning Concepts from Databases, Conference and Workshop of DEXA (1998) [11] Miura,T.
and Shioya, I.: Inductive Classication of Temporal Objects, proc.PACRIM (1999) [12] Miura,T.
and Shio ya, I.: Incremental Update of Decision Trees for Temporal Objects, proc.KRDB (1999) [13] Miura, T., Shioy a, I. and Mori, M.: Making Database Scheme More Accurate by Losing Information, proc.
of FoIKS (2000) [14] Quinlan, J.R: Induction of Decision Trees, Machine Learning 1-1 (1986) [15] Quinlan, J.R.: C4.5 - Programs for Machine Learning, Morgan Kauman (1993) [16] Sakai, H. et al.
: A Method for Behavior Modeling in Data Oriented Approach to Systems Design, ICDE (1984) [17] Piatetsky-Shapiro, G. and Frawley, W.J.
(ed.
): Knowledge Discovery in Databases, MIT Press (1991) [18] Wu, X.: Knowledge Acquisition from Databases, Ablex Publishing (1995)