Believing Change and Changing Belief Peter Haddawy  haddawy@cs.uwm.edu Department of Electrical Engineering and Computer Science University of Wisconsin-Milwaukee Milwaukee, WI 53201  Abstract  We present a rst-order logic of time, chance, and probability that is capable of expressing the relation between subjective probability and objective chance at dierent times.
Using this capability, we show how the logic can distinguish between causal and evidential correlation by distinguishing between conditions, events, and actions that 1) in	uence the agent's belief in chance and 2) the agent believes to in	uence chance.
Furthermore, the semantics of the logic captures commonsense inferences concerning objective chance and causality.
We show that an agent's subjective probability is the expected value of its beliefs concerning objective chance.
We also prove that an agent using this representation believes with certainty that the past cannot be causally in	uenced.
1 Introduction  The ability to distinguish evidential from causal correlation is crucial for carrying out a number of dierent types of problem solving.
To perform diagnosis we must be able to identify the factors that caused an observed failure in order to determine how to repair the faulty device.
If we cannot distinguish causal from evidential correlation, we may end up treating the symptoms rather than the causes of the fault.
When reasoning about plans, an agent may have goals that involve achieving a specied state of the world, or achieving a specied state of knowledge, or a combination of both.
In order to eectively reason about such goals, we need to distinguish actions that in	uence the state of the world from those that only in	uence our state of knowledge of the world.
In this paper we extend Haddawy's 3] logic of time, chance, and action L by adding a subjective probability operator.
We show how the resulting rst-order logic of time, chance, and probability, L , can distinguish between causal and evidential correlation by distinguishing between conditions and events that 1) in	uence the agent's belief in chance and 2) the agent believes to in	uence chance.
Furthermore, the semantics of the logic captures some commonsense inferences tca  tcp  This work was partially supported by NSF grant #IRI9207262.
concerning causality and the relation between objective chance and subjective probability.
We prove that an agent's subjective probability is the expected value of its beliefs concerning objective chance.
We also prove that an agent whose beliefs are represented in this logic believes with certainty that the past cannot be causally in	uenced.
On the other hand, an agent can execute actions that in	uence its subjective beliefs about the past.
2 Ontology  We brie	y present the ontology of the logic, which includes the representation of time, facts, events, objective chance, and subjective probability.
For simplicity of exposition, we will omit the representation of actions and will treat them as events.
For a more detailed development of chance, facts, events, and actions see 3].
Time is modeled as a collection of world-histories, each of which is one possible chronology or history of events throughout time.
A totally ordered set of time points provides a common reference to times in the various world-histories.
We represent an agent's beliefs with subjective probabilities.
Since beliefs may change with time, subjective probability is taken relative to a point in time.
We represent it by dening a probability distribution over the set of world-histories at each point in time.
So an agent can have beliefs concerning temporally qualied facts and events.
We represent causal correlation with objective chance.
Objectively, actions and events can only aect the state of the world at times after their occurrence.
That is to say, at each point in time, the past is xed| no occurrences in the world will cause it to change but at each point in time the future might unfold in any number of ways.
So relative to any point in time, only one objectively possible past exists, but numerous possible futures exist.
Thus we represent objective chance by dening a future-branching tree structure on the world-histories and by dening probabilities over this tree.
Like subjective probability, chance is taken relative to a point in time.
By dening chance in this way, conditions in the present and past relative to a given time are either certainly true of certainly false.
So actions and other events can only aect the chances of future facts and events.
This property distinguishes objective chance from subjective probability.
Subjectively the past can be uncertain but objectively it is completely determined.
The present characterization of objective chance is not to be confused with the frequentist interpretation of probability 10, 11] which is often called objective probability.
Frequentist theories dene probability in terms of the limiting relative frequency in an innite number of trials or events.
The current work does not rely on relative frequencies for its semantics.
Rather it models objective chance by formalizing the properties that characterize objective chance.
Thus while frequentist theories have diculty assigning meaningful probabilities to unique events like a sh jumping out of the water at a given location and time, our model has no problem in assigning nontrivial probabilities to such events.
Our model of objective chance and subjective probability is motivated by the subjectivist theories of objective chance 6, 8, 9], which dene chance in terms of properties that one would expect a rational agent to believe objective chance to possess.
This distinction between the frequentist theory of probability and our conception of objective chance puts the present work in sharp contrast with Bacchus's 1] logic of statistical probabilities which models exactly relative frequency type probabilities.
One telling dierence between the two logics is that Bacchus's logic Lp assigns only probability 0 or 1 to unique events (more precisely, to all closed formulas).
The present logic can assign any chance value to unique events in the future, while events in the past are assigned only chance values 0 or 1, as required by our denition of objective chance.
It is reasonable to expect the subjective beliefs of a rational agent concerning objective chance to obey certain constraints.
Skyrms 7, Appendix 2] has argued for a constraint he calls Millers' principle.
This asserts that an agent's subjective belief in a proposition, given that he believes the objective chance to be a certain value, should be equal to that value.
Skyrms argues that this is a plausible rule for assimilating information about chance.
We will call this relation the subjective/objective Miller's principle.
The world is described in terms of facts and events.
Facts tend to hold and events tend to occur over intervals of time.
So facts and events are associated with the time intervals over which they hold or occur in the various world-histories.
Facts are distinguished from events on the basis of their temporal properties.
A fact may hold over several intervals in any given world-history and if a fact holds over an interval then it holds over all subintervals of that interval.
Events are somewhat more complex than facts.
First, one must distinguish between event types and event tokens.
An event type is a general class of events and an event token is a specic instance of an event type.
Event tokens are unique individuals { the interval over which an event token occurs is the unique interval associated with the event token and an event token can occur at most once in any world-history.
The present work deals with event types, which for brevity are simply referred to as events.
3 The Logic of Time, Chance, and Probability 3.1 Syntax  The language of L contains two predicates to refer to facts and event types occurring in time: HOLDS (FA t1 t2) is true if fact FA holds over the time interval t1 to t2, and OCCURS (EV t1  t2) is true if event EV occurs during the interval t1 to t2 .
Henceforth we will use the symbol t, possibly subscripted, to denote time points , fi, and  to denote formulas and  and  to denote probability values.
In addition to the usual rst-order logical operators, the language contains two modal operators to express subjective probability and objective chance.
The operators are subscripted with a time since according to the ontology subjective probability and objective chance are taken relative to a point in time.
We write P () to denote the subjective probability of  at time t and we write pr () to denote the objective chance of  at time t. Probability is treated as a sentential operator in the object language.
So the probability operators can be arbitrarily nested and combined with one another, allowing us to write complex sentences like: \I believe there was a one in a million chance of my winning the lottery, yet I won."
P 3 (pr 2 (OCCURS (win t1 t2)) = 10;6^ OCCURS (win t1 t2)) = 1 where t1 < t2 < t3.
We also allow conditional probability sentences such as P (jfi) = , which is interpreted as shorthand for P ( ^ fi) =   P (fi).
The language of L is fully rst-order, allowing quantication over time points, probability values, and domain individuals.
A formal specication of the syntax is provided in the full paper 2].
tcp  t  t  t  t  t  t  t  tcp  3.2 Semantics  We describe only the more interesting aspects of the models of L .
The models are completely specied in the full paper.
A model is a tuple hW D, FN, NFN, PFN, FRL, ERL, NRL, FA, EVENTS, EV, R, X , PR , PR , F i, where: fi W is the set of possible world-histories, called worlds.
fi D is the non-empty domain of individuals.
fi FA is the set of facts, a subset of 2(<<) .
A fact is 0 a set of htemporal interval, worldi pairs: fhht1 t1 i w1i ::: hht  t0 i w ig.
If fa is a fact and hht1  t2i wi 2 fa then fa holds throughout interval ht1  t2i in world-history w. fi EVENTS is the set of event tokens, a subset of (<<)  W .
An event token is a single htemporal interval, worldi pair.
fi EV is the set of event types, a subset of 2EVENTS .
An event type is a set of event tokens: fhht1 t01 i w1i ::: hht  t0 i w ig.
If ev is an event and hht1  t2i wi 2 ev then ev occurs during interval ht1 t2i in world-history w. tcp  o  s  W  n  n  n  n  n  n  1.
HOLDS (rf (trm 1  ::: trm ) ttrm1  ttrm 2)]] = true i hh ttrm 1 ]   ttrm 2] i wi 2 F (rf )(trm 1]  :::  trm ] ): 2.
OCCURS (re(trm 1  ::: trm ) ttrm 1  ttrm 2)]] = true i hh ttrm 1 ]   ttrm 2] i wi 2 e for some e 2 F (re)(trm 1 ]  ::: trm ] ): 0 3.  prttrm ()]] =  o ttrm] (fw 2 R ttrm] :  ] = trueg).
4.
Pttrm ()]] =  s ttrm] (fw0 :  ] = trueg).
Mwg  n Mwg  Mwg  Mwg  Mwg  n  Mwg  n Mwg  Mwg  Mwg  Mwg  n  Mwg  Mwg  w  w  Mwg  w  0  Mw g  Mwg  0  Mw g  Mwg  Figure 1: Semantic denitions fi R is an accessibility relation dened on <W W .
R(t w1 w2) means that world-histories w1 and w2 are indistinguishable up to and including time t. If R(t w1 w2) we say a world-history w2 is Raccessible from w1 at time t. The set of all worldhistories R-accessible from w at time t will be designated R .
For each time t, the R partition the world-histories into sets of equivalence classes indistinguishable up to t. fi X is a -algebra over W 1 , containing all the sets corresponding to w's in the language, as well as all R-equivalence classes of world-histories.
fi PR is the objective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution  o dened over X .
fi PR is the subjective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution  s dened over X .
Given the models described above, the semantic definitions for the well-formed formulas can now be dened.
Denotations are assigned to expressions relative to a model, a world-history within the model, and an assignment of individuals in the domain to variables.
The denotation of an expression  relative to a model M and a world-history w, and a variable assignment g is designated by  ] .
Figure 1 shows the less familiar semantic denitions.
The remainder are provided in the full paper.
w t  w t  o  w t  s  w t  Mwg  3.2.1 Semantic Constraints  In order to obtain the properties discussed in the ontology, we impose eight constraints on the models.
The future-branching temporal tree is dened in terms of the R relation over world-histories.
To capture the property that the tree does not branch into the past, we say that if two world-histories are indistinguishable up to time t2 then they are indistinguishable up to any earlier time: (C1) If t1t2 and R(t2 w1 w2) then R(t1 w1 w2).
A -algebra over W is a class of subsets that contains W and is closed under complement and countable union.
1  Since R just represents the indistinguishability of histories up to a time t, for a xed time R is an equivalence relation, i.e., re	exive, symmetric, and transitive: (C2) R(t w w) If R(t w1 w2) then R(t w2 w1) If R(t w1 w2) and R(t w2 w3) then R(t w1 w3) As mentioned earlier, facts and events dier in their temporal properties.
This distinction is captured by the following two semantic constraints.
If a fact holds over an interval, it holds over all subintervals, except possibly at the endpoints: (C3) If t1 t2 t3t4 t1 6= t3  t2 6= t4  fa 2 FA and hht1 t4i wi 2 fa then hht2  t3i wi 2 fa : An event token occurs only once in each world-history: (C4) If evt 2 EVENTS , hht1 t2i wi 2 evt, and hht3  t4i wi 2 evt then t1 = t3 and t2 = t4 .
If two worlds are indistinguishable up to a time then they must share a common past up to that time.
And if they share a common past up to a given time, they must agree on all facts and events up to that time.
To enforce this relationship, we impose the constraint that if two world-histories are R-accessible at time t, they must agree on all facts(events) that hold(occur) over intervals ending before or at the same time as t: (C5) If t0 t1 t2 and R(t2  w1 w2) then hht0  t1i w1i 2 A i hht0  t1i w2i 2 A, where A is a fact or event.
The ontology discussed two desired characteristics of objective chance.
The rst is that the chance at a time t be completely determined by the history up to that time.
The second desired characteristic is that the chance of the present and past should be either zero or one, depending on whether or not it actually happened.
These two properties follow as meta-theorems from the following two constraints: (C6) For all 0 X 2 X  tt0 and w w0 such that R(t w w )   (R ) > 0 !
(X ) =   (X jR ).
w t  w t  0  w t0  0  w t  w t0  0  (C7)   (R ) > 0.
Meta-theorem 1 The probability of the present and w t  w t  past is either zero or one.
(R ) = 1 w t  w t  Theorem 7 Objective Miller's Principle (OMP)  1.
(R ) > 0 (C7) 2.
(R ) =   (R jR ) Modus Ponens: (C6),1 3.
(R ) = 1 def of c-prob w t w t w t  w t w t w t  w t  w t  w t  tcp  t  Dening the probabilities in this way makes good intuitive sense if we look at the meaning of R. R designates the set of world-histories that are objectively possible with respect to w at time t. It is natural that the set of world-histories that are objectively likely with respect to w at time t should be a subset of the ones that are possible.
w t  Meta-theorem 2 If two worlds are indistinguishable  up to time t then they have identical probability distributions at that time.
If R(t w w0) then   (X ) =   (X ) w t  1.
2.
3.
4.
5.
0  w t  (R ) > 0 (C2), (C7) (R ) =   (X jR ) Modus Ponens: (C6),1 (X jR ) =   (X jR ) (C2) (R ) = 1 Meta-theorem 1 (X ) =   (X ) def of c-prob  w t w t w t w t 0 w t  0  w t 0 w t  w t  w t  w t  0  w t  w t  0  w t  w t  In the ontology, we argued that subjective probability and objective chance should be related to one another by Millers' principle.
This relation is enforced by the following constraint, which says that the probability of a set of worlds X , given some R equivalence class, should just be the objective chance in that equivalence class.
(C8)  s (X jR ) =  o (X ) w t  w t  w t  4 Theorems  We rst provide several simple theorems that will be used in later proofs.
Then we prove two forms of Miller's principle and provide two associated expected value properties.
Proofs not provided here appear in the full paper.
Theorem 3 From  $ fi infer pr () = pr (fi): t  t  Theorem 4 Stronger sentences have lower probability.
From  !
fi infer P ()  P (fi).
Theorem 5 Certainty cannot be conditioned away from.
P ( ^ fi) = P (fi) !
P ( ^ fi ^  ) = P (fi ^  ) Theorem 6 The present and past are objectively certain.
Let be a fact or event: HOLDS ( t  t0 ) or OCCURS ( t  t0 ) then 8t t  t0 (t0  t) !
pr ( ) = 0 _ pr ( ) = 1] t  t  t  t          t  t      t  All instances of the following sentence schema are valid in L .
8 t0 t1 (t0  t1 ) !
pr 0 ( j pr 1 () = ) =  Proof:    t  The semantic constraints on objective chance give us a version of Miller's principle that relates objective chance at dierent times.
It says that the chance of a sentence  at a time, given that the chance of  at the same or a later time is , should be .
t  We rst prove an expected value property and then use it to prove Miller's principle.
Let t t0 be two time points t  t0 and consider the R-equivalence classes of worlds at time t0 .
Let the variable r range over these equivalence classes.
The r form a partition of W , so the probability of a set X can be written as the integral over this partition: Z  o (X ) =  o (X jr) o (dr)  Since the history up to time t0 determines the probability at time tZ0, this can be written as  o (X ) =  o (X ) o (dr)  where  o denotes the probability at time t0 in equivalence class r. Since the probability at a given time is assumed to be constant over all worlds in an Requivalence class, the probability at a given time is the expected value Z of the probability at any future time:  o (X ) =  o (X ) o (dw0 ): Next we show that Miller's principle is valid in the probability models.
By the expected value property,  o (ZX \ fw0 :  o (X ) = g) =  o (X \ fw0 :  o (X ) = g) o (dw00): Now, by semantic constraints (C6) and (C7) it follows that 8 w 2fw0 :  o (X ) = g  o (fw0 :  o (X ) = g) = 1 8 w 62fw0 :  o (X ) = g  o (fw0 :  o (X ) = g) = 0: So we can restrict the integral to the set fw0 :Z o (X ) = g: =  o (X \ fw0 :  o (X ) = g) o (dw00): w t  w t  r  W  r  W  w t  w t  r t0  w t  r t0  w t0  w t  0  w t  W  w t  w t0  w t0  0  00  w t0  0  w t  W  w t0  w t0  w t0  0  w t0  0  w t0  w t0  w t0  0  0  0  w  00  w t0  t0 0 w 0 fiow0 X t  f  ( )=g  :  0  w t  And by the above property again  o (XZ\ fw0 :  o (X ) = g) = , so =   o (dw00): w t0  00  w t0  f  0  ( )=g  0 w 0 fiow0 X t  :  w t  =    o (fw0 :  o (X ) = g): By the semantic denitions it follows that P ( ^ P () = ) =   P (P () = ): And by a slight generalization of the proof it follows that 8(t  t0) P ( ^ P ()  )    P (P ()  ): 2 From the Objective Miller's Principle it follows directly that current chance is the expected value of current chance applied to current or future chance.
w t  t  w t0  t0  0  t  t  t0  t0  t  t0  Theorem 8 Objective Expected Value Property  All instances of the following sentence schema are valid in L .
8  t1 t2 (t1  t2 ) !
pr 1 (pr 2 ()  )   !
pr 1 ()     ] tcp  t  t  t  As discussed in the ontology, the current subjective probability of a sentence, given that the current or future chance is some value should be that value.
The following theorem shows that this property follows from the semantics of the logic.
Theorem 9 Subjective/Objective Miller's Principle (SOMP)  All instances of the following sentence schema are valid in L .
8 t0 t1(t0  t1 ) !
P 0 (jpr 1 () = ) =  Proof: We rst prove an expected value property and tcp  t  t  then use it to prove Miller's principle.
Let t t0 be two 0 time points t  t and consider the R-equivalence classes of worlds at time t0 .
Let the variable r range over these  equivalence classes.
The r form a partition of W , so the probability of a set X can be written as the integral over this partition:   s (X ) =  Z  w t  r   s (X jr) s (dr) w t    W  w t  Z  w t  r   o (X ) s (dr) r t    W  w t  where  o denotes the objective chance at time t in equivalence class r. Since the chance at a given time is assumed to be constant over all worlds in an Requivalence class, the subjective probability at any time is the expected value of the subjective probability applied to the objective chance at that time: r t   s (x) =  Z  w t   o (X ) s (dw0) w t  W  0  w t  Next we show that the Subjective/Objective Miller's principle is valid in the probability models.
By the above subjective/objective expected value property,  s (ZX \ fw0 :  o (X ) = g) =  o (X \ fw0 :  o (X ) = g) s (dw00) By Objective Miller's Principle,  s (XZ\ fw0 :  o (X ) = g) =   o (fw0 :  o (X ) = g) s (dw00) w t  w t0  w t  0  00  w t0  0  w t  W  w t  w t0  w t  0  00  w t0  W  0  w t  Finally, by the subjective/objective expected value property,  s (X \ fw0 :  o (X ) = g) =  s (fw0 :  o (X ) = g) So by the semantic denitions it follows that 8t t0 (t  t0 ) !
P (jpr () = ) =  w t  w t0  w t  0  w t0  t  0  t0  t  t0  Theorem 10 Subjective/Objective Value Property  Expected  All instances of the following sentence schema are valid in L .
8  t1 t2 (t1  t2) !
P 1 (pr 2 ()  )   !
P 1 ()     ] tcp  t  t  t  5 Distinguishing Evidential and Causal Correlation  We wish to distinguish between two situations in which an agent may believe that two conditions are correlated.
An agent may believe that two conditions are correlated because one is simply evidence for another and an agent may believe that they are correlated because one causes the other.
Let stand for the formula HOLDS ( t  t0 ) or OCCURS ( t  t0 ) and let !
stand for the formula HOLDS (fi t  t0 ) or OCCURS (fi t  t0 ).
We represent evidential correlation as correlation in the subjective probability distribution, which is the standard approach in Bayesian decision theory.
Denition 11 We say that !
is evidence for or   By semantic constraint (C8), this can be written as   s (X ) =  And by a slight generalization of the proof it follows that 8t t0 (t  t0 ) !
P (jpr ()  )   2 From the subjective/objective Miller's principle it follows directly that subjective probability is the expected value of current subjective probability applied to present or future chance.
          against i Pnow ( j !)
= 6 Pnow ( )      (1) It follows from this denition that !
is not evidence for or against i Pnow ( j !)
= Pnow ( ) We represent causal correlation by reference to the objective chance distribution.
We represent an agent's belief that !
causally in	uences by saying that there is some value for the objective chance of such that the agent's belief in given the objective chance of just before !
holds or occurs is not the same as the agent's belief given also knowledge of !.
In other words, knowledge of !
overrides knowledge of the objective chance of .
Denition 12 We say that !
is a cause of i 9 Pnow ( j pr ( ) =  ^ !)
6= : (2) Note that this does not necessarily imply that Pnow ( j!)
6= Pnow ( ).
Thus we may have causal correlation without evidential correlation and, conversely, we may have evidential correlation without causal correlation.
It follows from this denition that !
is not a cause of i 8 Pnow ( j pr ( ) =  ^ !)
= : t  t  5.1 Example  We now present an example demonstrating the use of the denitions and theorems.
We wish to describe the following situation.
You have a coin that may be biased 3:1 towards heads or 3:1 towards tails.
You believe there is an equal probability of each.
You can observe the coin.
If the coin looks shiny, this increases your belief that the coin is biased towards heads.
You also have a magnet that you can use to in	uence the outcome of the coin toss.
Turning on the magnet biases the coin more toward heads.
We can describe the situation with the following set of sentences in which \heads" is the event of the coin landing heads, \shiny" is the event of the coin being observed to be shiny, and \magnet" is the fact that the magnet is on.
(now < t0 < t1 < t2 < t3 < t4 ) Turning on the magnet in	uences the chance of heads.
Pnow (OCCURS (Heads t2 t3)j (3) pr 1 (OCCURS (Heads t2 t3)) = 3=4 ^ HOLDS (Magnet t1  t4)) = 7=8 Pnow (OCCURS (Heads t2 t3)j (4) pr 1 (OCCURS (Heads t2 t3)) = 1=4 ^ HOLDS (Magnet t1  t4)) = 1=2 The probability that the coin is biased toward heads and the probability that the coin is biased toward tails are equal.2 Pnow (pr 1 (OCCURS (Heads t2 t3)) = 3=4) = (5) Pnow (pr 1 (OCCURS (Heads t2 t3)) = 1=4) = 1=2 Observing the coin doesn't in	uence the chance of heads.
(6) 8 t (t > now) !
Pnow (OCCURS (Heads t2 t3) j pr (OCCURS (Heads t2 t3)) =  ^ OCCURS (Shiny t0  t2)) =  Observing the coin gives us knowledge of its bias.
Pnow (pr 0 (OCCURS (Heads t2 t3)) = 3=4 j (7) OCCURS (Shiny t0  t2)) = 5=8 Pnow (pr 0 (OCCURS (Heads t2 t3)) = 1=4 j (8) OCCURS (Shiny t0  t2)) = 3=8 Turning on the magnet does not give us knowledge of the coin's bias.
8 Pnow (pr 1 (OCCURS (Heads t2 t3)) =  j (9) HOLDS (Magnet t1  t4)) = Pnow (pr 1 (OCCURS (Heads t2 t3)) = ) The coin is either biased toward heads or toward tails.
8t pr (OCCURS (Heads t2 t3 )) = 3=4 _ (10) pr (OCCURS (Heads t2 t3)) = 1=4 (11) t  t  t  t  t  t  t  t  t  t  t  It would be more appropriate to say that our belief that the current chance is 3/4 or 1/4 is 1/2 and that in the absence of events that will inuence the chance, chance will remain unchanged till time t1 .
Such an inference would require some kind of theory of persistence, which is beyond the scope of this paper.
2  Using this information, we can make several useful inferences.
First we can derive the unconditional probability that the coin will land heads.
From (5) by SOMP we have Pnow (OCCURS (Heads t2 t3)) = (12) (1=2)(3=4) + (1=2)(1=4) = 1=2 Next, we can use the above information to derive the probability that the coin will come up heads given that it is observed to be shiny.
Instantiating (6) with  = 3=4 and t = t0 and multiplying the result by (7) we get Pnow (OCCURS (Heads t2 t3)^ (13) pr 0 (OCCURS (Heads t2 t3)) = 3=4 j OCCURS (Shiny t0  t2)) = (5=8)(3=4) = 15=32 And instantiating (6) with  = 1=4 and t = t0 and multiplying the result by (8) we get Pnow (OCCURS (Heads t2 t3)^ (14) pr 0 (OCCURS (Heads t2 t3)) = 1=4 j OCCURS (Shiny t0  t2)) = (3=8)(1=4) = 3=32 From (10), (13), and (14) by the law of total probability we get Pnow (OCCURS (Heads t2 t3) j (15) OCCURS (Shiny t0  t2)) = 9=16 We can also derive the probability of heads given that we activate the magnet.
From (3), (5), and (9) we get Pnow (OCCURS (Heads t2 t3)^ (16) pr 2 (OCCURS (Heads t2 t3)) = 3=4 j HOLDS (Magnet t1 t4)) = (1=2)(7=8) = 7=16 From (4), (5), and (9) we get Pnow (OCCURS (Heads t2 t3)^ (17) pr 2 (OCCURS (Heads t2 t3)) = 1=4 j HOLDS (Magnet t1 t4)) = (1=2)(1=2) = 1=4 From (10), (16), and (17) by the law of total probability we get Pnow (OCCURS (Heads t2 t3) j (18) HOLDS (Magnet t1 t4)) = 11=16 t  t  t  t  5.2 The temporal ow of causality  Using our denition of causal in	uence and SOMP we can now show that an agent whose beliefs are represented with L believes that the past cannot be in	uenced.
tcp  Theorem 13 Let be a fact or event: 0 0  HOLDS ( t  t ) or OCCURS ( t  t ) and let !
be a fact or event: HOLDS (fi t  t0 ) or OCCURS (fi t  t0 ).
Then all instances of the following sentence schema are valid in L .
8 t t  t0  t  t0 (t0  t ) ^ (t  t ) !
P ( jpr ( ) =  ^ !)
=              tcp    t      t              Proof: We prove a slightly more general result of which  the above sentence is an instance.
By the Subjective/Objective Miller's Principle, 8 t t0 t  t0 (t0  t0 ) ^ (t  t0) !
(19) P ( ^ pr ( ) = ) =   P (pr ( ) = ) Since valid formulas have probability one, it follows by Theorem 6 that, 8 t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(20) P ( ^ pr ( ) =  ^ pr ( ) = 0 _ pr ( ) = 1]) =   P (pr ( ) =  ^ pr ( ) = 0 _ pr ( ) = 1]) Since pr ( ) = 0 and pr ( ) = 1 are mutually exclusive, we have 8 t t0 t  t0 (t0  t0 ) ^ (t  t0) !
(21) P ( ^ pr ( ) =  ^ pr ( ) = 0) + P ( ^ pr ( ) =  ^ pr ( ) = 1) =   P (pr ( ) =  ^ pr ( ) = 0) +   P (pr ( ) =  ^ pr ( ) = 1) Now we have three cases to consider: i)  = 0, ii)  = 1, iii) 0 <  < 1.
      t0  t            t0  t  t0  t0  t  t0  t  t0  t0  t0  t0  t0      t  t0  t  t0    t0 t0  t  t0  t0  t  t0  t0  Case i)  Expression (21) reduces to (22) 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 0) = 0  P (pr ( ) = 0) So by Theorem 4 and universal generalization, 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(23) P ( ^ pr ( ) = 0 ^ !)
= 0  P (pr ( ) = 0 ^ !)
          t0  t      t0  t        t0  t  t0  t  Case ii)  Expression (21) reduces to (24) 8t t0 t  t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 1) = P (pr ( ) = 1) So by Theorem 5 and universal generalization, 8t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
(25) P ( ^ pr ( ) = 1 ^ !)
= P (pr ( ) = 1 ^ !)
      t0  t    t          t0  t  t0  t  t0  Case iii)  For 0 <  < 1, P (pr ( ) = ) = 0.
So by Theorem 4 and universal generalization, 8 t t0 t  t0  t  t0 (26) 0 0 0 (t  t ) ^ (t  t ) ^ (0 <  < 1) !
P ( ^ pr ( ) =  ^ !)
= P (pr ( ) =  ^ !)
Therefore we have proven that the following sentence is valid (27) 8 t t0 t  t0  t  t0 (t0  t0 ) ^ (t  t0) !
P ( jpr ( ) =  ^ !)
=  from which it follows that the past cannot be in	uenced.
2 t0  t            t0  t    t    t0    t      t0  6 Related Work  Three outstanding subjective theories of objective chance from the philosophical literature are those of van Fraassen 9], Lewis 6], and Skyrms 7].
van Fraassen's model of objective chance is more constrained than Lewis's model which is more constrained than Skyrms's model.
Thus, in van Fraassen's model, chance has more inherent properties than in either Lewis's or Skyrms's models.
van Fraassen's theory is the only one of the three that is cast in a temporal framework.
All three are semantic theories and do not provide logical languages.
The model of objective chance used in L is based on van Fraassen's 9] model of objective chance.
He presents a semantic theory that models subjective probability and objective chance, using a future-branching model of time points.
van Fraassen places two constraints on objective chance: 1.
The chance of a past is either 0 or 1, depending on whether or not it actually occurred.
2.
Chance at a time is completely determined by history of the world up to that time.
From these assumptions, he shows the following relation between subjective probability and objective chance P (X jY ) = E C (X )] where P is the subjective probability at time t, C is the objective chance at time t, E is the expected value given Y , and provided the truth of Y depends only on the history up to t. This relation entails both Miller's principle and Lewis's principal principle, discussed below.
Note that van Fraassen does not show that a similar relation holds between objective chances at dierent times.
In van Fraassen's models, objective chance can change with time but truth values cannot.
Lewis's 6] theory of objective chance is based on his assertion that ... we have some very rm and denite opinions concerning reasonable credence (subjective probability) about chance (objective chance).
These opinions seem to me to afford the best grip we have on the concept of chance.
He describes a number of intuitive relationships between subjective probability and objective chance and shows that these are captured by his principal principle: Pr(Ajpr (A) =  ^ E ) =  where Pr is subjective probability, pr is objective chance, and E is any proposition compatible with pr (A) =  and admissible at time t. The interesting thing here is the proposition E .
The constraint that E be compatible with pr (A) =  means that Pr(E ^ pr (A) = ) > 0.
Admissibility is less readily dened.
Lewis does not give a denition of admissibility but he does characterize admissible propositions as \the sort of information whose impact on credence about outcomes comes entirely by way of credence about the chances of those outcomes."
So objective chance is invariant with respect to conditioning on tcp  t  Y  t  t  t  Y  t  t  t  t  admissible propositions.
This concept of invariance under conditioning is the central notion of Brian Skyrms's theory of objective chance.
Skyrms 7] works with the notion of resiliency.
A probability value is resilient if it is relatively invariant under conditionalization over a set of sentences.
The resiliency of Pr(q) being  is dened as 1 minus the amplitude of the wiggle about : The resiliency of Pr(q) being  is 1;maxj; Pr (q)j over p1  ::: p , where the Pr 's are gotten by conditionalizing on some Boolean combinationof the p 's which is logically consistent with q. Skyrms then denes propensity (objective chance) as a highly resilient subjective probability.
Independent of his resiliency notion, Skyrms requires that propensities and subjective probabilities be related by Miller's principle: Pr(Ajpr(A) = ) =  where Pr is a subjective probability and pr is a propensity.
He shows that Millers' principle entails that subjective probabilities are equal to the expectation of the subjective probabilities applied to the objective probabilities.
But Skyrms 7, p158] points out that, counter to intuition, independence in every possible objective distribution does not imply independence in the subjective distribution.
This observation provided the motivation for our use of the two probabilities to distinguish causal from evidential correlation.
Halpern 4, 5] presents a probability logic that can represent both statistical and subjective probabilities.
Statistical probabilities represent proportions over the domain of individuals, while propositional probabilities represent degrees of belief.
The two probability operators in the language can be nested and combined freely with other logical operators.
So the language is capable of representing sentences like \The probability is .95 that more than 75% of all birds can 	y."
The models for the language contain a domain of individuals, a set of possible worlds, a single discrete probability function over the individuals, and a single discrete probability function over the possible worlds.
The rst probability function is used to assign meaning to the statistical probability operator, while the second is used to assign meaning to the propositional probability operator.
Although he does not place constraints within the logic on the relation between the two probabilities, he does discuss a form of Miller's principle that relates subjective and objective probabilities.
His version of the principle states that \for any real number r0 the conditional probability of (a), given that the probability of a randomly chosen x satises  is r0, is itself r0."
He points out that this could be used as a rule for inferring degrees of belief from statistical information.
Bacchus 1] presents a logic essentially identical to that of Halpern.
He goes further than Halpern in exploring the inference of degrees of belief from statistical probabilities.
According to his principle of direct inference, an agent's belief in a formula is the expected j  n  i  j  value with respect to the agent's beliefs of the statistical probability of that formula, given the agent's set of accepted objective assertions.
References  1] F. Bacchus.
Representing and Reasoning With Probabilistic Knowledge.
MIT Press, Cambridge, Mass, 1990.
2] P. Haddawy.
Believing change and changing belief.
Technical Report TR-94-02-01, Dept.
of Elect.
Eng.
& Computer Science, University of Wisconsin-Milwaukee, February 1994.
Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu.
3] P. Haddawy.
Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action, volume 770 of Lecture Notes in Arti	cial Intelligence.
Springer-Verlag, Berlin, 1994.
4] J.Y.
Halpern.
An analysis of rst-order logics of probability.
In Proceedings of the International Joint Conference on Arti	cial Intelligence, pages 1375{1381, 1989.
5] J.Y.
Halpern.
An analysis of rst-order logics of probability.
Arti	cial Intelligence, 46:311{350, 1991.
6] D. Lewis.
A subjectivist's guide to objective chance.
In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 267{298.
D. Reidel, Dordrecht, 1980.
7] B. Skyrms.
Causal Necessity.
Yale Univ.
Press, New Haven, 1980.
8] B. Skyrms.
Higher order degrees of belief.
In D.H. Mellor, editor, Prospects for Pragmatism, chapter 6, pages 109{137.
Cambridge Univ.
Press, Cambridge, 1980.
9] B.C.
van Fraassen.
A temporal framework for conditionals and chance.
In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 323{340.
D. Reidel, Dordrecht, 1980.
10] J. Venn.
The Logic of Chance.
MacMillan, London, 1866.
(new paperback edition, Chelsea, 1962).
11] R. von Mises.
Probability, Statistics and Truth.
Allen and Unwin, London, 1957.