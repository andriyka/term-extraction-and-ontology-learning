2010 17th International Symposium on Temporal Representation and Reasoning  Ontology Based Spatial Planning for Human-Robot Interaction L. Belouaer and M. Bouzid and A.I.
Mouaddib GREYC (UMR 6072) UniversiteE de Caen Basse-Normandie Campus CoEte de Nacre, boulevard du Marchal Juin BP 5186 - 14032 Caen CEDEX, FRANCE {lamia.belouaer,maroua.bouzid, abdel-illah.mouaddib}@info.unicaen.fr  Abstract  A A A Spatial information  Spaceontology Planner  In the last decade, there has been significant progress on Robotics.
This development has widened the intervention fields of robots, particularly the assistance and interaction with humans.
Improving the quality of this interaction requires robots to be endowed with representation and/or reasoning system for spatial knowledge.
Our goal is to develop a planner allowing us to use human robot interaction to solve space sharing problems.
This work is original, in that the representation of the same space for humans (symbolic, fuzzy) and robots (numeric) is not the same.
Our objective is to combine human and robots representations of space in order to develop a mixed reasoning.
We propose here an ontology called SpaceOntology as a spatial knowledge representation and reasoning system.
In this paper, we focus on this ontology , and show how this type of knowledge can be profitably used for task planning.
Our objective is to incorporate this ontology into a planner by extending the planning language PDDL.
1  Figure 1.
Spatial planner.
The first sub-system is SpaceOntology.
It defined as a knowledge representation and reasoning system, for modeling and managing spatial entities, spatial relations and imprecise spatial information.
Moreover, SpaceOntology manages spatial semantic knowledge about spatial entities and how they are related.
These are respectively represented in terms of concepts and relations which are organized into a hierarchy called an ontology [8].
Different spatial representation and reasoning techniques have been proposed; maps [15, 11], algebraic approaches [3], etc.
However, these approaches can not manage quantitative, qualitative and imprecise knowledge at the same time.
We choose an ontology since it leads to: (1) a complex spatial description, (2) an easy management of large amounts and different types of spatial information, (3) a structure easily extensible and especially (4) infer spatial information by deduction of spatial relations.
As input, SpaceOntology takes a set of imprecise and incomplete spatial information.
However, as output, it provides structured knowledge about the environment to explore in planning.
The second sub-system, Planner explores the potential uses of spatial information incorporated in SpaceOntology.
It defines the set of actions to be executed by the robot in order to achieve its mission.
We consider that all spatial knowledge can be associated with the execution of each action.
Also, the actions may require navigation.
In this paper, we focus on spatial information, and show how this type of knowledge can be profitably used for task planning.
This paper is organized as follows.
In the next section we give a simple example to illustrate our work.
Section 3 presents our ontology.
Section 4 describes how  Introduction  Human-robot interaction (HRI) is not intuitive.
This constitutes a barrier to the acceptance of some humans to interact with robots.
Making this interaction intuitive and improving its quality requires endowing robots with representations and/or reasoning systems directly inspired by humans.
Many works have been dedicated to this purpose, mainly on task planning for autonomous robots ([9], [4], .
.
.
).
Task planning requires different types of knowledge encoded in the planner in a suitable way [7].
We focus here on spatial knowledge in task planning in HRI context.
Our goal is to develop a planner allowing us to solve problems taking into account spatial information: Spatial Planner (Fig.
1).
This planner consists of two sub-systems.
1530-1311/10 $26.00 AS 2010 IEEE DOI 10.1109/TIME.2010.8  Plan  ProblemA : A A A initialA state A A A goals  103  specialization  robot  O11  A do11  O25  human  A d1  A d2  A A A A A A A A A A A H  O12  A do12  (a) First floor plan.
A do25 A d1  building  O24 A do24 A do22_1  A do21_2 CM  A do22_2  SecondA floor  FirstA floor  A H1  A do21_1  O21  LevelA 0  A d2  A d3  A do23_1  O22 A d O23 o23_2  (b) Second floor plan.
O11  O12  A d11  A .........  A d1  A d2  H  O21  A ..................  LevelA 1  H1  LevelA 2  LevelA 3  A d21  A .........  (c) Hierarchical tree of a building.
abstraction  (d) Different levels.
Figure 2.
A building, its floors and its hierarchical organization.
our spatial representation and reasoning complements spatial information for task planning.
Section 5 concludes.
2  down computation.
Moreover, we propose a fuzzy representation.
From the robotas point of view, space is considered in numerical way (angles, distances, etc).
Thus, we consider a numeric representation by considering distance relations.
On the other hand, managing a considered space as a whole is difficult.
One solution is to make a hierarchical organization [6] of said space.
This organization reduces the amount of information considered for coping with a complex, high-detailed world: concepts are grouped into more general ones and these are considered new concepts that can be abstracted again.
The result is a hierarchy of concepts that ends when all information is modeled by a single universal concept (in abstraction case) or when all information is modeled by several concepts to a desired level of specialization (in specialization case).
Hierarchical space organization gives a structure easily manageable by humans and robots.
In addition, it provides better performance than a flat representation [6], in particularly in path planning.
Considering these aspects, we give here an environmental description understable by both humans and robots.
Illustrative Example  In this section, we present an example to identify our problem.
Throughout this paper, we rely on this example to illustrate our work.
Example 1 A human robot team is to perform a task in the environment defined in the figures 2(a) and 2(b).
The team is in the office O11 .
The human asks the robot to pick up a book located in the office near the coffee machine.
In our work, we consider that the robot has the ability to recognize objects, communicate and interpret orders.
From this example, two problems requiring spatial information are identified: (1) in which position the robot should execute an action, for example to enter in the office close to the coffee machine, i.e how to evaluate that an office is close to the coffee machine?
(2) how to move between different action areas?
i.e to define the robotas navigation during and between each action; for example, finding a path between the current position and the target position.
These problems can be resolved by focusing on how the human and the robot share and communicate information about space.
However, this is not simple.
Indeed, Humans and robots consider space differently.
From the humanas point of view, space is generally considered in a symbolic (in, disjoint, above, etc) and fuzzy way (very close, very far, etc).
Thus, we consider a symbolic representation by considering topological relations and an ontological definition.
There are several topological representations, namely the Intersection Method (xIM [5]), Region Connection Calculus (RCC [13]).
RCC is probably the best known model for spatial representation and reasoning.
The limitations of this representation are both in the boundaries definition of regions and in the expressiveness.
For instance, RCC method can not reason about cardinal relations such as an object north of an another.
This is possible with other qualitative formalisms such as rectangles algebra [3].This representation defines regions as rectangles.
It contains 169 relations.
This is very expressive but the number of relations slows  3  Our Formal Framework  As a formal language, we opted for the OWL DL formalism [2].
This formalism benefits from the compact and expressive nature of DLas.
Indeed, an important characteristic of DLas is their capability of inferring implicit knowledge from the explicitly represented knowledge.
In this section, we describe how we present and reason with regards to spatial knowledge.
3.1  Spatial representation  SpaceOntology allows a knowledge representation for modeling space (spatial entities, hierarchical organization), spatial relations and fuzzy information.
To the best of our knowledge, no work has developed an ontology that takes into account all these aspects.
104  3.1.1  Spatial entities  Topological relations We consider the ABLR (Above Below West Right) [12] relations.
This algebra balances between expressiveness and the number of relations (reasoning/complexity).
ABLR reduces the number of relations while preserving the directionality property of the representation defined there in [1].
It can represent the topological relations themselves (overlaps, etc) and express the cardinal relations.
A topological relation is an ABLR relation.
This relation is a couple hrX , rY i, where: rX a {Lef t(L), OverlapsLef t(OL ), Contains(Cx ), Inside(Ix ), OverlapsRightOR , Right(R)} and rY a {Above(A), OverlapsAbove(OA ), Contains(Cy ), Inside(Iy ), OverlapsBelow(OB ), Below(B)}.
A region in a considered environment is called a spatial entity.
The environment itself is seen as a spatial entity.
A spatial entity is localizable in a given space by one of its attributes or by its geometric transformation.
From a geometric point of view, a spatial entity  is defined by a rectangle rect , corresponding to its axis-aligned bounding rectangles.
Hierarchical representation Our organization is made from the highest abstraction level to the lowest (most detailed one) unlike the organization described in [6].
The highest level represents the environment with the maximum amount of detail available.
The lowest level represents the environment by a single concept.
From hierarchical organization two categories of spatial entities are derived.
Space represents a global space (Spacev T) (T for Thing1 ).
This entity is the highest abstraction and the lowest level in the hierarchy organization.
Region (Regionsv Space) represents any spatial entity belonging to different hierarchical levels (intermediate and final).
A region is a sub-space included in the given space.
A region itself considered as a space that can be decomposed into different sub-regions.
For each region we specify the current hierarchical level and scale.
The hierarchical relationship between concepts Space and Regions given by subsumption is symmetrical and transitive.
From these properties, we can compose these links and deduce new information.
3.1.2  YO11  O11  A do11 A A A A A A A A A A A H  A d1  A   YO12  O12 XO11  A d2  d12  XO12  Figure 3.
ALBR relation.
Consider the floor in figure 2(a).
Offices O11 and O12 are defined by rectangles having the same names.
In figure 3, XO12 is right of XO11 (R) and YO12 is below YO11 (B): relation1:HasRelation u 3 concernsSpatialRelation.right below u 3 hasReferent.O11 u 3 hasTarget.O12  Spatial relations  The topological relation (right below) is given by O12 hR, BiO11 :  A spatial relation is not considered in our ontology as a property between two regions but as a concept on its own (SpatialRelationsv T).
This concept represents a set of all spatial relations between two regions.
A spatial relation subsumes topological (TopologicalRelations) and distance relations (DistanceRelations).
The semantic of the relation office O22 is left of the coffee machine is not the same depending on whether the reference system is the coffee machine itself or an external observer.
In order to have a unique meaning and to remove the ambiguity, each spatial relation is linked explicitly to a given reference system that can be intrinsic or egocentric [10].
We consider a 2D space representation given by a a a a (O, i , j ).
A rectangle denoted  represents a region.
X a a (resp.
Y ) denotes the projection of  on the i axis (resp.
a a the j axis).
Additionally, a symmetry center of a rectangle will be known as the region name.
Px () (resp.
Py ()) a a a a denotes the projection of  on the i axis (resp.
the j axis).
right below:TopologicalRelations u 3 isAnHorizontalRelation.R u 3 isAVerticalRelation.B  Distance relations We consider (fig.
4) four linguistic variables to describe distance relations.
Consider the building given in figure 2(a) and2(b).
The office O11 is far from the office O23 is expressed as follows: relation2:HasRelation u 3 concernsSpatialRelation.far u 3 hasReferent.O11 u 3 hasTarget.O23  3.1.3 Fuzzy representation In HRI under spatial constraints, fuzzy information is a key point.
Indeed, a human may have an imprecise request such as take a book in the office close to the coffee machine.
The fuzziness is due to the imprecision of spatial description using linguistic variables such as close to, far from, etc.
In this  1 Thing is an OWL class that represents the set containing all individuals.
Because of this all classes are subclasses of OWL:Thing.
105  building:Space u 3 level.0 u 3 Ia.10 u 3 I,.15 A A A farA enough  f loor1:Regions u 3 level.1 u 3 Ia.5 u 3 I,.10  A A A farA A   A A A closeA to  A A closeA   enough  O11 :Regions u 3 level.2 u 3 Ia.1 u 3 I,.1  The exploitation of the fuzzy representation is described in section 3.2.3.
Figure 4.
Organization of distance.
work, vagueness and ambiguity concern the relation itself.
They mainly concern distance.
We note d(, r) in R+ , the Euclidean distance between the point of symmetry of two rectangles representing two regions (r referent object and  target object).
The aim is to find a way to represent the four linguistic variables in figure 4 by a numerical distance and vice versa.
To do so, we consider two degrees, defined in [14], N(Ia,I,) (p, q) ( 1) and F(Ia,I,) (p, q) ( 2).
The degree N represents how near two points p and q are to each other and the degree F represents how p is far from q (Ia, I, > 0).
8 < 1 0 N(Ia,I,) (p, q) = : Ia+I,ad(p,q)  if d(p, q) a$?
Ia if d(p, q) aL Ia + I, otherwise I, 6= 0  (1)  8 < 1 0 F(Ia,I,) (p, q) = : d(p,q)aIa  if d(p, q) > Ia + I, if d(p, q) a$?
Ia otherwise I, 6= 0  (2)  I,  I,  1  0  N iiV , i,i i p , qi  iV  3.2  The reasoning methods infer spatial information in order to enrich the description of the environment with new knowledge and/or to manage the lack of spatial information.
The reasoning methods proposed are related to the abstraction with hierarchical organization and the deduction with spatial relations composition.
3.2.1 Reasoning on the hierarchy Consider example 1.
A solution plan is to move between the current position (in office O11 ) and the target position ( in the office close to the coffee machine), take the book and go to the human positionas.
Finally, give the book to a human.
Now, consider the navigation problem between the initial position and the target.
The target position is defined in a fuzzy way .
Computing a path, by considering a global map of an environment (with all the corridors and all access, .
.
.
), quickly becomes expensive.
Hierarchical organization of space simplifies the path computation.
Indeed, it helps to decompose this problem into 3 sub-problems: (1) from initial position to reach an access point to the second floor, (2) from this access point plan to reach the second floor and (3) from arrival position on the second floor, plan to reach the coffee machine.
In each hierarchical level, we want to reach an intermediate target position (interest zone).
An interest zone IZ defines a region in a considered space to be reached and/or localized.
Thus, we combine the notions of hierarchy and interest zone: hierarchical interest zone.
In example 1, as a first goal, we want to reach a coffee machine.
This target region defines an interest zone.
Considering the hierarchy of the environment, we define the interset zone as IZl (r), where l is the hierarchy level and r the target region.
Thus, we can deduce from SpaceOntology a hierarchy for an interset zone.
This determines the most abstract interest zone (IZ0 (rCM ) = building) and the more detailed one (IZ3 (rCM )= current region of coffee machine).
This organization enables reasoning partitioned according to the hierarchical levels considered for a navigation action.
The exploitation of this reasoning is described in section 4.1.1.
F iiV , i,i i p , qi  iVii,  Spatial reasoning  d(p,q)  Figure 5.
Graphical representation of relationship between N(Ia,I,) (p, q) and F(Ia,I,) (p, q).
From equations 1 and 2 and organization given in figure 4, it is easy to deduce that: (1) if d a [0, Ia] then d is considered as close, (2) if d a]Ia, Ia + I,2 ] then d is considered as close enough, (3) if d a]Ia + I,2 , Ia + I,] then d is considered as far enough, (4) if d a]Ia + I,, +a[ then d is considered as far.
We have defined a hierarchical space organization.
This has an impact on the distance evaluation.
Indeed, the distance of 2 meters in a city is considered close, however, 2 meters in an office is considered far.
From this information, we define for each hierarchical level an Ia and a I, depending on the scale of this level.
Consider a building, a first floor and an office O11 given in figure 2.
From an ontological point of view, the hierarchical aspect taking into account the Ia and I, is modeled as follows: 106  3.2.2  zone to the second floor (IZ1 (rO24 ) = second floor).
However, this information is not sufficient to find O24 .
Indeed, to find the target the robot will look through all the floor in order to find its target.
Based on the composition mechanism (fig.
6), we can deduce that O21 hL, BiO24 (equation 6).
Reasoning on spatial relations  In order to enrich SpaceOntology with new knowledge and/or to manage the lack of spatial information, we consider two different aggregations of spatial relations: composition a and combination a.
Composition mechanism This mechanism infers new information about a spatial configuration.
Consider three regions 1 , 2 and 3 defined by rectangles with the same name.
The idea is to infer which relation R3 links between 1 and 3 where R1 is a relation between 1 and 2 and R2 is a relation between 2 and 3 .
The topological relation R3 is defined by R3 = R1 a R2 , then hrX3 , rY3 i = hrX1 , rY1 i a hrX2 , rY2 i  (3)  = hrX1 a rX2 , rY1 a rY2 i  (4)  hL, IY i a hOL , Bi = hL a OL , IY a Bi = hOL , Bi  3.2.3 Reasoning on fuzzy representation In the previous section, we relied on symbolic information to reach a defined interest zone (a portion of the corridor where the coffee machine is).
We consider that the current region of the robot is the interest zone.
However, it does not reach its target position.
To achieve/define its target position, the use of distance relations (imprecise and precise) is necessary.
Indeed, in the example 1, a robot must enter the office close to the coffee machine.
However, there are several offices near the coffee machine (fig.
2(b)).
Combination mechanism This mechanism consists of combining horizontal relation with vertical one rX1 a rY1 .
With this mechanism, we can deduce 36 topological relations given in Neighborhood graph of the ABLR relations [12].
This mechanism makes possible to enrich topological relations ( for example overlaps, touch, .
.
. )
and orientation relations.
Indeed, by this mechanism we can represent the 8 cardinal relations and other directional relations as at the same level, between, .
.
.
do25  Example 2 : Composition and exploitation of its results.
YO22  A d2  O25  O24  A H1  A d1  YO21  do21_3  do22_2  do21_1  do24  close  Interest Area  YO24 YO22  YO21  (6)  Based on the symmetry of spatial relations, we have O24 hR, AiO21 .
Thus, from this information the robot can plan its trajectory to reach the office O24 without considering the entire second floor but only the northeastern part of the floor from the office O21 .
This information is added in SpaceOntology.
The composition results of rX1 a rX2 and rY1 a rY2 are given by the composition table of rectangle algebra by preserving the directionality property as defined in ABLR.
YO24  (5)  O21  CM  XO21  Figure 7.
Distance evaluation.
A d3  O22  XO22  XO22  XO21  XO24  O23  Denoted by d(Oi , CM ) the Euclidean distance between the office Oi and coffee CM .
The selection of the closet office is as follows: The distance d(Oi , CM ) should allow that the degree NIa,I, (CM, Oi ) = 1.
The evaluation of distance is made by the data Ia and I, for the current hierarchical level.
By applying this system of evaluation, the offices O21 and O22 are close to the coffee machine.
Thus it selects the corresponding gates dO21 1 and dO22 2 (fig.
7).
We note that O21 and O22 verify the close relation to the coffee machine.
In this case, the robot may request additional information.
The robot asks the spatial direction.
The human answers the office in left of the coffee machine.
This allows the 2 direction and distance relations to combine by superimposing the 2 representations as defined in figure 8.
XO24  Figure 6.
Projection and composition.
In the second floor (fig.
2(b)), we assume that the team is in the office O21 .
The human asks the robot to go and stay in the office O24 .
From SpaceOntology, the robot has only this information: (1) O21 hL, IY iO22 , O22 hOL , BiO24 and (2) the office O24 is on the current floor.
The spatial information the office O24 is on the same floor as the office O21 allows the robot to limit its interest 107  Above  do25  Left  do22_2  do21_1  do24  the system, the purpose of this planning is to reach a final state in which all objectives are achieved.
The path planning focuses on geometric aspects of motion planning (avoidance of collisions with fixed obstacles in the environment).
The planner must be able to provide a path between two points or two regions of space.
The initial position/region is the current position.
We suppose it is known.
However, the definition of the target position/region is defined vaguely, for example, the office near the coffee machine.
In this paper, we focus mainly on how to exploit SpaceOntology in path planning between a precise and imprecise position.
Right  close  do21_3  Interest Area  Below  Figure 8.
Superimposing representations.
From a planning perspective, let us consider the action of enter office, these spatial constraints must be expressed in terms of preconditions for action enter office (see section 4).
4  4.1  Application Context: Planning  In the example 1, the robot must reach the office close to the coffee machine from its initial position then enter into the office and take the book.
To do so, the robot must: (1) reach the region in which the coffee machine is , (2) select the office close to it, and (3) enter into this office, position itself and take the book.
The goal of path planning is to define the path between the robotas current position and the interest zone, i.e a region in which it will execute the action of taking the book, defined imprecisely.
Our contributions to the path planning focused on taking into account: (1) space hierarchy, (2) topological relations (touche, left, .
.
.
), (3) distance and fuzzy information.
We can summarize the path planning in three points: (1) acquisition of the environmental model; it is based on SpaceOntology for spatial representation and reasoning in order to define the interest zone for the fuzzy position (denoted tEp ) and generate a structure called Crossing Network Graph; (2) in this graph we try to define the path between the current position and the interest zone; (3) then to define/delimit the fuzzy position.
The last step is described in the section 3.2.3, we develop here the first two steps.
Now, we explore the potential uses of spatial representation and reasoning offered by SpaceOntology in planning.
A planning process searches for a sequence of ordered actions that transform the initial state into the goal state.
Let us consider the problem defined in section 2.
This problem involves the use of spatial planner (Fig.
9).
This planner consists of a task and a path planner.
The task planner is used to define the sequence of actions performed to achieve its objectives.
The path planning is used to define the trajectory of the robot, i.e trying to define the robotas navigation during and between each action.
problem  Planner  InitialA state A goals  planA   A A InitialA spaceA stateA  A A GoalA spaceA state  Task A A PlannerA   SpaceOntology  Space repesentation  Using spatial knowledge for path planning  Path Planner  A actions  4.1.1 Acquisition of the environment model Figure 9.
Spatial planner in details.
Spatial modelisation A spatial relation is given by the concept SpatialRelations.
We define a concept HasRelation which refers to the spatial relation for which target and reference entities are defined.
In [9], the task and path planners are interlacing.
The navigation actions are not considered as actions but as preconditions for actions.
For example, to take the book in the office, the robot must be able to access this area and to position itself correctly.
We offer the same planner structure in [9].
However, the definition of these planners is not the same.
Future work will concern the spatial planner and how to link between sub planners.
Moreover, our planner manages symbolic, numerical and fuzzy spatial information in spite of managing only numeric information in [9].
The task planning focuses on defining the actions to be executed from an initial state of world and an initial state of  HasRelation v T u a concernsSpatialRelation.SpatialRelations u = 1 concernsSpatialRelation u a hasReferent.Regions u > 1 hasReferent u a hasTarget.Regions u = 1 hasTarget  Figure 10 models a part of a first floor with the office O11 and a corridor H (fig.
2(a)).
We consider that each spatial entity is a Regions concept.
Then, spatial relation between these different spatial entities are described 108  A  ref A A A A A Space A A A A Regions  concerns  A A HasRelation  target A intersection  ToplogicalRelations isaV  A A A A A AxisRelationsA A A A   A VerticalRelations  DistanceRelations  isaH  HorizantalRelations close  L  OL  CX  IX  R  OR  isaV  A  OA  CY  IY  B  OB  A far  A closeA enough A A farA enough  Inside  isaH OL  A Crossing Network(I) is a graph whose nodes are Crossing Network.
Edges represent spatial adjacency relations between two nodes described in SpaceOntology giving a gateway.
Edges are labeled by a couple (pass, dist), where pass gives the gateway connecting these regions (or networks) and dist is the distance separating these regions (or networks) passing through this gateway.
A SpatialRelations  HasRelationWithIntersection  concerns  relation6  A  ref  OA  Definition 1 (Crossing Network I) A graph I = (V ,E), where :  H A target  A  intersection  O11  aV V = (v1 , v2 , .
.
.
, vn ) set of vertices, each vi being a crossing network,  dO11  A   A   aV E = (e1 , e2 , .
.
.
, en ) set of edges, each ei is a spatial adjacency relation indicating a gateway and a distance.
Figure 10.
Graphical illustration.
by combining the SpatialRelations (inside) and HasRelation (relation6) concepts.
4.1.2 Path computing : Algorithm 1 Topological relations: Gateways A spatial relation allows, given an environment, description of its spatial configuration using a direct description or by deduction.
From topological relations, we can define for two regions if they are in contact or not and if there are points for direct passage between them: gateways.
A gateway (i.e door, passing lane, .
.
. )
allows transitions between adjacent regions and adjacent regions from different hierarchical levels.
A gateway allows us to connect more than two regions.
To extract the gateways between regions, we query our knowledge base.
From SpaceOntology, we can compute the path between the initial position and the target position according to the space hierarchy.
As stated, path computing between two positions can be decomposed into sub problems by defining hierarchical interest zone.
Each sub-problems requires a different level of detailed spatial information.
To reach the most abstract interest zone, we must ignore the details given in others steps.
However, considering the intermediate position as block boxes does not guarantee the path quality.
Consider that the quality is related to speed; passing through certain corridors with big distances can be faster than through the ones with short distances but many obstacles.
Our goal is to find the best path between two positions, according to the hierarchy of space, complying with two criteria: (1) minimize the Euclidean distance in the most abstract level, (2) facilitate access to a region, to ensure fast and simple actions.
These two criteria allow us to have a quality path solution.
Path computing in Crossing Network Graph consists of path research in Crossing Network for each hierarchical level.
Algorithm 1 gives computing path function.
A first step (line 1) consists in generation of a Crossing Network Graph (graph).
A second step ( from line 6 to line 19) consists in finding a path between current region and the interest zone in this structure respecting our criteria.
First, we verify if there is a path between the most ab-  Example 3 : Querying SpaceOntology Let us consider the first floor (fig.
2(a)).
As the door dO11 is already recognized, we can query SpaceOntology.
"SELECT ?referent ?target " + "WHERE {" ?x ns:label ?relation."
+ " ?x ns:hasintersection \"door1\"."
+ " ?x ns:hasReferent ?referent. "
+ " ?x ns:hasTarget ?target."
+"}";  The goal is to recognize if there are regions connected to this door and return them.
We deduce that the corridor H contains the office O11 and a gateway d11 exists allowing passage between these two regions(table 1).
Table 1.
Query results.
relation referent target relation7 dO11 H  l0  l0  i tE stract regions (IZ p (ip ), IZ p (tEp )) corrspending respectively  l0  l0  i tE to different positions (ip , tEp ) such as IZ p (ip ) and IZ p (tEp ).
Secondly, we select g and g 0 two gateways (line 7).
The first one allows exiting of the initial abstract region.
The second one allows entrance to the target abstract region.
The path (mostabstractpath) between these gateways must respect the optimality criteria.
Now, we consider that our target is the gateway g. Our goal is to find a path between ip and g. If  Graph generation from SpaceOntology A Crossing Network Graph(IG ) is a directed graph.
A node in this graph represents a Crossing Network.
Nodes are organized hierarchically.
Edges represent relations between nodes.
109  methods such as classification of regions for a better delimitation of interest zone areas.
The planning aspect in this paper is not finished since we present only the path planning.
Future work will concern integrating concepts defined in SpaceOntology in planning by extending the planning language PDDL.
This is an innovative concept.
We will use this model in ANR2 project AMORCES3 .
Algorithm 1 pathComputing Require: P osition ip , tEp , SpaceOntology O 1: graph a createCrossingNetworkGraph(ip , tEp ,O) 2: li0 p a the lowest level corresponding to ip , lt0E a the p l0  l0  i tE lowest level corresponding to tEp | IZ p (ip ) 6= IZ p (tEp ) 3: lip a the current level corresponding to ip 4: ltEp a the current level corresponding to tEp 5: path a   6: 7:  8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20:  if a a path between  li0 IZ p (ip )  References  lt0E  and IZ (tEp ) in graph then p  l0  [1] J. Allen.
Maintaining knowledge about temporal intervals.
ACM New York, NY, USA, 1983.
[2] F. Baader and all.
The description logic handbook: theory, implementation, and applications.
Cambridge Univ Pr, 2003.
[3] P. Balbiani, J.-F. Condotta, and L. F. del Cerro.
A new tractable subclass of the rectangle algebra.
IJCAI, pages 442a447, 1999.
[4] A. Bouguerra, L. Karlsson, and A. Saffiotti.
Monitoring the execution of robot plans using semantic knowledge.
Robotics and Autonomous Systems, 56(11):942a954, 2008.
[5] M. Egenhofer.
Reasoning about binary topological relations.
1991.
[6] J. FernaEndez-Madrigal, C. Galindo, and J. GonzaElez.
Assistive navigation of a robotic wheelchair using a multihierarchical model of the environment.
Integrated ComputerAided Engineering, 2004.
[7] C. Galindo, J. FernaEndez-Madrigal, J. GonzaElez, and A. Saffiotti.
Robot task planning using semantic maps.
56(11):955a966, 2008.
[8] T. Gruber et al.
Toward principles for the design of ontologies used for knowledge sharing.
International Journal of Human Computer Studies, 1995.
[9] J. Guitton and J. Farges.
Geometric and symbolic reasoning for mobile robotics.
pages 76a97, 2008.
[10] C. Hudelot, J. Atif, and I. Bloch.
Fuzzy spatial relation ontology for image interpretation.
Fuzzy Sets and Systems, 2003.
[11] B. Krose, N. Vlassis, R. Bunschoten, and Y. Motomura.
A probabilistic model for appearance-based robot localization.
Image and Vision Computing, 19(6), 2001.
[12] S. Laborie, J. Euzenat, and N. LayaAada.
A spatial algebra for multimedia document adaptation.
SMAT, 2006.
[13] D. Randell, Z. Cui, and A. Cohn.
A spatial logic based on regions and connection.
KR, 92:65a176, 1992.
[14] S. Schockaert.
Reasoning about fuzzy temporal and spatial information from the web.
PhD thesis, Ghent University, 2008.
[15] S. Thrun, D. Fox, and W. Burgard.
Probabilistic mapping of an environment by a mobile robot.
IEEE International Conference on Robotics and Automation, 1998.  l0  i tE select g and g 0 | g a G(IZ p (ip )), g 0 a G(IZ p (tEp )) and the path between g and g 0 respects optimality criteria mostabstractpath a abstractPath(g,g 0 , graph) localpath a  if ip , g a the same current region then localpath a path(ip ,g,graph) else localpath a pathComputing(ip ,g, O) end if path a localpath aS mostabstractpath else no path end if refinePath(path,graph) return path  ip and g belong to the same current region then we compute the local path between these positions.
Else, we call recursively the pathComputing function in order to compute the path between ip and g using O as ontology.
Then, we construct path solution path a localpath aS mostabstractpath.
To improve the solution quality (ie, accessibility, distance, .
.
.
), we perform a phase of post treatment: path refining (line 19).
This technique changes locally optimal portions by direct lines; in other words, paths allowing an easy access and having a positive impact on the portion of the path in next hierarchical level.
We start from one extremity of the solution: initial position.
For each node in the solution, we check whether we can reach the next node by a direct line.
If this happens, then the linear path between the two node replaces the original optimal order among these nodes.
Then we update the path in lower hierarchical level.
5  Conclusion  This paper shows spatial knowledge exploitation for improving planning efficiency, an issue that is rarely considered in HRI in spite of its relevance when we have to deal with large amounts of information with different representations.
This work can be further improved by incorporating  2 Research  Projects Agency.
and Models for Collaborative Eloquent and Social Robot.
3 Algorithms  110