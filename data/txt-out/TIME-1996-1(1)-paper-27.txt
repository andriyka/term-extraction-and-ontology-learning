Irrelevance in Uncertain Temporal Reasoning Ahmed Y. Tawfik and Eric M. Neufeld Department of Computer Science University of Saskatchewan, Saskatoon, Saskatchewan S7N 5A9, Canada { tawfik,eric}@cs.usask.ca  Abstract  answering task.
The analysis and conclusions can be directly applied to any other task.
In a query answering task, the subset of the theory relevant to a particular query is defined as follows:  In the presence of uncertainty, relevance of information degenerates as time evolves.
This work shows that this degeneration occurs in probabilistic temporal reasoning.
A mechanism f o r analyzing this phenomenon uses a Markov chain representation and a degree of relevance measure called temporal extraneousness.
Eficiency of probabilistic temporal reasoning can be improved b y ignoring irrelevant and weakly relevant information.
The analysis introduced here allows us to identify the portion of event history affecting the time instant of interest.
The duration of relevant history depends on the dynamic nature of the system and the chosen relevance threshold.
These notions are used to prune time-sliced Bayesian networks which constitute a popular probabilistic temporal reasoning knwolege representation.
1  Definition 1 Given a theory 0 consisting of a set of predicates and a query Q consisting of a conjunction Q = (q1 A q2 A .
.
.
A q n ) , the relevant theory OQ is a minimal subset of 0 such that V q i E Q , qi follows from 0, i f fqi also follows from 0 .
To extend the above definition to probabilistic queries, we first consider that all q i ' s in the query Q are indepenedent.
In this case, a probabilistic version of the definition would require that the probability of each individual belief qi remains unchanged in the full theory and the abridged one, or P ( q i ( 0 )= P ( q i ( 0 Q ) .
In probabilistic terms, irrelevance of the information in the set 0 - OQ with respect to query Q implies that Q is independent of 0 - 0 9 .
In general, the conjunctive query Q may contain dependent beliefs.
In this case, we require the abridged theory to provide the same values for the individual beliefs as well as for the joint distribution.
The objective of this work is to study irrelevance in temporal probabilistic domains.
These domains are dynamic with uncertain temporal evolution.
The ability to forecast and explain changes in such domains is required for a wide range of applications spanning planning, diagnosis, natural language understanding and scheduling.
Efficient performance of such tasks requires a theory of relevance in dynamic uncertain domains.
In such domains, two classes of irrelevant information fit directly into the notion of irrelevance as independence developed so far.
The two classes are mutually independent beliefs and conditionally independent beliefs.
Mutually independent beliefs do not affect each other in any way.
For example, the probability of precipitation does not depend on the color of my pen.
Two conditionally independent beliefs affect each other in general but become irrelevant once other  Introduction  The success of intelligent systems in performing useful tasks depends to a large extent on the availability of relevant knowledge.
A paradox arises in most practcal systems when the amount of knowledge grows beyond the capacity of the intelligent systems.
Too much knowledge usually results in a significant degradation of the systems' performance.
This performance degradation is usually attributed to the computational complexity of reasoning.
Poor performance threatens the usefulness of intelligent systems and their success.
Hence, it is desirable to have the knowledge base as concise as possible.
Nevertheless, coverage of different situations and exceptions is an equally sought feature.
The study of information relevance tries to determine what information is relevant to a particular task and what can be ignored without compromising the conclusion.
For example, a query answering system has to identify and select from a knowledge base information relevant to answering a given query.
Throughout this work, we assume, without loss of generality a query  196 0-8186-7528/96 $5.00 0 1996 IEEE  accuracy S and the probability distribution describing the process.
information is known.
For example, the probability of precipitation depends on the temperature but the absence of clouds rules out the possibility of precipitation completely.
In dynamic uncertain domains, we identify a third class of irrelevant information.
This class includes information that becomes obsolete with time due to the uncertain dynamic nature of change.
For example, knowing that the cat was lying on the living room couch several hours ago, does not help in predicting its present location.
The relevance of such information degenerates with time.
Unfortunately, the notion of relevance developed so far does not capture this class of irrelevant information.
It is not possible to claim that observing the cat on the couch is independent from its location.
In our example, there is a slim chance that the cat remained on the couch all this time.
It is not acceptable to claim that the probabilistic dependence fades away with time.
Instead, we try to bridge the gap between our commonsense notion of irrelevance and the definition.
We define a weaker temporal relevance criterion called temporal extraneousness.
2  Extraneousness Time  Before proceeding any further, it may be useful to examine more closely the performance savings that can be achieved by discarding irrelevant information.
To this end, we start by considering the following example.
The cat is seen in the living room at 9:00 AM.
We are interested in evaluating the probability that the cat is in the room at 2:OOPM.
The cat may leave the room during any minute with probability P(leave1inside) = 0.00579 and it may enter the room during any minute with probability P ( enter loutside) = 0.00773.
Time-sliced Bayesian networks are an increasingly popular technique for solving this type of problems.
A time-sliced Bayesian network is a sequence of instantiations each representing the state of different beliefs at a particular point in time.
The arcs connecting two i~nstantiationsare sometimes called temporal arcs and are responsible for propagating temporal effects such as causation and persistence across time.
There is no conscensus as to when a new instantiation is needed.
DHugin networks add new instantiations at equal intervals [ 5 ] .
Depending on the chosen temporal resolution, the network may contain a number of instamtiations n = T / A where T is the total duration and A is the temporal resolution.
Assuming a one minute resolution in our example, we can expect the network to have 300 instantiations.
Other approaches may generate networks with only two instantiations.
In either case, the computational complexity of inference in Bayesian Nets is high.
Reducing the size of the network invariably results in significant performance gains.
Most people do not seem to find the information regarding the location of the cat at 9:00 AM relevant to finding it at 2:OOPM.
The following theorem supports this intuition.
The theorem shows that there exists a duration T such that the probability of fluent f at a time t > to +T changes by at most 6 depending on the truth of f at to.
Moreover for any arbitrarily small 6 a different duration T can be found.
Definition 2 If the maxamum effect of knowledge 0 at tame t, on belaef q1 at tame t , is less than a small value 6, ti and t, are temporally extraneous wath respect t o 41.
The extraneousness level 6 << 1 as met when the anequalzty IP(ql,1O,)-P(ql,1lO,)I 5 6 holds.
The strength of the degree of relevance as measured by temporal extraneousness can change according to the value of S. A 6 value of zero results in the know strong irrelevance notion of probabilistic independence.
Irrelevance is weaker for higher S settings.
Weak temporal relevance corresponding to small 6 values is of particular interest here.
We redefine irrelevance using extraneousness instead of independence.
The new definition allows us to ignore weak relevance.
Definition 3 The theory 0 can be davaded anto a relevant theory OQ and and extraneous anformatzon OE t o answer the query Q wath accuracy 6 a f f IP(Ql0) P(Ql0~)lI S and f o r any q E Q IP(ql@) p((Il@Q)I I S. Starting with the complete theory 0 , we would like to identify the irrelevant and weakly relevant information.
This information can then be discarded and reasoning can proceed with the concise theory 0 0 .
Here, we concentrate on the degeneration of the relevance of information as time evolves.
Past information become irrelevant after a time duration T .
This duration depends on the dynamic nature, the required  Theorem 1 Consider a fluent f represented by the Markov Process in Figure 1 with states fi and f i and tran:sition probabilities P ( f i + , Ifi) = p l , p (fi+l15) = ~ 2 ' (, f i + l I f i ) = 1 - pland P ( f i + ~ l f = i ) 1 - p z such that 1 > p l , p 2 > 0 .
I f the system is in state f i , then the jauent is true at time i.
Let the probability that the system described by this Markov process be i n state ft  197  Similarly,  State Space t=O  t=l  t=T-l  t=T  P(fTlf0) = P n ( 1 -  1  p1 - p 2 ) T - - l [ 1 -  ____  PI + P 2  PZ  I+--- p1 + p 2  Therefore, IP(fTlf0)- P(fTlf0)l =  Depending on the values o f p l and p2 the duration T that makes the difference less than S can be determined as follows:  Phase Space Figure 1: A two-state Markov Process  T=  at tame t be P ( f , ) .
The claim here is that f o r any S << 1 there exists T such that  Thzs zs a recurrent relataon that can be solved usang the ateratzon method to get  [$I.
+  P(fTlf0) = (1 - Pl -P2)T-1P(fiIfo) P z ( 1 - P1 p 2 ( l - pl - P ~ ) ~ .
.-.
~  +  +- +  P2(1 - P1 - P 2 )  + P2  By substatutaon f o r P ( f1 Ifo) and summang the geometrzc serzes an the above expressaon, we get 1 Pl  +P2  -  log(4 log11 -P1 -Pal  Applying the above result to the cat example, it turns out that knowing the location of the cat at 9:00 AM affects the belief cat as an the h a n g room at 2:OO PM by less than 0.02.
It is therefore acceptable to answer the query based on the prior probability of the cat being in the living room without considering a 300 stage Bayes net.
This probability is 0.57.
The information is outdated by the dynamic nature of the system and the lack of knowledge about the developments occurring between the two points.
Ignoring such outdated information affects the prediction within a small range S The transition probabilities p l and p2 determine the dynamic properties of the system.
Small transition probabilities indicate that states are persistent.
A large p l and small p2 lead the system to stay longer in state $.
Hence, the transition probabilities determine the duration T beyond which we can consider the observations extraneous.
In the special case p1 = 0 and p2 = 0 the system maintains an initial truth value.
This results in the deterministic commensense law of inertia In this case no finite T can be found because the denominator log( 1-p1 - p 2 ) becomes zero.
If one of the states is an absorption state (i.e.
if either p l =O or p:!
= 0) the system would remain in this state once it reaches it and its behavior is fully determined henceforth.
For example, if the cat could not come back to the room once it leaves it, then the calculated T gives the duration when the cat would have left with certainty 1- S. This probability is sometimes called time to absorption.
Another extreme case occurs when p l = 1 and p2 = 1, the system oscillates  + P2  P(fTIf0)= (1 - P1 - PZ)P(fT-llfO)  P ( f T l f 0 ) =Pip -P1 -pz)T-l[-  l ( l - P1 - P 2 ) P  P2  11+ KTE  198  proceeds in a similar fashion except that for the number of probabilities as n2 transition probabilities are needed.
The result should also hold for continuous time.
In the case of continuous time the probabilities are calculated by integrating the probability density functions over an interval At.
The proof also assumes that, the transitions take no time, which is not the case in most practical situations.
Let 11-2 be the transition time from state f to state f and 1 2 - 1 the transition time from state f to state f .
c  0  0.2  0.4  0.6  0.8  1  1.2  1.4  PI +P2  1.6  1.8  Corollary 2 A fluent f modeled by a Markov Process wath states fi and J"z a n d transztzon probabalatzes P(f,+lIf,) = - P l , P ( f Z t l l f , ) = P2, p ( f i t l l f 2 )= 1-pland P ( f z + l I f 2= ) 1-p2 such that 1 > p l , p 2 > 0.
The praor probabzlaty that the system as an a state fi  2  Figure 2: Extraneousness Time vs.
Sum of Probabilities  as  h o o f By taking the limat as T tends t o infinaty an P ( f , lfo) and P (fTlfo) an the proof of the theorem.
and so does the probability difference l. In this case, the system is fully predictable given an initial state.
Figure (2) shows the change of the time T for different values of the sum of transition probabilities p1 +p2 for S = 0.01.
It is worth noting that this curve is symmetric around the point p l p2 = 1.
At this point the difference P (fT Ifo) - P ( fT is equal to zero for any t and the truth of f at any time is independent from its state previous states.
The following corollary shows this mathematically.
+  The convergence of probabilities in a regular Markov chain as time progresses [4] is related to the above result.
The convergence property implies that a longer time duration allows a higher accuracy (smaller 6).
2.1 Multiple States Markov Processes If P is a transition matrix, the element in the j th row of the i-th column of the matrix PT gives the prolbability of being in the state designated by the columin at time T assuming that the process started from the state designated by the row.
Checking for relevance of initial information in an m states Markov process can be performed in O(m310g(T)) using this property.
The procedure for relevance checking squares the transition matrix until reaching the power T .
The difference between the highest and lowest probabilities gives the maximum effect an initial state can have.
If this difference is less that the chosen S,the initial state can be considered irrelevant.
If,)  Corollary 1 A n y two time points t and t + A i n a process as described an the theorem are temporally independent if p2 = 1 - p l .
Proof P ( f t + A ) = p ( .
f t + A l f t ) p ( f t )+ P ( f t + A l f t ) P ( f t ) B u t P ( f t + a I f t ) = p(ft+aIft)= 1 - P I p(-ft+A)  --%.
= p2 then,  +  = P ( f t + A l f t ) [ P ( f t ) P ( f t ) ]= P ( f t + A l f t )  The proof of the theorem assumes a stationary process (i.e.
time invariant transition probabilities), but the result holds for time varying non-zero transition probabilities as well.
In the case of time varying probabilities, an upper bound on T can be found by considering the lowest value possible value for p l + pz if this sum is less than one or the highest possible value for the sum greater than one.
It is possible to generalize the proof to non-binary variables; for a variable with n truth values, the proof  Exinmple 1 Consader a three states Markov process with the following transataon matrax  P  :=  [ :::b .4  'r 1  .3 .3  .
W e would lzke t o determine the relevance of informataon gathered 50 time unats ago af the required accuracy S = 0.01.
T o check the relevance of thas znformataon we calculate P50  ' A negative difference simply indicates that the probability  .3759398497 .1804511278 ,4436090226  P(f~lf0).
As an extraneousness criterion, the absolute value of the difference is what matters.
P(f~lf0) is larger than the probability  ,3759398497 .1804511278 ,4436090226 .3759398497 .1804511279 .4436090227  199  1  .
To apply the above theorem to temporal Bayesian networks, estimation of p1 and p2 is necessary.
Those probabilities can be directly obtained in virtually any temporal probabilistic formalism.
By definition the probabilities are given by pl = P(ft+Alft) and pa = p ( f t + A l f t ) .
For example, in Figure 3 a time-sliced Bayesian network that can be used to calculate p1 and p2 for a fluent f. This fluent is affected by two possible events e l and e2 where el causes f to be true and e2 turns it false.
In this case,  P1 = 1 - P ( f t + A  lft)  Figure 3: Generic Time-Sliced Bayesian Network  It is clear that the effect of this information is almost nil and there is not need t o take it into consideration.
where E1 and E4  Note that the procedure described above can stop if the required accuracy is met before reaching T.  3  ( e l A e2),Ez Ez).
(el A F a ) , E3  3 (El  A ez)  (81 A  PZ = P ( f t + A I f t )  Irrelevance in Temporal Bayes Nets  Recent efforts to introduce temporality into Bayesian networks have resulted in a variety of networks intended primarily for applications such as planning, diagnosis, forecasting and scheduling.
Many of these use multiple instantiation of a static network.
New copies are instantiated at different time points.
The irrelevance criterion introduced here is particularly useful in such networks.
Dynamic nets [l],temporal Bayes nets [ a ] , and dHugin time-sliced Bayesian nets [6] are all based on the duplication approach.
These networks maintain Markov property which means that each node depends only on its immediate predecessor.
This property means that nodes representing fluents at time t depend on some fluents at time t - At.
A fluent at time t - At can affect a node at time t through two mechanisms: persistence or causation.
Persistence represent the probability that the fluent at time t - At maintains its truth values at time t .
In the absence of extreme probabilities, persistence is bound to decay as in the case of Markov chains.
Causation may trigger a change in truth value immediately or after a causation delay.
Instantaneous causation is weaker than evidence because the causal mechanism may fail.
Therefore the bound on relevance time continues to hold.
Delayed causation means that a fluent at time t causes another fluent to became true (or false) at time t + D. Delayed causation becomes irrelevant after a duration T + D where T is the relevance time and D is the causation delay.
The four terms in the summation correspond to both events happening concurrently, a single event happening or both not happening.
In our cat example, event el corresponds to the cat entering the room during any minute, e 2 corresponds to the cat leaving the room.
It is possible that the cat enters and leaves within the same minute or stay away from the room.
The transition probabilities p l and p z are conditional probabilities.
Therefore, the knowledge K available about different states during the interval [t,t-+ A] affect the probabilities.
In general, p l = P ( f t t A l f t , I{[t,t+A]) and P2 = p ( f t + A l f t , I{[t,t+A]).
For example, whether a car is in running condition or not, affects the probability of it staying parked or being driven away.
4  Discussion  The analysis of temporal degeneration of information relevance seems to suggest that maintaining a consistent level of predictive accuracy requires a continuous range of memory retention periods.
Implementing such variable term retention can be done by attaching to each proposition a time-stamp and an expiry tag.
The lack of information during the duration between the observation time and the query time made the observation insignificant.
In general, it is possible  200  to have fully reliable information or uncertain information about this interval.
In the case of fully reliable information, the Markov property allows us to consider only the most recent one.
However in the case of uncertain information, it is not generally possible to ignore the old observation or the recent one.
The effect of the recent information on the belief may depend on the degree of belief resulting from the old information.
In some special cases it is possible to ignore the old information.
These cases include situations when old and new information interact according to the additive storage model [lo] where the total belief is given by the sum of individual beliefs.
In such situations a weak relevance continues to have a weak effect.
5  nature of the process and the choice of the present window size does not depend on the probabilities or accuracy.
6  Conclusions  This study analyzed irrelevance in temporal probabilistic reasoning.
The results of this analysis are: 1.
Independence, conditional independence and extraneousness allow us to identify irrelevance and weak relevance in temporal domains.
2.
If the duration between the observation time and the time point of interest is long enough, the observations can be ignored without significant loss in the accuracy of the conclusion.
Related Research  3.
The length of the duration required to make past observations extraneous depends on the dynamic nature of the system as reflected by the probability of transitions.
Lin and Reiter [7] update a logical knowledge base by removing irrelevant information.
Information irrelevance in their framework, corresponds to the first two types of irrelevance mentioned in the introduction.
Irrelevance resulting from the dynamic nature of the process is not taken into account.
Ngo, Haddawy and Helwig [9] introduce a technique for finding information relevant to a particular query in a given context.
This is close to Lin and Reiter notion of irrelevance.
It also results in substantial reduction in the size of the problem.
This technique can be used in conjunction to the extraneousness criterion introduced here resulting in a more manageable solution to probabilistic temporal reasoning.
An algorithm for temporal reasoning, proposed by Hanks and McDermott [3], uses the most recent information first, then looks in the past for information that may affect the current conclusion.
This is a very different solution for the information obsolescence problem to the one proposed here.
The algorithm cannot identify extraneous events and eventually considers them.
Another problem occurs when events are not extraneous: the probability of a fluent may oscillate as it looks at older information which is a serious problem for such interruptible algorithm.
This cannot happen with the solution proposed here because our information obsolescence criterion would consider all the information that may significantly affect the belief.
Backward smoothing is another alternative technique for dealing with the irrelevance of past information [6].
According to this approach, time is divided into a present window of arbitrary size, a past and a future.
Statistical time series analysis techniques are used to perform backward smoothing and forward forecasting for the past and the future respectively.
This approach does not take into account the dynamic  Acknowledgements The first author acknowledges the support of the University of Saskatchewan.
Research of the second author is supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).
The authors would like to thank the reviewers for their useful comments and suggestions.
References [l] P. Dagum, A. Galper, and E. Horvitz.
Dynamic  network models for forecasting.
In Proceedzngs of the 1992 Conference on Uncertaznty zn Artzficzal Intellzgence, pages 41-48, 1992.
[a] T. Dean and K. Kanazawa.
A model for reasoning about persistence and causation.
Computatzonal Intellzgence, 5(3) :142-150 , August 1989.
[3]1 S. Hanks and D. McDermott.
Modeling a dynamic and uncertain world i: Symbolic and probabilistic reasoning about change.
Artzficzal Intellzgence, 66(1):1-55, March 1994.
[4:1 J .
Kemeny and J. Snell.
Fznzte Markov Chazns.
Springer-Verlag, New York, 1976.
[5:1 U. Kjaerulff.
A computational scheme for reasoning in dynamic probabilistic networks.
In Proceedzngs of the Ezghth Conference on Uncertaznty an Artzficzal Intellzgence, pages 121-129, San Mateo, CA, 1992.
Morgan Kauffmann Publishers.
[6:l U. Kjaerulff.
A computational system for dynamic time-sliced bayesian networks.
To appear in the International Journal of Forecasting, 1995.
20 1  [7] F. Lin and R. Reiter.
How t o progress a database (and why) i: Formal foundations.
In Proc.
Fourth Int.
Conf.
on Prznczples of Iinowledge Representatzon and Reasoning., 1994.
[8] J. McCarthy.
Applications of circumscription to formalizing commonsense knowledge.
ArtiJiciaE Intetlagence, 28:89-116, 1986.
[9] L. Ngo, P. Haddawy, and J. Helwig.
A theoretical framework for context-sensitive temporal probability model with application to plan projection.
In Proceedzngs of the l l t hInternatzonal Conference on Uncertaanty an Artzficzal Intellagence, 1995.
[lo] A. Tawfik and E. Neufeld.
Temporal bayesian networks.
In Proceedrngs of Tame-94: Internatzonal Workshop on Temporal Iinowledge Representation and Reasonzng, pages 85-92, Pensacola, Florida, 1994.
202