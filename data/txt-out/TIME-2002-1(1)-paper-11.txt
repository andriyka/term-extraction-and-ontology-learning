A Finite-State Approach to Event Semantics Tim Fernando Computer Science Department Trinity College, Dublin 2, Ireland Tim.Fernando@cs.tcd.ie  Abstract Events employed in natural language semantics are characterized in terms of regular languages, each string in which can be regarded as a motion picture.
The relevant finite automata then amount to movie cameras/projectors, or more formally, to finite Kripke structures with partial valuations.
The usual regular constructs (concatenation, choice, etc) are supplemented with superposition of strings/automata/languages, realized model-theoretically as conjunction.
(i) a (finite, 2-pointed) frame N, A, 0, 1 to be a finite set N of nodes, a set A a N A N of arcs, and distinguished nodes 0 and 1 (which often but not always are the numbers 0 and 1 ordinarily denote), and (ii) a (IS-)event-automaton E to be a frame NE , AE , 0E , 1E and labeling function lE : NE a Pow(IS) that maps a node n a NE to a set lE (n) a IS of formulas.
To illustrate, the very rudimentary picture (2) of die(Romeo) is provided by the event-automaton {0, 1}, {(0, 1)}, 0, 1, l where dom(l) = {0, 1}, l(0) = {alive(Romeo)} and l(1) = {dead(Romeo)}.
alive(Romeo) aa dead(Romeo)  1.
Introduction  (2)  Due in no small measure to [2], events of some form or another have become a common tool for semantically analyzing expressions of change in English (e.g.
[15, 6, 9]).
Under this approach, a sentence such as (1) is taken to describe an event of Mary swimming a mile, culminating in the past.
Alternative analyses of die(Romeo) are, of course, possible, the idea being to  (1) Mary swam a mile.
The language L(E) of E is  Such events are formulated below as runs of machines that collectively constitute a causal order around which to explain temporality in natural language ([11, 18]).
Similar ideas have been developed in [19, 13, 12, 17, 5], the distinctive feature of the present proposal being the use of a finite automaton for a declarative representation (as opposed to a procedural implementation) of a fragment of a first-order model.
That fragment is given by strings accepted by the automaton a that is to say, by motion pictures taken by a movie camera (or, passing from accepting to generating devices, by films played by a movie projector).
2.
Event-types as automata/languages Formally, it is convenient to present the relevant automata as Kripke models over some finite set IS of formulas (roughly the propositional fluents in [10]), defining  (i) generalize (0, 1) to a path 0 AV AV AV 1 from 0 to 1, and (ii) label a node n on that path by a set of formulas (true at n).
L(E) = {lE (0E ) AV AV AV lE (1E ) | 0E AV AV AV 1E a Path(E)} where Path(E) consists of strings n1 AV AV AV nk a NE + such that n1 = 0E , nk = 1E and (ni , ni+1 ) a AE for 1 a$?
i < k. Clearly, L(E) is just the language accepted by the finite automaton with initial node START a NE , accepting node 1E , and labeled transitions lE (m)  n aa m for (n, m) a AE lE (0E )  plus START aa 0E .
(That is, the finite automaton for E is obtained by moving node labels over to arcs that point to the node, throwing in an extra node START to point to 0E .)
Conversely, an obvious limitation on an event-automaton E is that it accepts only non-empty strings, any two of which begin with the same symbol and end with the same symbol.
This limitation can be overcome by permitting the empty  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  string  to label 0E and/or 1E , so as to implement nondeterministic choice + as follows.
E E + E  =  []      E    []  As it turns out, it suffices to allow lE (0E ) = lE (1E ) =  in order to capture all regular languages.
Proposition 1.
For every regular language L a Pow(IS)a , there is a finite set E[L] of IS-event-automata, the sum of which accepts the non-empty strings in L  L a {} = L(E) .
EaE[L]  Proof.
Working with regular expressions L, we define E[L] by induction.
Let E[L + L ] be E[L] aS E[L ], and E[LL ] be {EE  | E a E[L], E  a E[L ]} unioned with E[L] if  a L and/or E[L ] if  a L (defining EE  in the obvious way).
As for La , form N = {(n, E) | E a E[L], n a NE } A = {((n, E), (m, E)) | E a E[L], (n, m) a AE } aS {((1E , E), (0E  , E  )) | E, E  a E[L]} l(n, E) = lE (n) and set E[La ] = {N, A, (0E , E), (1E , E), l | E a E[L]}.
  2.1.
Moens-Steedman and the Vendler classes Applying [11], let 0 and 1 be preparatory and consequent states respectively, and let a durative event(-type) E come with an inceptive event E i and a culminative event E c , the consequent state of E i being the preparatory state of E c , termed the progressive state pE of E pE  = 1E i = 0 E c .
Extracting a loop pE a pE from the equality 1E i = 0E c and taking 0E = 0E i and 1E = 1E c , we get the transitions AE  = 0 E a p E a p E a 1E .
From this, Vendleras well-known aspectual classifications drop out once pE is related to 1E and 0E .
For activities E like aswim,a pE = 1E inasmuch as every subtransition of a swim counts as a swim.
By contrast, for accomplishments E such as aswim a mile,a no proper subtransition from 0E can end at 1E .
(This is the adirecteda analog of quantization [9]).
The contrasting factive entailments of activities Mary was swimming  |= Mary swam  and accomplishments Mary was swimming a mile  |= Mary swam a mile  can then be linked to the test: is pE = 1E ?
Identifying statives E with the equations 0E = pE = 1E , the oddness (or markedness) of the progressive form of stative verbs might be blamed on the equality of progressive and simple forms (making the progressive operator, as it were, semantically redundant) or, focusing on 0E , the lack of progress from 0E (insofar as 0E = 1E ).
Pushing this line further, let pE = 0E for achievements E such as awina and abegin,a reducing the difference between achievements and accomplishments mentioned, for example, in [6], pp 560-561, to whether or not pE = 0E (pE = 1E holding in neither case).
Path(E) 01+ 0p+ 1 1+ 0+ 1  Vendler-class(E) activity accomplishment stative [0 = 1] achievement  pE = 1E + a + a  pE = 0 E a a + +  Table 1.
A first stab.
Is Table 1 faithful to a reading of 0E and 1E as the preparatory and consequent states of E?
Do we want to confuse the progressive state of aswimminga with the consequent state for ahave swuma?
The answer to both questions must surely be: no.
Which is not to say that Table 1 is all wrong.
But rather that it ought to be re-interpreted with the identifications a0=preparatorya and a1=consequenta relaxed.
Table 1 gives only a partial picture a namely, that concerning some formula D expressing culmination of (an event-occurrence of type) E. Indeed, the entries 01+ and 0+ 1 in Table 1 are reminiscent of the constructs Con-BEC(D) and Min-BEC(D) in [13], where the Vendler classes are characterized by binary features [Aa for] and [Aa Prog] that Table 1 interprets according to (3).
(3) E is [+ for] iff pE = 1E .
E is [+ Prog] iff pE = 0E .
(3) leaves out the labeling lE that turns a frame into a Kripke model, suggesting that aspectual properties we ascribe to E might be reducible to the frame of E.  2.2.
Framing and/or simulating aspect?
Testing the hypothesis that aspect can be confined to frames calls for a fuller account of aspect than that offered by Table 1.
[19] provides an elegant analysis of aspect, with arcs in a frame beefed up to arrows ([20]).
Most (if not all) the ideas in [19] can, I suspect, be reformulated in terms of event-automata, with a single arrow blown up to a (sub)frame (of a monster frame).
To my knowledge, such  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  a reformulation has yet to be carried out, or shown conclusively to be impossible (or a step backwards).
Whether or not [19] provides, on balance, evidence for the reducibility of aspect to frames (be they irreducibly populated by arrows or not), I think it is fair to describe the focus of [19] as being a frame (drawn there as figure 12, page 98) wherein to locate certain formulas (written there D, Cl(D), P f (D), etc).
The attention paid to the frame is well-deserved inasmuch as it fleshes out a temporal ontology for aspect, with arrows for the progressive, the perfect, etc.
Further afield, aan active computational representation for verb semantics called x-schemasa is presented in [1] that analyzes aspect ain terms of the context-sensitive interaction between verb-specific x-schemas and a controller x-schema that captures important regularities in the evolution of events.a The controller x-schema goes beyond the temporal ontology of [19] in recognizing points at which events are suspended, resumed, etc.
Indeed, x-schemas go beyond much of formal natural language semantics in offering a cognitive processing picture with asimulative inference,a as opposed to a model-theoretic account oriented around (not so much a mind that processes language as) an external reality that language describes.
That said, there is a growing appreciation within model-theoretic semantics of the importance of cognitive considerations (e.g.
[18, 5]).
A model-theoretic account that says nothing about cognitive mechanisms can hardly be a complete theory of language.
But this does not render the admittedly incomplete pictures offered by traditional model-theoretic analyses irrelevant.
If programming languages have denotational semantics distinct from their operational semantics, why not natural languages?
It is precisely to understand what computational accounts such as [12] come to a and the proliferation of concurrency models suggests there are bound to be many such accounts a that one abstracts away as much of their computational details as one can usefully get away with.
(Exactly what is useful is, alas, a matter of taste.)
Getting back to the specifics at hand, we have from page 9 of [18] the following claim: aspectual categories like activity and accomplishment are ways of viewing a happenning, rather than intrinsic properties of verbs and associated propositions, or of objective reality and the external world.
Keeping in mind the motion picture-camera/projector metaphor previously mentioned, it is natural to associate (i) aways of viewinga with an event-automaton E (or, more narrowly, the frame of E) and, on the other hand, (ii) the aassociated propositions,a aobjective reality and the external worlda with what E is about.
But what is E about?
Notice that Table 1 falls short of a model-theoretic analysis of say, [Aa for] and [Aa Prog] under (3).
In particular, it is natural to ask: how can we make precise what information the nodes 1, 0 and p encode in Table 1?
A brief answer is: apply the labeling lE of E to 1, 0 and p. Passing from Path(E) to L(E), our emphasis shifts from the mechanism E to the description L(E) of athe external worlda that E contributes (as ASS3 below spells out).
2.3.
Superposition: from N and Pow(IS) to Cn Apart from the usual regular constructs composing finite automata with each other, the particular alphabet Pow(IS) suggests aligning two strings Ia1 AV AV AV Iak and Ia1 AV AV AV Iak of equal length against each other to form a string (Ia1 aS Ia1 ) AV AV AV (Iak aS Iak ) of length k, where the ith-symbol Iai aS Iai is Iai and Iai superimposed on each other.
For instance, taking Ia Ia1 Ia2 Ia3  = = =  {swim(Mary)} {in(Mary,Ireland)} {in(Mary,IrishSea)}  =  {in(Mary,Wales)} ,  the string IaIaIa portraying Mary swimming can be componentwise superimposed on Ia1 Ia2 Ia3 to give the string (Ia aS Ia1 ) (Ia aS Ia2 ) (Ia aS Ia3 ) depicting Mary swimming from Ireland to Wales.
Now, stepping from strings up to languages L and L , let L &aS L  = {(Ia1 aS Ia1 ) AV AV AV (Iak aS Iak ) | k aL 1, Ia1 AV AV AV Iak a L, Ia1 AV AV AV Iak a L } ,  while over event automata E and E  , define an eventautomaton E AaS E  by NEAaS E  = NE A NE  , 0EAaS E  = (0E , 0E  ), 1EAaS E  = (1E , 1E  ), and AEAaS E   = {((n, n ), (m, m )) | (n, m) a AE and (n , m ) a AE  }  lEAaS E  (n, n ) = lE (n) aS lE  (n ) .
E AaS E  is the (unconstrained) concurrent composition of E and E  , with language L(E AaS E  ) =  L(E) &aS L(E  ) .
But should we be allowed to superimpose any two pictures Ia and Ia on each other?
If pictures are assumed to be complete descriptions (as the sets labeling a Kripke model  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  ordinarily are), then they can be superimposed only on themselves, suggesting that we restrict the nodes of EAaS E  to the pullback     {(n, n ) a NE A NE  | lE (n) = lE  (n )}.
This restriction, call it P (E, E  ), yields the usual construction intersecting languages L(E) and L(E  ) L(P (E, E  )) =  L(E) aS L(E  ) .
On the other hand, if pictures are understood as incomplete (as we shall), then some middle ground between E AaS E  and P (E, E  ) might be sought, allowing the superposition of some but not all pairs of pictures.
(Take aMaryswimminga and atwo-ticks-of-an-hour clocka versus aMarysleepinga and aMary-wide-awake.a) Accordingly, let us weaken the requirement on acceptable node pairs n, n from lE (n) = lE  (n ) to lE (n)aSlE  (n ) being, in a precise sense, legitimate.
To pick out what pictures an event-automaton can frame, let us henceforth assume IS comes equipped with a nonempty family Cn a Pow(IS) that is a-closed (ie for all Ia a Cn, Pow(Ia) a Cn), with the intended reading Ia a Cn  Returning to ASS2.1, with an event-automaton E replaced by a language L, let us define analogs of 0E , pE and 1E as pictures Ia(L), I'(L) and D(L) a Pow(IS) of the inceptive, progressive and culminative stages of L given by  Ia(L) = {D1 | D a L}  I'(L) = {Di | i > 1 and D a L with length > i}  D(L) = {Di | i aL 1 and D a L with length i} where Di is the ith-symbol of the infinite string Daa obtained by concatenating D to the left of the infinite string aa of aas.
Next, instead of forming 0E a pE a pE a 1E , define the aMoens-Steedmana language MS(L) =  = (L &aS L ) aS Cn+ = {(Ia1 aS Ia1 ) AV AV AV (Iak aS Iak ) | k aL 1, Ia1 AV AV AV Iak a L, Ia1 AV AV AV Iak a L  and Iai aS Iai a Cn for 1 a$?
i a$?
k}      of &aS .
As for E AaS E , let E ACn E be the restriction of E AaS E  to the set of nodes {(n, n ) a NE A NE  | lE (n) aS lE  (n ) a Cn} provided this set includes both (0E , 0E  ) and (1E , 1E  ); otherwise, let E ACn E  be the event-automaton {0, 1}, a, 0, 1, l where l(0) = l(1) = a with empty language.
Proposition 2.
For all event-automata E and E  , L(E ACn E  ) = L(E) &Cn L(E  ) .
Henceforth, we focus on regular languages over Cn, as opposed to event-automata (linked to these languages according to Propositions 1 and 2).
This has a technical advantage illustrated by the ease in formulating Proposition 3.
For all languages L, L and L a Pow(IS)a ,  Ia(L) I'(L)+ D(L)  (which differs from Table 1 in yielding strings only with length aL 3) and in place of (3), let  iff Ia is consistent/conceivable/a cartoon  for every Ia a IS.
Cn induces the refinement L &Cn L  2.4.
Table 1 and (3) revisited with superposition  for(L) =  a D(L)+ a  prog(L) =  a Ia(L) a  +  where AV is a negation operation on subsets I, of IS such that I, aS I, a Cn and for all Il a Cn, Il aS I, a Cn  or  Il aS I, a Cn .
Finally, we turn Table 1 into the definitions Activ(L) = MS(L) &Cn for(L) &Cn prog(L) Accmp(L) = MS(L) &Cn fora (L) &Cn prog(L) Stat(L) = MS(L) &Cn for(L) &Cn proga (L) Achie(L) = MS(L) &Cn fora (L) &Cn proga (L) where +  fora (L) = a D(L) a proga (L) = a Ia(L)+ a .
Having used the function MS to motivate the definitions of for(L), prog(L), fora (L) and proga (L), notice that MS contributes nothing to differentiating v(L) for v a {Activ, Accmp, Stat, Achie}.
And instead of defining fora (L) and prog(L) in terms of negation AV on subsets of IS, we might specify how a function on languages classifies languages.
Given an arbitrary function f on languages, let us say  (a) L &Cn L = L &Cn L  (i) L is [af ] if L&Cn f (L) = a  (b) (L &Cn L ) &Cn L = L &Cn (L &Cn L )  (ii) L is f -acceptable if L&Cn f (L) = a, and  (c) L &Cn a+ = L iff L a Cn+ .
(iii) L is [+f ] if L is f -acceptable and L = L&Cn f (L).
Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  Notice that if L is Activ-acceptable, then L is for- and progacceptable, and Activ(L) is [+ for] and [+ prog].
Similar remarks can be made about the other v(L)as.
Under the definitions above, [+ for] amounts to a sortal/aspectual restriction that afora imposes on the verb phrase with which it combines.
(Furthermore, that restriction is treated along the lines of the approach to presupposition in [7], with L satisfying the presuppositions of afora precisely if L is [+ for].)
Passing again to arbitrary functions f on languages, let us call f Cn-conjunctive if f (L) =  f (f (L))  f (L) = f (L) =  f (L) &Cn f (L) f (L &Cn f (L))  example a aread for an hour,a analyzed as (a {read}+ ) &Cn for(a {read}+ ) &Cn ({time(x)} a+ {time(y), hour(x, y)}) = {time(x)} {read}+ {read, time(y), hour(x, y)} with parameters x and y, and restrictions time(x), time(y), hour(x, y) that we will return to in the next section.
3.
Event-tokens and models  for all languages L that are f -acceptable.
Our attention in this section shifts from event-types to event-tokens, embedded in a model of reality that the formulas in IS describe.
An important part of that model is a temporal frame (Ot, SD ) consisting of a asuccessora relation SD a Ot A Ot on a set Ot of aobservation times.a  Proposition 4.
Examples.
(a) If f is Cn-conjunctive, then for every f -acceptable language L, both f (L) and L&Cn f (L) are [+f ].
(b) Each of Activ, Accmp, Stat, Achie is Cn-conjunctive, as are the functions sending L to a D(L)+ D(L) and Ia(L) Ia(L)+ a (which are slight variants of for(L) and proga (L), respectively).
Pausing for an example, consider the following pair from [1].
(4)  a.
She read the book for an hour.
b.
She read the book in an hour.
On the surface, (4) poses a challenge to the prohibition against afora and aina being able to fill the same holes (ie [+ for]=[a in]).
But, as pointed out in [1], (4b) entails that ashe finished reading the booka whereas (4a) does not.
That is, aread the booka amounts in (4a) to aread parts of the booka and in (4b) to aread the entire book.a It is well-known (e.g.
[9, 13]) that the argument of a verb can shape the aspectual property of the verb phrase, so that, in particular, aread parts of the booka is naturally conceptualized as an activity, whereas aread the booka (or especially, aread the entire booka) is an accomplishment (that culminates with all unread parts of the book consumed).
Thus, afor an houra combines easily with aread parts of the book,a while ain an houra modifies aread the entire book.a But what does &Cn have to do with any of this?
Following the widespread use of conjunction in event semantics, we can apply &Cn to combine not only afor an houra with aread parts of the booka but also the argument aparts of the booka (or athe entire booka) with aread.a That is, &Cn is offered here as a tool for the logical investigation that lexical semantics richly deserves (e.g.
[3, 15]).
Focusing on time, let us work out a simple  (i) Ot is the set of integers, and SD is the usual successor (+1) function.
(ii) Ot a Pow(Pt) a {a} for some set Pt of points linearly ordered by <D , and SD is the set of all pairs (t, t ) a Ot A Ot such that (ax a t)(ay a t ) x <D y and not (at a Ot) t a gap(t, t ) where gap(t, t ) is {z a Pt a (t aS t ) | (ax a t)(ay a t ) x <D z <D y}.
(The second conjunct excludes gaps containing observation times, guarding against insertion anomalies.)
More concretely, if Pt is the set  of real numbers, I' is some positive number (fixing a level of granularity/degree of error-tolerance) and Ot is the set of non-empty open intervals o(p, q) =  {r a  | p < r < q}  with rational end-points p, q such that q a p > I', then for all o(p, q), o(p , q  ) a Ot, o(p, q) SD o(p , q  ) iff 0 a$?
p a q a$?
I' .
Note that Ot is countable and SD is not functional.
It will suffice throughout this section to equate an eventtype with a language L a Cn+ , the strings from which we anchor in a temporal frame as follows.
An event(-token) of event-type L is a function e from some finite subset {t1 , t2 , .
.
.
, tk } of Ot to Cn such that t1 SD t2 SD AV AV AV SD tk  and  e(t1 )e(t2 ) AV AV AV e(tk ) a L .
To state that e is an event of event-type L, we write  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  e:L.  For typical choices of SD , at most one SD -chain can be arranged from a finite subset dom(e) of Ot, whence e picks out at a unique string in L. Also, the definition of ae : La can be relativized to a binary relation SD that depends on L, but for simplicity, we will leave SD fixed in the background.
Assuming an observation time can occur at most once in an SD -chain (ie t1 SD t2 SD AV AV AV tk and i = j imply ti = tj ), the totality of events of event-type L is essentially L&Cn L(SD ) where L(SD ) is the set of finite SD -chains.
In general, however, L(SD ) is not a regular language, and the special role it plays in time-stamping L makes it natural to present an event as a function whose domain is a finite subset of Ot.
To form a model from events, we must spell out what contribution an event e makes.
A simple answer is that e contributes the set a(e) =  {@(D, t) | t a dom(e) and D a e(t)}  of formulas, where a@(D, t)a is some formula saying: D holds at t. Recalling the formulas time(x), time(y) and hour(x, y) from the end of section 2, we might equate @(time(x), t) with ax = ta, @(time(y), t) with ay = ta and @(hour(x, y), t) with ahour(x, y)a (the dependence on t of hour(x, y) being spurious).
By contrast, for read (and many other IS-formulas), it is useful to construe @(read,t) as literally the string a@(read, t)a.
In view of these differences, let us partition IS into three sets IS = IS= aS ISg aS ISl where IS= consists of IS-formulas such as time(x) that translate to equations, ISg consists of aglobala IS-formulas such as hour(x, y) that are independent of t, and ISl consists of alocala IS-formulas such as read.
From IS= -formulas in e, we form the substitution I,e  =  3.1.
Lumping events into forcing-conditions Next, generalizing from event(-token)s to the set Ot ( Cn of partial functions (p, q, .
.
.)
from Ot to Cn, let  be the partial order on Ot ( Cn comparing information content as follows pq  iff dom(p) a dom(q) and (at a dom(p)) p(t) a q(t) .
(The intuition is that p  q says q is at least as informative as p.) Given a collection ET of event-types and a partial function p : Ot ( Cn, let ET(p) be the set of ET-events -contained in p ET(p) =  {e | e  p and (aL a ET) e : L} ,  this being the bit of reality ET carves up from p. Fix an expansion Time = (Ot, SD , .
.
.)
of (Ot, SD ) to the vocabulary (aka signature, language, set of non-logical symbols) of ISg so that every D a ISg can be judged to be true or false in Time.
Also, to extract a model from a partial function p : Ot ( Cn, we have to be careful about overlapping observation times, which we henceforth assume is given by a family OD a Pow(Ot) a {a}.
(For example, if Ot a Pow(Pt) a {a}, then  OD consists of all non-empty families T a Ot such that T = a.)
Let (i) P (ET, Time, OD ) be the set of partial functions p : Ot ( Cn such that for all e a ET(p) and D a ag (e), Time |= D , and for all T a OD where T a dom(p),  p(t) a Cn  {(x, t) | t a dom(e) and time(x) a e(t)}  which we then apply to the rest of the IS-formulas in e to get ag (e)  = {D[I,e ] | (at a dom(e)) D a e(t) aS ISg }  al (e)  = {@(D[I,e ], t) | t a dom(e) and D a e(t) aS ISl }  with the understanding that D[I,e ] is falsum aL if I,e is not functional, else D[I,e ] is D with every variable x a dom(I,e ) replaced by I,e (x).1  taT  (ii) v(IS) be the vocabulary consisting of unary relation symbols @(D, AV) for every D a ISl (with a@(D, t)a to be read: aD holds at ta), and (iii) fET be the function that maps a partial function p : Ot ( Cn to  al (e) .
fET (p) = eaET(p)  1A  substitution pairs variables (or parameters) with terms a the terms in this case being observation times.
I,e provides a means of binding variables x a dom(I,e ) locally to e, allowing multiple instantiations of x to co-exist (in a model).
That is, instead of proliferating alphabetic variants of an event-type, the event-type is construed as parametric, with x as a temporal parameter that an event e instantiates as I,e (x).
The thematic arguments of an event-type (e.g.
agent, patient) can also be presented as parameters, provided an event specifies instantiations of these parameters.
For the sake of simplicity, parameters and substitutions are confined here to observation times.
Let us define a IS(Time)-model to be an expansion of Time to the vocabulary v(IS, Ot) (= v(IS) aS Ot) where the constants t (in Ot) are interpreted as t. (To simplify notation, we do not distinguish between t qua constant, and t qua semantic interpretation.)
Now, given an element pE of P (ET, Time, OD ), how might we build a IS(Time)-model that contains ET(pE)?
Allowing for IS(Time)-models that  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  may or may not contain events beyond those in ET(pE), let us pass from pE to a set P a P (ET, Time, OD ) with least element pE.
(To restrict events to those in ET(pE), take P = {pE}.)
Applying the aforcinga machinery in, for example, [8],2 let us define a forcing predicate ||aP (which we simplify to ||a) that relates forcing-conditions p a P to v(IS, Ot)-formulas (closed under AZ, a" and a) as follows:  (a) A generic set G induces a IS(Time)-model Time(G) such that for every v(IS, Ot)-formula D, Time(G) |= D  (b) Assuming ISl and Ot are countable, p ||aw D  iff for every generic G s.t.
p a G, Time(G) |= D .
(i) basing ||a on fET , p ||a @(D, t)  iff @(D, t) a fET (p)  for all D a ISl and t a Ot (ii) confining our search for AZD-counterexamples to qas in P such that p  q, p ||a AZD iff not (aq a P ) (p  q and q ||a D) (iii) externalizing a" to non-deterministic choice +, p ||a D a" D  iff p ||a D or p ||a D  Forcing-conditions p span the divide between events e a ET(p) and IS(Time)-models Time(G), for generic G p. Given P a P (ET, Time, OD ), let MOD(P ) be the set of IS(Time)-models generated by P -generic sets MOD(P ) = {Time(G) | G is P -generic} , and (going down , rather than [as is the case for generic sets] up), let PET be P with all its ET-events  ET(p) .
PET = P aS paP  The following proposition is easily proved.
(iv) restricting a to Ot, p ||a axD iff p ||a D[x/t] for some t a Ot .
3.2.
Between events and worlds Applied twice, AZ yields a notion of weak forcing ||aw p ||aw D  iff (ap a G) p ||a D .
iff p ||a AZAZD  that extends ||a in a manner that can be characterized by IS(Time)-models generated by certain subsets of P .
More specifically, a subset G of P is (P -)generic if for all p, q a P, (i) whenever p a G and q  p, q a G (ii) whenever p, q a G, there exists r a G such that p  r and q  r (iii) for every v(IS, Ot)-formula D, there exists r a G such that r ||a D or r ||a AZD.
Let us record fundamental results explained in [8] as Fact 5.
2 In the terminology of [8], we get a forcing property P, a$?, f fi (over the base vocabulary v(IS) and set Ot of constants) where a$?
is the restriction of  to P , and f is a function with domain P mapping p a P to f (p) = fET (p) aS {at = ta | t a Ot}.
As our only constants are those from Ot (no two of which are to be semantically identified), equality is trivial and is accordingly left out above.
fi It is perhaps also worth noting that [8] allows infinitary disjunctions , which should come in handy for infinitary +.
As it is, we can (in line with a finite-state perspective) limit the forcing-conditions in the present section to finite functions, provided we do not require that a generic set be represented by a single forcing-condition.
Proposition 6.
If P a P (ET, Time, OD ), then PET a MOD(PET ) =  P (ET, Time, OD ) MOD(P )  and ||aP is the restriction of ||aPET to P .
Why  bother forming PET ?
Because in PET , events e a paP ET(p) count as forcing-conditions, allowing us to ask of a v(IS, Ot)-formula D whether or not e forces D. But beyond D of the form @(D, t), what else is there to ae ||a Da?
Simplifying notation, let us henceforth assume P = PET .
Observe that for every ET-event e a P , D a ISl and t a Ot, e ||a @(D, t) iff t a dom(e) and D a e(t) and if IS is closed under negations az D (with {D, az D} a Cn), e ||a @(az D, t)  implies  e ||a AZ@(D, t) ,  the converse of which does not, in general, hold.
Readers familiar with [14] might liken the discrepancy here to that between constructible falsity (az) and intuitionistic negation (AZ).
More specifically, AZ brings the full space P of forcingconditions into the picture, denying the existence of a extension p of e in P such that p ||a @(D, t), whereas az requires local, positive evidence e. Indeed, the double negation translation AZAZ underlying ||aw weakens the requirement of local, positive evidence to e ||a AZAZD  iff (ap a P s.t.
e  p) (aq a P s.t.
p  q) q ||a D ,  Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE  allowing for the possibility that e ||aw @(D, t) but not e ||a @(D, t).
That is, e may not be enough to settle ae ||a AZAZ@(D, t)a, although arguably, if e ||a AZAZD, then, as e  e a P , there is positive evidence q " e in P for D (except that it alone may not suffice).
At stake between az and AZ is the distinction between explicit and implicit information.
ae ||a @(az D, t)a says that explicit in e is information for az D at t, whereas ae ||a AZ@(D, t)a claims only that information against D at t can be inferred from e, possibly with the aid of P .
The question arises: how do we pick P and/or MOD(P )?
I hope to report on this matter elsewhere.
4.
Conclusion The finite-state approach to event semantics above is presented in two parts: one centered around event-types, formulated as finite automata, or more abstractly, regular languages; and the other around event-tokens, grounding strings from an event-type in a model.
The strings are built from a set IS of formulas, which correspond to the propositional fluents of [10].
It is natural to ask: where in the present approach are the situations?
Given a generic set G and a time t a Ot, one might expect to reconstruct a situation, understood as athe complete state of the universe at an instant of timea [10], from the snapshot {D | (ap a G) p ||a @(D, t)}.
Evidently, the presentation above is not oriented around situations.
Much more prominent is partiality, embodied in the first part by ACn /&Cn (playing the role of conjunction in a Davidsonian approach to event modification), and in the second part by  (linking events to worlds, to give the pictures in IS model-theoretic bite).
Speaking of partiality, it bears stressing that the present approach puts finite automata in the service of declarative, as opposed to operational, semantics, shying away from details of how language is processed.
Despite this limitation, I do think that (i) a useful temporal ontology reflecting aways of viewinga ([18]) can be fashioned from finite automata (perhaps with help from [19, 13]), and that (ii) the restriction to regular languages ought to have positive consequences for both the representational and inferential aspects of the frame problem ([10]) for natural language ([18]).
Obviously, there is much work to be done.
As to what has been carried out, I close with the note that it was conceived as part of a model-theoretic re-interpretation of propositions-as-types (applied to natural language in [16]), pushing typed It-calculi analyses of logical connectives down to the sub-atomic (lexical) level through finite-state  methods.
(The interested reader is referred to the constructive eventuality assumption in [4], ASS3.1.)
References [1] N. Chang, D. Gildea, and S. Narayanan.
A dynamic model of aspectual composition.
In Proc.
CogSci 98, 1998.
[2] D. Davidson.
The logical form of action sentences.
In N. Rescher, editor, The Logic of Decision and Action.
University of Pittsburgh Press, 1967.
[3] D. R. Dowty.
Word Meaning and Montague Grammar.
Reidel, Dordrecht, 1979.
[4] T. Fernando.
Conservative generalized quantifiers and presupposition.
In Proc.
Semantics and Linguistic Theory XI.
Cornell University, 2001.
[5] F. Hamm and M. van Lambalgen.
Event calculus, nominalization, and the progressive.
Available from www.semanticsarchive.net, 2000.
[6] H. Kamp and U. Reyle.
From Discourse to Logic.
Kluwer Academic Publishers, Dordrecht, 1993.
[7] L. Karttunen.
Presupposition and linguistic context.
Theoretical Linguistics, pages 181a194, 1974.
[8] H. J. Keisler.
Forcing and the omitting types theorem.
In M. Morley, editor, Studies in Model Theory.
The Mathematical Association of America, 1973.
[9] M. Krifka.
Nominal reference, temporal constitution and quantification in event semantics.
In R. Bartsch, J. van Benthem, and P. van Emde Boas, editors, Semantics and Contextual Expressions.
Foris, Dordrecht, 1989.
[10] J. McCarthy and P. Hayes.
Some philosophical problems from the standpoint of artificial intelligence.
In M. Meltzer and D. Michie, editors, Machine Intelligence 4.
Edinburgh University Press, 1969.
[11] M. Moens and M. Steedman.
Temporal ontology and temporal reference.
Computational Linguistics, 14:15a28, 1988.
[12] S. Narayanan.
Reasoning about actions in narrative undertanding.
In Proceedings of IJCAI a99.
Morgan Kaufmann, San Francisco, 1999.
[13] R. Naumann.
Aspects of changes: a dynamic event semantics.
J.
Semantics, 18:27a81, 2001.
[14] D. Nelson.
Constructible falsity.
J.
Symbolic Logic, 14(1):16a26, 1949.
[15] T. Parsons.
Events in the Semantics of English: A Study in Subatomic Semantics.
MIT Press, Cambridge, MA, 1990.
[16] A. Ranta.
Type-Theoretical Grammar.
Oxford University Press, Oxford, 1994.
[17] R. Reiter.
Narratives as programs.
In Principles of Knowlege Representation: Procedings of KR 2000.
Morgan Kaufmann, San Francisco, 2000.
[18] M. Steedman.
The Productions of Time.
Draft, ftp:// ftp.cogsci.ed.ac.uk/pub/steedman/temporality/temporality.ps.gz, July 2000.
[19] S. Tojo.
Event, state and process in arrow logic.
Minds and Machines, 9:81a103, 1999.
[20] J. van Benthem.
A note on dunamic arrow logic.
In J. van Eijck and A. Visser, editors, Logic and Information Flow.
MIT Press, Cambridge, MA, 1994.
Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIMEa02) 1530-1311/02 $17.00 AS 2002 IEEE