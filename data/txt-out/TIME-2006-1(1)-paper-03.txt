In time alone: on the computational power of querying the history Alexei Lisitsa and Igor Potapov Department of Computer Science, The University of Liverpool, {alexei,igor}@csc.liv.ac.uk Abstract  sequences of the elements of S. In a sense, in that case the computation refers to its own past to generate the next state.
John McCarthy in his proposal of Elephant programming language [9] suggested to exploit the referring to the past as the main programming primitive, especially suitable for implementing transaction processing and electronic data interchange[9]:  Querying its own history is an important mechanism in the computations, especially those interacting with people or other computations such as transaction processing, electronic data interchange.
In this paper we study the computational power of referring to the past primitive.
To do that we propose a refined formal model, history dependent machine (HDM), which uses querying the history as its sole computational primitive.
Our main result may be spelled in general terms as: a model with a single agent wandering around a pool of resources and having ability to check its own history for simple temporal properties has a universal computational power.
Moreover, HDM can simulate any multicounter machine in real time.
Then we show that the computations of HDM may be specified in the extension of propositional linear temporal logic by flexible constants, the abstraction operator and equality.
We use then universality of HDM model to show that the above extension with a single flexible constant is not recursively axiomatizable.
Keywords: history-dependent computations, executable temporal logic, models of computations, universality  Elephant programs may not need data structures, because program statements can refer directly to past.
Thus, a program can say that an airline passenger has a reservation if he has made one and hasn't cancelled it.
Theoretically, referring to the past does not increase computational power of sufficiently rich computational models for one can implement it just by keeping the records of all relevant information about the past in the current state.
This observation leaves, however the question on computational power of such primitive itself open.
To address such a question we propose the model of history dependent computations with querying the history (or referring to the past) as its sole primitive and demonstrate its computational universality.
In a sense, it supports McCarthy's assumption that referring to the past is a powerful facility which can be used as the main programming primitive.
This support is still partial because we consider in this paper only non-interactive sequential computations of history dependent machines (HDMs), leaving the investigation of behavioural properties and expressive power of interactive history dependent machines to further research.
Informally, the computations of history dependent machines may be described as follows: being in some state the machine checks the history of computation up to the current moment, and, subject to the conditions satisfied in the history, either generates new state in which it never been before, or it returns to the one of the states it has been before and which has been singled out by some condition.
We show that very restricted set of temporal queries is enough to make the model universal.
To keep the model as general as possible we do not assume any structure on the states and rely only on the ability to distinguish between different  1 Introduction Computation is often considered as a process generating a sequence of states.
Starting with an initial state s 0 deterministic computation proceeds by application of a transition function s : S - S, where S is a set of possible states, and generates a sequence of states by taking s i+1 = s(si ).
Obviously this description is very general and abstracts away the nature of states and transition functions.
But it captures the idea that the next state in the history of computation depends solely on the current state.
For some computations however, it is more natural to consider the generation of the next state (say, sn+1 ) as depending not only on the current state sn but on the whole history up to the moment n that is s0 , s1 , .
.
.
, sn .
In that case one may assume a transition function sh : S * - S where S * is the set of all finite 1  states and on detection of the order in which they appear in the history.
Related models of computation with similar motivations have appeared in the area of executable temporal logics, and in particular, in METATEM paradigm[6].
In METATEM the temporal formulae are given an operational semantics and considered as the programs themselves, operating according to the principle "declarative past implies imperative future".
Although executable temporal logic approach and our history-dependent machines are close to each other, at least at the ideological level, we do not do detailed technical comparison in this paper.
Instead, in the Section 5 we demonstrate connections with temporal logic, further development of which would lead to clarification of relationships between both approaches.
The paper is organised as follows.
In the next section we discuss idealized scenario which, gives an intuition behind the model.
In the third section we introduce our History Dependent Machine model and discuss possible variations of the model .
The main result of the paper is presented in Section 4, where we demonstrated a universality of HDM model.
Section 5 introduces a fragment of temporal logic suitable for specification of HDM computations and, as application of the main result, we prove its nonaxiomatizability.
In Section 6 we discuss related work and we conclude the paper with the Section 7.  interest in history dependent computations we would like to consider some extreme case where we have only one agent that in some sense interacts with itself via its own history.
We found it also intuitive to think about history dependent computations as a behaviour of a one-pebble system.
Let S be a set of states.
Any evolution of a system over states from S defines a function s : N - S. If at some moment of time t, the state of a system M is r, i.e.
s(t) = r we interpret it as a pebble being put on the element r of S. Thus, the whole evolution of M may be though of as the movement of a single pebble over the abstract set S. Such metaphor gives the very abstract model of computational process (agent) using some resources.
In such a model a pebble may be thought of as a computational process and elements of the domain S as the abstract resources.
Then, if at some moment of time a pebble is on an element x of the domain, one may understand it as "process (agent) uses the resource x", or as in a model of agents above "the mobile agent resides at the host x".
The model can be easily extended to the case of several processes possibly using several resources at the same time.
Some relevant discussion can be found in [7, 8].
Our main result may be spelled in these terms as: even a model with a single agent wandering around a pool of resources and having ability to check its own path for simple temporal properties has a universal computational power, and is able to model multicounter machines in real time.
From the results of [8] one may easily extract a similar result but for the case of several agents.
2 Pebble system and history dependent mobile agents  3 History Dependent Machines  Before we give the definition of our History Dependent Machine model we consider less formal, but still idealized scenario which gives an intuition behind the model.
Let a group of mobile agents explore some hosts in a distributed way.
Assume the mobile agents themselves have limited computational resources (like small internal memory) and therefore can mostly rely on information observed from local environment.
We assume that each host independently records the mobile agents attendance.
These records form the history of computations by agents and environment.
Consider the following simple mode of agents operation.
Once an agent arrives to a host it writes down in a registration journal of the host its identity, time of arrival and the address of the host it came from.
Then it may perform some local actions and decide where to go next.
Two options are available.
Either to go to the host with one of the addresses left by an agent in the local registration journal, or to choose to go to the host with the new address.
Assuming that mobile agents can move autonomously from host to host and do not have any communication primitives, the only tool for coordination is indirect communication via their history of attendances.
According to our prime  Now we introduce a formal model of History Dependent Machine that incorporates some ideas from the previous section.
Let S be an arbitrary set, which in general may be infinite and elements of which we call states.
A history over S is a finite sequence of states s 0 , .
.
.
, sn from S with the last state being labelled by a constant now.
Formally, we represent the history h as a first-order two-sorted structure T, S, s, <=, next, 0, nowfi where T is a finite sort of moments of time; S is a sort of states; s : T - S is state function; <= is a linear order on T ; 0 and now are constants interpreted by minimal, respectively, maximal element of T wrt <=; next : T - T is the successor (partial) function giving a next element of T wrt <= and next(now) is undefined.
The set of all histories over S we denote by H(S).
The language of terms to encode some formulae satisfied at a single state of the history uses two new functional symbols f irst : T - T and last : T - T .
We also define a term of the language as follows: the constant now is a term and if t is a term then f irst(t) and 2  last(t) are terms.
Two functional symbols are interpreted in h = T, S, <=, next, 0, nowfi as follows: *  Let h be a history and P a program.
The result of applying P to h is a partial function P : H(S) - H(S) defined as follows:  - if s(t) = s(0) then f irst(t) = 0 for all t (0 <= t <= now;  * if for all applicable R 1 , .
.
.
Rk [?]
P R1 (h) = .
.
.
= Rk (h) = h then P(h) = h ;    - if s(t) = s(0) then f irst(t) = t , such that s(next(t )) = s(t) [?]
[?
]z < t s(next(z)) = s(t) for all t (0 < t <= now) *  * as a particular case of above, If there is a single applicable R [?]
P then P(h) = R(h);  - last(0) = 0  * if there are no applicable rules then the result of P(h) is not defined;  - last(t) = t , such that next(t ) = t for all t (0 <= t <= now)  * if there are two applicable rules R 1 and R2 such that R1 (h) = R2 (h) then the result P(h) is not defined.
Thus, for a moment of time y from a history, f irst(y) and last(y) are referring to the moments (in the past wrt y) when the machine made a transition to the state s(y) for the first,respectively, last time.
The interpretation of f irst and last is extended to the interpretation of all terms in a usual way.
A rule of a History Dependent Machine is any expression of one of two possible forms:  where t is a term, ph and ps are arbitrary conjunctions of the atomic formulae of one of the following forms: s(t i ) = s(tj ) or s(ti ) = s(tj ), where ti and tj are terms.
Let M = h, P fi be a history dependent machine.
The computation, or run of M is defined as a sequence of histories h0 , .
.
.
, hi , .
.
.
where h0 = h and hi+1 = P(hi ).
If for all i [?]
N P(hi ) is defined then machine generates an infinite computation h 0 , .
.
.
, hi , .
.
..
The assumption about the termination condition can be defined in the following way.
If for some i R(h i ) is undefined and for all j < i R(h j ) is defined then the machine generates a finite computation sequence h0 , .
.
.
, hi .
A sequence of states [s0 , s1 , .
.
.
, sk ], sk+1 , .
.
.
, si , .
.
.
generated by a computation is called the history of computation.
Here [s 0 , s1 , .
.
.
, sk ] is an initial history and for j >= k sj+1 is a state generated at the step j - k + 1.
Definition 1 Let R be a rule and h is a history.
The rule R = ph - move( ) is applicable to h iff h |= ph.
4 Universality of the History Dependent Machines  * ph - move(new) * ps - move(s(t))  Let R be a rule applicable to a history h = T, S, s, <= , next, 0, nowfi.
Then by R(h) we denote the result of applying R to h, which is a new (extended) history h  = T  , S  , s , <= , next , 0 , now fi defined as follows:  The main aim of this section is to demonstrate the computational universality of the HDM by simulating a wellknown model of counters automata.
The task is quite challenging since a single player accesses its own history with a very limited set of temporal queries (compositions of f irst, last and now).
The universality result is based on the idea that the movement of a single pebble over elements of the infinite domain can simulate basic type of memory such as integer value counters.
In fact we use different time slices to encode several counters in the the history of pebble moves.
Using that we then can simulate the behaviour of multi-counters automata with a single state.
We start with showing that the latter model is equivalent to Minsky machines (2-counter automata with states).
* if R is of the form ph - move(new) then T  = T [?]
{a}, where a is a fresh element, i.e.
a [?]
T , <= coincides with <= on all pairs of elements from T and [?
]t [?]
T (t <= a).
A constant now  is interpreted as a newly added element a (maximal in T  ); 0'=0; S  = S; s (now ) = b, where b is any element of S such that [?
]x [?]
T s(x) = b; next (t) = next(t) for all t < now, next (now) = now .
* if R is of the form ps - move(s(t)) then h  is defined as above except s  (now ) = s(t).
Definition 2 A program is any finite set of rules.
4.1 Multi-counter automata with a single state  Definition 3 A history dependent machine M over set of states S is a pair h, P fi, where h [?]
H(S) is an initial history and P is a program.
Let us consider the restricted, a single-state variant of the multi-counter automaton, which differs from the general model [3] as follows: 3  set of counters names C = {c 1 , .
.
.
, cL , cL+1 , cL+2 }.
The counters cL+1 , cL+2 represent the counters S 1 and S2 of M , while the remaining counters c 1 , .
.
.
, cL represent finite state control.
If the machine executes an instruction with the label (number) i then we model this by setting c i = 1 and cj = 0 for all j such that 1 <= j <= L and j = i.
We leave design of suitable translation and checking of all obvious details to the reader.
2  Definition 4 A multi-counters automaton with a single state is a pair (C, T ) where * C is finite set of counter names; * T is the set of rules built on the alphabet C, A member of T is an expression of the form if Ph then U , where Ph is either true or a conjunction of atomic formulas of the form x = 0 or x > 0 with x [?]
C and U is a set of updates of the form x := x + c, where x [?]
C and c [?]
{-1, 0, 1}.
Now we show that the model of HDM can simulate any multi-counter automaton with a single state defined above.
We start with showing how the movement of a single pebble over elements of the infinite domain can simulate basic type of memory such as integer-valued counter.
Then we extend it to the more sophisticated system of single pebble movements simulating two (and any finite number) of counters.
A configuration of the automaton is an evaluation v : C - N of counters names.
If C = {c 1 , .
.
.
cn } we represent configuration as an integer-valued vector v = (v 1 , .
.
.
, vn ) = (v(c1 ), .
.
.
, v(cn )).
The automaton may make a transition from a configuration v to a configuration v  , if there is a rule r [?]
T such that r = if Ph then U , v(C) |= Ph and v  is obtained by application of all updates from U to v. If Ph [?]
true than the corresponding transition can be made from any configuration.
If the set of updates U is inconsistent (e.g.
containing updates x := x + 1 and x := x - 1) then corresponding transition can not be made.
As an example consider the rule if c 1 = 0 [?]
c2 > 0 then c1 := c1 + 1; c2 := c2 - 1 This rule is applicable for the configurations where c 1 = 0 and c2 > 0 and when applied the value of c1 will be increased by 1, the value of c 2 will be decreased by 1 and the values of all other counters (if any) will be preserved.
This model is a particular case of multiple counters automata defined, e.g.
in [3].
The difference is that in our model we do not use a finite state control and the form of possible guards is restricted.
Still, it is not difficult to show that multi-counter automaton with a single state is an universal model of computation, e.g.
Minsky machines [11] can be embedded easily in that model.
4.2 Modeling of a single counter Let S be a set of states and H = s0 , .
.
.
, si , .
.
.
is a history of computation of some HDM over S, i.e., in other words, it is a sequence of pebble positions.
Let us associate with H directed, edge labelled, possibly infinite graph G: * the set of vertices V of G is the set of all visited states in the history of computation, i.e.
V = {s0 , .
.
.
, si , .
.
.}.
* a triple a, t, bfi [?]
V x N x V is an edge in G labelled by a natural number t iff the pebble has moved from the element a to the element b at the moment of time t. We can consider now the length of the shortest path from the initial vertex s0 to some vertex s t in G as the value of an integer-valued counter at the moment t. Assuming that, incrementing the counter by one corresponds to moving a pebble to a new (not visited before) element.
Decrementing the counter corresponds to returning the pebble to the position from where the pebble was moved to the current position for the first time.
Example 1 illustrates the idea.
Proposition 1 The model of a multi-counter automaton with a single state is a universal model of computation.
Proof: A Minsky machine may be defined as a simple imperative program M which is operating on two nonnegative counters and consisting of a sequence of instructions labelled by natural numbers from 1 to some L. Any instruction is one of the following forms:  Example 1 To illustrate the idea of counter simulation consider as an example the sequence of the updates shown in the Table 1.
The trace of the pebble movements simulating these updates is shown on the Figure 1 as a graph G. The number inside of each vertex shows the distance from the initial vertex.
Note, that we can easily test whether the counter have a zero or non-zero value by checking that s(now) = s(f irst(now)) or s(now) = s(f irst(now)).
In other words, we check that the current element coincides or does not coincide with an element from which we moved to it for the first time.
It is easy to see that only unique element satisfies the condition s(now) = s(f irst(now)) that is initial state s0 .
l: ADD 1 to Sk ; GOTO l  ; l: IF Sk = 0 THEN SUBTRACT 1 FROM Sk ; GOTO l  ELSE GOTO l  ; l: STOP.
where k [?]
{1, 2} and l, l  , l [?]
{1, .
.
.
, L}.
Any Minsky machine M can be translated into an equivalent multi-counter automaton with one state using the following simple idea.
If M has L instructions then we take 4  T ime 1 2 3 4 5 6 7 8 9 10  Update c := c + 1 c := c + 1 c := c c := c - 1 c := c + 1 c := c + 1 c := c - 1 c := c - 1 c := c - 1 c := c + 1  V alue 1 2 2 1 2 3 2 1 0 1  s(f irst(now)) - move(new).
In other words it moves to a new state to meet initial conditions for the above coding, i.e.
after applying this rule each of graphs (G 0 and G1 ) contains a single node each, that corresponds to a zero value in counters.
To increase the value of the first or the second counter as in the case of one counter one has to apply a rule of the form ph - move(new).
The decreasing of the counter is also similar to the one-counter case, but requires more complex references in time to get or update an information in an appropriate slice (i.e H 0 or H1 ).
The Table 2 shows the set of rules that allow us to control these values and update the counters by incrementing they values by one, decrementing by one or keep they unchanged.
In order to visualize this idea we suggest to con-  Rule applied true - move(new) true - move(new) true - move(s(now)) true - move(s(f irst(now))) true - move(new) true - move(new) true - move(s(f irst(now))) true - move(s(f irst(now))) true - move(s(f irst(now))) true - move(new)  Table 1.
Sequence of counter updates during 10 time steps.
2  1  0 10  1  9 8  4  2  3  5  U pdate ci := ci + 1 ci := ci - 1 ci := ci  6  1  2  7  3  Figure 1.
The directed edge-labelled graph that represents the dynamics of counter updates.
Rule applied true - move(new) true - move(s(last(f irst(last(now))))) true - move(s(last(now)))  Table 2.
Updates for counter ci at the moment of time t, i [?]
t (mod 2).
4.3 Modelling of several counters  sider the Example 2.
Applying more sophisticated encoding one can keep even more information than one integer value in the trace of the moving pebble.
We start with detailed explanation of two counters simulation that can be easy extended for a more general case.
Let H = s0 , s1 , .
.
.
, si , .
.
.
be a history over S, i.e.
be a sequence of pebble positions and its graphical interpretation is defined by a graph G. Split H into two disjoint subsequences: H0 = s0 , s2 , s4 .
.
.
, s2i , .
.
.
that corresponds to visited positions in even moments of time including initial position s0 and H1 = s1 , s3 , s5 .
.
.
, s2i+1 , .
.
.
that corresponds to visited positions in odd moments of time time.
Now we use H0 and H1 for modelling two counters in the same way as we did it for one counter simulation.
We associate independently constructed G 0 and G1 with sequences H0 and H1 that we can easy extract from the original trace of a single pebble in graph G. In this case the length of a shortest path in G 0 from initial to the last visited vertex keeps the first counter value and the length of a shortest path in G1 from initial to the last visited vertex keeps a value for the second counter.
In this case two consecutive moves of a single pebble in time 2i and 2i + 1 for i >= 1 correspond to updates of two counters.
We assume that a pebble uses the first moment of time for initialization, where it applies the rule s(now) =  Example 2 Let us visualize the idea of two-counter automata modelling.
The Table 3 shows the sequence of possible counter updates and the Figure 2 contains a single graph G that covers the updates of both counters simulated by a single pebble.
Other two graphs G 0 and G1 are given here to show independent updates of two counters.
T ime 1 2 3 4 5 6 7 8 9 10 11  Update c1 c2 c1 c2 c1 c2 c1 c2 c1 c2  := c1 + 1 := c2 := c1 + 1 := c2 + 1 := c1 - 1 := c2 := c1 + 1 := c2 - 1 := c1 - 1 = c2 + 1  Rule applied true - move(new) true - move(new) true - move(s(last(now))) true - move(new) true - move(new) true - move(s(last(f irst(last(now))))) true - move(s(last(now))) true - move(new) true - move(s(last(f irst(last(now))))) true - move(s(last(f irst(last(now))))) true - move(new)  Table 3.
Sequence of counter updates and corresponding pebble rules  If the last move of the pebble updates the second counter the condition s(last(now)) = s(f irst(last(now))) is true when the first counter has zero value and the condition 5  G0 0  1 6  5  3  G1  2  1  2  3  0 1  4  Theorem 1 The model of HDM is a universal model of computation.
2  1  4  5  Corollary 1 Let M be a given HDM with a set of rules P .
The liveness problem: "whether a rule R [?]
P will be applicable during the run of machine M " is algorithmically undecidable.
6  2  1 10  G  G0 11  2  0 1  1 6  2 7  4  5  5 Temporal logic abstraction  2  1  predicate  l-  G1  8  When querying the history we are mainly interested in temporal properties.
So, instead of choosing the language defined in Section 2 one may choose the language of temporal logic as the history query language.
Because in HDM we assume potentially infinite set of states the propositional temporal logic is not enough to get an equivalent model one needs some first-order extension.
It is fairly straightforward to devise an alternative (and even equivalent) model of HDM using a fragment of firstorder temporal logic.
So we leave it to an interested reader.
Instead, we present in this section an extension of propositional temporal logic by predicate l-abstraction suitable for this purpose.
We show that in that extension one can specify faithfully the computations of HDM.
Then as the application of the result on universality of HDMs we show that the fragment is not recursively axiomatizable.
In [5] M.Fitting has proposed the idea of extension of propositional modal logics by predicate (lambda)abstraction.
For a propositional modal logic L such an extension Ll(=) (either with or without equality) can be alternatively seen as a very restricted fragment of corresponding first-order variant QL of L. Thus, this is a general technique for obtaining the logics, which are in a sense, intermediate between propositional and first-order.
It is proved in [5] that S5 l= is undecidable, but for many other classical modal logics L their extensions L l(=) are still decidable.
In [7, 8] we have started the study of such an extension applied to the classical propositional linear time logic (with past and future modalities).
The full description of syntax and semantics of LT L l= is given in [7, 8] (see also [5] for the general case of modal logics).
Here we outline only some crucial clauses.
Given the alphabets of variables, constant symbols and predicate symbols the formulae and terms of LT L l= are defined as in the case of first-order temporal logic, except: * quantifiers are not allowed; * If ph is a formula, x is a variable, and t is a term, then lx.phfi(t) is a well-formed formula.
Formulae of LT L l= are interpreted in first-order temporal models with constant domain and with the time flow isomorphic to o.
Intuitively, first-order temporal model M is a sequence of first-order structures, or states, such  3  0  with  1 12 9  Figure 2.
Modelling of two counters by a single pebble.
s(f irst(now)) = s(last(f irst(now))) is true when the second counter has zero value.
Using the same technique of allocating different counter updates to different time intervals we can simulate any finite number of positive integer value counters.
Now let us show how to translate a rule of a deterministic multi-counter automaton with a single state if Ph then update of c 1 ,update of c 2 , .
.
., update of c n into the sequence of rules for the HDM.
First translate (non-)zero checking conditions Ph componentwise.
The result we denote by Ph  , that is a conjunction of equalities of terms.
Then we translate the set of counters updates into a sequence of suitable pebble moves move 1 , .
.
.
, moven for each counter.
In order to overcome one structural restriction that is only one movement of a pebble can be done at a time we define set of n formulas Ph  (now), Ph (last(now)), .
.
.
, Ph (last(.
.
.
last(now) .
.
.)).
Here Ph (t(now)) denotes a result of replacement of all occurrences of now in Ph  with the term t(now).
Thus a rule is translated into a set of formulae: Ph (now) - move1 Ph (last(now)) - move2 ... Ph (last(.
.
.
last(now) .
.
.))
- moven   implementing a sequence of counters updates.
It is easy to see that the modelling is done in real time, that is every step of n-counter machine is modelled by exactly n steps of HDM.
Taking into account Proposition 1 and the above constructions the following holds: 6  as M0 , M1 , .
.
.
, Mn .
.
.
.
Predicates and constants are assumed to be flexible, meaning their interpretations depend on moments of time.
In contrast, variables are considered as rigid, that is assignments do not depend on time in which variables are evaluated.
The truth-relation M n |=a ph (or simply n |= a ph, if M is understood ) in the structure M for the assignment a is defined inductively in the usual way using standard semantics of temporal operators g(next),   (sometime in the future), (always in the future), (last),  (sometimes in the past),  (always in the past).
The only specific case is that of abstraction:  t : (move(s(last(now)))) glx.
( ly.
(x = y)fi(a))fi(a)  (move(s(last(f irst(last(now))))))t : glv.
 lx.(f irstt (x) [?]
vfi(a))fi(a)fi(a)   lz.z  =  (s(now) = s(f irst(now)))t : lx.f irstt (x)fi(a) (s(last(now)) = s(f irst(last(now))))t :  lx.f irstt (x)fi(a) Given a rule R of the form [?]
i phi - move(.
.
.
), define its translation Rt as a LT L1l= formula ([?
]i phti - t (move(.
.
.))
).
Now, given a program P = {R 1 , .
.
.
, Rk } of an HDM define its translation P t = {R1t , .
.
.
, Rkt } Straightforward, but tedious checking shows that we get a faithful translation, i.e.
any model of P t is a computation of P and a computation of P is a model of P t .
Further, consider the formula Ps = 3(s(now) = s(f irst(now))) t which says that the specified (first) counter gets the value 0 infinitely often.
The set of multi-counter automata with such a property is not recursively enumerable.
It follows that a set of valid formulae of the form P t - Ps is not r.e.
which, in turn, implies the statement of the theorem.
2    n |=a lx.phfi(t) iff n |=a ph, where a coincides with a on all variables except x and a  (x) equals to the interpretation of t at the moment n. Despite being very restricted fragment of the first-order temporal logic the logic LT L l= can express many nontrivial properties of its models.
Because of the interpretation given to flexible constants they can be though of as the pebbles moving over elements of the domain as the time goes by.
Thus, LT L l= can be used to specify dynamic properties of pebble systems and, in particular, history dependent machines [8].
We have shown in [7] that LT L l= is not recursively axiomatizable:  5.1 Executable semantics of LT L 1l=  Theorem 2 [7] The set of valid formulas of LT L l= is not recursively enumerable.
The above modelling suggests that one can reverse argument and assign an executable semantics to a subset of LT L1l= according to the principle " declarative past implies imperative future" [1].
Here we assume that the language of LT L1l= contains no predicates except equality.
 Consider a formula Ph of the form P - glx.
( ph)fi(a)), where P and ph are formulae without future time operators.
Let M0 , M1 , .
.
.
, Mn be an initial fragment of a first-order temporal model.
Then one-step execution of Ph does the following: if Mn |= P then the initial fragment of the temporal model is extended with the structure M n+1 such  that Mn |= glx.
( ph)fi(a)).
Notice that this extension amounts to choosing (in general, non-deterministically) an interpretation of a at the moment n+1.
It is straightforward to extend the executable semantics to the arbitrary conjunc-closed formulae of the above form.
Then we tions of get computational universality of the very restricted fragment of executable first-order temporal logic.
In fact, very restricted fragment of LT L l= has been used to model faithfully the universal model of computation, that is two counter Minsky machine.
So, we have proved the above theorem for LT L l= in the vocabulary consisting of three flexible constants and no predicate symbols, except equality and 0-ary predicate symbols (propositional letters ).
We denote such a fragment by LT L 3l= .
Here we show that one can model faithfully the computations of HDMs in LT Ll= with just one flexible constant.
Theorem 3 LT L1l= is not recursively axiomatizable.
Proof: We demonstrate how any history-dependent machine M used in the modelling multiple-counter automata can be translated into a formula Ph M of LT L1l= whose models are precisely computations of M .
First, we introduce the formula f irst t (x) of LT L1l= capturing the semantics of f irst construct:  ly.
(x = y)fi(a) f irstt (x) : ly.
(x = y)fi(a) [?]
6 Related work In [4] a constraint linear temporal logic Contraint LTL with the freeze quantifier is studied.
As it has turned out, this logic and our LT L l= are syntactical variants of each other.
The recursive non-axiomatizability of Constraint  Further, define translations: t (move(new)) : glx.
( ly.
(x = y)fi(a))fi(a)  7  References  LTL with the freeze quantifier and one flexible variable ([?]
flexible constant in our terms) is proven in [4] also using a modelling of (2-)counter machine computations.
The modelling in [4], unlike ours, is not a real time: one needs unbounded numbers of time slices to model one step of a 2counter machine.
The topic of history depended computations has appeared also in the research on temporal and active databases.
Both checking temporal integrity conditions [2] and maintaining triggers [12] involve computations referring to the (finite) history of a database.
To show that potential satisfiability of integrity contraints is undecidable, authors of [2] demonstrate how to encode Turing machine computations in a fragment of first-order temporal logic.
On the one hand that fragment is more powerful that our LT Ll= because it uses standard quantifiers.
On the other hand in the encoding from [2], unlike in our modelling, only referring to the immediate past is needed.
One can see it as the indication of trade-off between power of history querying primitives and non-temporal primitives nedeed to get Turing complete computational models.
Maintaining temporal triggers in active databases involve computations which check some conditions on the database history and fire the triggers.
In [12] temporal logic languages for specifying temporal triggers are proposed.
The only quantifier allowed in these languages is the assignment operator, whose semantics is the same as of freeze quantifier or, indeed, of l-abstraction operator.
The expressive and computational power of the languages from [12] depends on underlying database query languages and assumed built-in domains.
We notice that our HDM model can be specified in a small fragment of a trigger specification language from [12] modified to allow both past and future time modalities.
[1] H. Barringer, M.Fisher, D. Gabbay, R.Owens, M.Reynolds (eds.
), The Imperative Future: Principles of Executable Temporal Logic, Research Studies Press Ltd, 1996.
[2] Jan Chomicki, Damian Niwinski, On the Feasibility Checking Temporal Integrity Constraints, Journal of Computer and System Sciences, 51(3), pp 523-535, 1995.
[3] H. Comon and Y.Jurski, Multiple counters automata, safety analysis and Presburger arithmetic, Research Report LSV-98-1, Mar.1998, Laboratoire Specification at Verification.
[4] Stephane Demri, Ranco Lazic, David Nowak, On freeze quantifier in Constraint LTL: decidablity and complexity, 12th International Symposium on Temporal Representation and Reasoning, TIME'05, 113- 121, IEEE Computer Society, 2005.
[5] M. Fitting, Modal Logic Between Propositional and First Order, Journal of Logic and Computation, 12, 1017-1026, 2002.
[6] Dov M.Gabbay, Mark A. Reynolds, Marcelo Finger, Temporal Logic.
Mathematical Foundations and Computational Aspects, Volume 2, Oxford Science Publications, Clarendon Press, 2000.
[7] Alexei Lisitsa and Igor Potapov, Temporal logic with predicate abstraction, CoRR cs.LO/0410072, http://xxx.lanl.gov/archive/cs/, 14pp, 2004.
[8] Alexei Lisitsa and Igor Potapov.
Temporal logic with predicate lambda-abstraction, 12th International Symposium on Temporal Representation and Reasoning, TIME'05, 147-155, IEEE Computer Society, 2005.
7 Concluding remarks  [9] John McCarthy.
Elephant 2000.
Technical report, Stanford Formal Reasoning Group, 1996.
Available only as http://wwwformal.stanford.edu/jmc/elephant.html.
We have introduced a simple abstract computation model of history-dependent machines and have shown that the model is computationally universal.
It is shown by modelling muliticounter machine computations in real time.This reveals the computational power of querying the history as a programming primitive.
We have pointed out two relevant lines of research.
One is related to the development of Elephant (and the like) programming language(s), another to the investigation of a temporal logic as a programming language itself (METATEM approach).
Making a link with the second line we have outlined how to assign an executable semantics to a very restricted subset of the first-order temporal logic to get an universal model of computation.
More work on clarification of relationships with these two lines is required.
[10] M. Minsky, Recursive unsolvability of Post's problem of "tag" and other topics in theory of Turing machines, Annals of Mathematics, 74, pp 437-455, 1961.
[11] M. Minsky, Computation: Finite and Infinite Machines, Prentice-Hall International, 1967.
[12] A. Sistla, O. Wolfson, Temporal Triggers in Active Databases, !emphIEEE Transactions on Knowledge and Data Engineering, 7 (3), pp 471-486, 1995.
8