Knowledge-Based Temporal Interpolation Yuval Shahar Section on Medical Informatics, Knowledge Systems Laboratory Medical School Office Building (MSOB) x215 Stanford University, Stanford, CA 94305 USA  Abstract  weeks of grade-I1 bone-marrow toxicity in the context of therapy for potential complications of a bonemarrow transplantation event" (Figure 1).
Solving the TA task involves the solution of several subtasks (see Section 2).
One of these tasks is the temporal-interpolation task: bridging gaps between point- or interval-based temporal predicates of a similar-type that are temporally disjoint, to create longer intervals (see Figure 1).
Temporal interpolation requires, among other knowledge types, some measure of temporal persistence of temporal predicates (denoting either raw data or abstract concepts).
For instance, if we measured hemoglobin levels on Tuesday and on Friday, both being abstracted as LOW, was the patient's hemoglobin level on Thursday also LOW?"
In fact, the very notion of an episode implies some form of bounded persistence of concepts over time, preventing the clumping together of similar, but distinct instances of the same concept.
The concept of persistence was addressed previously; we discuss the relationship of such work to ours in Section 6.
In this paper, we present the knowledge-based temporalinterpolation model and computational module.
Temporal interpolation is the task of bridging gaps between time-oriented concepts in a context-sensitive manner.
It is a subtask important for solving the temporal-abstraction task-abstraction of intervalbased, higher-level concepts from time-stamped data.
We present a knowledge-based approach to the temporal-interpolation task and discuss in detail the precise knowledge required by that approach, its theoretical foundations, and the implications of the approach.
The temporal-interpolation computational mechanism we discuss relies, among other knowledge types, on a temporal-persistence model.
The temporalpersistence model employs local temporal-persistence functions that are temporally bidirectional (i.e., extend a belief measure in a predicate both into the future and into the past) and global, maximal-gap temporalpersistence functions that bridge gaps between intervalbased predicates.
We investigate the quantitative and qualitative properties implied by both types of persistence functions.
We have implemented our approach and evaluated it in several different domains.
We discuss its implications for acquisition, maintenance, reuse, and sharing of temporal-abstraction knowledge.
2.
Knowledge-based temporal abstraction The framework we employ for solving the TA task is the knowledge-based temporal-abstraction (KBTA) method [ 11.
The KBTA method is a general problemsolving method [ 2 ] for interpreting data in timeoriented domains, with clear semantics for both the m e t h o d and its domain-specific knowledge requirements.
The KBTA method comprises a knowledge-level representation of the TA task and of the knowledge required to solve that task.
The KBTA method has a formal model of input and output entities, their relations, and properties associated with these entities-the KBTA ontology.
The KBTA method decomposes the TA task into five parallel subtasks: ( 1) temporal-context restriction: creation of relevant contexts for interpretation of data (e.g., effect of a drug), crucial for focusing and limiting the scope of the inference  1.
Temporal-abstractionand temporal interpolation Time-stamped data often need to be abstracted in a context-sensitive manner into more abstract, intervalbased concepts, meaningful for a specific domain of application and a particular task.
We term this interpretation task the temporal-abstraction (TA) task.
For instance, most clinical tasks require measurement and capture of numerous patient data.
An automated, knowledge-based decision-support tool that assists physicians should provide short, informative, context-sensitive summaries, at various desirable levels of abstraction, of time-oriented clinical data stored on electronic media.
Data abstraction assists both physicians and automated decision-support systems.
A meaningful summary characterizes significant features over periods of time, such as "2  0-8186-7937-9/97 $10.000 1997 IEEE  102  PAZ protocol  BMT  I  0  50  -I  Exnected CGVHD  1  100  400  200  Time (days) Figure 1: Typical inputs to and outputs of the temporal-abstraction task in a clinical domain.
The figure presents examples of abstractions of platelet and granulocyte values during administration of the PAZ clinical protocol for treating patients who have chronic graft-versus-host disease (CGVHD).
The time line starts with a bone-marrow transplantation (BMT) event.
k 4 = event; * = platelet counts; A = granulocyte counts; = open context interval; H= closed abstraction interval; M[n] = myelotoxicity (bone-marrow-toxicity) grade n.  h  (2) vertical temporal inference: inference from values of contemporaneous input data or abstractions (e.g., results of several blood tests conducted during the same day) into values of higher-level concepts (e.g., classification into bone-marrow toxicity Grade 11) (3) horizontal temporal inference: inference from similar-type propositions that hold over different time intervals (e.g., joining different-value abstractions of the same parameter that hold over two meeting time intervals and computing the value of the new abstraction) 4) temporal interpolation: bridging of gaps between similar-type but temporally disjoint point- or interval-based propositions to create longer intervals (e.g., joining two disjoint episodes of anemia, occurring during different days, into a longer episode) (5) temporal-pattern matching: creation of intervals by matching patterns over disjoint intervals over which hold propositions of various types.
The five subtasks of the KBTA method are solved by five temporal-abstraction mechanisms (nondecomposable computational modules), which depend on four domain-specific knowledge types: structural, classification (functional), temporalsemantic (logical), and t e m p o r a l - d y n a m i c (probabilistic) knowledge.
Values for the four knowledge types are specified as the domain's temporal-abstraction ontology., The KBTA method has been implemented in the RESUME system and evaluated encouragingly in several medical and engineering domains [3,4].
In this paper, we analyze one of the key TA subtasks: context-specific temporal interpolation.
First, we define briefly the KBTA ontology, and then discuss the temporal-interpolation mechanism which uses that ontology and analyze its theoretical foundations and the implications of the approach for acquisition and maintenance of temporal-dynamic knowledge.
3.
The knowledge-based temporalabstraction ontology The KBTA temporal model includes both time intervals and time points.
Timepoints are the basic temporal primitives, but propositions can be interpreted only over time intervals.
Therefore, all propositions are fluents [5] and in our model must be interpreted over a particular time period.
The KBTA ontology contains the following entities: 1.
Time stamps, z i E T, comprise the basic primitives of time.
A time-standardization function, fs(q ), can map a time stamp into an integer amount of any pre-defined temporal granularity unit G, E r (e.g., hour).
Time stamps are measured in Gi units with respect to a zeropoint time stamp.
A finite positive or negative amount of Gi units is a time measure.
2.
A time interval is an ordered pair of time stamps that denote the endpoints, [Istart, Z.end], of the interval.
A zero length interval in which Z.start = Z.end is a time point.
103  3.
4.
5.
6.
7.
8.
9.
An interpretation context 5 E E is a proposition representing a relevant state of affairs (e.g., "the drug insulin exerts its effect during this interval"), within which certain parameters may be interpreted differently.
Two relations, IS-A and SUBCONTEXT, are defined over the set of interpretation contexts.
Basic interpretation contexts are atomic propositions.
Composite interpretation contexts are created by the temporal intersection of a basic or a composite interpretation context and one of its subcontexts, and enable a definition of increasingly specific interpretation contexts.
A context interval is a structure <{, I> (i.e., interpretation context 5 holds during I>.
An event proposition or event e E E is the occurrence of an external willful act or process, such as the administration of a drug.
Events are instantiated event schemata; an event schema has a series aiof event attributes (e.g., drug dose) that must be mapped to attribute values vi.
A PART-OF (or subevent) relation is defined over event schemata.
An event interval is a structure <e, I> represents the occurrence of event e during I.
A parameter schema or parameter n E n is a measurable or describable state of the world.
Parameters may represent raw input data (e.g., hemoglobin level) or abstractions from the raw data (e.g., state of hemoglobin).
Parameter schemata have various properties, such as a domain V, of possible symbolic or numeric values and measurement units.
An extended parameter is a combination <7c, <>of a parameter TC and an interpretation context 6.
An extended parameter can have a value v E V n, which is typically known only at runtime (i.e., parameter values require a context).
A parameter proposition is the combination of a parameter, a parameter value, and an interpretation context, <n, v, {> (e.g., "the state of hemoglobin is LOW in the context of chemotherapy").
Parameter propositions can have special properties, such as temporal persistence.
A parameter interval <n,v, 4, I> represents the fact that the value v of parameter TC in a specific context 5 holds during interval I.
An abstraction function e E 0 is a unary or multiple-argument function that takes one or more parameters as input and returns an abstract parameter.
The abstract parameter may be one of three abstraction types: state, gradient, and rate.
An additional abstraction type is pattern which defines a temporal pattern of several other parameters.
An abstraction of a parameter (e.g., state(n)) is a Darameter (e.g.. both the  hemoglobin value and the state of hemoglobin value are different parameters).
10.
An abstraction is a parameter interval <n,v, 5.
I> where rcis an abstract parameter.
11.
An abstraction goal y E Y is a proposition that indicates an intention relevant to the TA task (e.g., the intention to control a diabetes patient's blood-glucose values).
12.
An abstraction-goal interval is a structure <y, h,where vis an abstraction goal that is posted during the interval I .
13.
Interpretation contexts are induced or inferred dynamically from event, parameter, or abstraction-goal propositions.
The time intervals over which the inducing propositions hold impose temporal constraints on the interval in which the inferred context will be valid (e.g., the interpretation context of the effect of an AZT therapy event might begin 2 days following its start and end 2 weeks after its termination).
The TA ontology of a domain describes all potentially relevant (for the TA task) events, parameters, contexts, abstraction-goals, and relations (e.g., induction of contexts).
The TA task is thus the following: Given a set of event, parameter, and goal intervals and the domain's TA ontology, produce an interpretation-a set of new abstractions that can answer any temporal query about all the abstractions derivable from the transitive closure of the input data and the domain's TA ontology.
(A temporal query is a set of temporal and value constraints over the components of a set of parameter and context intervals.)
4.
The temporal-interpolationmechanism The temporal-interpolation subtask can be solved by temporal-interpolation a k n o w 1e d g e - b a s e d mechanism.
The temporal-interpolation mechanism accepts as input two parameter points, two parameter intervals, or a parameter interval and a parameter point, and returns as output an abstraction, interpreted over a superinterval of the input's time points or intervals, interpolating over the gap between these time intervals.
Primary interpolationaccepts two parameter points and returns an abstraction interval.
Secondary interpolation accepts two parameter intervals (or a parameter interval and a parameter point), and returns an abstraction (super)interval.
Both interpolation types are relevant to primitive parameters and to all abstraction types (e.g., gradient)).
Thus, secondary gradient interpolation infers, from two gradientabstraction intervals of parameter n, a gradientabstraction superinterval of TC whose value, unless otherwise specified, is one of the six default values we have predefined [Shahar et al., 19921: S A M E ,  104  tuples of the form (n,V I ,v2, v3, 5), meaning that, for parameter n (assuming that 7c includes its abstraction type), when an abstraction interval with parameter value V I meets an abstraction interval with parameter value v 2 , in the context 5, the value of the parameter of the joined abstraction interval should be ~ 3 That .
is, V I 0 v 2 = v 3 .
The 0 operator is the horizontal-join (qualitative sum) operator.
In a horizontal-inference table, it is assumed that concatenated abstractions are of the same abstraction type (e.g., state).
In the specific (but quite common and important) case of secondary gradient interpolation, we have defined a rather intuitive qualitative algebra over the six values (e.g., SAME 0 SAME = SAME; INCREASING 0 SAME = NONDECREA S I N G ; NONDECREASING 0 DECREASING = NONMONOTONIC) that can easily be shown to be closed (i.e., the result is always within the six values) and associative (i.e., the order of performing join operations does not affect the final result) [5].
In the case of other abstraction types, such as state, both the values of the abstractions and the result of the join operation are specific to the domain (e.g., HIGH 0 MODERATE = ABOVE-AVERAGE)) and might not be closed, but still need to be associative.
In the case of joining different values, both the temporalsemantic knowledge (inferential property) and the temporal-dynamic knowledge (A function) that are used for the interpolation are those specific to the output value v3.
Secondary state, gradient, and rate interpolation require additional conditions to preserve consistency, apart from an upper bound on the temporal gap between intervals.
An interpolation-inference table defines the interpolation operation for every relevant parameter (e.g., hemoglobin-state) and value combination (e.g., INCREASING and SAME).
An interpolation-inference table represents horizontalclassification knowledge, persistence knowledge, and the special temporal conditions that should hold between the temporal elements of the involved abstractions for successful interpolation.
For example, we need to check that, when we use secondary temporal interpolation to join two INCREASING abstractions for a that are true over two intervals I 1 , 1 2 , into a INCREASING abstraction for over a superinterval l j , the value of n has indeed increased, or at least has not decreased below a certain predefined threshold during the time gap [Zl.end, Z2.startI (see Figure 1).
In other words, we have to check that Il.end.
n <12.
start.
ni-C,, where C, represents a measurement variation for n i t h e maximal decrement in parameter n,below which a change in n will not be considered as a decrease.
C , can be interpreted as a measurement error of n, or as a natural random variation of 7~ over time, or as a significant change of n,for a particular task, depending on the context.
In  INCREASING, DECREASING, NONDECREASING, NONINCREASING, and NONMONOTONIC.
Temporal interpolation requires that the temporal distance between the two time points or intervals of the parameter propositions be less than a certain time gap.
Within that time gap, a certain value of the parameter is then be assumed to hold.
The maximal allowed gap is a domain-, task-, and context-dependent function (e.g., the maximal allowed gap for LOW hemoglobin in the domain of oncology, the task of caring for patients using protocols, and the interpretation context of patients receiving X-ray therapy).
The arguments of the maximal-gap function also include a measure of the rate of change of the parameter before and after the time gap; as an approximation, we use the length of the intervals before and after the gap.
A maximal-gap function A is a function A (x,v, L(I1), L&), of a parameter x (assuming that n includes its abstraction type) and lengths L(Z1), L ( Z 2 ) of the intervals 11 and 12, to be joined in the context 5 into an interval with a n abstraction value v. The A function returns the length of the maximal temporal gap that still allows interpolation between 11 and I 2 .
For instance, in any context, joining two intervals where the hemoglobinstate abstraction was classified as LOW into a longer interval whose hemoglobin-state abstraction is classified as LOW depends on the time gap separating the two intervals, on the particular context, and on the length of time in which the LOW property was known both before and after the time gap.
Primary interpolation is the initial constructor of abstraction intervals, since it joins two separate time points T I and T 2 into a new interval [TI,T 2 ] , over which v is true for  e)  r. Thus, a necessary requirement for primary interpolation is that L([T1, T23) < A(x, V, 0, 0, where L(I) is the length of I.
A prerequisite to an interpolation operation is that the value v of the parameter a is has the value TRUE for the concatenable inferential property [Shoham, 19871 in the context 5 (i.e., the parameter propositions involved can indeed be joined).
This prerequisite involves temporal-semantic knowledge.
We summarize the temporal-semantic knowledge for a domain in an inference-properties table, a relation in which every tuple (n,v, 4, U, 5> represents the knowledge that the temporal-semantic property 4 E Q, for value v, of parameter n, in the context 5, has the truth value U (UE {TRUE,FALSE}) (nis assumed here to include its abstraction type).
Similarly, deciding what is the value of the resulting abstraction when joining two abstraction intervals with different values, V I and v 2 , of the same parameter n requires using horizontal classification knowledge.
A horizontal-inference table is a relation that includes  4,  105  general, C, is a function of n, fc(n), that is defined either by the domain expert or through analysis of the distribution of K In principle, f,.
(n) might also use a context argument 5 and the initial value of n,Z1.end.n (e.g., what is considered as a significant variation in the value of the hemoglobin-value parameter might have a different value within the interpretation context BONEMARROW DEPRESSION, and furthermore, when the last hemoglobin value known is abstracted as VERY  measured, there is no particular reason to assume that a parameter proposition was not true before time t o .
Thus, t might actually have a negative value.
We need this extension if we are to include an approximation of the past value of a parameter, for purposes of interpretation, as opposed to forecasting a future value of the parameter.
Thus, our model includes both forward decay and backward decay in belief.
The function describing this decay is equivalent to a statistical survival function.
In practice, the important question for performing an interpolation using a local persistence function is how long t can be before the belief in the parameter proposition v, E P (i.e., its probability) drops below a certain context-specific threshold (Pth (Figure 2).
LOW).
Primary temporal interpolation for the INCREASING gradient abstraction, requires that T2.n - T1.n 2 C,.
Primary temporal interpolation for the DECREASING gradient abstraction requires that T1.n - T2.n 2 C ., Primary temporal interpolation for the SAME gradient abstraction requires that lT2.n - T1.d I C,.
Using the C, property, we can ignore minor absolute changes in the value of n that are less than a certain threshold when we wish to identify general qualitative trends.
5.2.
Global persistence functions Global (A) maximal-gap functions bridge the gap between two propositions.
A functions are an extension of p functions, and, in special cases, as we show in this section, they can be constructed from the latter functions.
The A function returns the maximal time gap that still allows us to join the propositions into an abstraction that is believed to be true, with a sufficient, task-specific, predefined degree of belief in the proposition, during the gap (and thus over a superinterval of the input propositions, given that both were true for some time before and after the gap).
Thus, the A functions are a global extension of the local (p) persistence functions, since they assume both forward and backward decay of the propositions involved.
Figure 2 presents a graphic view of the A function as an interpretation of a decay in the belief in the truth of a proposition.
For instance, in the case that the abstractions' parameter values are identical-that is, the propositions are the same before and after the gap interval-and the forward and decay times are relatively independent, we are interested in whether, at all points inside the gap interval, either of the values, approximated by the forward belief decay in proposition q, BELfomard(q),or by the backward belief decay, BELbackward(v,),is true with a probability p 2 qth.
As the time gap At between the two abstractions increases, the belief that either the backward- or forward- decay value is true will eventually fall below the predefined threshold value nh (see Figure 2).
If the local (p) persistence function is an exponential-decay survivor function and the backwardand forward-decay rates are independent, we can compute the A function.
Assume that the probability p ( t ) of the parameter proposition cp being true is e-ht, a function of the time t since the reference time in which P was true, regardless of the length of the time interval Zduring which cp was true.
5.
Local and global persistence functions The maximal-gap A functions, which allow interpolation between point and interval primitive and abstract parameters, can be interpreted as creating a default abstraction during the maximal-gap interval.
Like all conclusions inferred by the temporalabstraction mechanisms, the inference that creates such default abstractions is nonmonotonic and can be overridden by additional data or by other inferences.
The maximal-gap functions represent domain- and task-dependent knowledge regarding the rate of change of a parameter proposition <n,V, 0 over time, or the persistence of the truth of that proposition over a temporal gap.
In general, however, we distinguish two types of persistence functions: Local (p) persistence functions and global (A) functions.
For the purpose of the following discussion, we assume that the context 5 and the value of n, unless mentioned explicitly, are known.
5.1.
Local persistence functions Local (p ) persistence functions represent the local persistence of the truth of a parameter proposition, given a single parameter point or interval: p(n, L(Z), t), where L(Z) is the length of the interval Z during which the parameter proposition is known to hold, and tis the time since an endpoint of I .
The p function returns a degree of belief-a probability distribution-in the proposition <n,v> being true at time to + t, given that <n,v, was true at endpoint b.
The p function extends a proposition temporally in both directions: to the future and to the p a s t .
Assuming that time to is a random (first) time in which the proposition was  106  -  01  I  I  4  11  02 12  I  1 -.
(Ah *  0  b  Time Figure 2: Local and global persistence functions.
The maximal time gap A t returned by a global A function is used to decide whether the parameter propositions ql and R, attached to intervals I, and /*, can be joined (possibly, if they do not denote the same value of the relevant parameter, into a new proposition rp3 = ql 63 v)2) .
The time gap At can be interpreted-in the case that ql R, and that the truth values of the propositions are relatively independent-as the maximal time gap in which the belief produced by either the local forward or backward decay (represented by a local persistence p function) stays above the predefined confidence threshold flh.
Bel(cp) = degree of belief in 9;flh = the task- and context-specific belief threshold value.
We can generalize this analysis.
Assume that the longer q is known to be true in the past or in future, the longer we are likely to keep believing it or to believe that it already existed in the past, before we measured it (this assumption will be discussed in Section 5.3).
One (not necessarily the only) way to represent that assumption would be to modify the decay rate A by assuming that it is inversely proportional to the length of the relevant intervals, L(Zi), which we denote simply as 4.
Let BEL ( p )= e[-WLiIt, j = 1,2.
Let the forward decay rate be A1 and the backward decay rate be 4.
Then, we need to know the maximal gap At such that, in the point of minimal belief, p ( t ) is at or above the threshold fib.
Note that the minimum point of BELforward(q) or BELbackward(q) is when the values of the forward- and backward-decay functions are equal (see Figure 2).
Thus, at the minimal p(t), BELforward(q) = BELbackward(q), that is,  ,-alt = e-Az(Ar-r  ),  So, if p(t) is minimal, and as before,  so, when p ( t ) is minimal,  BELforward(q) = BELbackward(q)*  t = [a24a1+a2)] At;  then  ,[-AI/L~I~= ,[-h.LLz](Ar-r  but p ( t ) 2 q t h implies, after substituting for t in BELforward(qh that  );  that is, when p ( t ) is minimal,  e - [ ( A i * W ( A i + ~ 2 ) l A ~2 cpth = e-K,  t = [(Lli22)/(AlL2+4Ll)lAt.
and thus  Substitute for t in BELfo,,d(q),  [(a, +a2)4a1*a2)] K, K = -invth.
At I In other words, the A function for two parameter points, A(z, 0, 0), or for two parameter intervals when the duration of the intervals has no effect on the persistence of the propositions, is a constant determined by the forward- and backward-decay rates and the desired level of confidence.
and assume that  P(t) 2 (Pth:  At I [ ( A ~ ~ ~ ~ + ~ ~ L ~ L K~=) -In%.
~ A ~ A ~ L ~ ] K ,  For instance, if A1 =A2 then  =A  and L(Z1) = L(Z2) = L,  At S [( aL2+aL2)/A2L]K; that is,  107  At I [2LlA]K, K = -In%.
In other words, if exponential decay rates decrease (equally) linearly forward and backward as a function of the duration of the proposition, then the maximal time gap allowing us to join equal-length abstractions would be proportional to a linear function of the length of either interval, with the rest of the factors kept constant.
The duration of the gap would be inversely proportional to the uniform decay rate.
These simplified examples serve to show that even though the decay rates A, are in general unknown, and the decay function is perhaps difficult to compute, the resulting global A function (using a belief threshold) might be a simple constant or polynomial, and thus can be more easily described, computed, or acquired, than the underlying local-persistence function.
Furthermore, if there is evidence for a particular type of decay function (e.g., logarithmic), we can compute the latter's coefficients by acquiring from the domain expert a few maximal-gap values-that is, several examples of At.
We might even check the expert's consistency (or the adequacy of the decay @nction) by repeating the calculation for several other examples.
Alternatively, we can simply acquire a table of typical At values for various common L(Z1) and L(Z2) values, and can interpolate between these values, or extrapolate from them, when necessary.
Due to the dependence between the forward decay of a parameter proposition attached to one time point and the backward decay of that proposition at a later time point, and, therefore, an implied joint distribution of the forward and backward belief values, we usually need the actual global (A) function, in addition to (or instead of) the local (p) persistence function.
(In the example above, we in fact computed a lower bound for the A function.)
In practice, the domain expert often knows several A function values (such as what is the maximal time gap allowed in order to join two parameter points for several parameter values in each context), even if she cannot define any particular, precise, local-decay function p (except, possibly, for specifying the forward and backward local decay times At corresponding to reaching the local threshold value q&).
Knowing only the global A function still enables interpolation between two point-based or intervalbased parameter propositions.
In view of the preceding discussion, in many domains, knowing only the values needed to maintain Bel(q) above the threshold value q7,th-that is, the (simpler) A function-would be a common state of affairs.
5.3.
A typology of persistence functions Global (A) persistence functions can have four qualitative types, depending on whether the A function is either (1) positive monotonic or (2) negative  monotonic, with respect to (a) the length of the first parameter interval L(Z,) or (b) the length of the second parameter interval L(Z,) (see Figure 2).
For example, the maximal allowed gap might be the same or longer, the longer the interval before the gap; the global persistence function would then be positive monotonic relative to the length of that interval.
Theoretically, there are positive-positive (PE'), positive-negative (PN), negative-positive (NP), and negative-negative (NN) monotonic A functions.
We refer to these categories as qualitative persistence types.
Formally, PP A functions are functions such that  L(Z') > L(Z) => V i [A(Z', 9 2 A(Z, i) A A(i, Z') 2 A(i, 41.
NN A functions are functions such that  L(Z')> L(Z) => Vi [A(Z',i) I A(Z, i) A A(i, Z') 5 A(i, Z)], where L(Z) is the length of interval Z and A(Z, i) stands for A(L(4, L(i)).
In the case of local (p) persistence functions, whether representing backward or forward local persistence, we can categorize functions qualitatively into positive (P) and negative (N) categories with similar meaning (i.e., whether the longer I, the longer or shorter the relevant validity interval, before or after  4.
Most A functions, in practice, seem to be of the PP type, In other words, the longer we know that a parameter proposition was true either before or after a time gap, the longer we would allow that gap to be while maintaining our belief that the parameter proposition stayed true throughout that gap (i.e., its probability was always above a certain threshold).
(For instance, the proposition denoting the MODERATEANEMIA value of the hemoglobin-state parameter usually would be associated with a PP A function, as would be the proposition denoting the DEEP-COMA value of the consciousness parameter).
Negative-monotonic A functions occur when a longer duration of either I , or of Z2 lowers the probability that the abstraction was true during the gap, and the longer the lengths, the shorter the allowed At.
For instance, knowing about a longer Z, interval of an almost-fatal cardiac arrhythmia (say, ventricular fibrillation) actually lowers the probability that the (following) gap interval had the same characterization, given the same Z2 interval and assuming that the patient is alive.
Most of the negative-monotonic functions emerge from a total-length constraint on the time allowed for the abstraction (or an analogous probabilistic distribution on the expected total time), or from a total cardinality constraint on the number of events allowed.
We often can limit ourselves, as a first approximation, to the common PP A functions.
Note  108  that the exponential-decay local (p) functions that were given as an example in Section 5.2 for decay functions dependent on the length of either of the two intervals implied, with the independence assumption, a PP-type A function.
However, there is also an important computational advantage in adhering to PP A functions.
lemma 1: PP A functions are associative.
(The order of joining intervals and points cannot change the resulting set of abstractions.)
Proof Assume a situation where parameter points T I , T2, and T3 exist in that temporal order.
If we can form both the parameter interval [ T I ,T 2 ] and the parameter interval [Tz,T3 1 , then, if we can eventually form the interval [ T I ,T3 1, we can do so by forming initially either subinterval, since the A function is PP.
That is, if we can join one point to another point, we can certainly join that point-forwards or backwards, as necessary-to an interval starting or ending, respectively, with the other point.
For instance, if we join points T1 and 7'2, we could certainly also join pointT1 to the interval [T2,T3], since  The dynamic knowledge about the domain does not necessarily need to include complete, closed, definitions of A functions-partial tables may suffice, or the actual ' functions might be approximated.
But knowing whether a maximal-gap function is positive (PP) or negative (NN) is important for estimating the value of that function from a few examples or for interpolating that value from several discrete entries in a table.
This qualitative-persistence type is easy to acquire, since domain experts usually have an excellent intuition about whether, qualitatively, a longer duration of a parameter proposition before or after a gap increases or decreases the probability of the proposition being true during a longer gap, even if the probabilities involved are in fact unknown.
6.
Related work  L([Ti, T21) I A(0,O)=> L ( [ T i ,Tzl) I N O , L([T2,T31)), since the A function is PP, and therefore A(0,O) I L([T2, T31)).
A similar argument holds for any four consecutive points.
Thus, the claim is true for any sequence of primary or secondary interpolations, since A functions are applied only when there are no intervening points between the two intervals or points to be joined.
Ci The associativity property is important for datadriven systems, in which the order of the parameter intervals the system reasons with might be arbitrary.
This property is necessary also to guarantee that the final abstractions do not depend on the order of arrival of the input data.
lemma 2: NN A functions are not associative.
Proof It is easy to construct a case for consecutive parameter points T I ,T2, and T3, where, if we create the interval [ T I ,T2], we no longer can join it to T3, and if we create the interval [T2, T 3 ] ,the A function value will prevent our joining it to T I (e.g., a total-sum constraint does not allow creating the interval [ T I ,T3 ] with high enough probability).
c11 NP and PN functions cannot be associative for similar reasons.
Whether such functions can even exist is doubtful, and we leave it as an open research question.
It would seem that appropriate semantic restrictions on the nature of A functions might preclude the existence of PN and NP functions.
In the case of p (local) persistence functions, we can categorize functions into P and N categories with similar meaning (i.e., whether the longer I , the longer or shorter the validity interval before or after I>.
Several temporal logics include some form of a persistence axiom for facts, that states that a proposition stays true until known to be otherwise.
The p local-persistence function can be viewed as an extension of McDermott's persistence assumption [8,9] and of McCarthy's inertia principle [ l o ] .
Both, however, include infinite persistence as a default.
McDermott [SI suggested that a fact does not cease to be true unless we explicitly hear that it no longer is true.
Since this assumption is not always realistic, McDermott introduced the idea of a typical lifetime of a fact.
Thus, an event causes persistence of a fact.
Our p function belief threshold creates a value- and contextspecific validity time for a parameter proposition, but p functions extend temporally in both directions.
Tawfik and Neufeld [ l l ] have computed the relevance of time-stamped knowledge in a temporal Bayesian framework, modeling relevance as a Markov process and looking only at a single predicate and a forward projection.
Their analysis can be viewed as providing bounds on relevance due to a local persistence function, with certain independence assumptions.
Dean and Kanazawa [ 1 2 ] proposed a model of probabilistic temporal reasoning about propositions that decay over time.
They modeled explicitly the probability of a proposition P being true at time t, P(<P, t > ) , given the probability of <p, t-A>.
The assumption is that there are events of type Ep that can cause proposition p to be true, and events of type ETP that can cause it to be false.
Thus, one can define a survivorfunction for P(<P, D) given <p, t - b , such as an exponential decay function.
Our p function model is somewhat similar.
However, Dean and Kanazawa's main intention was not to solve an interpretation task (such as the TA task) but to solve a projection task, in particular in the context of the planning task.
Thus, unlike in our model, persistence is only considered forwards in time.
In a later work, Kanazawa [ 1 3 ]  109  presented a logic of time and probability, Lep.
Propositions asserted in Lcp were stored in a time network, which maintained probabilistic dependencies among various facts, such as the time of arrival of a person at a place, or the range of time over which it is true that the person stayed in one place, and was used to answer queries about probabilities of facts and events over time.
Two other somewhat similar approaches are de Zegher-Geets' time-oriented probabilistic functions (TOPFs) in the I D E F I X system [14] for summarization of medical records, and Blum's [ 151 time-dependent database access functions and proxy variables to handle missing data in the context of the Rx project for automated discovery in clinical databases.
The goals of these systems were also closer in nature to the TA task-that is, interpretation of time-stamped data.
When de Zegher-Geets' TOPFs represent the probability of a state or disease given a previous identical state, they simulate a forward p function; in addition, states in IDEFIX can have an expected length attribute.
Russ [I61 has analyzed the computational cost of limited temporal persistence, and has shown the improvements enabled by data abstraction.
Since the KBTA method operates at multiple levels of abstraction, it often capitalizes automatically on such improvements.
7.
Discussion and conclusions The knowledge requirements for the temporalinterpolation mechanism include (1) structural knowledge: the qualitative-dependency aspect of the ABSTRACTED-INTO relation; domain time units; ( 2 ) classification knowledge: classification of domainspecific gradient and, in particular, rate abstraction values (e.g., SLOW, FAST) as changes per time unit; horizontal-classification knowledge, that is, the horizontal-inference table; (3) temporal-dynamic knowledge: maximal-gap (A) functions and local (p) persistence functions, both specific to each parameter proposition (which includes an explicit context); significant change values C, or functions fc(z)for the relevant parameters in various contexts; additional temporal constraints for completing the interpolationinference table; and (4) temporal-semantic knowledge: truth values for the concatenable property [Shoham, 19871 for input and inferred parameters.
Temporal-dynamic knowledge about a domain does not necessarily need to include complete definitions of A functions-partial functions may suffice, and knowing whether a maximal-gap function is PP or NN might complete the picture.
The qualitative type of a persistence function is easy to acquire from domain experts.
Furthermore, one of the insights underlying our model is that higher-level abstractions are more  persistent.
Since temporal interpolation operates simultaneously at all abstraction levels, the more stable abstract conclusions often mask faster changes (and uncertainties) in lower-level abstractions and raw data.
The bidirectional temporal persistence model we present is relevant when data is abstracted and interpreted retrospectively, as is the goal of the TA task.
Furthermore, both p and A functions are context sensitive and are thus represented explicitly.
Finally, as shown in Sections 5.2, the use of global (A) persistence functions facilitates acquisition of temporal-dy namic,knowledge.
The RESUME system, implementing the KBTA method, was evaluated in several domains, such as various areas of clinical-medicine [3] and traffic control [4] with highly encouraging results.
The RESUME system is also a component of the current EON project, a component-based architecture for guideline-based clinical therapy [ 171, in which it perfoms the TA task as part of a temporal-abstraction server.
The results of employing &SUME in various domains emphasized not only the validity of the methodology, but the advantages of explicit representation of temporal-abstraction knowledge for acquiring, maintaining, and reusing that knowledge.
In the case of the traffic-control domain, the results have also indicated the usefulness of the KBTA method (inclding the interpolation model) for both temporal abstraction and linear spatial abstraction within the same application, using essentially a 1 : 1 correspondence between linear time and linear space (each highway was considered as a timeline, and spatial abstractions such as "1500 meters of severe conjestion in zone 1 at time 0" were formed.
The (static) output was abstracted over time to produce temporal abstractions such as "increasing congestion in zone one over time interval [0, Smin]).
The current knowledge-based temporalinterpolation model has three major limitations.
From the soundness aspect, the threshold cutoff assumed by the model is convenient in practice, but might potentially lead to unsound conclusions (from the domain's point of view) of higher-level abstractions that use the result of the interpolation (which is assumed to hold with certainty once its probability is higher than a domain-specific threshold).
Thus, a confidence value should still be attached to the conclusion.
From the completeness point of view, the model cannot conclude values of the parameter during the gap in the specific case when the values before and after the gap are different and also are not part of a horizontal-join relation.
Finally, from the knowledge acquisition point of view, even when using the results of the analysis in Section 5.2, considerable amounts of knowledge might still need to be acquired from human experts.
(Currently, we are using a graphic knowledgeacquisition tool that uses three-dimensional tables to  110  represent A functions [18] and that is generated automatically by the P R O ~ G E - I 1 set of tools [19].
To address these limitations, w e are planning to (1) construct a Bayesian-semantics framework f o r t h e  10.
J. McCarthy, Applications of circumscription to formalizing commonsense knowledge, Artificial Intelligence 28(1) (1986) 89-116.
11.
A. Y. Tawfik and E. M. Neufeld, Irrelevance in uncertain temporal reasoning, Proceedings ofthe Third International Workshop on Temporal Representation and Reasoning (TIME '96) (Key West, Florida, 1996)  interpolation operation, (2) attempt to learn local and global interpolation functions from large temporal databases (given some domain knowledge, such as the abstraction hierarchy and classification functions, and the temporal-semantic properties of relevant parameters), and (3) to test the automatically acquired functions using methodologies that have been shown to b e valuable in similar cases [20].
196-202.
12.
T. Dean and K. Kanazawa, Probabilistic temporal reasoning, in: Proceedings of the Eight National Conference on Artificial Intelligence , Minneapolis, MN (1986) 524-528.
13.
K. Kanazawa, A logic and time nets for probabilistic inference, Proceedings, Ninth National Conference on Artificial Intelligence, Los Angeles, CA (MIT Press, Cambridge, MA, 1991) 360-365.
14.
I.M.
De Zegher-Geets, A.G. Freeman, M.G.
Walker, R.L.
Blum, and Wiederhold, G., Summarization and display of on-line medical records.
M.D.
Computing 5 (1988) 38-46.
15.
R.L.
Blum, Discovery and representation of causal relationships from a large time-oriented clinical database: The RX project, in D.A.
Lindberg and P.L.
Reichartz, eds., Lecture Notes in Medical Informatics, vol.
19 (Springer-Verlag, New York, 1982).
16.
T.A.
Russ, Use of data abstraction methods to simplify monitoring, Artijicial Intelligence in Medicine 7 (6) (1995) 497-514.
17.
M.A.
Musen, S.W.
Tu, A.K.
Das, and Y. Shahar, EON: A component-based approach to automation of protocol-directed therapy.
Journal of the American Medical Association 3 (6) (1996) 367-388.
18.
A. Stein, M.A.
Musen, and Y. Shahar, Knowledge acquisition for temporal abstraction.
Proceedings of the 1996 AMIA Annual Fall Symposium (formerly the Symposium on Computer Applications in Medical Care), Washington, DC (Hanley & Belfus, Philadelphia, 1996) 204-208.
19.
S.W.
Tu, H.Eriksson, J. Gennari, Y. Shahar, and M.A.
Musen, Ontology-based configuration of problemsolving methods and generation of knowledgeacquisition tools: Application of PROTEGE-I1 to protocol-based decision support.
Artijicial Intelligence in Medicine 7 (3) (1995) 257-289.
20.
K.M.
Albridge, J. Standish, and J.F.
Fries, Hierarchical time-oriented approaches to missing data inference, Computers and Biomedical Research 21 (1984), 349366.
Acknowledgments This work has been supported by grants LM05708 and LM06245 from the National Library of Medicine and IRI-9528444from the National Science Foundation.
Computing resources were provided by the CAMIS project, funded under grant No.
LM05305 from the National Library of Medicine.
References 1.
Y. Shahar, A framework for knowledge-based temporal abstraction, Artificial Intelligence 90 (1997) (in press).
2.
H. Eriksson, Y. Shahar, S.W.
Tu, A.R.
Puerta, and M.A.
Musen, Task modeling with reusable problem-solving methods, Artijicial Intelligence 79 (2) (1995) 293--326.
3.
Y. Shahar and M.A.
Musen, Knowledge-based temporal abstraction in clinical domains, Artificial Intelligence in Medicine 8(3) (1996) 267-298.
4.
Y. Shahar and M. Molina, Knowledge-based spatiotemporal abstraction, in Proceedings of the AAAI-96 Workshop on Spatial and Temporal reasoning (Portland, Oregon, 1996) 21-30.
5.
J. McCarthy and P. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: Machine Intelligence (University Press, Edinburgh, UK, 1969).
6.
Y. Shahar, S.W.
Tu, and M.A.
Musen, Knowledge acquisition for temporal-abstraction mechanisms.
Knowledge Acquisition 4, (1992) 217-236.
7.
Y. Shoham, Temporal logics in AI: Semantical and ontological considerations, Artificial Intelligence 33( 1) (1987) 89-104.
8.
D.V.
McDermott, A temporal logic for reasoning about processes and plans, Cognitive Science 6(2) (1982) 101155.
9.
T. Dean and D.V.
McDermott, Temporal database management, Artificial Intelligence 32 (1987) 1-55.
111