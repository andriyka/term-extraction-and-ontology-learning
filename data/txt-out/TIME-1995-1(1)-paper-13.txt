Time and Uncertainty in Reasoning about Order Robert A. Morris and Dan Tamir Florida Institute of Technology Melbourne, FL 32901 email:morris@cs.
t.edu  Abstract  The ability to intelligently order events is important for planning and scheduling in the presence of uncertainty about the expected duration of those events.
This paper presents a time-based theory of an agent in a dynamic environment, and a framework for reasoning for the purpose of generating eective orderings of events.
1 Setting the Stage In this study, the interest is in the role of time in the ability of intelligent agents to plan or schedule events, especially actions, events of which they are the agent.
Researchers in AI have, for a number of years, oered analyses and computational models of the temporal reasoning underlying these abilities.
These models have explained the intuitive complexity of reasoning about time in terms of proving the consistency of a set of temporal constraints, an inherently intractable problem.
This study adds further complexity by folding into the framework a dynamically changing environment, wherein temporal knowledge becomes outdated, as well as being partial and incomplete.
How, we ask, can an agent utilize the information found in such an environment in order to eectively solve planning and scheduling problems?
The impetus for this investigation is a system which provides a solution to the dicult problem of scheduling telescope observations  Kenneth M. Ford  University of West Florida Pensacola FL 32514 email: kford@ai.uwf.edu 1].
This solution required attention be given to the fact that the duration of a repeating event may be dierent on dierent occasions.
This made any generated schedule \fragile", which means that there was a tendency for it to \break" during execution.
The novelty of the approach of the researchers was the integration of statistical information about past occurrences of events in order to predict how well a schedule will stand up against a contrary night sky.
This allowed for sensitive locations in the schedule to be identied, and made it feasible to maintain a library of contingency schedules.
We feel this approach to solving planning and scheduling problems in a changing world can be extended and generalized to other problems with similar, dynamic environments.
One objective of this study is to perform these transformations.
The objectives of this paper consist of Constructing an abstract representation of the intelligent behavior which is manifested in the telescope scheduling example, as well as others Proposing a formal representation of the knowledge required to realize this behavior and Presenting a computational model of learning the requisite knowledge based on statistical evidence inferred from the experience of temporal duration and order.
2 Abstract Representation of Behavior The interest here is in systems embedded in a dynamic environment with feedback in the form of rewards.
It is desirable for the system to learn from these rewards in order to maximize its rewards over the long run.
Traditionally, such a system is modeled in terms of state transition networks, consisting of states, actions and state-transition functions.
Here, an alternative model is presented with an underlying temporal ontology.
Specically, there are events represented by their durations, and a single atomic temporal ordering relation, immediately precedes (<).
Given a set E = fA B C g of events, if an agent prefers a certain ordering of their occurrences, say, A < B < C (\A immediately before B immediately before C ") to another, the reason may have to do with constraints which lead to a preference for that order.
There are many varieties of constraints possibly underlying this preference.
Here the interest is in criteria for orderings that are based on temporal constraints.
One example of such a constraint involves minimizing the overall extent of the performance of all the tasks.
By overall extent is meant the interval of time it takes all the events in E to complete.
On this criterion, an ordering of E which is expected to minimize the overall extent of E will be the most preferred ordering.
Another criterion for ordering will be in terms of minimizing the overall duration uncertainty of the set of tasks.
Intuitively, duration uncertainty is manifested in terms of a relative lack of condence concerning how long an event, or a set of events, will take.
If it is possible to predict that one ordering of the tasks will exhibit less duration uncertainty than another, then choosing the ordering with less uncertainty will be preferred.
This is analogous to taking a \sure bet", even if the payo is less than another choice which  is less likely.
The inability to predict how long an event will last on a given occasion (duration uncertainty) is a pervasive feature of common sense experience.
Things that happen in a given day, e.g., breakfast, driving to work, faculty meetings, going to the dentist, exhibit varying amounts of duration uncertainty.
Duration uncertainty is undesirable to a rational agent because it leads to failure in the completion of plans and schedules, and the need for time-consuming repair and revision.
To satisfy one or the other of these constraints, an agent can choose to order the occurrences of the events in such a way that events in close temporal proximity share one or more stages.
Informally, a stage of an action or event E is an action or event which occurs as part of the occurrence of E .
For example, \preparing the cleaning utensils" can be viewed as a stage in most or all cleaning actions.
Often, an event can be \sliced" in dierent ways to uncover its stages.
Suppose two cleaning room actions, clean kitchen (K ) and clean bath (B ) are performed together, say K < B .
There will be a tendency for the preparation stage of B to not be required (or be simplied) hence the overall duration of performing both should be reduced.
Furthermore, since the duration uncertainty of the whole will be a function of the duration uncertainty of the dierent stages, there's a chance that duration uncertainty can also be reduced as a result of this pairing.
This situation is illustrated in Figure 1.
In this gure, stage S1 of K is shared with B .
The temporal eect of sharing stages is that the events can be viewed as overlapping in time.
Notice that when speaking of such relations, there is no assumption of convexity (no interruption) with respect to the intervals making up the durations of the events.
It follows that an agent should be able to more accurately predict how long the bathroom cleaning will take when preceded by the  K B  S1 S1  Figure 1: Eect of Pairing Similar Events in Close Temporal Proximity kitchen cleaning action than it could predict its duration in isolation, or when preceded by a event sharing no stages with it.
The point of the examples, then, is that events that share stages will tend to be mutually inuencing with respect to duration, especially when paired in close temporal proximity.
This sort of information would be useful for an agent who is either lacking the requisite knowledge about the events for which it needs to nd an intelligent ordering, or in which the environment is constantly changing, making its knowledge outdated.
Consider, for example, a robot assigned the task of delivering mail in a dynamically changing environment.
Oces may move, for example, or construction to dierent parts of the complex may require dynamically revising the routes, and hence possibly the order, in which mail is delivered.
Similarly, it may be equipped with only a crude or outdated map of its environment.
We proceed to formalize a model of an agent in a dynamically changing environment.
The model is based on the familiar idea of using a network to store temporal information.
Here, the nodes, or variables represent events in terms of their durations, and the arcs store values which represent the eect of orderings of events on the durations of events that follow them in close temporal proximity.
Denition 1 (Duration Network )A Duration Network N is a set of variables V = V1 : : : Vn , and a set of labeled edges E =  '$ &% '$ &% -2  '$ &% '$ &% V =6  2 ( ( ( ( ( V1 = 4 ((( 0 ;; C C QQ CC QQ ;; CC 0 Q -1 C ; C ;; QQQ 0 CC CC ; QQ C Q  V3 = 5  -1  V4 = 2  Figure 2: Instantiated Duration Network  instantiation of  fhVi  Vj i : 8Vi Vj 2 V g. An N is a function I : V fi E !
Z , such that, all Vi  Vj 2 V , Eij 2 E :  for  I (Vi) > 0 I (Eij )  0 and Let Eij = hVi  Vj i.
Then jI (Eij )j < I (Vi) and jI (Eij )j < I (Vj ).
A duration network is a complete network in which the variables stand for events, and their values are durations of these events.
The labels on the arcs represent the eect of sharing stages on durations.
A negative value for I (hVi  Vj i) represents the advantage of performing Vi and Vj together by virtue of their sharing a stage the negative value is the \reward" for doing them in close temporal proximity.
Figure 2 depicts an instantiated duration graph.
To illustrate the meaning of the graph, consider the nodes V1 and V2 .
The order V1 < V2 < V3 would yield a \reward" of 2 time units.
This means that the overall duration of performing this sequence would be 4 ; 2 + 6 + 0 + 5 = 13 time units.
Compared with performing V1 < V3 < V2, which has overall duration 4 ; 1 + 5 + 0 + 6 = 14 time units, the rst ordering would have the smaller overall extent.
It is useful to distinguish what we will call legs of a tour of a duration network N .
Intuitively, if a tour is a complete path through the network, a leg of the tour is any subpath of that path.
More formally, we use the notion of sub-sequence of a sequence (using the notation t v t) to characterize tour legs.
If t = hVt1  Vt2  : : : Vtn i is a tour through N , then, for example, hVt3  Vt4  Vt5 i is a leg.
To relate a leg to its tour, we use t=hVti  : : :Vti +mi to mean \the part of t consisting of the indicated leg".
Denition 2 (Process/Tour of a Duration Network)A k-process of a duration network N = (V E ) is a sequence P = hI1 I2 : : :  Iki of instantiations of N .
A tour t of a duration network N with variables V = fV1 : : : Vn g is a permutation of V .
We write t = hVt1  : : :  Vtn i to enumerate the elements of t. Denition 3 (Cost of a Tour/Tour Series)Given an Instantiation I and tour t = hVt1  : : :  Vtn i, the cost of a tour in I (c(t I )) is c(t I ) = I (Vt1 )+I (hVt1  Vt2 i)+: : :+I (hVtn;1  Vtn i)+I (Vtn ) Given a k-process P = hI1 : : :Ik i and a sequence of corresponding tours T = ht1 : : :  tk i, called a tour series, the cost of the series T in process P (C (T P )) is X C (T P ) = c(ti Ii) 0  1ik  More generally, we can introduce the notion of \cost of a leg L = hVti  : : :Vti+m i of a tour t in I " as follows: ( 6v t c(t=L I ) = c(L I0) :: Lotherwise Finally, we can speak of the cost of a leg in a tour series T and a process P :  C (T=hVti  : : :Vti+m i P )  as the sum of the costs of this leg in all the tours in the series containing this leg.
The interest now is to dene a set of oneperson games involving tours of the duration graph.
The specic goal of interest is to nd a tour series Tmest of length k which is an agent's estimate of the minimal tour series Tmin .
The latter is the tour series which, given a duration network N and k-process P , incurs the minimum cost over all possible tour series.
Other goals are of course possible.
One is to minimize the standard deviation from the mean of tour durations in the series.
Another goal is to complete as many of the events (i.e., visit as many of the variables) as possible, given rigorous time constraints (i.e.
cost).
Other versions of the game dier on assumptions concerning either the agent's initial knowledge of N , its abilities to update the knowledge based on experience in the form of tours it has made, or on the properties of P .
The interest is in nding denitions of P which characterize properties and relations of the abstract world which are homomorphic to those properties and relations which occur in real world planning and scheduling domains.
First, let us say that an instantiation I is totally repeating in P = hI1 I2 : : : Imi if 9i ji 6= j I = Ii = Ij 2 P .
We can rene this to \repeats n times" in an obvious way.
Two total repetitions of I , say Im and Ip are n units apart if km ; pk = n. If n = 1, then the repetitions will be said to be consecutive.
I will be said to be p-periodic in P if any pair of occurrences of I in P repeat r units apart, where r is a factor of p. Similarly, I is almost periodic in P if there exists a p such that any pair of occurrences of I in P occur a distance apart which is \close" to being a factor of p. We assume this notion of being almost periodic is intuitive enough to remain qualitative, although obviously it can be made more precise.
Finally, we can dene a notion of a partially repeating instantiation  in P , and derivative notions, in terms of instantiations that share some of their values.
Secondly, a process will be said to be invariant if the values of the dierent instantiations do not dier a great deal.
We distinguish two kinds of invariance, duration and path invariance.
First, consider total duration invariance.
We can draw an even ner distinction between weak and strong total duration invariance.
We can express strong invariance in terms of mean, or average duration, and standard deviation.
Thus, let the mean duration of an event represented by Vi in a process P be the average duration of Vi over all instantiations in P .
Let VPi be a variable denoting the standard deviation from the mean.
We say that a process P is -invariant if for each Vi , the value of VPi is less than .
Finally, we say that a process P is totally invariant if there exists a  which is close to 0 such that P is -invariant.
Path invariance means that there is never a large dierence in the cost among dierent paths through N throughout a process P .
More precisely, let c(t1 I ) and c(t2 I ) be the costs of any two of the n!
tours through a duration network N with n variables, given I .
Then path invariance implies that the the dierence between these values is not greater than some small value .
Strong invariance is a global property of a process: intuitively, it says that the duration of any variable or edge of a duration network never strays excessively from the mean.
This does not allow a \real good" path ever to become \real bad", although it may become less good.
Weak invariance is a strictly local phenomenon: it constrains every pair Ii Ii+1 of consecutive instantiations in P to be \close in their assignments" to all elements of N .
(This notion can be made precise in an obvious manner.)
Thus, weak invariance allows for a good path to become bad over the long run.
We can generalize any of these notion of invariance to (partial) invariance, in which a  subset of I exhibits invariance.
Again, for our purposes, it is enough to leave this intuitive notion qualitative.
We view the world as exhibiting varying degrees of invariance and periodicity.
An intelligent agent can learn and apply knowledge about invariance and periodicity in order to make plans which are intelligent.
This is the case although the knowledge the agent has is incomplete, and partial, and the world is in constant ux.
In the next section, we consider this capability in the context of constructing the tour series Tmest.
3 Computational Theory As noted, the ability of an agent to eectively solve the class of problems abstractly characterized as a traversal of a duration network depends on The goal of the game The properties of P  and Assumptions about the agent's knowledge of N and P .
For example, if the agent is given the requisite knowledge to determine P , then it does not matter whether P exhibits any invariance or periodicity: the agent will be able to \precompute" an optimal Tmest based on an exhaustive search of each instantiation.
The case to be examined here is the one in which the knowledge the agent has of P is, at best, partial.
In this section, we describe a version of the game in which 1.
The agent has, initially, an \abstract map" of N  2.
The agent has no quantitative knowledge about P  3.
P exhibits total strong duration and path invariance.
4.
The goal of the game is for the agent to construct Tmest .
We next present a computational theory which explains and realizes this behavior.
To solve for a goal, given the initial constraints, the agent needs to have a means to learn and apply knowledge it discovers about P to select a tour tj , given t1 : : : tj 1, as part of a series.
To make use of the rewards aorded by certain paths, we introduce the notion of relative mean duration: Denition 4 (Relative Duration) Let N = (V E ) be a duration network, T = ht1 : : :tk i be a tour series and P = hI1 : : : Ik i be a process.
The relative duration of an event Vi with respect to an event Vj in an instantiation In and corresponding tour tn (rd(hVi  Vj i tn In)) is c(tn=hVi  Vj i In) + c(tn=hVj  Vii In ).
Furthermore, the relative mean duration of an event Vi with respect to an event Vj over a set of k occurrences of Vi and Vj (rmdViVj (I T ))is ;  C (T=hVi Vj i I ) + C (T=hVj  Vii I ) k Let rmdViVj (I T ) denote the standard deviation of rmdViVj (I T ).
If I and T are given, the notation for these values is simplied to rmdViVj and rmdVi Vj .
Intuitively, relative duration is the cost of the leg Vi < Vj or Vj < Vi in a tour, given an instantiation of the variables and the edge connecting them.
Since the relation of \sharing a stage" is symmetrical, these costs are assumed to be identical e.g., any reward for pairing cleaning actions K and B in immediate temporal proximity will be collected, whether the order be K < B or B < K .
Relative mean duration, then, consists of the average relative duration of pairs of events over a set of tours in a series.
Assuming P exhibits total duration and path invariance, an agent can incrementally  '$ &% '$ &%  '$ &% '$ &%  8 (((( V2 ((( ( V1 11 ;; CC QQ CC QQ ;; CC 8 Q ; 8 CC CC ; QQQ 6  CC ;; V3  6  QQ C Q  V4  Figure 3: A Possible -Graph Associated with Figure 2  learn the requisite knowledge for constructing Tmest on the basis of computing and storing relative mean durations.
This information will be stored in what will be called a -network: Denition 5 Given a duration network N and a process P , a -network for N = (V E ) is a weighted undirected network with the following characteristics.
Each vertex is labeled by one of the elements in a set V .
Each edge (Vi  Vj ) is labeled.
The value of the label represents rmdViVj .
Figure 3 is an example of a -network corresponding to the duration network in the previous gure.
The labels on each edge represent values for rmdViVj .
These values would be accurate, for example, at the end of a kprocess P consisting of k repetitions of the instantiation depicted in the previous gure.
With the information in the -network, an agent can determine the next best tour in Tmest .
Let us assume that the process P exhibits strong duration and path invariance, but incorporates no assumptions about periodicity.
The method TS for constructing Tmin is summarized in Figure 4.
For the sake of simplicity, there is an assumption of a \learn-  UpdateMean(var :  ; graph t : tour I :  instantiation k : index)  Algorithm TS Input:  A process P = hI1 : : :  Iki A Duration Network N = (V E ), V = fV1  V2  : : :  Vn g, initialized by an instantiation Iinit A -network = (V  E ), where V = V and E = E .
For each edge Eij in , let v(Eij ) represent the value of the label on that edge.
Initially, this value is 0.
Output: The updated -network , which now contains statistical information about P based on its having executed a tour series Tmest = htmest1  : : :tmestk i and C (Tmest I ).
For each edge Eij in do v(Eij )   rd(hVi  Vj i Iinit) k   1 Tmest   hi  loop  tk   HamiltonPath( ) UpdateMean(  tk  Ik k) Tmest   Tmest + htk i /* hui + hvi = hu vi */ k  k+1 until k = p Return and C (Tmest P ) Figure 4: Algorithm for Constructing a Tour Series which Minimizes Overall Extent  begin For each edge Eij = hVi  Vj i in do rmdViVj   c(tk =hVi  Vj i I ) + c(tk =hVj  Vii I ) if rmdViVj > 0 then v(Eij )   (k 1)v(Eijk)]+rmdViVj end ;  Figure 5: Updating Algorithm for -graph ing phase" in which the agent is supplied values for one instantiation Iinit of N .
This can be viewed as, e.g., a robot being supplied a \map" of the world it needs to navigate repeatedly.
The main loop iteratively generates tk , the next tour in the series, from by performing a Hamilton Tour of this network, and updates based on information it has acquired about Ik as the result of its tour tk .
The Hamilton tour gives the best estimate of the tour with the lowest overall extent.
The \nal score" of the game is the overall cost of the tour series Tmest.
The UpdateMean Algorithm records the cost of tk as the result of Ik , by updating the -network accordingly.
The procedure is summarized in Figure 5.
This procedure simply updates the mean relative duration rmdViVj for each edge in , based on the result of the cost of traversing this edge in Ik by tour tk (if this tour contains this leg if not, then this cost is 0 and no updates are made).
This algorithm, we claim, realizes behavior which, under the constraints posed by this version of the game, is useful in the generation of intelligent orderings of a set of events.
As a variation on the game, suppose the agent is interested, not in reducing overall extent, but rather in reducing the duration uncertainty associated with a set of events.
This would be the case, e.g., if the agent has no constraints on the time of the completion  of a set of tasks, but wanted to be reasonably sure, at each moment in every tour, on which leg of the tour it is located.
A minor modication of the game in the preceding section will allow the agent to estimate a tour series Tdu, which approximates the tour series which is minimal with respect to duration uncertainty.
Again, let rmdViVj be the standard deviation of the relative mean duration of a set of occurrences of events Vi and Vj in immediate temporal succession.
Imagine modifying the -network so that the labels on each edge Eij stores values of rmdViVj .
We can replace UpdateMean with a procedure, call it UpdateSD, for updating standard deviations, based again on the result of the most recent tour.
Then, applying TS with UpdateSD computes Tdu , which estimates the tour series with the minimal duration uncertainty.
Numerous other enhancements to the representation are possible.
For example, incorporating duration uncertainty as a constraint would lead to a variation of the one-person game in which the agent's goal is to minimize the duration uncertainty associated with a tour.
Another enhancement to the game involves incorporating assumptions regarding periodicity to I would make such information useful to store in a -network.
Relative durations would be further relativized to time periods, which are represented by the index k on the instantiation Ik .
Relative mean durations, and their standard deviations, would be required to reect this relativization.
For this information, it is possible that a quantitative model for probabilistic temporal reasoning such as found in 2], could be applied alternatively, a qualitative model of recurrence, such as 3], might serve the same purpose.
4 Conclusion This paper has provided a framework for developing planning and scheduling systems in a dynamic world.
One primary assumption  motivating this framework is that events tend to exhibit varying degrees of duration uncertainty, and that an intelligent agent needs to confront this uncertainty in planning situations.
One aid in reducing duration uncertainty exploits the fact that events share stages with other events.
References  1] Drummond, M. Bresina, J. Swanson, K., 1994.
Just-In-Case Scheduling.
In Proceedings of the Twelfth National Conference on Articial Intelligence (AAAI94).
AAAI Press/MIT Press, Menlo Park, 1994:1098-1104.
2] Goodwin, Scott D., Hamilton, H. J., Neufeld, E., Sattar, A., Trudel, A.
Belief Revision in a Discrete Temporal Probability-Logic.
Proceedings of Workshop on Temporal Reasoning, FLAIRS94, 3] Morris, R., Shoa, W., and Al-Khatib, L., (1994) Domain Independent Reasoning About Recurring Events.
Forthcoming in The Journal of Computational Intelligence.