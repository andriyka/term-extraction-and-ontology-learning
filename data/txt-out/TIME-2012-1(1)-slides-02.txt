Reasoning about Plan Revision in Agent Programs Natasha Alechina University of Nottingham, UK  TIME 2012, Leicester 14 September 2012  Natasha Alechina  Reasoning about plan revision  TIME 2012  1 / 46  What this talk is about  verification (of agent programs with changing plans) transition systems correspond to agent program execution model-checking agent programs joint work with Brian Logan, Mehdi Dastani and John-Jules Meyer on a theorem-proving approach (using dynamic logic) main extension: explicit operator for ahaving a plana  Natasha Alechina  Reasoning about plan revision  TIME 2012  2 / 46  Transition systems  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  3 / 46  Dynamic logic ha; bip, hc; dip  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  4 / 46  Having and executing a plan  Plan(a;b) a  b  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  5 / 46  What is an agent?
many definitions of aagenta in the literature a key ideas include: autonomy: an agent operates without the direct intervention of humans or other agents situatedness: an agent interacts with its environment (which may contain other agents) reactivity: an agent responds in a timely fashion to changes in its environment proactivity: an agent exhibits goal-directed behaviour  Natasha Alechina  Reasoning about plan revision  TIME 2012  6 / 46  What I will mean by an agent  a computational system whose behaviour can be usefully characterised in terms of propositional attitudes such as beliefs and goals and which is programmed in an agent programming language which makes explicit use of propositional attitudes  Natasha Alechina  Reasoning about plan revision  TIME 2012  7 / 46  What is an agent programming language?
Belief, Desire and Intentions (BDI) framework, (Bratman 1987) BDI agent programming languages are designed to facilitate the implementation of BDI agents: programming constructs corresponding to beliefs, desires and intentions agent architecture or interpreter enforces relationships between beliefs, desires and intentions and which causes the agent to choose actions to achieve its goals based on its beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  8 / 46  3APL  one of the first agent programming languages PRS (Georgeff and Ingrand 1988), very rich.
I will talk about a more modern and less rich langauge, 3APL 3APL is a BDI agent programming language proposed in (Dastani et al.
2003) I present a cut-down version of 3APL (mostly regarding the language for beliefs, but also distinction between external and internal actions, not considering messages etc.)
Natasha Alechina  Reasoning about plan revision  TIME 2012  9 / 46  3APL beliefs  the beliefs of a 3APL agent represent its information about its environment and itself beliefs are represented by a set of positive literals the initial beliefs of an agent are specified by its program e.g., the agent may initially believe that itas in room1 and its battery is charged: Beliefs: room1, battery  Natasha Alechina  Reasoning about plan revision  TIME 2012  10 / 46  3APL goals  the agentas goals represent situations the agent wants to realise (not necessarily all at once) goals are represented by a set of arbitrary literals the initial goals of an agent are specified by its program e.g., the agent may initially want to achieve a situation in which both room1 and room2 are clean Goals: clean1, clean2  Natasha Alechina  Reasoning about plan revision  TIME 2012  11 / 46  Declarative goals  the beliefs and goals of an agent are related to each other if an agent believes p, then it will not pursue p as a goal if an agent does not believe that p, it will not have a p as a goal  these relationships are enforced by the agent architecture  Natasha Alechina  Reasoning about plan revision  TIME 2012  12 / 46  3APL basic actions  basic actions specify the capabilities of the agent (what it can do independent of any particular agent program) 2 types of basic actions: belief test actions: test whether the agent has a given belief belief update actions: aexternala actions which change the agentas beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  13 / 46  Belief test actions  a belief test action D?
tests whether a boolean belief expression D is entailed by the agentas beliefs, e.g.
: (room2 and -battery)?
tests whether the agent believes it is in room2 and its battery is not charged  Natasha Alechina  Reasoning about plan revision  TIME 2012  14 / 46  Belief update actions  belief update actions change the beliefs (and goals) of the agent a belief update action is specified in terms of its pre- and postconditions (sets of literals), e.g.
: {room1} moveR {  }, {-room1, room2}  an action can be executed if one of its pre-conditions is entailed by the agentas current beliefs executing the action updates the agentas beliefs to make one of the postconditions entailed by the agentas beliefs (actions non-deterministic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  15 / 46  Belief entailment  a belief query (a belief test action or an action precondition) is entailed by the agentas belief base if all positive literals in the query are contained in the agentas belief base, and for every negative literal a p in the query, p is not in the belief base i.e., we use entailment under the closed world assumption  goal entailment corresponds to a formula being classically entailed by one of the goals in the goal base  Natasha Alechina  Reasoning about plan revision  TIME 2012  16 / 46  Belief update  executing a belief update action adds all positive literals in the corresponding postcondition to the belief base, and for every negative literal a p in the postcondition, p is removed from the agentas belief base  goals which are achieved by the postcondition of an action are dropped for simplicity, we assume that the agentas beliefs about its environment are always correct and its actions in the environment are always successful  Natasha Alechina  Reasoning about plan revision  TIME 2012  17 / 46  Abstract plans  unlike basic actions, abstract plans cannot be directly executed by the agent.
abstract plans provide an abstraction mechanism (similar to procedures in imperative programming) which are expanded into basic actions using plan revision rules if the first step of a plan D is an abstract plan IaE, execution of D blocks.
Natasha Alechina  Reasoning about plan revision  TIME 2012  18 / 46  3APL plans  plans are sequences of basic actions and atomic plans composed by plan composition operators: sequence: aD1 ;D2 a (do D1 then D2 ) conditional choice: aif D then {D1 } else {D2 }a conditional iteration: awhile D do {D}a  e.g., the plan: if room1 then {suck} else {moveL; suck} causes the agent to clean room1 if itas currently in room1, otherwise it first moves (left) to room1 and then cleans it  Natasha Alechina  Reasoning about plan revision  TIME 2012  19 / 46  3APL PG rules planning goal rules are used for plan selection based on the agentas current goals and beliefs a planning goal rule Is a I, | D consists of three parts: Is: an (optional) goal query which specifies which goal(s) the plan achieves I,: a belief query which characterises the situation(s) in which it could be a good idea to execute the plan D: a plan  a PG rule can be applied if Is is entailed by the agentas goals and I, is entailed by the agentas beliefs applying the rule adds D to the agentas plans Natasha Alechina  Reasoning about plan revision  TIME 2012  20 / 46  Example 3APL PG rules clean2 <- battery | if room2 then {suck} else {moveR; suck} states that aif the agentas goal is to clean room2 and its battery is charged, then the specified plan may be used to clean the rooma an agent can generate a plan based only on its current beliefs (reactive invocation), e.g., the rule: <- -battery | if room2 then {charge} else {moveR; charge} states aif the battery is low, the specified plan may be used to charge ita  Natasha Alechina  Reasoning about plan revision  TIME 2012  21 / 46  Example 3APL PR rules a plan revision rule pj = Dj a I,j | D 0 j can be applied if Dj is in the plan base, I,j is entailed by the agentas beliefs and Dj is not executable, in other words the first action of Dj is either a belief update or belief test action which is not executable in the current belief state, or an abstract plan for example, if moveR fails, the agent may execute a slow but reliable version of the action, slowR: charge <- room1 | {slowR; charge}  Natasha Alechina  Reasoning about plan revision  TIME 2012  22 / 46  Operational semantics we define the operational semantics of 3APL in terms of a transition system states are agent configurations hD, Il, I i where D, Il are sets of literals representing the agentas beliefs and goals, and I  is a set of plan entries representing the agentas current active plans (annotated by the goals which they were adopted to achieve) each transition corresponds to a single step in the execution of the agent different execution strategies give rise to different semantics for simplicity we focus on non-interleaved executionai.e., the agent executes a single plan to completion before choosing another plan Natasha Alechina  Reasoning about plan revision  TIME 2012  23 / 46  Formal entailment definitions |=cwa (belief entailment for closed world assumption): D |=cwa p iff p a D D |=cwa ap iff p 6a D D |=cwa D and D iff D |=cwa D and D |=cwa D D |=cwa D or D iff D |=cwa D or D |=cwa D D |=cwa {D1 , .
.
.
, Dn } iff a1 a$?
i a$?
n D |=cwa Di |=g (goal entailment): Il |=g p iff p a Il Il |=g ap iff ap a Il Il |=g D or D iff Il |=g D or Il |=g D  Natasha Alechina  Reasoning about plan revision  TIME 2012  24 / 46  Belief update function let a be a belief update action and D a belief base such that D |=cwa precj (a) intuitively, D |=cwa precj (a) if it contains all positive literals in precj (a) and does not contain the negative ones the result of executing belief update action a with respect to D (assuming precj (a) holds and the action results in the postj,i becoming true) is defined as:  Tj,i (a, D) = (D aS {p : p a postj,i (a)}) \ {p : a p a postj,i (a)} intuitively, the result of the update satisfies (entails under |=cwa ) the corresponding postcondition postj,i (a) Natasha Alechina  Reasoning about plan revision  TIME 2012  25 / 46  Transitions: belief test actions  belief test actions D |=cwa I, hD, Il, {I,?
; D .
Is}i aa hD, Il, {D .
Is}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  26 / 46  Transitions: belief update actions  belief update actions when the corresponding goal not achieved yet: D |=cwa preci (Ia) Ti,j (Ia, D) = D 0 Il 0 = Il \ {D | D 0 |=cwa D} D 0 6|=cwa Is hD, Il, {Ia; D .
Is}i aa hD 0 , Il 0 , {D .
Is}i belief update actions when the corresponding goal is achieved: D |=cwa preci (Ia) Ti,j (Ia, D) = D 0 Il 0 = Il \ {D | D 0 |=cwa D} D 0 |=cwa Is hD, Il, {Ia; D .
Is}i aa hD 0 , Il 0 , { }i  Natasha Alechina  Reasoning about plan revision  TIME 2012  27 / 46  Transitions: plans conditional choice D |=cwa D hD, Il, {(if D then D1 else D2 ); D .
Is}i aa hD, Il, {D1 ; D .
Is}i D 6|=cwa D hD, Il, {(if D then D1 else D2 ); D .
Is}i aa hD, Il, {D2 ; D .
Is}i conditional iteration  D |=cwa D hD, Il, {(while D do D1 ); D .
Is}i aa hD, Il, {D1 ; (while D do D1 ); D .
Is D 6|=cwa D hD, Il, {(while D do D1 .
Is); D}i aa hD, Il, {D .
Is}i Natasha Alechina  Reasoning about plan revision  TIME 2012  28 / 46  Transitions: PG rules  planning goal rules Is a I, | D Il |=g Is Dcwa |= I, hD, Il, {}i aa hD, Il, {D .
Is}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  29 / 46  Transitions: PR rules  plan revision rules pj = Dj a I,j | D 0 j ai D 6|=cwa preci (Ia) D |=cwa I,j hD, Il, {Dj = Ia; D .
Is}i aa hD, Il, {D 0 j .
Is}i D 6|=cwa I, D |=cwa I,j hD, Il, {Dj = I,?
; D .
Is}i aa hD, Il, {D 0 j .
Is}i D |=cwa I,j hD, Il, {Dj = IaE; D .
Is}i aa hD, Il, {D 0 j ; D .
Is}i where IaE is the name of an abstract plan.
Natasha Alechina  Reasoning about plan revision  TIME 2012  30 / 46  State of the art  State of the art in model-checking agent programs  Model-checking AgentSpeak (Promela, Spin) Rafael H. Bordini, Michael Fisher, Carmen Pardavila, Michael Wooldridge: Model checking AgentSpeak.
AAMAS 2003:409-416 General platform for model-checking BDI agents (AIL and AJPF) Louise A. Dennis, Michael Fisher, Matthew P. Webster, Rafael H. Bordini: Model checking agent programming languages.
Autom.
Softw.
Eng.
19(1): 5-63 (2012) Work with Goal, 3/2APL,...  Natasha Alechina  Reasoning about plan revision  TIME 2012  31 / 46  State of the art  Challenges In common with general model-checking: scalability issues In common with general (software) model-checking: hard to deal with an infinite number of possible inputs/events, first-order properties I think there is still no system specification language at the right level of abstraction Beliefs, goals, plans, etc.
are treated as just ordinary data structures: same as lists of strings or some other adumba values However, they do have some logical structure (e.g.
closure under the agentas reasoning rules) and connections to each other, which should be used, in a transparent fashion (use something more like Maude?)
The most interesting logical challenge here I think is the logic of having committed to a set of intentions Natasha Alechina  Reasoning about plan revision  TIME 2012  32 / 46  State of the art  What does having a set of intentions mean  If an agentas set of intentions is {a; b; c, d; e; f } then it is easy to figure out what the possible actions by the agent are (a and d); for more general plans it is more complicated, but also well defined no logic with explicit adopted plans (in the logical language), apart from TCS11 (for single agent/single plan) and a paper in informal proceedings of DALT 2009. there are logics with explicit strategies (Simon and Ramanujam 2008,2009), but strategies and plans are not exactly the same and logics have no ahe has adopted this strategya operator  Natasha Alechina  Reasoning about plan revision  TIME 2012  33 / 46  State of the art  Verification by theorem proving  State properties of the system as axioms (completely axiomatise the operational semantics) Prove that the desired property logically follows from them This is a more complex problem than model-checking, but it is easier to deal with first-order, infinite domains, etc.
Natasha Alechina  Reasoning about plan revision  TIME 2012  34 / 46  Logic  Signature of an agent program The signature of an agent program R is defined as R = hP, PG, AZ Act, Plani PR, Ac, Ac, P is a set of belief and goal atoms PG is a set of planning goal rules, ri = Isi a I,i | Di PR is a set of plan revision rules, pj = Dj a I,j | Dj0 Ac is a set of belief update actions occurring in the plans of PG and PR rules AZ is a set of abstract plans occurring in the plans of PG and PR Ac rules Act is the set of specifications for belief update actions Ac Plan is the set of all possible D .
Is pairs where Is is one of the agentas goals and D is a plan occurring in PG and PR rules or a suffix of such a plan  Natasha Alechina  Reasoning about plan revision  TIME 2012  35 / 46  Logic  Language of PDL-3APL  program expressions: AZ | I'r i | I'p | D1 ; D2 | D1 aS D2 | Da D ::= Ia a Ac | t(D) | aE a Ac j formula: D ::= Bp | Gp | G a p | x | P Is D | P |AZD | D1 aSS D2 | hDiD  Natasha Alechina  Reasoning about plan revision  TIME 2012  36 / 46  Logic  Models of PDL-3APL AZ Act, Plani be the signature of an agent Let R = hP, PG, PR, Ac, Ac, program.
A PDL-3APL model M relative to R is defined as M = (W , V , RIa , Rt(D) , RIaE , RI'r i , RI'p j ) where W is a non-empty set of states.
V = (Vb , Vg , Vc , Vp ) such that for every s a W : Vb (s) = {p1 , .
.
.
, pm : pi a P} is the set of the agentas beliefs in s; Vg (s) = {( a )u1 , .
.
.
, ( a )un : ui a P} is the set of the agentas goals in s (note that Vg assigns literals rather than propositional variables); Vc (s) is either an empty set or {x}; Vp (s) is either the empty set or a singleton set {D .
Is}, where D is the agentas plan in s and Is is the goal(s) achieved by this plan  RIa , Rt(D) , RIaE , RI'r i , RI'p i are binary relations on W Natasha Alechina  Reasoning about plan revision  TIME 2012  37 / 46  Logic  Conditions on models  C1 Vg (s) aS Vb (s) = a and {p : a p a Vg (s)} a Vb (s) C2 If Vp (s) = {Ia; D .
Is}, Vb (s) |=cwa preci (Ia) and x 6a Vc (s), then there is an RIa transition to a state s0 where Vb (s0 ) = Ti,j (Ia, Vb (s)), Vg (s0 ) = Vg (s) \ ({p : p a Vb (s0 )} aS { a p : p 6a Vb (s0 )}) and if Vb (s0 ) 6|=cwa Is, Vp (s0 ) = {D .
Is}.
If Vb (s0 ) |=cwa Is, x a Vc (s0 ) and Vp (s0 ) = {}.
C3aC10 similarly correspond to operational semantics in non-x states  Natasha Alechina  Reasoning about plan revision  TIME 2012  38 / 46  Logic  Conditions for exceptional states  Condition for non-executable actions: if Vp (s) = {Ia; D .
Is}, Vb (s) 6|=cwa preci (Ia), and x 6a Vc (s), then there is an RIa transition to a state s0 where x a Vc (s0 ).
Condition for executing in exceptional states: if x a Vc (s) then there are RIa , RIaE and Rt(D) transitions from state s to itself Condition for PR rules: if x a Vc (s), Vp (s) = {Dj .
Is}, Vb (s) |=cwa I,j , then there is a RI'p j transition to a state s0 where Vp (s0 ) = {Dj0 .
Is} and x 6a Vc (s0 ) (where pj = Dj a I,j | Dj0 ).
Natasha Alechina  Reasoning about plan revision  TIME 2012  39 / 46  Logic  Satisfaction  M, s |= Bp iff p a Vb (s) M, s |= Gp iff p a Vg (s) M, s |= G a p iff a p a Vg (s) M, s |= x iff x a Vc (s) M, s |= P Is D iff Vp (s) = {D .
Is} M, s |= P iff Vp (s) = {} M, s |= AZD iff M, s 6|= D M, s |= D1 aSS D2 iff M, s |= D1 and M, s |= D2 M, s |= hDiD iff there exists s0 such that RD (s, s0 ) and M, s0 |= D.  Natasha Alechina  Reasoning about plan revision  TIME 2012  40 / 46  Logic  Translation into PDL  fb : fb (p) = Bp; fb (D and D) = fb (D) aSS fb (D); fb (D or D) = fb (D) a" fb (D) fg (p) = Gp; fg ( a p) = G a p fp : fp (Ia) = Ia fp (D?)
= t(D) fp (IaE) = IaE fp (D1 ; D2 ) = fp (D1 ); fp (D2 ) fp (if D then D1 else D2 ) = t(D); fp (D1 )) aS (t(AZD); fp (D2 )) fp (while D do D) = (t(D); fp (D))a ; t(AZD).
Natasha Alechina  Reasoning about plan revision  TIME 2012  41 / 46  Logic  Axioms A1 Bp a AZGp A2 G a p a Bp 0  A3a P Is D a AZP Is D 0 where D 0 6= D or Is0 6= Is W A3b P a" D.IsaPlan P Is D BA1 AZx aSS P Is (Ia; D) aSS fb (preci (Ia)) aSS D aSS D 0 a hIai( (fb (postij (Ia))aSSAZfb (Is)aSSP Is DaSSD)a"(fb (postij (Ia))aSSfb (Is)aSSx aSSPaSSD 0 )) where D, D 0 are any formulas not containing plan expressions or literals in fb (postij (Ia)), and in addition D 0 does not contain x AZ BA2a AZx aSS P Is D a [u]aL where D 6= u; D 0 and u a Ac aS Ac BA2b AZx aSS P Is D a [t(D)]aL if D does not start with a belief test action D?
or a conditional plan test on D where D = D or D = AZD  Natasha Alechina  Reasoning about plan revision  TIME 2012  42 / 46  Logic  Axioms continued  V V 0 Is (Ia; D) aSS f (prec (Ia)) aSS BA3 AZx aSS P D aSS b j i j j Dj a [Ia]( W Is Wj ( fb (postij (Ia)) aSS AZfb (Is) aSS P D aSS Dj )0 a" j ( fb (postij (Ia)) aSS fb (Is) aSS x aSS P aSS Dj )) where Dj and Dj0 are any formulas not containing plan expressions or literals in fb (postij (Ia)), and in addition Dj0 does not contain x BA4 AZx aSS P Is (D?
; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D aSS Dnp ) V BA5 AZx aSS P Is (Ia; D) aSS i AZfb (preci (Ia)) aSS Dnx a h[Ia]i(x aSS Dnx ) BA6 AZx aSS P Is (D?
; D) aSS AZfb (D) aSS Dnx a h[t(D)]i(x aSS Dnx ) BA7 AZx aSS P Is (IaE; D) aSS Dnx a h[IaE]i(x aSS Dnx ) BA8 x aSS D a h[u]iD where u is Ia, t(D) or IaE  Natasha Alechina  Reasoning about plan revision  TIME 2012  43 / 46  Logic  Axioms continued CP1 AZx aSS P Is (Dif ; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D1 ; D aSS Dnp ), where Dif is of the form if D then D1 else D2 CP2 AZx aSS P Is (Dif ; D) aSS AZfb (D) aSS Dnp a h[t(AZD)]i(P Is D2 ; D aSS Dnp ), where Dif is as in CP1 CP3 AZx aSS P Is (Dwh ; D) aSS fb (D) aSS Dnp a h[t(D)]i(P Is D1 ; Dwh ; D aSS Dnp ), where Dwh is of the form while D do D1 CP4 AZx aSS P Is (Dwh ; D) aSS AZfb (D) aSS Dnp a h[t(AZD)]i(P Is D aSS Dnp ), where Dwh is as in CP3 CP5 AZx aSS (P Is Dif a" P Is Dwh ) aSS AZfb (D) a [t(D)]aL where Dif and Dwh are as above PG1 P aSS fg (Isi ) aSS fb (I,i ) aSS Dnpx a h[I'r i ]i(AZx aSS P Isi Di aSS Dnpx ) PG2 AZP a" AZfg (Isi ) a" AZfb (I,i ) a [I'r i ]aL PR1 x aSS P Is Dj aSS fb (I,j ) aSS Dnpx a h[I'p j ]i(AZx aSS P Is Dj0 aSS Dnpx ) PR2 AZx a" AZP Is Dj a" AZfb (I,j ) a [I'p j ]aL Natasha Alechina  Reasoning about plan revision  TIME 2012  44 / 46  Logic  Translation of the program  tr (R) = (aSi (I'r i ; fp (Di ))  S  aSj (I'p j ; fp (Dj0 )))+  Theorem: tr (R) picks out exactly those paths in a model which correspond to an execution of the program Can verify liveness and safety properties by checking whether htr (R)iD and [tr (R)]D are entailed by the formulas describing initial conditions complications: encoding plan expressions; encoding properties which hold along a path (Fahad Khan 2012, Regular Path Temporal Logic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  45 / 46  Logic  Conclusions  agent programs can be verified just as ordinary programs however they have additional properties which it may be possible to expoit one of the properties is having an explicit set of plans, which seems to be an interesting logical property may be also of interest for game logics (being able to say athis player is going to play this strategya rather than aif this player plays this strategya)  Natasha Alechina  Reasoning about plan revision  TIME 2012  46 / 46